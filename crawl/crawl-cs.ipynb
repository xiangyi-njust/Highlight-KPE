{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 获取待下载论文的网页链接"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 先获取对应期刊论文的网页链接\n",
    "\n",
    "journals = ['INTERNATIONAL JOURNAL OF INFORMATION MANAGEMENT',\n",
    "            'GOVERNMENT INFORMATION QUARTERLY',\n",
    "            'INFORMATION PROCESSING & MANAGEMENT',\n",
    "            'TELEMATICS AND INFORMATICS',\n",
    "            'INFORMATION & MANAGEMENT',\n",
    "            'Journal of Informetrics',\n",
    "            'Information and Organization',\n",
    "            'JOURNAL OF STRATEGIC INFORMATION SYSTEMS',\n",
    "            'JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION',\n",
    "            'TELECOMMUNICATIONS POLICY',\n",
    "            'LIBRARY & INFORMATION SCIENCE RESEARCH']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 测试requests put方法作用\n",
    "import requests\n",
    "import json\n",
    "\n",
    "url = 'https://api.elsevier.com/content/search/sciencedirect'\n",
    "\n",
    "headers = {\n",
    "    \"X-ELS-APIKEY\": '5245a5ea0be97233a73906d8b805c460',\n",
    "    \"X-ELS-Insttoken\": '808e542de03a7a118f187de5081d8521'\n",
    "}\n",
    "\n",
    "data = {\n",
    "    'title':\"\\\"Predicting the evolution of scientific communities by interpretable machine learning approaches\\\"\",\n",
    "    'pub':\"\\\"Journal of Informetrics\\\"\",\n",
    "}\n",
    "\n",
    "response = requests.put(url, data=json.dumps(data), headers=headers)\n",
    "\n",
    "if response.status_code != 200:\n",
    "    print(response.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 单个期刊上的处理\n",
    "\n",
    "和LIS期刊上处理方式一致，但由于计算机学科论文数量较多，因此需要进行过滤\n",
    "\n",
    "    1. 每个期刊先过滤，保留下来1000条左右的数据\n",
    "    2. 获取Pii, 使用采集器采集数据\n",
    "    3. 过滤掉爬取不到highlight的文章，大概每个期刊保留下800条左右数据\n",
    "    4. 再进一步对每个期刊的论文数过滤，尽量和LIS的数据量保持一致"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5031\n",
      "5016\n",
      "5016\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Year</th>\n",
       "      <th>Abstract</th>\n",
       "      <th>Author Keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A self-adaptive soft-recoding strategy for per...</td>\n",
       "      <td>2023</td>\n",
       "      <td>The technique of error-correcting output codes...</td>\n",
       "      <td>Error-correcting output code; Multiclass class...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WSDS-GAN: A weak-strong dual supervised learni...</td>\n",
       "      <td>2023</td>\n",
       "      <td>Underwater Image Enhancement (UIE) is a crucia...</td>\n",
       "      <td>CycleGAN; Deep learning; Two-stage learning; U...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Construction of a feature enhancement network ...</td>\n",
       "      <td>2023</td>\n",
       "      <td>Limited by the size, location, number of sampl...</td>\n",
       "      <td>Collision detection; FENet; Granular computing...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Haar wavelet downsampling: A simple but effect...</td>\n",
       "      <td>2023</td>\n",
       "      <td>Downsampling operations such as max pooling or...</td>\n",
       "      <td>Downsampling; Haar wavelet; Information entrop...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Underwater object classification combining SAS...</td>\n",
       "      <td>2023</td>\n",
       "      <td>Combining synthetic aperture sonar (SAS) image...</td>\n",
       "      <td>Contour-based features; Feature extraction; Fo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  Year  \\\n",
       "0  A self-adaptive soft-recoding strategy for per...  2023   \n",
       "1  WSDS-GAN: A weak-strong dual supervised learni...  2023   \n",
       "2  Construction of a feature enhancement network ...  2023   \n",
       "3  Haar wavelet downsampling: A simple but effect...  2023   \n",
       "4  Underwater object classification combining SAS...  2023   \n",
       "\n",
       "                                            Abstract  \\\n",
       "0  The technique of error-correcting output codes...   \n",
       "1  Underwater Image Enhancement (UIE) is a crucia...   \n",
       "2  Limited by the size, location, number of sampl...   \n",
       "3  Downsampling operations such as max pooling or...   \n",
       "4  Combining synthetic aperture sonar (SAS) image...   \n",
       "\n",
       "                                     Author Keywords  \n",
       "0  Error-correcting output code; Multiclass class...  \n",
       "1  CycleGAN; Deep learning; Two-stage learning; U...  \n",
       "2  Collision detection; FENet; Granular computing...  \n",
       "3  Downsampling; Haar wavelet; Information entrop...  \n",
       "4  Contour-based features; Feature extraction; Fo...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 将下载后的pii复制到原始文件当中\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('../data/Elsevier-CS/PR/PR.csv')\n",
    "\n",
    "# 第一种处理方式 即先爬取到Pii\n",
    "# columns = ['Title', 'Year', 'Abstract', 'Author Keywords','Pii']\n",
    "# 第二种处理方式 先过滤\n",
    "columns = ['Title', 'Year', 'Abstract', 'Author Keywords']\n",
    "df = df[columns]\n",
    "print(len(df))\n",
    "df = df.dropna()\n",
    "print(len(df))\n",
    "df = df[df['Abstract'] != '[No abstract available]']\n",
    "print(len(df))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4634\n",
      "0.9238437001594896\n",
      "4634\n",
      "['A self-adaptive soft-recoding strategy for performance improvement of error-correcting output codes', 'WSDS-GAN: A weak-strong dual supervised learning method for underwater image enhancement', 'Construction of a feature enhancement network for small object detection', 'Haar wavelet downsampling: A simple but effective downsampling module for semantic segmentation', 'Underwater object classification combining SAS and transferred optical-to-SAS Imagery']\n"
     ]
    }
   ],
   "source": [
    "# 保留关键词长度在一定范围内的论文集合\n",
    "keywords = df['Author Keywords'].tolist()\n",
    "keyword_lengths = [len(keyword.split(';')) for keyword in keywords]\n",
    "\n",
    "min = 3\n",
    "max = 6\n",
    "cnt = 0\n",
    "for length in keyword_lengths:\n",
    "    if length >= min and length <=max:\n",
    "        cnt += 1\n",
    "\n",
    "print(cnt)\n",
    "print(cnt/len(keyword_lengths))\n",
    "\n",
    "# 获取对应长度关键词集合的论文标题\n",
    "titles = df['Title'].tolist()\n",
    "sub_titles = []\n",
    "\n",
    "for i, title in enumerate(titles):\n",
    "    if keyword_lengths[i] >= min and keyword_lengths[i] <=max:\n",
    "        sub_titles.append(title)\n",
    "print(len(sub_titles))\n",
    "print(sub_titles[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['Title'].isin(sub_titles)]\n",
    "df.to_excel('../data/Elsevier-CS/PR/PR_filter.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1252\n",
      "1194\n"
     ]
    }
   ],
   "source": [
    "# 保存1200条左右数据 2012~2023 每一年100左右\n",
    "df = pd.read_excel('../data/Elsevier-CS/IF/IF_filter.xlsx')\n",
    "print(len(df))\n",
    "year_counts = df['Year'].value_counts()\n",
    "\n",
    "# reserved_size 设为1000也可以，可以在Pii爬取或者后期过滤的时候再处理\n",
    "reserved_size = 1200\n",
    "reserved_counts = year_counts*(reserved_size/len(df))\n",
    "reserved_counts = reserved_counts.astype(int)\n",
    "\n",
    "reserved_df = pd.DataFrame()\n",
    "\n",
    "for year, count in reserved_counts.items():\n",
    "    year_df = df[df['Year'] == year]\n",
    "    reserved_year_df = year_df.sample(n=count, replace=False)\n",
    "    reserved_df = pd.concat([reserved_df, reserved_year_df], ignore_index=True)\n",
    "\n",
    "print(len(reserved_df))\n",
    "reserved_df.to_excel('../data/Elsevier-CS/IF/IF_filter.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_excel('../data/Elsevier-CS/PR/PR_filter.xlsx')\n",
    "titles = df['Title'].tolist()\n",
    "piis = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1193/1193 [14:49<00:00,  1.34it/s]\n"
     ]
    }
   ],
   "source": [
    "# 补充Pii\n",
    "# 第二种处理方式\n",
    "from tqdm import tqdm\n",
    "\n",
    "offset = len(piis)\n",
    "\n",
    "for title in tqdm(titles[offset:]):\n",
    "    data = {\n",
    "        'title':title,\n",
    "        # 'pub':\"\\\"Journal of Informetrics\\\"\",   \n",
    "    }\n",
    "\n",
    "    response = requests.put(url, data=json.dumps(data), headers=headers)\n",
    "    if response.status_code != 200:\n",
    "        piis.append('error')\n",
    "    elif response.json()['resultsFound'] == 0:\n",
    "        piis.append('not found')\n",
    "    else:\n",
    "        piis.append(response.json()['results'][0]['pii'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1192\n",
      "1064\n"
     ]
    }
   ],
   "source": [
    "prefix_url = 'https://www.sciencedirect.com/science/article/pii/'\n",
    "df['Pii'] = piis\n",
    "df = df[df['Pii'] != 'not found']\n",
    "print(len(df))\n",
    "df = df[df['Pii'] != 'error']\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Pii'] = [prefix_url + pii for pii in df['Pii'].tolist()]\n",
    "df.to_excel('../data/Elsevier-CS/PR/PR_filter.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 利用采集器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1193\n",
      "1193\n",
      "1197\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_crawl = pd.read_excel('../data/Elsevier-CS/IF/IF_highlight.xlsx')\n",
    "df_meta = pd.read_excel('../data/Elsevier-CS/IF/IF_filter.xlsx')\n",
    "\n",
    "piis_crawl = df_crawl['Pii'].tolist()\n",
    "piis_crawl = [pii.replace('abs/', '') for pii in piis_crawl]\n",
    "df_crawl['Pii'] = piis_crawl\n",
    "\n",
    "df = pd.DataFrame()\n",
    "df = pd.merge(df_meta, df_crawl, on='Pii')\n",
    "\n",
    "print(len(df_crawl))\n",
    "print(len(df_meta))\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1035\n",
      "1033\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "df = df.dropna()\n",
    "print(len(df))\n",
    "df = df.drop_duplicates()\n",
    "print(len(df))\n",
    "\n",
    "highlights = df['Highlights'].tolist()\n",
    "empty_nums = 0\n",
    "for text in highlights:\n",
    "    if type(text) == float:\n",
    "        empty_nums += 1\n",
    "\n",
    "print(empty_nums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_highlights = []\n",
    "for highlight in highlights:\n",
    "    new_highlight = highlight.replace('highlights', '')\n",
    "    items = new_highlight.split(\"•\")[1:]\n",
    "    highlight = ';'.join(items)\n",
    "    new_highlights.append(highlight)\n",
    "\n",
    "df['Highlights'] = new_highlights\n",
    "df.to_excel('../data/Elsevier-CS/IF/IF_expe.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "领域数据集合并"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "954\n",
      "1948\n",
      "2950\n",
      "3983\n",
      "3982\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Year</th>\n",
       "      <th>Abstract</th>\n",
       "      <th>Author Keywords</th>\n",
       "      <th>Pii</th>\n",
       "      <th>Highlights</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Factorized multi-Graph matching</td>\n",
       "      <td>2023</td>\n",
       "      <td>In recent years, multi-graph matching has beco...</td>\n",
       "      <td>Factorization; Graph matching; Multi-graph mat...</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "      <td>The equivalence between the two kinds of multi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Invariance encoding in sliced-Wasserstein spac...</td>\n",
       "      <td>2023</td>\n",
       "      <td>Deep convolutional neural networks (CNNs) are ...</td>\n",
       "      <td>Generative model; Invariance learning; Mathema...</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "      <td>We present a mathematical framework to learn i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RA-YOLOX: Re-parameterization align decoupled ...</td>\n",
       "      <td>2023</td>\n",
       "      <td>YOLOX is a state-of-the-art one-stage object d...</td>\n",
       "      <td>Decoupled head; Label assignment; Object detec...</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "      <td>We propose a lightweight RepA decoupled head t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Weakly Supervised Instance Segmentation via Ca...</td>\n",
       "      <td>2023</td>\n",
       "      <td>Deep convolutional neural networks (DCNN) trai...</td>\n",
       "      <td>Centerness; Coarse localization annotation; In...</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "      <td>A novel two-branch DCNN is constructed to perf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Multi-label feature selection via robust flexi...</td>\n",
       "      <td>2023</td>\n",
       "      <td>Multi-label feature selection is an efficient ...</td>\n",
       "      <td>Classification; Feature selection; Multi-label...</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "      <td>A regularization norm named robust flexible sp...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  Year  \\\n",
       "0                    Factorized multi-Graph matching  2023   \n",
       "1  Invariance encoding in sliced-Wasserstein spac...  2023   \n",
       "2  RA-YOLOX: Re-parameterization align decoupled ...  2023   \n",
       "3  Weakly Supervised Instance Segmentation via Ca...  2023   \n",
       "4  Multi-label feature selection via robust flexi...  2023   \n",
       "\n",
       "                                            Abstract  \\\n",
       "0  In recent years, multi-graph matching has beco...   \n",
       "1  Deep convolutional neural networks (CNNs) are ...   \n",
       "2  YOLOX is a state-of-the-art one-stage object d...   \n",
       "3  Deep convolutional neural networks (DCNN) trai...   \n",
       "4  Multi-label feature selection is an efficient ...   \n",
       "\n",
       "                                     Author Keywords  \\\n",
       "0  Factorization; Graph matching; Multi-graph mat...   \n",
       "1  Generative model; Invariance learning; Mathema...   \n",
       "2  Decoupled head; Label assignment; Object detec...   \n",
       "3  Centerness; Coarse localization annotation; In...   \n",
       "4  Classification; Feature selection; Multi-label...   \n",
       "\n",
       "                                                 Pii  \\\n",
       "0  https://www.sciencedirect.com/science/article/...   \n",
       "1  https://www.sciencedirect.com/science/article/...   \n",
       "2  https://www.sciencedirect.com/science/article/...   \n",
       "3  https://www.sciencedirect.com/science/article/...   \n",
       "4  https://www.sciencedirect.com/science/article/...   \n",
       "\n",
       "                                          Highlights  \n",
       "0  The equivalence between the two kinds of multi...  \n",
       "1  We present a mathematical framework to learn i...  \n",
       "2  We propose a lightweight RepA decoupled head t...  \n",
       "3  A novel two-branch DCNN is constructed to perf...  \n",
       "4  A regularization norm named robust flexible sp...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "paths = ['PR/PR_expe.xlsx', 'JSS/JSS_expe.xlsx', 'JPDC/JPDC_expe.xlsx','IF/IF_expe.xlsx']\n",
    "prefix_path = '../data/Elsevier-CS'\n",
    "\n",
    "df = pd.DataFrame()\n",
    "for path in paths:\n",
    "    df = pd.concat([df, pd.read_excel(prefix_path + '/' + path)], ignore_index=True)\n",
    "    print(len(df))\n",
    "\n",
    "df = df.dropna()\n",
    "df = df.drop_duplicates()\n",
    "print(len(df))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3982\n",
      "1.0\n",
      "3982\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    防止有部分文章的关键词数量在6个以上，此处再进行一次过滤\n",
    "    此外，这里也可以对数据量进一步抽样，保持和LIS数据量大体上一致\n",
    "    LIS: 2589   CS: 3000\n",
    "\"\"\"\n",
    "keywords = df['Author Keywords'].tolist()\n",
    "keyword_lengths = [len(keyword.split(';')) for keyword in keywords]\n",
    "\n",
    "min = 3\n",
    "max = 6\n",
    "cnt = 0\n",
    "for length in keyword_lengths:\n",
    "    if length >= min and length <=max:\n",
    "        cnt += 1\n",
    "\n",
    "print(cnt)\n",
    "print(cnt/len(keyword_lengths))\n",
    "\n",
    "# 获取对应长度关键词集合的论文标题\n",
    "titles = df['Title'].tolist()\n",
    "sub_titles = []\n",
    "\n",
    "for i, title in enumerate(titles):\n",
    "    if keyword_lengths[i] >= min and keyword_lengths[i] <=max:\n",
    "        sub_titles.append(title)\n",
    "\n",
    "df = df[df['Title'].isin(sub_titles)]\n",
    "print(len(df))\n",
    "df.to_excel('../data/Elsevier-CS/Texts.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2996\n"
     ]
    }
   ],
   "source": [
    "year_counts = df['Year'].value_counts()\n",
    "\n",
    "# reserved_size 设为1000也可以，可以在Pii爬取或者后期过滤的时候再处理\n",
    "reserved_size = 3000\n",
    "reserved_counts = year_counts*(reserved_size/len(df))\n",
    "reserved_counts = reserved_counts.astype(int)\n",
    "\n",
    "reserved_df = pd.DataFrame()\n",
    "\n",
    "for year, count in reserved_counts.items():\n",
    "    year_df = df[df['Year'] == year]\n",
    "    reserved_year_df = year_df.sample(n=count, replace=False)\n",
    "    reserved_df = pd.concat([reserved_df, reserved_year_df], ignore_index=True)\n",
    "\n",
    "print(len(reserved_df))\n",
    "reserved_df.to_excel('../data/Elsevier-CS/Texts_3000.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "keywords = reserved_df['Author Keywords'].tolist()\n",
    "piis = reserved_df['Pii'].tolist()\n",
    "\n",
    "pii_to_words = {}\n",
    "for i, pii in enumerate(piis):\n",
    "    pii_to_words[pii] = []\n",
    "    items = keywords[i].split(';')\n",
    "    items = [item.strip() for item in items]\n",
    "    pii_to_words[pii].extend(items)\n",
    "\n",
    "with open('../data/Elsevier-CS/Keywords.json', 'w') as f:\n",
    "    json.dump(pii_to_words, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
