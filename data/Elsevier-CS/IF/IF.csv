"Title","Year","Source title","DOI","Link","Abstract","Author Keywords"
"Cross-modal contrastive learning for aspect-based recommendation","2023","Information Fusion","10.1016/j.inffus.2023.101858","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85161989116&doi=10.1016%2fj.inffus.2023.101858&partnerID=40&md5=57ee8dbb6658e2576ea10208cec4fcf3","Knowledge-enhanced recommender systems with aspects have improved recommendation performance by better profiling user preferences. Existing models can be divided into graph-based and text-based depending on the type of external knowledge: knowledge graph and review text. Since each knowledge provides different information from the scope and detail of aspects, it is necessary to integrate them for modeling sophisticated aspect-level preferences. However, it is difficult to directly fuse the aspects defined on two types of knowledge because they are expressed in different latent spaces. To tackle this problem, we explore self-supervised learning on multi-modal data. Specifically, we propose a novel model called COntrastive learning with croSs-MOdal aSpects (COSMOS). To take the data imbalance between knowledge graph and review texts into consideration, we devise a cross-modal contrastive learning scheme, which generates multiple views of a user or an item based on inter-modal correlation. With the correlation between aspects, COSMOS captures the inherent dependency between graph and text data. The fine-grained aspect-level preference, which contains salient features (from review text) as well as general ones (from knowledge graph), leads to providing high-quality recommendation results, even if a user only has one of the two data. Experimental results on two datasets show that COSMOS outperforms state-of-the-art recommender systems. © 2023 Elsevier B.V.","Aspect-based recommendation; Graph neural networks; Knowledge graph; Self-supervised learning"
"Cross-directional consistency network with adaptive layer normalization for multi-spectral vehicle re-identification and a high-quality benchmark","2023","Information Fusion","10.1016/j.inffus.2023.101901","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85166474482&doi=10.1016%2fj.inffus.2023.101901&partnerID=40&md5=c49ccefd6fbf937389e29a71150e6362","To tackle the challenge of vehicle re-identification (Re-ID) in complex lighting environments and diverse scenes, multi-spectral sources like visible and infrared information are taken into consideration due to their excellent complementary advantages. However, multi-spectral vehicle Re-ID suffers cross-modality discrepancy caused by heterogeneous properties of different modalities as well as a big challenge of the diverse appearance with different views in each identity. Meanwhile, diverse environmental interference leads to heavy sample distributional discrepancy in each modality. In this work, we propose a novel cross-directional consistency network (CCNet) to simultaneously overcome the discrepancies from both modality and sample aspects. In particular, we design a new cross-directional center loss (Lcdc) to pull the modality centers of each identity close to mitigate cross-modality discrepancy, while the sample centers of each identity close to alleviate the sample discrepancy. Such a strategy can generate discriminative multi-spectral feature representations for vehicle Re-ID. In addition, we design an adaptive layer normalization unit (ALNU) to dynamically adjust individual feature distribution to handle distributional discrepancy of intra-modality features for robust learning. To provide a comprehensive evaluation platform, we create a high-quality RGB-NIR-TIR multi-spectral vehicle Re-ID benchmark (MSVR310), including 310 different vehicles from a broad range of viewpoints, time spans and environmental complexities. Comprehensive experiments on both created and public datasets demonstrate the effectiveness of the proposed approach comparing to the state-of-the-art methods. The dataset and code will be released for free academic usage at https://github.com/superlollipop123/Cross-directional-Center-Network-and-MSVR310. © 2023 Elsevier B.V.","Benchmark dataset; Cross-directional center consistency; Layer normalization; Multi-spectral representation; Vehicle Re-ID"
"Enhancing social network hate detection using back translation and GPT-3 augmentations during training and test-time","2023","Information Fusion","10.1016/j.inffus.2023.101887","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85162149978&doi=10.1016%2fj.inffus.2023.101887&partnerID=40&md5=5115749deef0b9b084598acd41f2e050","Social media platforms have become an essential means of communication, but they also serve as a breeding ground for hateful content. Detecting hate speech accurately is challenging due to factors such as slang and implicit hate speech. In response to these challenges, this paper presents a novel ensemble approach utilizing DeBERTa models, integrating back-translation and GPT-3 augmentation techniques during both training and test time. This method aims to address the complexities associated with detecting hate speech, resulting in more robust and accurate results. Our findings indicate that the proposed approach significantly enhances hate speech detection performance across various metrics and models in both the Parler and GAB datasets. For reproducibility and further exploration, our code is publicly available at https://github.com/OrKatz7/parler-hate-speech. © 2023 Elsevier B.V.","Back-translation; GPT; Hate-detection; TTA"
"Parker: Data fusion through consistent repairs using edit rules under partial keys","2023","Information Fusion","10.1016/j.inffus.2023.101942","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85167791498&doi=10.1016%2fj.inffus.2023.101942&partnerID=40&md5=7de74fa449c47d8c685697f3a544777c","Data integration is the problem of consolidating information provided by multiple sources. After schema mapping and duplicate detection have been dealt with, the problem consists in fusing disparate data that comes from the sources. In this work, we treat this problem as a data cleaning problem where consistency within and between sources is modelled by respectively edit rules and a partial key. The combination of these constraints leads to the definition of edit rules under a partial key (EPKs). We show that we can adapt the well-known set cover method for edit rules to the setting of EPKs and this yields an efficient algorithm to find minimal-cost repairs. These repairs then provide solutions for the initial data fusion problem. The methodology is implemented in a repair engine called Parker. Empirical results show that Parker is several orders of magnitude faster than state-of-the-art repair tools. At the same time, the quality of the repairs in terms of F1-score ranges from comparable to better compared to these tools. © 2023 Elsevier B.V.","Data fusion; Data quality; Edit rules; Functional dependencies; Key constraints"
"Deep adversarial autoencoder recommendation algorithm based on group influence","2023","Information Fusion","10.1016/j.inffus.2023.101903","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85164667262&doi=10.1016%2fj.inffus.2023.101903&partnerID=40&md5=77c5ae11b3097bace0f0a310612444a9","Recommender systems are crucial in the big data era, effectively mitigating information overload. Existing recommendation methods are limited on highly sparse data and have mediocre recall performance. Group influence aggregates knowledge from different users or organizations to generate decisions, improving information fusion efficiency and group decision-making quality. In this paper, a group influence-based deep adversarial autoencoder (GI-AAE), is proposed for top-N recommendation. It leverages group influence to strengthen autoencoder latent features and address sparse data and uses adversarial learning from GANs to enhance reconstruction. The group influence based deep autoencoder (GI-AE) is the generative model for the GI-AAE. Experimental results show that the proposed algorithm is competitive and gets higher recall values. © 2023 Elsevier B.V.","Autoencoder; Deep learning; Group decision-making; Group influence; Recommender system"
"Generalizing max pooling via (a,b)-grouping functions for Convolutional Neural Networks","2023","Information Fusion","10.1016/j.inffus.2023.101893","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85162972847&doi=10.1016%2fj.inffus.2023.101893&partnerID=40&md5=ee046759e0034bb78c085262796c13f5","Due to their high adaptability to varied settings and effective optimization algorithm, Convolutional Neural Networks (CNNs) have set the state-of-the-art on image processing jobs for the previous decade. CNNs work in a sequential fashion, alternating between extracting significant features from an input image and aggregating these features locally through “pooling” functions, in order to produce a more compact representation. Functions like the arithmetic mean or, more typically, the maximum are commonly used to perform this downsampling operation. Despite the fact that many studies have been devoted to the development of alternative pooling algorithms, in practice, “max-pooling” still equals or exceeds most of these possibilities, and has become the standard for CNN construction. In this paper we focus on the properties that make the maximum such an efficient solution in the context of CNN feature downsampling and propose its replacement by grouping functions, a family of functions that share those desirable properties. In order to adapt these functions to the context of CNNs, we present (a,b)-grouping functions, an extension of grouping functions to work with real valued data. We present different construction methods for (a,b)-grouping functions, and demonstrate their empirical applicability for replacing max-pooling by using them to replace the pooling function of many well-known CNN architectures, finding promising results. © 2023 The Author(s)","Convolutional neural networks; Grouping functions; Image classification; Pooling functions"
"Integrating the traffic science with representation learning for city-wide network congestion prediction","2023","Information Fusion","10.1016/j.inffus.2023.101837","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85161694368&doi=10.1016%2fj.inffus.2023.101837&partnerID=40&md5=5d7b1e9f514cf5baecd9fa40b0abac83","Recent studies on traffic congestion prediction have paved a promising path towards the reduction of potential economic and environmental loss. However, at the city-wide scale, current approaches face substantial hurdles, such as being unable to support the multiple sensors modalities, insufficient congestion fluctuation and propagation modeling, and weak generalization to heterogeneous traffic network structures. To address these pitfalls, this paper investigates how to integrate the missing urban science domain priors into a general sequential prediction model, and proposes the customized Traffic-informed Transformer (TinT). To prevent receptive field bias, a novel mixture of long and short range information routing mechanism is proposed with the traffic-informed tokenization. To capture the unbalanced traffic flow propagation, an original anisotropic graph aggregation is developed to differentiate the traffic fluctuation based on orientations. Extensive results demonstrated TinT's outstanding performance over other twelve state-of-the-art models and its broad applicability to multiple data modalities in six well-known cities throughout the world. We released our implementations at: https://github.com/VITA-Group/TinT. © 2023 Elsevier B.V.","Cyber–physcial system; Representation learning; Traffic prediction; Transformer"
"Heterogeneous and clustering-enhanced personalized preference transfer for cross-domain recommendation","2023","Information Fusion","10.1016/j.inffus.2023.101892","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85164026192&doi=10.1016%2fj.inffus.2023.101892&partnerID=40&md5=701da2ae137f0e798bff029615f85baa","As a promising solution to alleviate the critical cold-start problem in recommendation systems, Cross-Domain Recommendation (CDR) aims to transfer users’ preferences from the source domain to the target domain. However, the negligence of semantic differences of heterogeneous relations when modeling user preferences and the non-consideration of a user's common characteristics inferred from similar users when transferring the user's preferences make recent CDR works cannot well handle the two core issues of CDR—‘what to transfer’ and ‘how to transfer’. To this end, we propose a novel heterogeneous and clustering-enhanced user preference transfer model for CDR (named HCCDR). To well address the first issue, the heterogeneous latent factor modeling component is firstly built to compute high-quality representations of users and items to be transferred based on the heterogeneous relations among users and items. Note that the heterogeneous relations with different semantics are processed with different models. Then, the clustering-enhanced preference transfer component well addresses the second issue by learning an effective personalized preference transfer function between two domains for a user, where the individual and common characteristics of the user are concurrently considered. Finally, the personalized recommendation component achieves the personalized recommendation in the target domain based on the transferred user embeddings calculated via the learned personalized preference transfer functions. Experimental results performed on large public datasets demonstrate that the proposed HCCDR markedly outperforms all baselines. In particular, HCCDR gains a maximum performance improvement of 12.69% (or 8.99%) for RMSE (or MAE) compared with the best baseline. © 2023 Elsevier B.V.","Cross-domain recommendation; Graph representation learning; Heterogeneous information networks; Soft clustering; User cold-start problem"
"ENCODE - Ensemble neural combination for optimal dimensionality encoding in time-series forecasting","2023","Information Fusion","10.1016/j.inffus.2023.101918","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85165390632&doi=10.1016%2fj.inffus.2023.101918&partnerID=40&md5=7b14d141ded3b8261d109e2545f8380a","Nowadays, predictive models based on a time series are widely used in many fields, from geology to healthcare and from traffic management to industrial production. One of the most important tasks in machine and deep learning is designing predictive algorithms that provide increasingly reliable and accurate forecasts from a time series. This work proposes a novel ensemble approach to producing predictions in a multivariate framework. Its main idea is to reduce data dimensionality through an encoding technique, with the aim to extract useful information via single predictive procedures and then to gather all the processed data through a combiner to give the final forecast. In our framework, the combiner is composed of a hybrid neural architecture: a Convolutional Neural Network to extract local patterns from the predictions and a Recurrent Neural Network to infer information about the temporal patterns of the time series. Furthermore, a fully connected network is adopted to merge these two components and to provide the prediction. Extensive experiments on different datasets, both public and private, related to different applications have been carried out. Comparisons of the errors with conventional methods and state-of-the-art strategies confirm both accuracy and robustness of the proposed ensemble. Finally, we also show a comparison in terms of computational time, both in the hyperparameter optimization and forecasting tasks. © 2023","Deep learning; Ensemble learning; Machine learning; Multivariate prediction; Time-series forecasting"
"The robust maximum expert consensus model with risk aversion","2023","Information Fusion","10.1016/j.inffus.2023.101866","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85161268724&doi=10.1016%2fj.inffus.2023.101866&partnerID=40&md5=2cf37e0c667e2e2fd23a7e09410263e1","The maximum expert consensus model (MECM) is an effective model for achieving consensus during the consensus reaching process (CRP) in group decision making (GDM). However, previous literature on MECM has focused only on the resources in CRP and ignored the uncertainty and the risks resulting from the unpredictable decision environment. To address these issues, this paper constructs novel MECMs that can handle both the uncertainty and risks emerging in the CRP. First, the risk maximum expert consensus model (RMECM) is proposed based on the mean-variance (MV) theory. Then, the novel robust risk maximum expert consensus model (R-RMECM) is developed to address the uncertainty caused by the estimation error of the mean and covariance matrix of unit adjustment cost. Additionally, the R-RMECMs are developed under three uncertain scenarios to comprehensively make the models closer to the real decision environment. Finally, the proposed models are verified by applying them to a specific example of the new energy vehicle subsidy policy negotiation and the sensitivity analysis is also conducted. © 2023 Elsevier B.V.","Group decision making; Maximum expert consensus; Mean-variance; Robust optimization; Uncertainty set"
"Minimum conflict consensus models for group decision-making based on social network analysis considering non-cooperative behaviors","2023","Information Fusion","10.1016/j.inffus.2023.101855","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85160813563&doi=10.1016%2fj.inffus.2023.101855&partnerID=40&md5=461744fba026e2ce161b45a3851c516c","Decision makers (DMs) may exhibit non-cooperative behaviors such as deviating from recommendations or making only minor modifications in consensus-based group decision-making (GDM) problems. These non-cooperative behaviors will lead to high intra-group conflicts and low consensus efficiency. This paper designs a budget-constrained consensus framework with minimum group conflict based on social network analysis to address non-cooperative behaviors. First, the conflict degrees among DMs are quantified by opinion discrepancies and asymmetric 2-tuple linguistic trust values. Then, DMs’ weights are derived by considering degree centrality and node strength indices in the constructed conflict network. To obtain a feasible budget constraint for the consensus, the non-linear optimization models considering non-cooperative behaviors are proposed. Furthermore, two kinds of minimum conflict consensus models are established to deal with general and completely non-cooperative DMs, respectively. The existence of the optimal solutions of these consensus models and the convergence of the consensus reaching process are proved. Finally, the proposed consensus models are illustrated by an example of the negotiation of the sewage discharge standards. Compared with the consensus models based on minimum cost or adjustment, the proposed consensus models could achieve higher consensus and lower group conflict. © 2023 Elsevier B.V.","Budget constraint; Consensus reaching process; Group decision-making; Minimum conflict consensus; Non-cooperative behaviors"
"Encoding–decoding-based fusion estimation with filter-and-forward relays and stochastic measurement delays","2023","Information Fusion","10.1016/j.inffus.2023.101963","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168541345&doi=10.1016%2fj.inffus.2023.101963&partnerID=40&md5=287310858fc032870bc5c2a492dc011a","This paper addresses the encoding–decoding-based fusion estimation problem for a class of systems with signal relays and stochastic measurement delays. A set of Bernoulli distributed random variables is used to model the randomly occurring measurement delays. To enhance the system performance and extend the transmission distance, a filter-and-forward relay is adopted in the transmission link. To handle the limited bandwidth of the communication channels, an encoding–decoding scheme based on a probabilistic quantizer is proposed for the sensor–relay and relay–estimator channels. For each relay, a local filter is constructed with a proper filter gain at each time step with aim to minimize an upper bound of the local estimation error covariance. The effects of the encoding–decoding scheme on the error covariance are also analyzed quantitatively. The estimates obtained from the local filters are then fused at the remote estimator using the covariance intersection fusion strategy. Finally, a target tracking simulation example is presented to demonstrate the effectiveness of the proposed framework. © 2023 Elsevier B.V.","Covariance intersection fusion; Encoding–decoding scheme; Filter-and-forward relay; Fusion estimation; Measurement delay; Recursive algorithm"
"Tensorized topological graph learning for generalized incomplete multi-view clustering","2023","Information Fusion","10.1016/j.inffus.2023.101914","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85165658365&doi=10.1016%2fj.inffus.2023.101914&partnerID=40&md5=b63196087b461cc736e556e5e9e36a1d","The success of the current multi-view clustering lies in the default assumption of completeness on each view, while it is hardly satisfied for real-world applications. Incomplete multi-view clustering (IMC) studies clustering multi-view instances that are partially observed due to data corruption or sensor failure. Although making some progress, the current research suffers from the following obstacles: (1) Existing works are always built on pairwise similarity measurement, which cannot fully capture the topological structure of incomplete multi-view samples for precise clustering; (2) Due to the absence of partially-observed samples across multiple views, how could we recover and enhance the high-order similarities across different views becomes one of the main bottlenecks of IMC; (3) Current research mainly aims to handle specific dual-view IMC, which greatly limits the deployment in real-world applications. In this paper, we propose a novel Tensorized Topological Graph Learning (TTGL) for the generalized incomplete multi-view clustering, which jointly considers the topological graph construction, missing feature completion, and high-order uncertain correlation enhancement. Specifically, instead of using pairwise similarity measurement, we formulate a consensus topological graph construction module, which can coalesce affinity matrices to analyze the topological structure of incomplete multi-view data. Moreover, we build an iterative missing similarity imputation scheme for feature completion, which ensures the intrinsic similarity preservation on observed instances as well as an imputation on unobserved ones. Furthermore, a low-rank tensor structure is imposed to capture the high-order similarities via both feature and similarity enhancement and completion across different views. Our method can cluster incomplete data with an arbitrary number of views and any missing statuses. Extensive experiments on several benchmark datasets validate the effectiveness of our method when compared with a series of state-of-the-art IMC clustering algorithms. The source code of our TTGL is available at: https://github.com/DarrenZZhang/TTGL. © 2023 Elsevier B.V.","Incomplete multi-view clustering; Low-rank tensor approximation; Similarity completion; Topological graph clustering"
"Exploring the balance between interpretability and performance with carefully designed constrainable Neural Additive Models","2023","Information Fusion","10.1016/j.inffus.2023.101882","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85163149038&doi=10.1016%2fj.inffus.2023.101882&partnerID=40&md5=e0ff2fbe13a9146baf77f6ed825cdabf","The interpretability of an intelligent model automatically derived from data is a property that can be acted upon with a set of structural constraints that such a model should adhere to. Often these are in contrast with the task objective and it is not straightforward how to explore the balance between model interpretability and performance. In order to allow an interested user to jointly optimise performance and interpretability, we propose a new formulation of Neural Additive Models (NAM) which can be subject to a number of constraints. Accordingly, our approach produces a new model that is called Constrainable NAM (or just CNAM in short) and it allows the specification of different regularisation terms. CNAM is differentiable and is built in such a way that it can be initialised as a solution of an efficient tree-based GAM solver (e.g., Explainable Boosting Machines). From this local optimum the model can then explore solutions with different interpretability-performance tradeoffs according to different definitions of both interpretability and performance. We empirically benchmark the model on 56 datasets against 12 models and observe that on average the proposed CNAM model ranks on the Pareto front of optimal solutions, i.e., models generated by CNAM exhibit a good balance between interpretability and performance. Moreover, we provide two illustrative examples which are aimed to show step by step how CNAM works well for solving classification tasks, but also how it can yield insights when considering regression tasks. © 2023 The Author(s)","Explainability; Explainable Artificial Intelligence; Generalised additive models; Interpretability; Interpretable modelling; Neural additive models"
"Deep learning in food category recognition","2023","Information Fusion","10.1016/j.inffus.2023.101859","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85162740678&doi=10.1016%2fj.inffus.2023.101859&partnerID=40&md5=2646a7108cee0951812eeda1f912dbcf","Integrating artificial intelligence with food category recognition has been a field of interest for research for the past few decades. It is potentially one of the next steps in revolutionizing human interaction with food. The modern advent of big data and the development of data-oriented fields like deep learning have provided advancements in food category recognition. With increasing computational power and ever-larger food datasets, the approach's potential has yet to be realized. This survey provides an overview of methods that can be applied to various food category recognition tasks, including detecting type, ingredients, quality, and quantity. We survey the core components for constructing a machine learning system for food category recognition, including datasets, data augmentation, hand-crafted feature extraction, and machine learning algorithms. We place a particular focus on the field of deep learning, including the utilization of convolutional neural networks, transfer learning, and semi-supervised learning. We provide an overview of relevant studies to promote further developments in food category recognition for research and industrial applications. © 2023 The Author(s)","Computer vision; Convolutional neural network; Data augmentation; Deep learning; Food category recognition; Machine learning; Semi-supervised learning; Transfer learning"
"Conflict analysis based on a novel three-way decisions graph model for conflict resolution method under hesitant fuzzy environment","2023","Information Fusion","10.1016/j.inffus.2023.101936","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85166644057&doi=10.1016%2fj.inffus.2023.101936&partnerID=40&md5=73559245426db5a72d267b8048402cdf","Multi-criteria decision aiding/making (MCDA/M) approach and three-way decisions (3WD) are embedded into the framework of graph model for conflict resolution (GMCR). The objective of this study is to develop more reasonable preference ranking for decision makers (DMs) produced from the perspective of options. This implies further simplification of the underlying computing behind conflict resolution. More specifically, DMs’ original option statements are evaluated by hesitant fuzzy sets (HFSs), then a three-way decisions approach is used to screen out the infeasible and rank the feasible option statements, and the feasible option statements’ loss values of three-way decisions approach are determined based on the hesitant fuzzy (HF) evaluation values. In addition, based on the value of conditional probability of the feasible option statements, an improved option prioritization technique with objective weights is developed to efficiently rank the conflict states, so that it can efficiently reflect the intensity of the ranking. Then, considering the preference thresholds of DMs, new definitions of threshold stabilities are proposed. As demonstrated by the case study in the problem of a carbon emission conflict in supply chain under “3060 carbon peak and neutrality” goal in China, the proposed novel three-way decisions graph model for conflict resolution (3WD-GMCR) framework can be widely applied to the realistic scenarios of decision-making. Compared with previous studies, the proposed approach can not only obtain the intensity ranking of conflict states, but also resolve complex large-scale conflicts effectively. © 2023","carbon peak and neutrality; graph model for conflict resolution; hesitant fuzzy sets; option prioritization; three-way decisions"
"Reimagining multi-criterion decision making by data-driven methods based on machine learning: A literature review","2023","Information Fusion","10.1016/j.inffus.2023.101970","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85169912998&doi=10.1016%2fj.inffus.2023.101970&partnerID=40&md5=8e824ba5c79f175f5e9cf9e22be0c1f2","Multi-criterion decision making (MCDM) methods can derive alternative rankings as solutions to decision-making problems based on survey or historical data about the performance or preference information of alternatives regarding multiple criteria. Today's information age makes it easy to accumulate data, but also brings challenges to MCDM, such as massive data and weak data correlation. The real data in the information age should be fully utilized to put MCDM from theoretical formulation into practical application. In this regard, machine learning technologies that can adaptively discover rules as well as patterns from data of different types and characteristics show great application potential. This study dedicates to exploring the status of implementing machine learning technologies in solving MCDM problems. The related work and research advances of MCDM and machine learning technologies are briefly described. A bibliometric analysis is conducted to provide an overview of the research status, hotspots, and trends. Then, we summarize the challenges of implementing MCDM in the information age in four aspects, around which we review the research status of applying machine learning technologies to criteria extraction, criteria interaction, parameter determination, and integrated solutions of MCDM. Also, the fields of practical applications about the subject matter including business management, industrial engineering, sustainable development, emergency management, along with other fields are reviewed. This study outlines how machine learning technologies contribute to MCDM. The lessons learned from the review and future research directions are discussed. It is hoped that this review can serve as a reference and provide convenience for scholars and practitioners in the fields of decision analysis and machine learning. © 2023 Elsevier B.V.","Bibliometrics; Information fusion; Literature review; Machine learning; Multi-criterion decision making"
"Distributed event-triggered fusion estimation for networked asynchronous multi-rate systems","2023","Information Fusion","10.1016/j.inffus.2023.101846","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85160400590&doi=10.1016%2fj.inffus.2023.101846&partnerID=40&md5=28794713a908d9b6df22b96e2e1d1fd4","This paper studies the event-triggered distributed fusion estimation problem for a class of networked asynchronous multi-rate systems with nonlinear disturbances and bounded noises. Firstly, the asynchronous multi-rate systems are transformed into synchronous ones at the measurement sampling points (MSPs) by iterating the state equation. This paper proposes an event-triggered strategy to alleviate the communication burden to meet the finite communication resources during information transmission. Since the reduction of information will inevitably reduce the estimation performance, a compensation mechanism is adopted to restructure the untransmitted measurement. Then, a local estimator at the MSP is designed by the compensation information, and the local estimation at the unsampled measurement point is obtained by the multi-step prediction. Furthermore, by constructing the upper bound of the fusion estimation error, a robust recursive optimization approach, which can deal with nonlinear disturbances and bounded noises, is proposed to determine the distributed fusion criterion. Meanwhile, the stability conditions are derived such that the square errors of the designed estimators are asymptotically bounded. Finally, a target tracking example is used to demonstrate the effectiveness of the proposed method. © 2023 Elsevier B.V.","Bounded recursive optimization; Distributed fusion estimation; Event-triggered; Multi-rate systems; Nonlinear disturbances"
"Detail-aware near infrared and visible fusion with multi-order hyper-Laplacian priors","2023","Information Fusion","10.1016/j.inffus.2023.101851","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85165716738&doi=10.1016%2fj.inffus.2023.101851&partnerID=40&md5=4ecb3142678981dc3423cf13ca76ce3e","Heavy haze/noise can cause unpleasant information loss in near infrared (NIR) and visible (VI) image fusion. To generate high-quality fused images, this paper proposes a detail-aware near infrared and visible image fusion method, which establishes a detail injection variational framework based on multi-order hyper-Laplacian priors (MHLP). As the core idea, the MHLP is a l1/2 norm penalty term with first-order and second-order gradient differences, and applies sparsity-promoting and complete-comprehensive injection terms to enhance salient structures and fine-scale details. Besides, a noise map is introduced to suppress the structure inconsistency caused by heavy noise. Combining MHLP and a noise map, a novel near infrared and visible fusion framework is organized to deal with harsh environment imaging problems. The framework recovers visual visibility and preserves the significant scenery structural information and intrinsic colors. The video fusion of near infrared and visible also can be realized by the framework, which introduces the inter-frame coherence of successive frames additionally to retain the information lost in the degraded scene. Experiment results on public datasets and industrial sites demonstrate the advantages of our method from both qualitative and quantitative perspectives. The code is available at: https://github.com/BOYang-pro/MHLP. © 2023 Elsevier B.V.","Alternative optimization; Detail-aware variational framework; Multi-order hyper-Laplacian priors; Near infrared and visible fusion"
"A perioperative risk assessment dataset with multi-view data based on online accelerated pairwise comparison","2023","Information Fusion","10.1016/j.inffus.2023.101838","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85162105406&doi=10.1016%2fj.inffus.2023.101838&partnerID=40&md5=054b4dbf404aaf4bc49c2e49c1c4a97b","Perioperative risk assessment (PRA) aims to evaluate the risk to patients from surgery, and knowing the risk can contribute to allocating scarce medical resources. Despite the clinical significance of PRA, to our best knowledge, there is currently no comprehensive perioperative risk (PR) dataset to facilitate the development of standard criteria and machine learning-based models for PRA. In this paper, we propose the first perioperative risk assessment dataset (PRAD) with multi-view data by applying online accelerated pairwise comparison (OAPC). Specifically, OAPC combines prior knowledge-based presorting and online probability insertion sorting to efficiently obtain robust pair comparisons. To obtain labels from doctors conveniently, we develop an online PRA system to enable doctors to label medical records anywhere and anytime. Our PRAD provides 300 medical records with multi-view data, including various types of preoperative and postoperative data, together with the corresponding comparisons and risk scores obtained from doctors with different experiences. Furthermore, we analyze the PRAD to investigate relationships between the patient's preoperative data and risk score, e.g., cardiovascular disease history is highly related to PR, providing a complementary view with current research on PRA. The labeling procedure is still ongoing, and additional records and analyses will be made available in the future. We believe our dataset and analysis provide new insights that will significantly facilitate the building of new PRA models. © 2023 Elsevier B.V.","Insertion sort; Multi-view data; Pairwise comparison; Perioperative risk assessment"
"Multi-sensor spectral fusion to model grape composition using deep learning","2023","Information Fusion","10.1016/j.inffus.2023.101865","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85161630820&doi=10.1016%2fj.inffus.2023.101865&partnerID=40&md5=d7009eafd4c17b094acc3750f9480ea3","Spectral instruments can be useful for the rapid assessment of chemical compounds in different targets, and their use have been already reported for the modeling of grape composition comparing two spectral ranges. Still, with the increased easiness of acquiring data with several sensors, it would be valuable to explore spectral fusion techniques for the modeling with deep learning, seeking to obtain improved performance. Therefore, the objective of this work was to develop multi-sensor spectral fusion approaches for the deep learning modeling of grape composition. From 128 grape samples, two spectra per sample were acquired from two different ranges using two sensors (visible and shortwave near infrared, 570–1000 nm; and wider NIR 1100–2100 nm). From each sample, 15 grape nitrogen compounds were analyzed by wet chemistry. Three different data fusion approaches are defined using neural networks and deep learning, testing several ways of structuring and merging the input spectra. Statistical analyses supported that (i) the proposed deep learning fusion architectures performed better than single spectral range models, and (ii) neural networks have better modeling capabilities than partial least squares in spectral fusion. The results demonstrate the potential of deep learning for spectral data fusion in grape nitrogen composition regression, and potentially other traits in food and agriculture spectroscopy. © 2023 The Authors","Amino acids; Chemometrics; Convolutional neural networks; Multi-block; Multilayer perceptrons; Nitrogen compounds; Spectrometer; Spectroscopy"
"Cross-view Graph Matching Guided Anchor Alignment for Incomplete Multi-view Clustering","2023","Information Fusion","10.1016/j.inffus.2023.101941","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85166655298&doi=10.1016%2fj.inffus.2023.101941&partnerID=40&md5=1937af9257301b88fc9be9a8fcd8c159","Multi-view bipartite graph clustering methods select a few representative anchors and then establish a connection with original samples to generate the bipartite graphs for clustering, which maintains impressive performance while reducing time and space complexities. Despite their effectiveness in large-scale applications, few of them focus on cross-view anchor misalignment (CAM) problem. Then, misaligned anchor sets could destroy the consistent graph semantic structure of bipartite graphs across different views, thus hindering subsequent graph fusion and degrading the clustering performance. Especially when it comes to incomplete data, solving CAM problem becomes an intractable challenge. To address this challenge, we propose a novel Cross-view Graph Matching guided Anchor Alignment (CGMAA) for incomplete multi-view bipartite clustering. Specifically, we first propose a novel CGMAA framework to address CAM problem by predefining an anchor graph according to the prior anchor information. In addition, we unify CGMAA and bipartite graph tensor learning for incomplete multi-view clustering. Extensive experiments on ten complete/incomplete benchmark datasets demonstrate the effectiveness, efficiency, and superiority of the proposed CGMAA framework. © 2023 Elsevier B.V.","Anchor alignment; Bipartite graph learning; Incomplete multi-view clustering; Low-rank tensor"
"MMIEA: Multi-modal Interaction Entity Alignment model for knowledge graphs","2023","Information Fusion","10.1016/j.inffus.2023.101935","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85167413849&doi=10.1016%2fj.inffus.2023.101935&partnerID=40&md5=40e06d4f72397ba8bc74d053bdf3978f","Fusing data from different sources to improve decision making in smart cities has received increasing attention. Collected data through sensors usually exist in a multi-modal form, such as values, images, and texts. Thus, designing models that handle multi-modal data has an important role in this field. Meanwhile, security and privacy issues cannot be ignored, as the leakage of big data may provide opportunities for criminals. To solve the above challenges, we focus on research on multi-modal entity alignment for knowledge graphs and proposed the Multi-Modal Interaction Entity Alignment model (MMIEA). The model is proposed from the perspective of fusing data from different modalities while maintaining privacy. We determined that the model is privacy-preserving because it does not need to transmit the raw data of each modality (only the vector representation is transmitted). Specifically, we introduce and improve the BERT-INT model for the entity alignment task in multi-modal knowledge graphs. Experimental results on two commonly used multi-modal datasets show that our method outperforms 17 algorithms, including nine multi-modal entity alignment methods. © 2023 Elsevier B.V.","BERT; Entity alignment; Interaction; Knowledge graph; Multi-modal"
"Exploring fusion strategies for accurate RGBT visual object tracking","2023","Information Fusion","10.1016/j.inffus.2023.101881","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85165230726&doi=10.1016%2fj.inffus.2023.101881&partnerID=40&md5=68dedb5c5754cc503f17fc598e8db031","We address the problem of multi-modal object tracking in video and explore various options available for fusing the complementary information conveyed by the visible (RGB) and thermal infrared (TIR) modalities, including pixel-level, feature-level and decision-level fusion. Specifically, in contrast to the existing approaches, we propose and develop the paradigm for combining multi-modal information for image fusion at pixel level. At the feature level, two different kinds of fusion strategies are investigated for completeness, i.e., the attention-based online fusion strategy and the offline-trained fusion block. At the decision level, a novel fusion strategy is put forward, inspired by the success of the simple averaging configuration which has shown so much promise. The effectiveness of the proposed decision-level fusion strategy owes to a number of innovative contributions, including a dynamic weighting of the RGB and TIR contributions and a linear template update operation. A variant of the proposed decision fusion method produced the winning tracker at the Visual Object Tracking Challenge 2020 (VOT-RGBT2020). A comprehensive comparison of the innovative pixel and feature-level fusion strategies with the proposed decision-level fusion method highlights the advantages fusing multimodal information at the decision score level. Extensive experimental results on five challenging datasets, i.e., GTOT, VOT-RGBT2019, RGBT234, LasHeR and VOT-RGBT2020, demonstrate the effectiveness and robustness of the proposed method, compared to the state-of-the-art approaches. The Code is available at https://github.com/Zhangyong-Tang/DFAT. © 2023","Adaptive weighting strategy; Decision-level fusion; RGBT tracking; Visual object tracking"
"Fixed-time synchronization of delayed dynamic networks: Average aperiodic intermittent control interval approach","2023","Information Fusion","10.1016/j.inffus.2023.101897","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85164692341&doi=10.1016%2fj.inffus.2023.101897&partnerID=40&md5=9fee628851650aefe00b705f3bb80e12","In this paper, aperiodic intermittent control (AIC) is presented for the fixed-time synchronization of delayed dynamic networks. To overcome the difficulty that the AIC strategy cannot solve the fixed-time synchronization of delayed dynamic networks directly, the concept of anaverage intermittent control interval is proposed. Based on this average concept and by constructing an auxiliary function, a new lemma is given, which is used to study the fixed-time synchronization of dynamic networks. The upper/lower bound restrictions on each control width for AIC input are relaxed using average intermittent control. A novel Lyapunov function is proposed, and flexible criteria are established for finite-time/exponential synchronization of general dynamic networks using the average intermittent control strategy. The relationship between the average control interval and intermittent interval with afixed-time is given. Finally, typical networks are used to show the validity of our AIC approach. © 2023 Elsevier B.V.","Aperiodic intermittent control; Dynamic networks; Fixed-time synchronization; Time delay"
"Neighbor group structure preserving based consensus graph learning for incomplete multi-view clustering","2023","Information Fusion","10.1016/j.inffus.2023.101917","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85165230964&doi=10.1016%2fj.inffus.2023.101917&partnerID=40&md5=6147eab3831c523f24bd9dac1219f815","In the area of clustering, multi-view clustering has drawn a lot of research attention by making full use of information from different views. In many practical applications, collecting complete multi-view data without missing views is sometimes expensive and impossible. Therefore, the study in incomplete multi-view clustering has become a trend in the field of clustering analysis. Graph learning-based approach is one of the most effective tools. The essence of graph learning is how to construct the affinity graph or similarity matrix, whose elements depict the similarity of the corresponding sample pairs. In this paper, we propose a new method, called Neighbor Group Structure Preserving-based Consensus Graph Learning (NGSP_CGL), to learn a high-quality consensus graph for incomplete multi-view clustering. Different from the existing graph learning-based works which only focus on the relationship between isolated sample pairs, NGSP_CGL seeks to explore the neighbor group structure corresponding to the nearest neighbor sets of sample pairs and designs a novel but simple nearest neighbor group structure embedding constraint so as to enhance the quality of consensus graph. The experimental results on several datasets demonstrate the effectiveness of NGSP_CGL. © 2023 Elsevier B.V.","Graph learning; Incomplete multi-view clustering; Neighbor group structure; Structure preserving"
"MFIR: Multimodal fusion and inconsistency reasoning for explainable fake news detection","2023","Information Fusion","10.1016/j.inffus.2023.101944","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85169880209&doi=10.1016%2fj.inffus.2023.101944&partnerID=40&md5=c2fabbf2811168f56d18767fb5c5ea7d","Fake news possesses a destructive and negative impact on our lives. With the rapid growth of multimodal content in social media communities, multimodal fake news detection has received increasing attention. Most existing approaches focus on learning the respective deep semantics of various modalities and integrating them by traditional fusion modes (like concatenation or addition, etc.) for improving detection performance, which has achieved a certain degree of success. However, they have two crucial issues: (1) Shallow cross-modal feature fusion, and (2) Difficulty in capturing inconsistent information. To this end, we propose Multimodal Fusion and Inconsistency Reasoning (MFIR) model to discover multimodal inconsistent semantics for explainable fake news detection. Specifically, MFIR consists of three modules: (1) Different from the traditional fusion modes, cross-modal infiltration fusion is designed, which is absorbed in continuously infiltrating and correlating another modality features into its internal semantics based on the current modality, which can well ensure the retention of the contextual semantics of the original modality; (2) Multimodal inconsistent learning not only captures the local inconsistent semantics from the perspectives of text and vision, but also integrates the two types of local semantics to discover global inconsistent semantics in multimodal content; (3) To enhance the interpretability of inconsistent semantics as evidence for users, we develop explanation reasoning layer to supplement the contextual information of inconsistent semantics, resulting in more understandable evidence semantics. Extensive experiments confirm the effectiveness of our model on three datasets and improved performance by up to 2.8%. © 2023 Elsevier B.V.","Fake news detection; Multimodal content analysis; Natural language processing; Social media analysis"
"Knowledge-enhanced event relation extraction via event ontology prompt","2023","Information Fusion","10.1016/j.inffus.2023.101919","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85165542822&doi=10.1016%2fj.inffus.2023.101919&partnerID=40&md5=6366785fc27544d091dd26e895e2f3d0","Identifying temporal and subevent relationships between different events (i.e., event relation extraction) is an important step towards event-centric natural language processing, which can help understand how events evolve and potentially facilitate many downstream tasks, such as timeline generation and event knowledge graph construction. Existing work has extensively leveraged external knowledge to improve the performance of relation extraction. Despite the progress made, the current knowledge-enhanced approach still has some shortcomings, e.g., knowledge missing, knowledge noise, and suboptimal knowledge injection. In this paper, we propose OntoEnhance, a novel event relation extraction framework that fuses semantic information from event ontologies to enhance event representation. Specifically, we first inject the latent knowledge in the event ontology into the prompt text to address the issue of knowledge missing. Then a dual-stack attention fusion mechanism is further introduced to enhance the injection of key knowledge to alleviate knowledge noise. In order to prevent the knowledge in the event ontology from being wrongly dominated, we use the event direction induction mechanism to obtain the event context-based relational sequence representation. Finally, a gate mechanism is used to fuse ontology-based knowledge and context-based event features dynamically. Extensive experiments demonstrate that OntoEnhance outperforms all comparison baselines by a large margin on all four datasets under both standard and few-shot settings. © 2023 Elsevier B.V.","Event temporal relation extraction; Knowledge enhancement; Neural networks; Subevent relation extraction"
"Robust optimal consensus feedback mechanism with private interest in the context of uncertain cost","2023","Information Fusion","10.1016/j.inffus.2023.101938","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85166214548&doi=10.1016%2fj.inffus.2023.101938&partnerID=40&md5=e8918cd5f97d56b3be1e373ec9fe8d4b","During the process of obtaining a consensus, the moderator may recommend modifications based on his personal interests to steer decision-makers (DMs) toward modifying their viewpoints so that the consensus evolves in the desired direction. In the process of revising opinions, the moderator must provide sufficient monetary remuneration to those who are willing to modify their opinions. Nevertheless, there is a lot of uncertainty and both internal and external factors affect the adjustment cost of decision-making. This paper proposes two robust optimal consensus feedback mechanisms with private interests in the context of uncertain cost (UCRFM), taking into account the moderator's private interests and uncertain cost, minimizing the consensus cost under the established consensus threshold, and maximizing the fuzzy consensus measure under the given cost budget. Initially, two types of UCRFMs are presented by employing two uncertainty sets to characterize the uncertain cost, and then two UCRFMs are turned equivalently into a 0-1 programming model. Secondly, based on different uncertainty sets, the corresponding robust counterparts of UCRFMs are constructed to obtain the optimal total consensus cost and the maximum fuzzy consensus. Finally, comprehensive experimental research is conducted to confirm the effectiveness of the proposed approach, and a comparison between the models is given. © 2023 Elsevier B.V.","Maximum fuzzy consensus; Minimum consensus cost; Private interest; Robust optimal consensus feedback mechanism; Uncertain cost"
"Application of data fusion for automated detection of children with developmental and mental disorders: A systematic review of the last decade","2023","Information Fusion","10.1016/j.inffus.2023.101898","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85164218642&doi=10.1016%2fj.inffus.2023.101898&partnerID=40&md5=27a52a2aaecd1e808e05b05cdb023035","Mental health is a basic need for a sustainable and developing society. The prevalence and financial burden of mental illness have increased globally, and especially in response to community and worldwide pandemic events. Children suffering from such mental disorders find it difficult to cope with educational, occupational, personal, and societal developments, and treatments are not accessible to all. Advancements in technology have resulted in much research examining the use of artificial intelligence to detect or identify characteristics of mental illness. Therefore, this paper presents a systematic review of nine developmental and mental disorders (Autism spectrum disorder, Attention deficit hyperactivity disorder, Schizophrenia, Anxiety, Depression, Dyslexia, Post-traumatic stress disorder, Tourette syndrome, and Obsessive–compulsive disorder) prominent in children and adolescents. Our paper focuses on the automated detection of these developmental and mental disorders using physiological signals. This paper also presents a detailed discussion on signal analysis, feature engineering, and decision-making with their advantages, future directions and challenges on the papers published on mental disorders of children. We have presented the details of the dataset description, validation techniques, features extracted and decision-making models. The challenges and future directions present open research questions on signal or availability, uncertainty, explainability, and hardware implementation resources for signal analysis and machine or deep learning models. Finally, the main findings of this study are presented in the conclusion section. © 2023 The Author(s)","Artificial intelligence; Child; Deep learning; Electrocardiogram; Electroencephalogram; Electromyogram; Electrooculogram; Machine learning; Mental health; Photoplethysmogram"
"KnowleNet: Knowledge fusion network for multimodal sarcasm detection","2023","Information Fusion","10.1016/j.inffus.2023.101921","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85165537676&doi=10.1016%2fj.inffus.2023.101921&partnerID=40&md5=c35204436c8f98f7e25c6d9ff2548836","Sarcasm is a form of communication often used to express contempt or ridicule, where the speaker conveys a message opposite to their true meaning, typically intending to mock or belittle a specific target. Sarcasm detection has gained great attention in the field of natural language processing due to the fact that sarcasm is widespread on social media and difficult to detect for machines. While early efforts in sarcasm detection solely relied on textual data, the abundance of multimodal data on social media is also non-negligible. Recent research has focused on multimodal sarcasm detection, where attention mechanisms and graph neural networks were commonly used to identify relevant information in both image and text data. However, these methods may overlook the importance of prior knowledge and cross-modal semantic contrast, which are crucial factors for human sarcasm detection. In this paper, we propose a novel model named KnowleNet that leverages the ConceptNet knowledge base to incorporate prior knowledge and determine image–text relatedness through sample-level and word-level cross-modal semantic similarity detection. Contrastive learning is also introduced to improve the spatial distribution of sarcastic (positive) and non-sarcastic (negative) samples. The proposed model achieves state-of-the-art performance on publicly available benchmark datasets. © 2023 Elsevier B.V.","Information fusion; Multimodal learning; Sarcasm detection"
"Perception-latency aware distributed target tracking","2023","Information Fusion","10.1016/j.inffus.2023.101857","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85161721138&doi=10.1016%2fj.inffus.2023.101857&partnerID=40&md5=ef261c53935940a5aa9d20152f93879b","This work is devoted to the problem of distributed target tracking when a team of robots detect the target through a variable perception-latency mechanism. A reference for the robots to track is constructed in terms of a desired formation around the estimation of the target position. However, it is noted that due to the perception-latency, classical estimation techniques have smoothness issues which prevent asymptotic stability for the formation control. We propose a near-optimal smooth-output estimator which circumvents this issue. Moreover, local estimations are fused using novel dynamic consensus techniques. The advantages of the proposal as well as a comparison with a non-smooth optimal alternative are discussed through simulation examples. © 2023 The Author(s)","Estimation fusion; Mobile robot; Perception-latency; Target tracking"
"Regret theory-based multivariate fusion prediction system and its application to interest rate estimation in multi-scale information systems","2023","Information Fusion","10.1016/j.inffus.2023.101860","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85161266447&doi=10.1016%2fj.inffus.2023.101860&partnerID=40&md5=8cd1bfecda4e5333c0389c98ccd5dcc2","Estimating interest rates is a typical multivariate prediction problem that has garnered considerable attention in the finance industry. However, the rising complexity of the prediction environment has presented significant obstacles to the methodology and application of traditional single-scale rational prediction models. Considering this challenge, the paper presents a new multivariate fusion prediction system that aims to tackle the following issues: (1) How to mine prediction information from multi-scale information systems (MSISs)? (2) How to describe the irrational behavior of decision-makers (DMs) in prediction processes? (3) How to improve the prediction performance and generalization capability of the models? Specifically, the score function of each feature under MSISs is primarily established by applying scale rules, regret theory (RT), and dominance relations to thoroughly explore prediction information across varying scales. Second, an adaptive S3WD model is developed for feature selection, which leverages the feature score distribution and the sequential three-way decision (S3WD) concept to avoid the problem of dimensional disasters, thereby improving the accuracy of selected features and reducing the learning cost. Furthermore, to enhance the effectiveness and rationality of the kernel extreme learning machine (KELM), an improved version known as IKELM is developed, which combines the regret-based comprehensive score of each sample. Finally, a multivariate fusion prediction system is constructed and abbreviated as an S3WD-IKELM-PSO system, where the particle swarm optimization (PSO) algorithm is employed to determine optimal parameters. It is worth noting that actual interest rate estimation datasets are utilized to verify the feasibility and validity of the proposed prediction system. According to the experimental results, the S3WD-IKELM-PSO system exhibits superior prediction performance and generalization ability compared to existing machine learning models. © 2023 Elsevier B.V.","Kernel extreme learning machine; Multi-scale information system; Multivariate prediction; Regret theory; Sequential three-way decision"
"Cross-view graph contrastive learning with hypergraph","2023","Information Fusion","10.1016/j.inffus.2023.101867","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85162020320&doi=10.1016%2fj.inffus.2023.101867&partnerID=40&md5=281af76838dfe21bc53f199dacc909ab","Graph contrastive learning (GCL) provides a new perspective to alleviate the reliance on labeled data for graph representation learning. Recent efforts on GCL leverage various graph augmentation strategies, i.e., node dropping and edge masking, to create augmented views of the original graph, and then contrast the representations in these augmented views to learn expressive graph embeddings. Nevertheless, the contrasting is still conducted between small variations of the original graph, where limited information can be extracted. In this work, for the first time, we propose to use hypergraph to establish a new view for graph contrastive learning. Specifically, for each graph, we construct its corresponding hypergraph, and then contrast the graph representations learned in the hypergraph view and the original graph view, by which the high-order information of a graph can be captured to produce graph representations of higher quality. Furthermore, to bridge the potential gap between the graph and hypergraph representations, we utilize the diffusion model to exchange the information contained in these two views, enabling better graph contrastive learning. We evaluate our proposal with a collection of experiments, and the empirical results validate that the proposed model can improve node and graph classification performance. © 2023 Elsevier B.V.","Graph contrastive learning; Graph neural networks; Graph representation learning; Hypergraphs neural networks; Self-supervised learning"
"Resilient labeled multi-Bernoulli fusion with peer-to-peer sensor network","2023","Information Fusion","10.1016/j.inffus.2023.101965","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85167979835&doi=10.1016%2fj.inffus.2023.101965&partnerID=40&md5=0d3f24b23d1eaec5637c6e385afb91b0","This paper addresses fusion of labeled multi-Bernoulli (LMB) densities in a peer-to-peer sensor network subject to misbehaviors due to abnormal conditions of the signal propagation channel (i.e. low signal-noise-ratio) or to malicious attacks. In such situations unintentional or intentional modifications of the transmitted messages can occur which degrade the performance of standard fusion methods. In order to overcome the aforementioned difficulties, we propose a resilient approach to distributed fusion of LMB densities in which each node exploits the local density as trusted source of information to detect the modified/false data coming from neighboring nodes. The implementation issues of the proposed method as well as possible cyber-attack models in the context of multi-object filtering are also discussed. The performance of the proposed method is verified via simulation experiments concerning fusion under cyber-attacks. © 2023 Elsevier B.V.","Attack-resilient estimation; Distributed multi-target tracking; Labeled multi-Bernoulli; Multi-object fusion; Random finite set"
"Simple multiple kernel k-means with kernel weight regularization","2023","Information Fusion","10.1016/j.inffus.2023.101902","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85165953271&doi=10.1016%2fj.inffus.2023.101902&partnerID=40&md5=af80da953fad33da4fd8def3b536d580","Multiple kernel clustering (MKC) aims to determine the optimal kernel from several pre-computed basic kernels. Most of MKC algorithms follow a common assumption that the optimal kernel is linearly combined by basic kernels. Based on a min–max framework, a newly proposed MKC method termed simple multiple kernel k-means can acquire a high-quality unified kernel. Although it has achieved promising clustering performance, we have observed that it cannot benefit from any regularization or prior knowledge, thus the learned kernel weight coefficients may be seriously sparse or over-selected. To tackle this issue, we have developed a new algorithm termed simple multiple kernel k-means with kernel weight regularization (SMKKM-KWR), where we introduce average coefficients to avoid too sparse kernel weights. Specially, we add the average kernel coefficients as a regularization term to prevent the learned weight coefficients being far from the average values. After that, an efficient optimization strategy is proposed to solve the new resultant problem. By this way, the unified partition can learn clustering structure from fusion information of all the kernel views, with the goal to reach better clustering performance. Extensive experiments on nine benchmark datasets and four large-scale datasets have demonstrated the effectiveness and efficiency of the proposed algorithm. © 2023 Elsevier B.V.","Kernel k-means; Multi-view clustering; Multiple kernel clustering"
"A review of deep learning techniques for speech processing","2023","Information Fusion","10.1016/j.inffus.2023.101869","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85162051266&doi=10.1016%2fj.inffus.2023.101869&partnerID=40&md5=90a58330b1ebc9e04605b2cf2b3d9351","The field of speech processing has undergone a transformative shift with the advent of deep learning. The use of multiple processing layers has enabled the creation of models capable of extracting intricate features from speech data. This development has paved the way for unparalleled advancements in speech recognition, text-to-speech synthesis, automatic speech recognition, and emotion recognition, propelling the performance of these tasks to unprecedented heights. The power of deep learning techniques has opened up new avenues for research and innovation in the field of speech processing, with far-reaching implications for a range of industries and applications. This review paper provides a comprehensive overview of the key deep learning models and their applications in speech-processing tasks. We begin by tracing the evolution of speech processing research, from early approaches, such as MFCC and HMM, to more recent advances in deep learning architectures, such as CNNs, RNNs, transformers, conformers, and diffusion models. We categorize the approaches and compare their strengths and weaknesses for solving speech-processing tasks. Furthermore, we extensively cover various speech-processing tasks, datasets, and benchmarks used in the literature and describe how different deep-learning networks have been utilized to tackle these tasks. Additionally, we discuss the challenges and future directions of deep learning in speech processing, including the need for more parameter-efficient, interpretable models and the potential of deep learning for multimodal speech processing. By examining the field's evolution, comparing and contrasting different approaches, and highlighting future directions and challenges, we hope to inspire further research in this exciting and rapidly advancing field. © 2023 Elsevier B.V.","Deep learning; Speech processing; Survey; Transformers; Trends"
"Enhanced semantic representation model for multisource point of interest attribute alignment","2023","Information Fusion","10.1016/j.inffus.2023.101852","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85163509666&doi=10.1016%2fj.inffus.2023.101852&partnerID=40&md5=46181443e7edf31076402ce8708ae62f","Multisource point of interest (POI) attribute alignment is the consistent processing of heterogeneous attribute values from different data sources pointing to the same POI data, which is one of the key technologies to achieve geospatial data fusion. However, semantic heterogeneity problems of synonyms and homographs among different POI data sources are encountered, which makes multisource POI data fusion challenging. This paper proposes a multisource POI attribute alignment method based on the Enhanced Semantic Representation Model (ESRM). First, the unlabeled corpus is preprocessed by Chinese word segmentation and attribute expression sequence construction. Then, the ESRM is pre-trained using the relational consistency prediction and replacement language model tasks. Finally, the model is fine-tuned through supervised learning to perform the attribute alignment task for multisource POI data, as per the specific downstream tasks. We used the POI attributes of Baidu Map, Tencent Map, and Gaode Map in Chengdu, China as the experimental data. The findings demonstrate that the proposed model outperforms existing methods for attribute alignment. Specifically, the category attribute consistency achieves a Macro-F1 value of over 90%, and the address attribute standardization achieves a BLEU-4 score of over 95%. © 2023","Data fusion; ESRM; Relational consistency prediction; Replacement language model"
"Generic Dynamic Graph Convolutional Network for traffic flow forecasting","2023","Information Fusion","10.1016/j.inffus.2023.101946","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85166946951&doi=10.1016%2fj.inffus.2023.101946&partnerID=40&md5=ae291773d407d3166603e05e4df72f43","In the field of traffic forecasting, methods based on Graph Convolutional Network (GCN) are emerging. But existing methods still have limitations due to insufficient sharing patterns, inflexible temporal relations and static relation assumptions. To address these issues, a Generic Dynamic Graph Convolutional Network (GDGCN) for traffic flow forecasting is proposed. A generic framework with both parameter-sharing and independent blocks across stacked layers is proposed to explore parameter sharing systematically in all data dimensions, which can exploit distinct patterns from layer to layer and stable patterns across layers simultaneously. Then, we design a novel temporal graph convolutional block to view historical time slots as nodes in graph perspective and handle temporal dynamics with graph convolution. This temporal convolutional block can capture flexible and global temporal relations to have a better understanding of current traffic conditions. Lastly, a dynamic graph constructor is proposed to model not only the time-specific spatial dependencies between nodes, but also the changing temporal interactions between time slots to discover dynamic relations from data thoroughly. Experimental results on four real-world datasets show that GDGCN not only outperforms state-of-the-art methods, but also obtains interpretable dynamic spatial relations of segments. Codes are available at https://anonymous.4open.science/r/GDGCN. © 2023 Elsevier B.V.","Graph Convolutional Network; Parameter sharing; Temporal graph convolution; Traffic forecasting"
"When CLIP meets cross-modal hashing retrieval: A new strong baseline","2023","Information Fusion","10.1016/j.inffus.2023.101968","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168807202&doi=10.1016%2fj.inffus.2023.101968&partnerID=40&md5=2c9e4545e66fd3f7c24cc2b76ff1a921","Recent days witness significant progress in various multi-modal tasks made by Contrastive Language-Image Pre-training (CLIP), a multi-modal large-scale model that learns visual representations from natural language supervision. However, the potential effects of CLIP on cross-modal hashing retrieval has not been investigated yet. In this paper, we for the first time explore the effects of CLIP on cross-modal hashing retrieval performance and propose a simple but strong baseline Unsupervised Contrastive Multi-modal Fusion Hashing network (UCMFH). We first extract the off-the-shelf visual and linguistic features from the CLIP model, as the input sources for cross-modal hashing functions. To further mitigate the semantic gap between the image and text features, we design an effective contrastive multi-modal learning module that leverages a multi-modal fusion transformer encoder supervising by a contrastive loss, to enhance modality interaction while improving the semantic representation of each modality. Furthermore, we design a contrastive hash learning module to produce high-quality modal-correlated hash codes. Experiments show that significant performance improvement can be made by our simple new unsupervised baseline UCMFH compared with state-of-the-art supervised and unsupervised cross-modal hashing methods. Also, our experiments demonstrate the remarkable performance of CLIP features on cross-modal hashing retrieval task compared to deep visual and linguistic features used in existing state-of-the-art methods. The source codes for our approach is publicly available at: https://github.com/XinyuXia97/UCMFH. © 2023 The Authors","CLIP; Contrastive learning; Cross-modal retrieval; Hashing; Modality fusion"
"Context-aware deep learning with dynamically assembled weight matrices","2023","Information Fusion","10.1016/j.inffus.2023.101908","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85165009856&doi=10.1016%2fj.inffus.2023.101908&partnerID=40&md5=69229a45eee8437b5f30d15f78890512","Deep neural networks are static by nature, meaning they use a single set of parameters to process each data sample. However, for more complex and larger systems, for which samples can be obtained under a large variety of circumstances, a need for more dynamic networks that adapt to these variations seems apparent. To this end, the concept of context information and its integration in deep learning is considered. Contrary to current practices, that treat all modalities as equally informative to the decision process, contextual and feature information is considered to be vastly different in nature. A set of definitions and subsequent arguments are given in order to provide the necessary clarification regarding the interpretation of context with the purpose of using all information in a maximally efficient way. From this interpretation, a problem statement of context aware deep learning is constructed and consequently linked to its multiple model and transfer learning solutions. These solutions, however, are in-efficient since samples are spread across models. Based on the existence of this multiple model solution, a new approach, which integrates contextual information directly into a single context-dependent model, is proposed. This single model uses weight matrices that are dynamically assembled based on the contextual information to process each data sample individually. This allows for the single model to consume and learn from all samples. The corresponding training routine is constructed and evaluated on multiple benchmark problems. We start with an artificially generated problem on which the methods’ ability to model multiple linear classification problems concurrently is confirmed. Next, both a time series forecasting and image classification dataset are used for evaluation. Evaluations of our proposed method are done and compared to standard context aware implementations based on concatenation and gating. These standard methods implement context information by adding additional parameters in order to try modeling all interactions between the context information and the samples. However, our proposed approach integrates the contextual information directly into the network weights, allowing parameter efficient modeling of dynamic contextual behavior. In both cases the proposed solution outperforms its standard counterparts with significant margins in both evaluation metrics and parameter efficiency. Specifically, a mean absolute error improvement of eleven standard deviations and an eight percent increase in classification accuracy, for the forecasting and image classification problems respectively, is observed, showing the potential of our approach. © 2023","Context; Deep learning; Dynamic neural networks; Singular value decomposition"
"Multimodal feature fusion for illumination-invariant recognition of abnormal human behaviors","2023","Information Fusion","10.1016/j.inffus.2023.101949","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85166266617&doi=10.1016%2fj.inffus.2023.101949&partnerID=40&md5=cf8e295f1874135631ba0831b2662431","This paper presents a fusion of feature maps extracted from visible and thermal infrared surveillance videos to recognize abnormal human behaviors in low illumination conditions. Abnormal human behaviors often occur at night or in darkness, where a visible camera alone may not capture sufficient visual information for analysis. The proposed scheme uses additional data captured by a thermal infrared camera to enhance information on human appearance and motion. Thermal and visible data are assumed to be informative for analyzing human behaviors, yet they contribute differently to certain areas of video frames. This paper proposes a multimodal feature fusion (MFF) to produce a weight matrix that determines how much thermal or visible input should contribute to obtain optimal performance. Experiment results demonstrate that MFF effectively recognizes abnormal human behaviors in darkness. MFF achieves an overall accuracy of 91.01%, which is at least 4.53% higher than individual thermal or visible data and 2.17% higher than the state-of-the-art fusion-based abnormal human behavior recognition techniques. © 2023 Elsevier B.V.","Human behavior recognition; Multimodal feature fusion; Thermal and visible imaging"
"A novel Out-of-Distribution detection approach for Spiking Neural Networks: Design, fusion, performance evaluation and explainability","2023","Information Fusion","10.1016/j.inffus.2023.101943","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85169930989&doi=10.1016%2fj.inffus.2023.101943&partnerID=40&md5=591d007a60e9ab9afe3cb1fda2ea9eed","Research around Spiking Neural Networks has ignited during the last years due to their advantages when compared to traditional neural networks, including their efficient processing and inherent ability to model complex temporal dynamics. Despite these differences, Spiking Neural Networks face similar issues than other neural computation counterparts when deployed in real-world settings. This work addresses one of the practical circumstances that can hinder the trustworthiness of this family of models: the possibility of querying a trained model with samples far from the distribution of its training data (also referred to as Out-of-Distribution or OoD data). Specifically, this work presents a novel OoD detector that can identify whether test examples input to a Spiking Neural Network belong to the distribution of the data over which it was trained. For this purpose, we characterize the internal activations of the hidden layers of the network in the form of spike count patterns, which lay a basis for determining when the activations induced by a test instance is atypical. Furthermore, a local explanation method is devised to produce attribution maps revealing which parts of the input instance push most towards the detection of an example as an OoD sample. Experimental results are performed over several classic and event-based image classification datasets to compare the performance of the proposed detector to that of other OoD detection schemes from the literature. Our experiments also assess whether the fusion of our proposed approach with other baseline OoD detection schemes can complement and boost the overall OoD detection capability As the obtained results clearly show, the proposed detector performs competitively against such alternative schemes, and when fused together, can significantly improve the detection scores of their constituent individual detectors. Furthermore, the explainability technique associated to our proposal is proven to produce relevance attribution maps that conform to expectations for synthetically created OoD instances. © 2023 Elsevier B.V.","Explainable artificial intelligence; Model fusion; Out-of-Distribution detection; Relevance attribution; Spiking Neural Networks"
"OTFPF: Optimal transport based feature pyramid fusion network for brain age estimation","2023","Information Fusion","10.1016/j.inffus.2023.101931","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85165534154&doi=10.1016%2fj.inffus.2023.101931&partnerID=40&md5=c6242c6216e3d732128220e5aa62ad53","Deep neural networks have shown promise in predicting the chronological age of a healthy brain using T1-weighted magnetic resonance images (T1 MRIs). This predicted brain age has the potential to serve as a valuable biomarker for identifying development-related and aging-related disorders. In this study, we propose the Optimal Transport based Feature Pyramid Fusion (OTFPF) network for estimating brain age using T1 MRIs. The OTFPF network comprises three key modules: the Optimal Transport based Feature Pyramid Fusion (OTFPF) module, the 3D overlapped ConvNeXt (3D OL-ConvNeXt) module, and the fusion module. These modules enhance the OTFPF network's ability to comprehend the semi-multimodal and multi-level feature pyramid information of each brain, thereby improving its understanding of brain development and aging. Compared to recent state-of-the-art models, the proposed OTFPF network demonstrates faster convergence, superior performance, and enhanced interpretability. Experimental results utilizing a dataset of 12,909 MRIs from individuals aged 3–97 years demonstrate the accurate estimation of brain age by the OTFPF network, achieving a mean absolute error (MAE) of 1.846, Pearson's correlation coefficient (PCC) of 0.9941, and Spearman's rank correlation coefficient (SRCC) of 0.9802. Thorough parameter evaluations, quantitative comparison experiments, dataset-scale evaluations, cross-validations, and ablation studies convincingly demonstrate the stability, interpretability, and superiority of the OTFPF network. According to the OTFPF network, the age-related heatmaps of the brain explain the biological mechanisms underlying brain aging. Furthermore, the OTFPF network is applied to analyze datasets associated with brain disorders, effectively demonstrating its practical utility. © 2023","Brain age estimation; Deep learning; Feature pyramid fusion; Optimal transport"
"Automated scholarly paper review: Concepts, technologies, and challenges","2023","Information Fusion","10.1016/j.inffus.2023.101830","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85160737382&doi=10.1016%2fj.inffus.2023.101830&partnerID=40&md5=547b3d2e0bbc9861810946da3cfe42b2","Peer review is a widely accepted mechanism for research evaluation, playing a pivotal role in academic publishing. However, criticisms have long been leveled at this mechanism, mostly because of its poor efficiency and low reproducibility. Recent years have seen the application of artificial intelligence (AI) in assisting the peer review process. Nonetheless, with the involvement of humans, such limitations remain inevitable. In this paper, we propose the concept and pipeline of automated scholarly paper review (ASPR) and review the relevant literature and technologies of achieving a full-scale computerized review process. On the basis of the review and discussion, we conclude that there is already corresponding research and preliminary implementation at each stage of ASPR. We further look into the challenges in ASPR with the existing technologies. The major difficulties lie in inadequate data, imperfect document parsing and representation, defective human–computer interaction, and flawed deep logical reasoning. Moreover, we point out the future directions and discuss the possible moral and ethical issues of ASPR. In the foreseeable future, ASPR and peer review will coexist in a reinforcing manner before ASPR is able to fully undertake the reviewing workload from humans. © 2023 Elsevier B.V.","Academic publishing; Artificial intelligence; Automated scholarly paper review; Natural language processing; Peer review"
"Learning from the global view: Supervised contrastive learning of multimodal representation","2023","Information Fusion","10.1016/j.inffus.2023.101920","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85166002532&doi=10.1016%2fj.inffus.2023.101920&partnerID=40&md5=8a2d376316bf6121415880255026d946","The development of technology enables the availability of abundant multimodal data, which can be utilized in many representation learning tasks. However, most methods ignore the rich modality correlation information stored in each multimodal object and fail to fully exploit the potential of multimodal data. To address the aforementioned issue, cross-modal contrastive learning methods are proposed to learn the similarity score of each modality pair in a self-/weakly-supervised manner and improve the model robustness. Though effective, contrastive learning based on unimodal representations might be, in some cases, inaccurate as unimodal representations fail to reveal the global information of multimodal objects. To this end, we propose a contrastive learning pipeline based on multimodal representations to learn from the global view, and devise multiple techniques to generate negative and positive samples for each anchor. To generate positive samples, we apply the mix-up operation to mix two multimodal representations of different objects that have the maximal label similarity. Moreover, we devise a permutation-invariant fusion mechanism to define the positive samples by permuting the input order of modalities for fusion and sampling various contrastive fusion networks. In this way, we force the multimodal representation to be invariant regarding the order of modalities and the structures of fusion networks, so that the model can capture high-level semantic information of multimodal objects. To define negative samples, for each modality, we randomly replace the unimodal representation with that from another dissimilar object when synthesizing the multimodal representation. By this means, the model is led to capture the high-level concurrence information and correspondence relationship between modalities within each object. We also directly define the multimodal representation from another object as a negative sample, where the chosen object shares the minimal label similarity with the anchor. The label information is leveraged in the proposed framework to learn a more discriminative multimodal embedding space for downstream tasks. Extensive experiments demonstrate that our method outperforms previous state-of-the-art baselines on the tasks of multimodal sentiment analysis and humor detection. © 2023 Elsevier B.V.","Contrastive learning; Multimodal humor detection; Multimodal representation learning; Multimodal sentiment analysis"
"Smooth representation learning from multi-view data","2023","Information Fusion","10.1016/j.inffus.2023.101916","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85170059645&doi=10.1016%2fj.inffus.2023.101916&partnerID=40&md5=39c78b74af01f7674114424e3b8988f6","Multi-view subspace clustering has aroused more and more attention due to its ability to explore data correlation from multiple views without stressful label annotations. Although a plethora of methods have been developed, they are powerless considering the original data may not be separable into subspaces. In this paper, we target to achieve a smooth representation from multi-view data which is committed to facilitating the downstream clustering task. Our assumption is that samples in the same cluster always tend to be densely connected. In detail, the proposed method can maintain the graph geometric structure by performing graph filtering to obtain the smooth representation. Furthermore, we unify the smooth representation learning and the subsequent multi-view clustering in a joint framework, hence the “multi-view clustering-friendly” representation can be expected. As a result, the smooth representation learning of each view and the achieving of multi-view clustering can be boosted in a mutual reinforcement manner towards an overall optimal solution. Extensive experiments on common multi-view datasets are conducted to demonstrate the effectiveness of our mode, compared to other SOTAs over the clustering performance. © 2023 Elsevier B.V.","Graph filtering; Multi-view learning; Smooth representation; Subspace clustering"
"MEGACare: Knowledge-guided multi-view hypergraph predictive framework for healthcare","2023","Information Fusion","10.1016/j.inffus.2023.101939","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85166338703&doi=10.1016%2fj.inffus.2023.101939&partnerID=40&md5=b8e75fc08489666f54df85c5ef6871a9","Predicting a patient's future health condition by analyzing their Electronic Health Records (EHRs) is a trending subject in the intelligent medical field, which can help clinicians prescribe safely and effectively, and also make more accurate diagnoses. Benefiting from powerful feature extraction capabilities, graph representation learning can capture complex relationships and achieve promising performance in many clinical prediction tasks. However, existing works either exclusively consider single domain knowledge with an independent task or do not fully capitalize on domain knowledge that can provide more predictive signals in the code encoding stage. Moreover, the heterogeneous and high-dimensional nature of EHR data leads to a deficiency of hardly encoding implicit high-order correlations. To address these limitations, we proposed a knowledge-guided Multi-viEw hyperGrAph predictive framework (MEGACare) for diagnosis prediction and medication recommendation. Our MEGACare leveraged multi-faceted medical knowledge, including ontology structure, code description, and molecular information to enhance medical code presentations. Furthermore, we constructed an EHR hypergraph and a multi-view learning framework to capture the high-order correlation between patient visits and medical codes. Specifically, we propose three perspectives around the pairwise relationship between patient visits and medical codes to comprehensively learn patient representation and enhance the robustness of our framework. We evaluated our MEGACare framework against a set of state-of-the-art methods for two clinical outcome prediction tasks in the public MIMIC-III dataset, and the results showed that our proposed framework was superior to the baseline methods.1 © 2023 Elsevier B.V.","Electronic health record; Healthcare; Hypergraph; Information bottleneck; Multi-view learning"
"Semi-supervised attribute reduction based on label distribution and label irrelevance","2023","Information Fusion","10.1016/j.inffus.2023.101951","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85169807140&doi=10.1016%2fj.inffus.2023.101951&partnerID=40&md5=992beb1ec6e30a1574fe2be29e213b46","Attribute reduction in partially labeled data, also called semi-supervised attribute reduction, is an important issue. In recent years, the research on semi-supervised attribute reduction has attracted the attention of many scholars. Unfortunately, most existing semi-supervised attribute reduction methods do not handle the information loss caused by missing labels well. Meanwhile, these methods in general only consider the relevance between attributes and labels to measure attribute correlations, which ignores the irrelevant information contained in the attributes with respect to the labels. In view of this, this paper proposes a novel semi-supervised attribute reduction algorithm considering attribute relevance, redundancy and label irrelevance from the perspective of label distribution. Firstly, the membership degree of unlabeled objects relative to labels is defined by fuzzy similarity relation, which implements information restoration and converts partially labeled data into label distribution data. Secondly, some fuzzy uncertainty measures for label distribution are defined and related properties are investigated accordingly. Additionally, considering that irrelevant information brought by attributes may lead to over-fitting, label irrelevance criterion based on fuzzy uncertainty measures is constructed. Thirdly, a novel semi-supervised attribute reduction algorithm via the maximum relevance, minimum redundancy, and minimum irrelevance is proposed. Finally, compared with the representative semi-supervised attribute reduction algorithms and supervised attribute reduction algorithm, the effectiveness of the proposed algorithm is verified by various experiments. © 2023 Elsevier B.V.","Attribute reduction; Fuzzy similarity relation; Label distribution; Label irrelevance; Semi-supervised"
"SKEAFN: Sentiment Knowledge Enhanced Attention Fusion Network for multimodal sentiment analysis","2023","Information Fusion","10.1016/j.inffus.2023.101958","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85167455472&doi=10.1016%2fj.inffus.2023.101958&partnerID=40&md5=6ccebb5990541d3695d4afa240e42aba","Multimodal sentiment analysis is an active research field that aims to recognize the user's sentiment information from multimodal data. The primary challenge in this field is to develop a high-quality fusion framework that effectively addresses the heterogeneity among different modalities. However, prior research has primarily concentrated on intermodal interactions while neglecting the semantic sentiment information conveyed by words in the text modality. In this paper, we propose the Sentiment Knowledge Enhanced Attention Fusion Network (SKEAFN), a novel end-to-end fusion network that enhances multimodal fusion by incorporating additional sentiment knowledge representations from an external knowledge base. Firstly, we construct an external knowledge enhancement module to acquire additional representations for the text modality. Then, we design a text-guided interaction module that facilitates the interaction between text and the visual/acoustic modality. Finally, we propose a feature-wised attention fusion module that achieves multimodal fusion by dynamically adjusting the weights of the additional and each modality's representations. We evaluate our method on three challenging multimodal sentiment analysis datasets: CMU-MOSI, CMU-MOSEI, and Twitter2019. The experiment results demonstrate that our model significantly outperforms the state-of-the-art models. The source code is publicly available at https://github.com/doubibobo/SKEAFN. © 2023 Elsevier B.V.","External knowledge; Multi-head attention; Multi-view learning; Multimodal sentiment analysis; Multiple feature fusion"
"A two-stage consensus model for large-scale group decision-making considering dynamic social networks","2023","Information Fusion","10.1016/j.inffus.2023.101972","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168306039&doi=10.1016%2fj.inffus.2023.101972&partnerID=40&md5=9cd5689ed65e073f502b0f711396f84b","Clustering and the feedback mechanism in a consensus reaching process (CRP) have been regarded as two critical components when solving the large-scale group decision-making (LSGDM) problem. However, the necessity of treating decision makers (DMs) as a dynamic social network (in terms of their trust relationships) in the DM clustering has not been fully investigated. Also, with people's increased democratic awareness, it appears essential to consider the individual's willingness to cooperate when designing the feedback mechanism in the CRP. This study will focus on solving the LSGDM problem considering dynamic social networks and propose a novel two-stage consensus model. First, a hybrid trust network is built to dynamically represent social relationships among DMs (i.e., the hybrid trust network evolves with the CRP). Spectral clustering algorithm is then used to cluster DMs into more trusted sub-groups, thus improving the efficiency of coordinating DMs. Second, a two-stage feedback mechanism is designed to help DMs reach a consensus in a more human-centric manner. To reach a consensus without seriously violating the willingness of DMs, we strike a balance between maximizing the consensus degree and minimizing the adjustment cost and further develop two nonlinear programming models to provide modification suggestions for sub-groups and individuals, respectively. The originality of the proposed consensus model can be summarized as clustering the dynamic hybrid trust network integrated with balancing the decision-making efficiency against the willingness of DMs to cooperate. The feasibility and effectiveness of the developed model are demonstrated through the detailed application study. © 2023 Elsevier B.V.","consensus reaching; dynamic social networks; Large-scale group decision-making; spectral clustering; willingness to cooperate"
"Flexible Adaptive Graph Embedding for Semi-supervised Dimension Reduction","2023","Information Fusion","10.1016/j.inffus.2023.101872","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85163037133&doi=10.1016%2fj.inffus.2023.101872&partnerID=40&md5=47cca1972ed786b884ff8c22451962d5","Graph-based semi-supervised dimension reduction can use the inherent graph structure of samples to propagate label information, and has become a hot research field in machine learning. However, most current methods have strict linear constraints and cannot handle data sampled from nonlinear manifolds; and rely on predefined graphs, which cannot capture the local structure information of data and cannot handle complex non-Gaussian data. To address these issues, this paper proposes a new locality-preserved flexible dimension reduction framework, called Semi-supervised Flexible Adaptive Graph Embedding (SFAG), which learns the embedding space that can preserve the local neighborhood structure by constructing a k1-nearest neighbor graph over labeled samples. Then, another k2-nearest neighbor graph is constructed on all samples to adaptively construct the optimal graph, clustering labeled and unlabeled embedding sample points with neighborhood relations into the same sub-manifold sharing the same label information. Last but not least, the hard linear projection constraint is relaxed by adding residual terms to obtain not only the nonlinear embedding of the training samples, but also the linear projection matrix applied directly to the out-of-sample. In addition, two different semi-supervised dimension reduction methods for adaptive construction of optimal graphs are proposed based on the SFAG framework. Several evaluation experiments validate the effectiveness of our method in exploring manifold structures and classification tasks. © 2023 Elsevier B.V.","Adaptive neighbors; Flexible projection; Graph embedding; Semi-supervised dimension reduction; Subspace learning"
"On the notion of fuzzy dispersion measure and its application to triangular fuzzy numbers","2023","Information Fusion","10.1016/j.inffus.2023.101905","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85165059080&doi=10.1016%2fj.inffus.2023.101905&partnerID=40&md5=8f23fd3986661ded9e52acdcc2426beb","In this paper, based on the analysis of the most widely used dispersion measure in the real context (namely, the variance), we introduce the notion of fuzzy dispersion measure associated to a finite set of data given by fuzzy numbers. This measure is implemented as a fuzzy number, so there is no loss of information caused by any defuzzification. The proposed concept satisfies the usual properties in a genuinely fuzzy sense and it avoids limitations in terms of its geometric shape or its analytical properties: under this conception, it could have a piece of its support in the negative part of the real line. This novel notion can be interpreted as a way of fusing the information included in a fuzzy data set in order to make a decision based on its dispersion. To illustrate the main characteristics of this approach, we present an example of a fuzzy dispersion measure that allows to conclude that this new way to deal this problem is coherent, at least, from the point of view of human intuition. © 2023 The Author(s)","Decision making; Dispersion measure; Fuzzy number; Fuzzy set; Variance"
"FL-FD: Federated learning-based fall detection with multimodal data fusion","2023","Information Fusion","10.1016/j.inffus.2023.101890","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85165233215&doi=10.1016%2fj.inffus.2023.101890&partnerID=40&md5=c1d05b5fc23c0ae6d6d7ae6f0eaa18dd","Multimodal data fusion is a critical element of fall detection systems, as it provides more comprehensive information than single-modal data. Yet, data heterogeneity between sources has posed a challenge for the effective fusion of such data. This paper proposes a novel multimodal data fusion method under a federated learning (FL) framework that addresses the privacy concerns of users while exploiting the complementarity of such data. Specifically, we fuse time-series data from wearable sensors and visual data from cameras at the input level, where the data is first transformed into images using the Gramian Angular Field (GAF) method. Moreover, each user is treated as a private client in the FL system whereby the fall detection model is trained without requiring the sharing of user data. The proposed method is evaluated using the UP-Fall dataset, where we perform different fall detection tasks: binary classification for fall and non-fall detection yields a remarkable accuracy of 99.927%, while multi-classification for different fall activity recognition attains an accurate result of 89.769%. © 2023 Elsevier B.V.","Data fusion; Fall detection; Federated learning; IoMT; Multimodal data fusion"
"Explainability meets uncertainty quantification: Insights from feature-based model fusion on multimodal time series","2023","Information Fusion","10.1016/j.inffus.2023.101955","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85169791871&doi=10.1016%2fj.inffus.2023.101955&partnerID=40&md5=8adfeeb4f3b4d626f8eca443f791e483","Feature importance evaluation is one of the prevalent approaches to interpreting Machine Learning (ML) models. A drawback of using these methods for high-dimensional datasets is that they often lead to high-dimensional explanation output that hinders human analysis. This is especially true for explaining multimodal ML models, where the problem's complexity is further exacerbated by the inclusion of multiple data modalities and an increase in the overall number of features. This work proposes a novel approach to lower the complexity of feature-based explanations. The proposed approach is based on uncertainty quantification techniques, allowing for a principled way of reducing the number of modalities required to explain the model's predictions. We evaluated our method in three multimodal datasets comprising physiological time series. Results show that the proposed method can reduce the complexity of the explanations while maintaining a high level of accuracy in the predictions. This study illustrates an innovative example of the intersection between the disciplines of uncertainty quantification and explainable artificial intelligence. © 2023 The Author(s)","Complexity; Explainable AI; Feature-based explanations; Multimodal; SHAP; Uncertainty quantification"
"M-FCCL: Memory-based concept-cognitive learning for dynamic fuzzy data classification and knowledge fusion","2023","Information Fusion","10.1016/j.inffus.2023.101962","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168544020&doi=10.1016%2fj.inffus.2023.101962&partnerID=40&md5=e2a698b0653e33de4a67de6c40d95220","Concept-cognitive learning (CCL) is an emerging field for studying the representation and processing of knowledge embedded in data. Many efforts are focused on this field due to the interpretability and effectiveness of the formal concept (not pseudo concept). However, the standard CCL methods cannot tackle continuous data directly. Although the current fuzzy-based CCL (FCCL) is a straightforward approach to discovering the knowledge embedded in continuous data, it does not sufficiently utilize the native advantage of concepts in simulating the cognitive mechanism. Then it causes it to be incomplete and complex cognition. Inspired by the memory mechanism, this paper combines the recalling and forgetting mechanisms with CCL, called memory-based concept-cognitive learning (M-FCCL). Specifically, a cosine measure is introduced to describe the relationship of samples and construct cosine-similar granules to learn the concept. Subsequently, a fuzzy three-way concept based on the cosine similar granules is defined to represent and discover knowledge. Furthermore, two memory mechanisms are borrowed for the process of concept cognition for dynamic data classification and knowledge fusion: concept-recalling can enhance the effectiveness of concept learning, and concept-forgetting can effectively reduce the complexity of concept cognition. Finally, some experiments are compared with other methods on 16 benchmark datasets to show that M-FCCL achieves superior performance. Specifically, on these datasets, the proposed M-FCCL method achieves 17.02% and 18.54% classification accuracy gain compared with some advanced CCL mechanisms and popular classification methods. © 2023 Elsevier B.V.","Concept-cognitive learning; Dynamic data classification; Granular computing; Knowledge fusion; Three-way decision"
"Computational approaches to Explainable Artificial Intelligence: Advances in theory, applications and trends","2023","Information Fusion","10.1016/j.inffus.2023.101945","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85166914338&doi=10.1016%2fj.inffus.2023.101945&partnerID=40&md5=a3a4fa082936e04744d376af77301df3","Deep Learning (DL), a groundbreaking branch of Machine Learning (ML), has emerged as a driving force in both theoretical and applied Artificial Intelligence (AI). DL algorithms, rooted in complex and non-linear artificial neural systems, excel at extracting high-level features from data. DL has demonstrated human-level performance in real-world tasks, including clinical diagnostics, and has unlocked solutions to previously intractable problems in virtual agent design, robotics, genomics, neuroimaging, computer vision, and industrial automation. In this paper, the most relevant advances from the last few years in Artificial Intelligence (AI) and several applications to neuroscience, neuroimaging, computer vision, and robotics are presented, reviewed and discussed. In this way, we summarize the state-of-the-art in AI methods, models and applications within a collection of works presented at the 9th International Conference on the Interplay between Natural and Artificial Computation (IWINAC). The works presented in this paper are excellent examples of new scientific discoveries made in laboratories that have successfully transitioned to real-life applications. © 2023 The Author(s)","Biomedical applications; Computational approaches; Computer-aided diagnosis systems; Data science; Deep learning; Explainable Artificial Intelligence; Machine learning; Neuroscience; Robotics"
"Multi-granularity fusion resource allocation algorithm based on dual-attention deep reinforcement learning and lifelong learning architecture in heterogeneous IIoT","2023","Information Fusion","10.1016/j.inffus.2023.101871","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85161667062&doi=10.1016%2fj.inffus.2023.101871&partnerID=40&md5=4f02a9677504d3d4db95dcdcc4af7e24","Deep reinforcement learning (DRL) is a promising technology to address the resource allocation problem for efficient data transmission in complex network environments. However, most DRL-based resource allocation algorithms suffer from limited feature extraction capabilities and lack scalability and generalization, especially in heterogeneous Industrial Internet of Things (IIoT) environments. In this paper, we develop a lifelong learning architecture that can integrate artificial intelligence (AI) algorithms into the heterogeneous IIoT network for efficient data transmission. Based on this, we propose an intelligent resource allocation algorithm based on dual-attention DRL (DADR) for forwarding node selection and channel access slot allocation in a specific network environment. The proposed DADR algorithm combines the advantages of multi-dimension convolutional attention and multi-head self-attention mechanisms. It can provide local- and global-feature fusion capabilities for distributed nodes while maximizing the performance of data transmission. Furthermore, we present a lifelong federated meta reinforcement learning (LFMRL) that can effectively utilize prior knowledge and enable the DRL agent quickly adapt to a new environment. Specifically, LFMRL adopts a federated meta learning-based knowledge fusion algorithm to fuse the knowledge of learned DADR algorithms and iteratively update the shared model, thereby improving the scalability and generalization of the shared model in heterogeneous IIoT environments. In addition, a simple and efficient knowledge transfer mechanism is enabled to accelerate the DRL model convergence by transferring the knowledge of the shared model to the new environment. Simulation results demonstrate the effectiveness of the proposed algorithms in terms of energy efficiency, data transmission reliability, and network stability. Compared to DADR and FedAvg algorithms, LFMRL algorithm can further reduce the energy consumption, training time, and average forwarding node switching times, while improving packet delivery rate to 99.2%. © 2023 Elsevier B.V.","Deep reinforcement learning; Federated meta learning; Heterogeneous industrial Internet of Things; Lifelong learning; Resource allocation"
"Two improved N-two-stage K-means clustering aggregation algorithmic paradigms for HFLTS possibility distributions","2023","Information Fusion","10.1016/j.inffus.2023.101964","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85167820780&doi=10.1016%2fj.inffus.2023.101964&partnerID=40&md5=75009de0b8ca1d22959fae0e208fb4c7","The available method based on statistical principles for aggregating hesitant fuzzy linguistic term set (HFLTS) possibility distribution is the N-two-stage algorithmic aggregation paradigm driven by the K-means clustering (N2S-KMC). Nonetheless, the N2S-KMC method is subject to two significant limitations. (i) The grouping technique is capable of effectively partitioning decision-making information into N groups. However, it does not determine the appropriate placement of members within each group, as the number of computations is dependent on the number of elements present in each group, rather than the elements themselves. (ii) The initial clustering centers of K-means clustering are chosen without adhering to the distribution law within the aggregated hesitant 2-tuple linguistic terms set (H2TLTS) possibility distribution. This may result in a reduction in the clustering performance. In order to address the aforementioned limitations, we suggest two enhancement techniques for the former. Firstly, we propose the utilization of the minimum average difference (MAD) method to ascertain the number of groups. This approach aims to reduce the time required for the initial stage of aggregation following grouping. Secondly, we recommend the implementation of the maximize compactness degree of inter-group grouping (MCDIGG) method. This method enables the identification of group members, resulting in a more concentrated distribution of data subsequent to grouping. The present study suggests the utilization of MAD and MCDIGG techniques as a substitute for the grouping approach in the N2S-KMC model. This leads to the development of a new algorithm, IN2S-DO-KMC, wherein the data is partitioned into K subsets in a descending order to determine the initial center for KMC. Furthermore, with respect to the issue present in the subsequent phase, we propose the utilization of the density canopy (DC) algorithm to perform pre-clustering of the data and produce the initial clustering center and the quantity of clusters for the K-means algorithm. Subsequently, a refined version of the N2S-KMC model, denoted as IN2S-DC-KMC, has been suggested. Ultimately, an empirical study is conducted to assess the validity and practicability of the proposed framework for evaluating failure modes in medical devices. The outcomes are evaluated with regards to the efficacy of the algorithm, the numerical dispersion, and the pragmatic ramifications. © 2023 Elsevier B.V.","Aggregation paradigm; Computing with words; Hesitant fuzzy linguistic term sets; Information fusion; K-means clustering"
"UNTIE: Clustering analysis with disentanglement in multi-view information fusion","2023","Information Fusion","10.1016/j.inffus.2023.101937","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85165908089&doi=10.1016%2fj.inffus.2023.101937&partnerID=40&md5=6271c9f1441ca4eb63fb419d1aed9b8c","Multi-view clustering focuses on exploring cluster structures among multiple views and is an effective approach to achieve multi-view information fusion without requiring label supervision. However, multiple views’ useful and meaningless information usually is entangled and the latter might cause negative influences in the fusion process. In this paper, we research the interpretability for different information in multiple views and propose a novel method (termed UNTIE) to address their entanglement. Specifically, in UNTIE, discrete view-common variable is introduced to explore all views’ common information, and continuous view-private variables are introduced to learn individual views’ private information. In this way, the learned representations are disentangled and interpretable where each variable represents a single factor among multi-view data. Then, the useful information in disentangled view-common and view-private representations are leveraged to conduct comprehensive multi-view clustering, making UNTIE can explore common and complementary information from multiple views while obtaining the robustness to meaningless information. Finally, UNTIE has the ability to controllably generate samples and extensive experiments demonstrate its superior representation ability and clustering performance. © 2023 Elsevier B.V.","Clustering analysis; Interpretability of multi-view learning; Multi-view disentangled representation learning"
"Explainable Artificial Intelligence (XAI): What we know and what is left to attain Trustworthy Artificial Intelligence","2023","Information Fusion","10.1016/j.inffus.2023.101805","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159601901&doi=10.1016%2fj.inffus.2023.101805&partnerID=40&md5=4ab083e2f6a076ba5601fd040b4afa41","Artificial intelligence (AI) is currently being utilized in a wide range of sophisticated applications, but the outcomes of many AI models are challenging to comprehend and trust due to their black-box nature. Usually, it is essential to understand the reasoning behind an AI model's decision-making. Thus, the need for eXplainable AI (XAI) methods for improving trust in AI models has arisen. XAI has become a popular research subject within the AI field in recent years. Existing survey papers have tackled the concepts of XAI, its general terms, and post-hoc explainability methods but there have not been any reviews that have looked at the assessment methods, available tools, XAI datasets, and other related aspects. Therefore, in this comprehensive study, we provide readers with an overview of the current research and trends in this rapidly emerging area with a case study example. The study starts by explaining the background of XAI, common definitions, and summarizing recently proposed techniques in XAI for supervised machine learning. The review divides XAI techniques into four axes using a hierarchical categorization system: (i) data explainability, (ii) model explainability, (iii) post-hoc explainability, and (iv) assessment of explanations. We also introduce available evaluation metrics as well as open-source packages and datasets with future research directions. Then, the significance of explainability in terms of legal demands, user viewpoints, and application orientation is outlined, termed as XAI concerns. This paper advocates for tailoring explanation content to specific user types. An examination of XAI techniques and evaluation was conducted by looking at 410 critical articles, published between January 2016 and October 2022, in reputed journals and using a wide range of research databases as a source of information. The article is aimed at XAI researchers who are interested in making their AI models more trustworthy, as well as towards researchers from other disciplines who are looking for effective XAI methods to complete tasks with confidence while communicating meaning from data. © 2023 The Author(s)","AI principles; Data Fusion; Deep Learning; Explainable Artificial Intelligence; Interpretable machine learning; Post-hoc explainability; Trustworthy AI; XAI assessment"
"QNMF: A quantum neural network based multimodal fusion system for intelligent diagnosis","2023","Information Fusion","10.1016/j.inffus.2023.101913","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85165445106&doi=10.1016%2fj.inffus.2023.101913&partnerID=40&md5=952bbee1e4de26bc4c3236f888c69485","The Internet of Medical Things (IoMT) has emerged as a significant research area in the medical field, enabling the transmission of various types of data to the cloud for analysis and diagnosis. Fusing data from multiple modalities can enhance accuracy but requires substantial computing power. Theoretically, quantum computers can rapidly process large volumes of high-dimensional medical data. Despite accelerated developments in quantum computing, research on quantum machine learning (QML) for multimodal data processing remains limited. Considering these factors, this paper presents a quantum neural network-based multimodal fusion system for intelligent diagnosis (QNMF) that can process multimodal medical data transmitted by IoMT devices, fuse data from different modalities, and improve the performance of intelligent diagnosis. This system employs a quantum convolutional neural network (QCNN) to efficiently extract features from medical images. These QCNN-based features are then fused with other modality features (such as blood test results or breast cell slices), and used to train an effective variational quantum classifier (VQC) for intelligent diagnosis. The experimental results demonstrate that a QCNN can effectively extract image data features. Furthermore, QNMF achieved an accuracy of 97.07% and 97.61% on breast cancer diagnosis and Covid-19 diagnosis experiments, respectively. In addition, the QNMF exhibits strong quantum noise robustness. © 2023 Elsevier B.V.","Internet of medical things; Multimodal fusion; Quantum neural network; Smart healthcare"
"Causal knowledge fusion for 3D cross-modality cardiac image segmentation","2023","Information Fusion","10.1016/j.inffus.2023.101864","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85162135922&doi=10.1016%2fj.inffus.2023.101864&partnerID=40&md5=dc80217299d6d83310f4a99ae83ac97c","Three-dimensional (3D) cross-modality cardiac image segmentation is critical for cardiac disease diagnosis and treatment. However, it confronts the challenge of modality-specific spatial confounding. This challenge derives from the entanglement between the anatomical factor and the modality factor in space. It hurts the inference about the causality between the 3D cardiac image and the predicted label. The challenge is exacerbated by the modality distribution discrepancy and the slice structure discrepancy. The existing cross-modality segmentation methods are difficult to address this challenge due to the lack of causality. In this paper, we propose the causal knowledge fusion (CKF) framework to solve the above challenge. First, the CKF explores the causal intervention to obtain the anatomical factor and discard the modality factor. The anatomical factor is the causal invariant representation that transfers between different modalities. Thus, the CKF improves the information fusion on different imaging modalities. Second, the CKF proposes the 3D hierarchical attention mechanism to extract the multi-scale information from 3D cardiac image. It improves the spatial learning ability on 3D anatomical structure. Extensive experiments on 3D cardiac image of 503 MR patients and 518 CT patients show that the CKF is effective (Dice > 0.949), and superior to eighteen state-of-the-art segmentation methods. © 2023 Elsevier B.V.","3D cardiac image, Cross-modality segmentation, Causal learning, Causal invariant representation, Causal knowledge fusion"
"Information fusion for multi-scale data: Survey and challenges","2023","Information Fusion","10.1016/j.inffus.2023.101954","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85167428086&doi=10.1016%2fj.inffus.2023.101954&partnerID=40&md5=e607c33099210423c084ac97016d7446","Information fusion is a useful technique of combining and merging different information to form a more complete and accurate result. Traditional information fusion models mainly focus on the single-scale data in which each object has a unique value for any attribute. However, in practice, an object may take on different values under the same attribute, depending on the scale used to measure it. Information fusion of multi-scale data has become a hot topic in the field of intelligent computing. In the past decade, various models and algorithms of multi-scale information fusion (MIF) with rough set theory have been proposed. In this paper, a detailed and comprehensive review about the current research developments of MIF is carried out. First, the multi-scale decision system is introduced to perform the knowledge representation of multi-scale data. On the basis, the classical model of MIF, i.e., the Wu–Leung model, is presented. Second, some MIF models with different information granulation and information fusion strategies are summarized, respectively. Next, for optimal granularity selection, which is the key issue of MIF, existing information measurements interpreting consistency criteria are listed and analyzed, and the common strategies of scale fusion and attribute fusion in optimal granularity selection are summarized. Then, the local MIF and the applications of MIF are reviewed, respectively. Finally, the potential research directions and challenges of MIF are discussed. © 2023 Elsevier B.V.","Attribute fusion; Granular computing; Information fusion; Multi-scale decision systems; Scale fusion"
"Multi-level correlation mining framework with self-supervised label generation for multimodal sentiment analysis","2023","Information Fusion","10.1016/j.inffus.2023.101891","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85162851536&doi=10.1016%2fj.inffus.2023.101891&partnerID=40&md5=6303162dca514050648e27879dde29a0","Fusion and co-learning are major challenges in multimodal sentiment analysis. Most existing methods either ignore the basic relationships among modalities or fail to maximize their potential correlations. They also do not leverage the knowledge from resource-rich modalities in the analysis of resource-poor modalities. To address these challenges, we propose a multimodal sentiment analysis method based on multilevel correlation mining and self-supervised multi-task learning. First, we propose a unimodal feature fusion- and linguistics-guided Transformer-based framework, multi-level correlation mining framework, to overcome the difficulty of multimodal information fusion. The module exploits the correlation information between modalities from low to high levels. Second, we divided the multimodal sentiment analysis task into one multimodal task and three unimodal tasks (linguistic, acoustic, and visual tasks), and designed a self-supervised label generation module (SLGM) to generate sentiment labels for unimodal tasks. SLGM-based multi-task learning overcomes the lack of unimodal labels in co-learning. Through extensive experiments on the CMU-MOSI and CMU-MOSEI datasets, we demonstrated the superiority of the proposed multi-level correlation mining framework to state-of-the-art methods. © 2023 Elsevier B.V.","Linguistic-guided transformer; Multimodal sentiment analysis; Self-supervised label generation; Unimodal feature fusion"
"SIGNed explanations: Unveiling relevant features by reducing bias","2023","Information Fusion","10.1016/j.inffus.2023.101883","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85162180973&doi=10.1016%2fj.inffus.2023.101883&partnerID=40&md5=40593b323ecf3f33793c2953fd7041d4","The rise of artificial intelligence (AI) is accompanied by a growing need for methods to explain the decisions of AI models. In the last decade, new explanation methods have been developed in the field of explainable AI (XAI) that enable the interpretation of predictions and provide additional information to human experts. In computer vision tasks, XAI methods are typically used to compute heatmaps to identify regions or pixels of an image that were particularly relevant to the output of the AI model. Heatmaps computed on deep neural networks often appear visually noisy due to the Shattered Gradients Problem. Therefore, several explanation methods use multiplication by the input values to increase contrast and reduce noise in heatmaps. However, this can induce a bias with the magnitude of the input values in the explanation. In this work, we proposed a novel technique called SIGN, which can be combined with existing XAI methods to prevent this bias. We implemented SIGN-based variants of the existing XAI methods Gradient × Input, SmoothGrad, DeconvNet, Guided Backpropagation, and Layer-wise Relevance Propagation (LRP), called Gradient × SIGN, SmoothGrad × SIGN, DeconvNet × SIGN, Guided Backpropagation × SIGN, and LRP-SIGN, and compared them to ten state-of-the-art XAI methods on MNIST, ImageNet, and MIT Places365 using different dense and convolutional model architectures. The SIGNed explanations were able to outperform the existing methods in all tested metrics. The code to reproduce the experiments is available from GitHub via https://github.com/nilsgumpfer/SIGN. © 2023 The Author(s)","Benchmark; Computer vision; Deep learning; Explainable AI; Layer-wise Relevance Propagation; SIGN"
"Globally optimal distributed and sequential state fusion filters for multi-sensor systems with correlated noises","2023","Information Fusion","10.1016/j.inffus.2023.101885","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85162086162&doi=10.1016%2fj.inffus.2023.101885&partnerID=40&md5=01f506c23a5d3e2d7b4d2bfde7ae3521","The problem concerning the multi-sensor fusion filtering for systems with correlated system and measurement noises is studied in this paper. Each sensor produces a local predictor by using its own measurements and then sends it to a fusion center. In the fusion center, by applying the projection theory and difference technology, the globally optimal distributed state fusion filter without feedback and sequential state fusion filter with recursive estimators of noises are presented in the sense of linear minimum variance by using all received local predictors, respectively. Under the condition that local prediction gain matrices are of full column rank, the proposed distributed and sequential state fusion filters can achieve the same estimation accuracy as the centralized fusion filter, i.e., they both have global optimality. The optimality is strictly proved. The corresponding steady-state fusion filters are also explored. A sufficient condition for the convergence of the proposed fusion filters is given. A target tracking example verifies the effectiveness of the proposed algorithms. © 2023 Elsevier B.V.","Correlated noise; Distributed fusion filter; Global optimality; Multi-sensor system; Sequential fusion filter"
"Multi-correntropy fusion based fuzzy system for predicting DNA N4-methylcytosine sites","2023","Information Fusion","10.1016/j.inffus.2023.101911","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85165027582&doi=10.1016%2fj.inffus.2023.101911&partnerID=40&md5=a8d36d8e1ad4004183c704087ba2dfe4","The identification of DNA N4-methylcytosine (4mC) sites is an important field of bioinformatics. Statistical learning methods and deep learning have been applied in this direction. The previous methods focused on feature representation and feature selection, and did not take into account the deviation of noise samples for recognition. Moreover, these models were not established from the perspective of prediction error distribution. To solve the problem of complex error distribution, we propose a maximum multi-correntropy criterion based kernelized higher-order fuzzy inference system (MMC-KHFIS), which is constructed with multi-correntropy fusion. There are 6 4mC and 8 UCI data sets are employed to evaluate our model. The MMC-KHFIS achieves better performance in the experiment. © 2023","4mC; DNA N4-methylcytosine; Fuzzy model; Multi-correntropy fusion; Sequence classification"
"Knowledge graph relation reasoning with variational reinforcement network","2023","Information Fusion","10.1016/j.inffus.2023.101900","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85165233080&doi=10.1016%2fj.inffus.2023.101900&partnerID=40&md5=6182b976c245621c9d0a219f4b60ad85","Knowledge graphs typically suffer from incompleteness due to construction defects and therefore need to be complemented by reasoning methods to facilitate advanced applications. Although many approaches have been proposed to address knowledge graph reasoning, they are heuristic and limited by the search quality and quantity of paths between entities. Inspired by variational inference and reinforcement learning, this paper proposes a variational reinforcement network (termed VRNet), which aims to infer new relation by fusing the information found on the paths connecting a pair of entities to complete the knowledge graph. Specifically, we assume that the direct relation between two entities can be inferred by multiple paths, which are likely to be multi-hop and modeled by Markov chains. We introduce latent variables to bridge the paths and relation, and design a multi-class classifier and score functions to determine the relations. Instead of traversing all the paths, we use the variational approach combined with reinforcement learning to search necessary paths with relational discrimination information. Experimental results on multiple real-world datasets indicate that VRNet integrates information from different paths and has achieved competitive performances in relation reasoning tasks. © 2023 Elsevier B.V.","Knowledge graph; Multi-hop paths; Reinforcement learning; Relation reasoning; Variational inference"
"A novel depression risk prediction model based on data fusion from Chilean National Health Surveys to diagnose risk depression among patients with mood disorders","2023","Information Fusion","10.1016/j.inffus.2023.101960","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85172423436&doi=10.1016%2fj.inffus.2023.101960&partnerID=40&md5=c543d34eafc76e68b914cf5f84645d6d","Artificial intelligence (AI)-based techniques have been widely applied in depression research and treatment. Nevertheless, no specific predictor model for depression has been developed yet in Chile using specific Chilean characteristics (variables). The present study used data from 11525 participants of the National Health Survey (NHS) to create a model to predict risk of depression (PDRM). This model was contrasted with data from 280 outpatients diagnosed with depression. To develop the PDRM we employed classification algorithms models and fusion of data about depression from two waves of the NHS (2009–2010 and 2016–17). Validation of the model of 19 variables (questions) was done applying machine learning algorithms. Based on 2009–10 data, Recall for Naive Bayes (NB) yielded 0.92, LOGIT was 0.86 and SVM=0.84. After setting up the PDRM this predictor was contrasted with the data from patients (P) diagnosed Bipolar Disorder (140 P); Major Depressive Disorder (MDD, 140 P); and Adjustment Disorder (80 P, control). Fusion of patient's data from anamnesis and consultations was used to determine the presence or absence of each 16 variables per patient. Prediction of depression using the PDRM model detected 122 cases of depression out of the total 140 depressive cases, with a mean area under the receiver operating characteristic curve of 0.8 and a recall 0.74 (with NB). This predictive model may contribute to decision-making processes in a fast, simple and economical way. © 2023 Elsevier B.V.","Depression; Health data fusion; Machine learning; Patients with mood disorders"
"Few-shot multi-view object classification via dual augmentation network","2023","Information Fusion","10.1016/j.inffus.2023.101967","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85167985590&doi=10.1016%2fj.inffus.2023.101967&partnerID=40&md5=8ffd24dbf2327aba329841a7aef30963","Existing multi-view object classification algorithms usually rely on sufficient labeled multi-view objects, which substantially restricts their scalability to novel classes with few annotated training samples in real-world applications. Aiming to go beyond these limitations, we explore a novel yet challenging task, few-shot multi-view object classification (FS-MVOC), which expects the network to build its classification ability efficiently based on limited labeled multi-view objects. To this end, we design a dual augmentation network (DANet) to provide excellent performance for the under-explored FS-MVOC task. On the one hand, we employ an attention-guided multi-view representation augmentation (AMRA) strategy to help the model focus on salient features and suppress unnecessary ones on multiple views of multi-view objects, resulting in more discriminative multi-view representations. On the other hand, during the meta-training stage, we adopt the category prototype augmentation (CPA) strategy to improve the class-representativeness of each prototype and increase the inter-prototype difference by injecting Gaussian noise in the deep feature space. Extensive experiments on the benchmark datasets (Meta-ModelNet and Meta-ShapeNet) indicate the effectiveness and robustness of DANet. © 2023 Elsevier B.V.","Dual augmentation network; Few-shot learning; Multi-view object classification"
"FTransCNN: Fusing Transformer and a CNN based on fuzzy logic for uncertain medical image segmentation","2023","Information Fusion","10.1016/j.inffus.2023.101880","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171370227&doi=10.1016%2fj.inffus.2023.101880&partnerID=40&md5=5740c8d76f91c08dcb8de40fb78f4c6c","The accurate segmentation of medical images plays a crucial role in diagnosing and treating diseases. Although many methods now use multimodal joint segmentation, the joint use of segmentation features extracted by multiple models can lead to heterogeneity and uncertainty. Unreasonable fusion methods cannot exploit the advantages of multiple models and still lack good performance in segmentation. Therefore, this study proposes the FTransCNN model, which is composed of a convolutional neural network (CNN) and Transformer and is based on a fuzzy fusion strategy that jointly utilizes the features extracted by a CNN and Transformer through a new fuzzy fusion module. First, the CNN and Transformer act as the backbone network for parallel feature extraction. Second, channel attention is used to promote the global key information of Transformer to improve the feature representation ability, and spatial attention is used to enhance the local details of CNN features and suppress irrelevant regions. Third, the proposed model applies the Hadamard product to model fine-grained interactions between the two branches and uses the Choquet fuzzy integral to suppress heterogeneity and uncertainty in fused features. Fourth, FTransCNN employs fuzzy attention fusion module (FAFM) hierarchical upsampling to effectively capture both low-level spatial features and high-level semantic context. Finally, the new model obtains the final segmentation result by using the deconvolution and results in an improvement in segmentation. The experimental results on Chest X-ray and Kvasir-SEG dataset show that FTransCNN has better performance on segmentation tasks than the-state-of-the-art deep segmentation models. © 2023 Elsevier B.V.","Choquet fuzzy integral; Convolutional neural network (CNN); Fuzzy fusion; Medical image segmentation; Transformer"
"High-order multi-view clustering for generic data","2023","Information Fusion","10.1016/j.inffus.2023.101947","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85167446195&doi=10.1016%2fj.inffus.2023.101947&partnerID=40&md5=5540054dffdc42ec2140d75d6aafd6fc","Graph-based multi-view clustering has achieved better performance than most non-graph approaches. However, in many real-world scenarios, the graph structure of data is not given or the quality of initial graph is poor. Additionally, existing methods largely neglect the high-order neighborhood information that characterizes complex intrinsic interactions. To tackle these problems, we introduce an approach called high-order multi-view clustering (HMvC) to explore the long-distance structural information of generic data. Firstly, graph filtering is applied to encode structure information, which unifies the processing of attributed graph data and non-graph data in a single framework. Secondly, up to infinity-order intrinsic relationships are exploited to enrich the learned graph. Thirdly, to explore the consistent and complementary information of various views, an adaptive graph fusion mechanism is proposed to achieve a consensus graph. Comprehensive experimental results on both non-graph and attributed graph data show the superior performance of our method with respect to various state-of-the-art techniques, including some deep learning methods. © 2023 Elsevier B.V.","Graph clustering; High-order information; Multi-view learning"
"Bi-level ensemble method for unsupervised feature selection","2023","Information Fusion","10.1016/j.inffus.2023.101910","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85165094065&doi=10.1016%2fj.inffus.2023.101910&partnerID=40&md5=8ca2a91f15906a3654996c1dcb5599ec","Unsupervised feature selection is an important machine learning task and thus attracts increasingly more attention. However, due to the absence of labels, unsupervised feature selection often suffers from stability and robustness problems. To tackle these problems, some works try to ensemble multiple feature selection results to obtain a consensus result. Most of the existing methods do the ensemble on the feature level, i.e., they directly ensemble feature selection results by feature ranking or voting aggregation, without paying any attention to the following downstream tasks. In this paper, we take clustering as the downstream task and wish to ensemble the base results to select features which are appropriate for clustering. To this end, we propose a novel bi-level feature selection ensemble method, which ensembles on two levels: the feature level and the clustering level. Together with feature level ensemble, we also learn a consensus clustering result from base feature selection results with self-paced learning. Then, we apply the consensus clustering result to guide the feature selection in turn. Extensive experiments are conducted to demonstrate that the proposed method outperforms other state-of-the-art feature selection and feature selection ensemble methods in the clustering task. The codes of this paper are released in https://doctor-nobody.github.io/codes/BLFSE.zip. © 2023 Elsevier B.V.","Clustering ensemble; Ensemble learning; Feature selection"
"FL-Enhance: A federated learning framework for balancing non-IID data with augmented and shared compressed samples","2023","Information Fusion","10.1016/j.inffus.2023.101836","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85160612794&doi=10.1016%2fj.inffus.2023.101836&partnerID=40&md5=5054a2d501af66dd26859cd012f28460","Federated Learning (FL), which enables multiple clients to cooperatively train global models without revealing private data, has gained significant attention from researchers in recent years. However, the data samples on each participating device in FL are often not independent and identically distributed (IID), leading to significant statistical heterogeneity challenges. In this paper, we propose FL-Enhance, a novel framework to address the non-IID-ness data issue in FL by leveraging established solutions such as data selection, data compression, and data augmentation. FL-Enhance, specifically, utilizes cGANs that are trained locally on the server level, which represents a relatively novel approach within the FL framework. Also, data compression techniques are applied to preserve privacy during data sharing between clients and servers. We compare our framework with the commonly used SMOTE data augmentation technique and test it with different FL algorithms, including FedAvg, FedNova, and FedOpt. We conducted experiments using both image and tabular data to evaluate the effectiveness of our proposed framework. The experimental findings show that FL-Enhance can substantially enhance the performance of the trained models in situations of severe pathological clients while still preserving privacy, which is the fundamental requirement in the FL context. © 2023 Elsevier B.V.","Data fusion; Federated learning; Model fusion; Non-IID data"
"TWC-EL: A multivariate prediction model by the fusion of three-way clustering and ensemble learning","2023","Information Fusion","10.1016/j.inffus.2023.101966","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85167589524&doi=10.1016%2fj.inffus.2023.101966&partnerID=40&md5=3529beb84c68313a450319fc71e58ded","Multivariate data analysis, as an important research topic in the field of machine learning, focuses on how to utilize the intrinsic connection between feature variables and target variables. However, in the face of complex multivariate prediction environments, existing single prediction models often fail to obtain ideal results. Meanwhile, existing ensemble prediction models are not always adapted to certain complex data. Moreover, the randomness in the clustering process cannot guarantee the clustering accuracy. Therefore, to improve the model's prediction accuracy and ability to adapt to complex data and reduce the impact of randomness on clustering accuracy, this paper designs a multivariate prediction model utilizing three-way clustering (TWC) and ensemble learning, which is named the TWC-EL model. First, the initial division of the sample set is realized by k-means clustering algorithm, and further the sample set is divided again via the k-means clustering algorithm to solve the problem of clustering accuracy. Then, the results of clustering twice are combined according to the difference in the number of intersection points and the distance from the samples to the center point of each cluster, and the core and fringe regions of each cluster in the initial clustering results are obtained, forming a new TWC method. Next, based on the correlation between the regions, the obtained core and fringe regions are classified into low-correlation, medium-correlation and high-correlation regions, and an ensemble prediction model is designed by combining the advantages of the Elman neural network model, the Extreme Learning Machine (ELM) model and the back propagation neural network (BPNN) model. Finally, the experimental analysis results exhibit that the constructed TWC-EL model is efficient and feasible, and points out the excellent performance compared with the existing prediction models. The validity of the TWC method and the ensemble prediction model in the proposed TWC-EL model are verified by experiments, respectively. © 2023 Elsevier B.V.","BPNN model; Elman neural network; Ensemble learning; Multivariate prediction; Three-way clustering"
"Real-time infrared and visible image fusion network using adaptive pixel weighting strategy","2023","Information Fusion","10.1016/j.inffus.2023.101863","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85161619531&doi=10.1016%2fj.inffus.2023.101863&partnerID=40&md5=56ee78d1888015f4dd83d1a72555cb33","Efficiently fusing infrared and visible images is critical for their real-time application in various electro-optic systems. In recent years, deep learning-based methods have significantly improved fusion quality by leveraging feature-based fusion. However, large-scale networks are usually time and resource-consuming. Although current lightweight networks have improved efficiency by tailoring network size, image fusion quality and processing speed are still unsatisfactory especially when deployed on embedded systems. In this paper, we propose to use pixel-based fusion strategy to design simple yet efficient network that learns pixel-by-pixel weights adaptively for image fusion. Based on the proposed fusion network, we further combine it with a detection model to construct a joint optimization framework which optimizes low-level and high-level tasks cooperatively. The fusion quality and processing speed of various infrared and visible image fusion networks are evaluated on multiple datasets and platforms. The evaluation results demonstrate that, the proposed method yields comparable or even better quantitative and qualitative results than current state-of-the-art large-scale and lightweight networks. Besides, the joint optimization is effective for producing better fusion quality and detection accuracy. More importantly, the proposed fusion network only requires ∼27 ms to fuse a pair of infrared and visible images with the resolution of 512 × 512 on Jeston Xavier NX, which is only a third of the time required by the previous fastest network. Therefore, the proposed method is an efficient solution for real-time infrared and visible image fusion on embedded systems. © 2023 Elsevier B.V.","Embedded platform; Joint optimization; Lightweight model; Multispectral image fusion; Real-time"
"Ask and Ye shall be Answered: Bayesian tag-based collaborative recommendation of trustworthy experts over time in community question answering","2023","Information Fusion","10.1016/j.inffus.2023.101856","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85161302417&doi=10.1016%2fj.inffus.2023.101856&partnerID=40&md5=e2f2493db23d9c5040318f2a39dba64c","Several challenging issues have yet to be jointly addressed in the recommendation of experts for community question answering, including dynamicity, comprehensive profiling, the incorporation of auxiliary data, and the manipulation of heterogeneous information. We argue that a unified treatment of these issues is beneficial in improving recommendation effectiveness. In this paper, we introduce and formalize a new and more thorough instance of the expert-recommendation task for community question answering, which is conceived to suitably account for the connections among the targeted issues. Moreover, in order to carry out the devised task, we present an innovative Bayesian tag-based approach that systematically handles all of the targeted issues in a coherent and seamlessly unified manner. At the heart of the proposed approach is an unprecedented principled fusion of various types of information. The integrated information enables a peculiar characterization of community members in terms of three inherent properties, i.e., their tag-based temporally-discounted interest, expertise, and willingness to respond. The first property is determined by looking into questions, while the last two are determined from answers. Within a generic question answering community, the three properties of its members allow for selectively routing any question to a specifically addressed set of responders. These are recommended as trustworthy repliers, who are not only actually experts in the themes of the routed question as per its tags, but also still interested in such themes and willing to answer at routing time. An extensive empirical assessment involving real-world benchmark data from heterogeneous domains reveals the higher recommendation effectiveness of the presented approach compared to state-of-the-art competitors. © 2023 Elsevier B.V.","Comprehensive user profiling; Expert finding; Heterogeneous information fusion; Tag-based expertise over time; Tag-based interest over time; Tag-based willingness to respond over time"
"Improving airport arrival flow prediction considering heterogeneous and dynamic network dependencies","2023","Information Fusion","10.1016/j.inffus.2023.101924","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85165530488&doi=10.1016%2fj.inffus.2023.101924&partnerID=40&md5=d03ae83860668e7b3106af26402dbafa","Predicting airport arrival flow serves as a crucial technique in air traffic flow management. Given the unique operational characteristics of air traffic systems, airport arrival flow simultaneously presents complex dynamics in spatial–temporal dimensions, specific spatial heterogeneity, non-rigid periodicity, and robust plannability. These factors pose challenges to existing modeling methods in achieving optimal performance. To address these challenges, we propose a novel large-range air traffic flow prediction model to forecast airport arrival flow. More specifically, a dynamic multi-graph neural network is designed to automatically capture the time-evolving and heterogeneous spatial correlations using convolution and attention operations. In terms of the temporal dimension, a temporal-aware attention module is constructed to extract the temporal transitions of traffic data, considering both the local context and stationarity of the traffic representation sequence. Furthermore, a prior-guided recalibration fusion module is employed to explicitly incorporate the prior knowledge, including historical-periodic and future-scheduled arrival flow features, to recalibrate the temporal module prediction results, thereby enhancing the prediction accuracy. Experimental results on a real-world airport traffic flow dataset demonstrate that the proposed method outperforms the state-of-the-art baselines, and all proposed technical modules contribute to desired performance improvements. © 2023 Elsevier B.V.","Airport arrival flow prediction; Deep learning; Graph neural network; Large-range airport network; Multi-graph fusion; Spatial–temporal correlations"
"A robust ordinal regression feedback consensus model with dynamic trust propagation in social network group decision-making","2023","Information Fusion","10.1016/j.inffus.2023.101952","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85166677463&doi=10.1016%2fj.inffus.2023.101952&partnerID=40&md5=813abfb23307ee0646977646fa116a29","This paper proposes a robust ordinal regression feedback consensus model based on trust relationships for social network group decision-making problems in intuitionistic fuzzy environment. The model consists of two main parts: (a) the construction of the complete trust matrix among decision makers (DMs) and (b) the design of a feedback mechanism formulated on robust ordinal regression. In Part (a), to complete the initial trust matrix between DMs, a dynamic trust propagation mode founded on maximum credibility is proposed to investigate indirect trust relationships between unfamiliar DMs from the perspective of overall optimization. In Part (b), when the group consensus does not reach the consensus threshold, the utility function compatible with the preference information of DMs is constructed through robust ordinal regression, and the most representative utility function is selected by maximizing the difference of the necessary weak preference relationship. In addition, the performance of DMs under four evaluation dimensions, individual consensus degree, individual comprehensive influence, individual opinion retention, and individual proximity centrality, is aggregated into a total utility value. In each iteration, the DM with the lowest total utility value is identified for opinion adjustments. Further, based on trust-similarity analysis, recommendations are designed for opinion adjustments to improve the group consensus. An illustrative example along with the related sensitivity analysis and comparative study is used to examine the effectiveness and advantages of the proposed model. © 2023 Elsevier B.V.","Consensus reaching process; Feedback mechanism; Group decision-making; Robust ordinal regression; Social network analysis"
"Dual-interactive fusion for code-mixed deep representation learning in tag recommendation","2023","Information Fusion","10.1016/j.inffus.2023.101862","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85161944146&doi=10.1016%2fj.inffus.2023.101862&partnerID=40&md5=081a143c7a64d57e9f3675aaa045824c","Automatic tagging on software information sites is a tag recommendation service. It aims to recommend content-based tags for a software object to help developers make distinctions among software objects. Due to deep correlations between software objects and tags, it is challenging to simultaneously consider the code snippet and text description of a software object. Towards automatic tagging service, we propose a novel CDR4Tag method, Code-mixed Deep Representation learning via dual-interactive fusion for Tag recommendation on software information sites. In CDR4Tag, a code-mixed dual interaction strategy is designed to fuse the deep semantic correlations between software objects and tags into a joint representation space. On the basis of it, the matching probability is predicted to complete our tag recommendation. Comprehensive experimental results on four software information site datasets have demonstrated the effectiveness of our proposed CDR4Tag in tag recommendation compared with the state-of-the-art methods. © 2023","Automatic tagging; Code snippet; Interactive information fusion"
"Connecting the dots in trustworthy Artificial Intelligence: From AI principles, ethics, and key requirements to responsible AI systems and regulation","2023","Information Fusion","10.1016/j.inffus.2023.101896","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85165229141&doi=10.1016%2fj.inffus.2023.101896&partnerID=40&md5=227e799a222807d695482be476e999d8","Trustworthy Artificial Intelligence (AI) is based on seven technical requirements sustained over three main pillars that should be met throughout the system's entire life cycle: it should be (1) lawful, (2) ethical, and (3) robust, both from a technical and a social perspective. However, attaining truly trustworthy AI concerns a wider vision that comprises the trustworthiness of all processes and actors that are part of the system's life cycle, and considers previous aspects from different lenses. A more holistic vision contemplates four essential axes: the global principles for ethical use and development of AI-based systems, a philosophical take on AI ethics, a risk-based approach to AI regulation, and the mentioned pillars and requirements. The seven requirements (human agency and oversight; robustness and safety; privacy and data governance; transparency; diversity, non-discrimination and fairness; societal and environmental wellbeing; and accountability) are analyzed from a triple perspective: What each requirement for trustworthy AI is, Why it is needed, and How each requirement can be implemented in practice. On the other hand, a practical approach to implement trustworthy AI systems allows defining the concept of responsibility of AI-based systems facing the law, through a given auditing process. Therefore, a responsible AI system is the resulting notion we introduce in this work, and a concept of utmost necessity that can be realized through auditing processes, subject to the challenges posed by the use of regulatory sandboxes. Our multidisciplinary vision of trustworthy AI culminates in a debate on the diverging views published lately about the future of AI. Our reflections in this matter conclude that regulation is a key for reaching a consensus among these views, and that trustworthy and responsible AI systems will be crucial for the present and future of our society. © 2023 The Author(s)","AI ethics; AI regulation; Regulatory sandbox; Responsible AI systems; Trustworthy AI"
"Heterogeneous multi-sensor fusion for PHD filter in decentralized sensor networks","2023","Information Fusion","10.1016/j.inffus.2023.101956","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85166960631&doi=10.1016%2fj.inffus.2023.101956&partnerID=40&md5=79280bcf07ad9144a0f93c0935d5bea4","This paper addresses distributed multi-sensor multi-object tracking based on probability hypothesis density (PHD) filter. Due to the scalar fusion weights, existing distributed fusion methods only work well in cases where the information confidence within multi-object densities (MODs) returned by local filters remains unchanged over the object state space. Therefore, severe performance degradation can be observed as, in practice, the information confidence of an MOD is usually space-varying and can be utterly different due to the limited sensor abilities and various environment impacts. We make three contributions towards addressing this problem. Firstly, we propose a heterogeneous fusion method for multi-object Poisson process (MPP) MODs. The resulting MOD has a parallelizable structure that allows multiple clusters of sub-densities to be fused independently based on different sets of heterogeneous fusion weights. Secondly, a density-based heterogeneous fusion weights design method is proposed, in which the fusion weights are determined according to the relative information confidence of MODs. Lastly, to enhance the adaptability and robustness of the proposed fusion method, we extend it to decentralized sensor networks in conjunction with consensus and flooding protocols, respectively. The implementation of the proposed fusion algorithms using Gaussian approximation is also presented. The efficacy of the proposed fusion methods is demonstrated in various numerical experiments, including a challenging scenario in which each sensor in a decentralized network has dynamic detection probability and space-varying detection accuracy. In the experiments, the proposed method significantly outperforms the state-of-the-art in distributed fusion. In fact, the Optimal Sub-Pattern Assignment (OSPA) distances returned by the proposed method are at least 38.8% less than other solutions. © 2023 Elsevier B.V.","Decentralized sensor networks; Density-based fusion weights; Heterogeneous fusion method"
"Few-shot IoT attack detection based on SSDSAE and adaptive loss weighted meta residual network","2023","Information Fusion","10.1016/j.inffus.2023.101853","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85162835337&doi=10.1016%2fj.inffus.2023.101853&partnerID=40&md5=553ba2c10efe74299a66af175c950665","The Internet of Things (IoT) is an open and comprehensive network of smart objects. Unfortunately, it is also becoming increasingly vulnerable to security attacks during the increasing popularity of the IoT. It can lead traditional antivirus software to be less likely to prevent this threat. Therefore, it is necessary to design a model for the IoT attack detection. Current detection models are trained using massive big data samples. However, the distribution of traffic samples is few in specific scenarios. Also, existing models are also susceptible to noise interference in IoT environments, lowering detection efficiency and accuracy. In this work, we propose a few-shot IoT attack detection approach using a semi-supervised deep sparse autoencoder (SSDSAE) and an adaptive loss weighted meta residual network (ALWM-ResNet). First, an SSDSAE feature extraction model for local graph embedding is designed using local and non-local graph embedding constraints. Then, we design an ALWM-ResNet model to achieve IoT attack detection with few-shot samples under noise labels. A weighted function map is established using a weighted network and a meta-model, and weights are adaptively learned from the noise labels. Finally, we validate our approach using four IoT datasets. Several experimental results demonstrate the superior performance of our approach in IoT attack detection under few-shot samples. © 2023 Elsevier B.V.","Adaptive loss weighted meta residual network; Detection accuracy; Dynamic weighting; Few-shot sample IoT attack; Local and non-local graph embeddings; Semi-supervised DSAE"
"A multi-resolution fusion approach for human activity recognition from video data in tiny edge devices","2023","Information Fusion","10.1016/j.inffus.2023.101953","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85167835416&doi=10.1016%2fj.inffus.2023.101953&partnerID=40&md5=17fa403b32e8b2764553d89dc546f6be","Human Activity Recognition (HAR) is the process of automatic recognition of Activities of Daily Living (ADL) from human motion data captured in various data modalities by wearable and ambient sensors. Advances in Deep Learning, especially Convolutional Neural Networks (CNNs) and sequential models have revolutionalized HAR from video data sources. Although these models are incredibly accurate and utilize both spatial and temporal information, they require huge computation and memory resources — making them unsuitable for edge or wearable applications. Tiny Machine Learning (TinyML) aims to optimize these models in terms of compute and memory requirements – aiming to make them suitable for always-on resource constrained devices – leading to a reduction in communication latency and network traffic for HAR frameworks. In this paper, we propose a two-stream multi-resolution fusion architecture for HAR from video data modality. The context stream takes a resized image as input and the fovea stream takes the cropped center portion of the resized image as input, reducing the overall dimensionality. We tested two quantization methods: Post-Training Quantization (PTQ) and Quantization Aware Training (QAT) to optimize these models for deployment in edge devices and tested the performance in two challenging video datasets: KTH and UCF11. We performed ablation studies to validate the two-stream model performance. We deployed the proposed architecture in commercial resource constrained devices and monitored their performance in terms of inference latency and power consumption. The results indicate that the proposed architecture clearly outperforms other relevant single-stream models tested in this work in terms of accuracy, precision, recall, and F1-Score while also reducing the overall model size. © 2023 Elsevier B.V.","Convolutional Neural Network; Deep learning; Human Activity Recognition; Resource-constrained devices; TinyML"
"Statistics-based method for large-scale group decision-making with incomplete linguistic distribution fuzzy information: Incorporating reliability and entropy","2023","Information Fusion","10.1016/j.inffus.2023.101894","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85164029563&doi=10.1016%2fj.inffus.2023.101894&partnerID=40&md5=3324956162ec2805227e9b3cb412f9a0","Aiming at large-scale decision-makers (DMs) and the loss of decision sample information in large-scale group decision-making (LSGDM), a novel statistical estimation method incorporating the reliability and entropy of linguistic distribution assessment is proposed. First, classify the large-scale DMs into several subgroups according to their prior decision efficiency distribution. After clustering, collect the five-number summary of the incomplete decision sample information provided by the DMs in the subgroups. Second, estimate the mean, standard deviation, skewness and kurtosis of the decision sample via the Cornish–Fisher expansion. Then utilize the Bayes estimation to address the reliability of the subgroups, thereby obtaining the confidence interval, which is used to develop the interval linguistic distribution preference relation (ILDPR) for the subgroups. Moreover, combine the reliability and the entropy measure constructed by the above four estimators to determine subgroup weights. Furthermore, present the expectation and variance of the ILDPR to sort the alternatives. Finally, demonstrate the feasibility and validity of the proposed LSGDM method based on a case and a comparison. © 2023 Elsevier B.V.","Entropy measure; Interval linguistic distribution preference relation; Large-scale group decision-making; Reliability; Statistics"
"InMyFace: Inertial and mechanomyography-based sensor fusion for wearable facial activity recognition","2023","Information Fusion","10.1016/j.inffus.2023.101886","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85162083029&doi=10.1016%2fj.inffus.2023.101886&partnerID=40&md5=ea275e0ff505b8fa819331dcd9b506f1","Recognizing facial activity is a well-understood (but non-trivial) computer vision problem. However, reliable solutions require a camera with a good view of the face, which is often unavailable in wearable settings. Furthermore, in wearable applications, where systems accompany users throughout their daily activities, a permanently running camera can be problematic for privacy (and legal) reasons. This work presents an alternative solution based on the fusion of wearable inertial sensors, planar pressure sensors, and acoustic mechanomyography (muscle sounds). The sensors were placed unobtrusively in a sports cap to monitor facial muscle activities related to facial expressions. We present our integrated wearable sensor system, describe data fusion and analysis methods, and evaluate the system in an experiment with thirteen subjects from different cultural backgrounds (eight countries) and both sexes (six women and seven men). In a one-model-per-user scheme and using a late fusion approach, the system yielded an average F1 score of 85.00% for the case where all sensing modalities are combined. With a cross-user validation and a one-model-for-all-user scheme, an F1 score of 79.00% was obtained for thirteen participants (six females and seven males). Moreover, in a hybrid fusion (cross-user) approach and six classes, an average F1 score of 82.00% was obtained for eight users. The results are competitive with state-of-the-art non-camera-based solutions for a cross-user study. In addition, our unique set of participants and minimally biased experimental design demonstrate the inclusiveness of the approach, which is beneficial for further generalizability. © 2023 Elsevier B.V.","Activity recognition; Facial expressions; Mechanomyography; Multimodal fusion"
"Learning a 3D-CNN and Transformer prior for hyperspectral image super-resolution","2023","Information Fusion","10.1016/j.inffus.2023.101907","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85166351890&doi=10.1016%2fj.inffus.2023.101907&partnerID=40&md5=a781524527e759308a64065d2bf112a8","To address the ill-posed problem of hyperspectral image super-resolution (HSISR), a commonly employed technique is to design a regularization term based on the prior information of hyperspectral images (HSIs) to effectively constrain the objective function. Traditional model-based methods that rely on manually crafted priors are insufficient in fully characterizing the properties of HSIs. Learning-based methods usually use a convolutional neural network (CNN) to learn the implicit priors of HSIs. However, the learning ability of CNN is limited, it only considers the spatial characteristics of the HSIs and ignores the spectral characteristics, and convolution is not effective for long-range dependency modeling. There is still a lot of room for improvement. In this paper, we propose a novel HSISR method that leverages the Transformer architecture instead of the CNN to learn the prior of HSIs. Specifically, we employ the proximal gradient algorithm to solve the HSISR model and simulate the iterative solution process using an unfolding network. The self-attention layer of the Transformer enables global spatial interaction, while a 3D-CNN is added behind the Transformer layers to better capture the spatio-spectral correlation of HSIs. Both quantitative and visual results on three widely used HSI datasets and the real-world dataset demonstrate that the proposed method achieves a considerable gain compared to all the mainstream algorithms including the most competitive conventional methods and the recently proposed deep learning-based methods. The source code and trained models are made publicly available at https://github.com/qingma2016/3DT-Net. © 2023","Deep learning; Hyperspectral image super-resolution; Image prior; Spatio-spectral correlation; Transformer"
"ChatGPT: Jack of all trades, master of none","2023","Information Fusion","10.1016/j.inffus.2023.101861","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85162121706&doi=10.1016%2fj.inffus.2023.101861&partnerID=40&md5=50aafcd73742a897267f9e0ea3796df5","OpenAI has released the Chat Generative Pre-trained Transformer (ChatGPT) and revolutionized the approach in artificial intelligence to human-model interaction. The first contact with the chatbot reveals its ability to provide detailed and precise answers in various areas. Several publications on ChatGPT evaluation test its effectiveness on well-known natural language processing (NLP) tasks. However, the existing studies are mostly non-automated and tested on a very limited scale. In this work, we examined ChatGPT's capabilities on 25 diverse analytical NLP tasks, most of them subjective even to humans, such as sentiment analysis, emotion recognition, offensiveness, and stance detection. In contrast, the other tasks require more objective reasoning like word sense disambiguation, linguistic acceptability, and question answering. We also evaluated GPT-4 model on five selected subsets of NLP tasks. We automated ChatGPT and GPT-4 prompting process and analyzed more than 49k responses. Our comparison of its results with available State-of-the-Art (SOTA) solutions showed that the average loss in quality of the ChatGPT model was about 25% for zero-shot and few-shot evaluation. For GPT-4 model, a loss for semantic tasks is significantly lower than for ChatGPT. We showed that the more difficult the task (lower SOTA performance), the higher the ChatGPT loss. It especially refers to pragmatic NLP problems like emotion recognition. We also tested the ability to personalize ChatGPT responses for selected subjective tasks via Random Contextual Few-Shot Personalization, and we obtained significantly better user-based predictions. Additional qualitative analysis revealed a ChatGPT bias, most likely due to the rules imposed on human trainers by OpenAI. Our results provide the basis for a fundamental discussion of whether the high quality of recent predictive NLP models can indicate a tool's usefulness to society and how the learning and validation procedures for such systems should be established. © 2023 The Author(s)","ChatGPT; Emotion recognition; GPT-4; Humor detection; Large language model; Model personalization; Natural language inference (NLI); Natural language processing (NLP); Offensive content; Pragmatic NLP tasks; Prompting; Question answering (QA); Semantic NLP tasks; Sentiment analysis; SOTA analysis; Stance detection; Subjective NLP tasks; Text classification; Word sense disambiguation (WSD)"
"Multimedia analysis of robustly optimized multimodal transformer based on vision and language co-learning","2023","Information Fusion","10.1016/j.inffus.2023.101922","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85165528887&doi=10.1016%2fj.inffus.2023.101922&partnerID=40&md5=b79e1bfdfd9210713e5a7bb1ce2b7535","Recently, research on multimodal learning using all modality information has been conducted to detect disinformation on multimedia. Existing multimodal learning methods include score-level fusion approaches combining different models, and feature-level fusion methods combining embedding vectors to integrate data of different dimensions. Because a late-level fusion method is combined after the modalities are individually operated, there is a limit in that the recognition performance of a unimodal determines the performance. In addition, a fusion method has constraints in that the data among the modalities must be matched. In this study, we propose a classification system using a RoBERTa-based multimodal fusion transformer (RoBERTaMFT) that applies a co-learning method to solve the limitations of the recognition performance of multimodal learning as well as the data imbalance among the modalities. RoBERTaMFT consists of image feature extraction, co-learning using the reconstruction of image features with text embedding, and a late-level fusion step applied to the final classification. As experiment results using the CrisisMMD dataset indicate, RoBERTaMFT achieved an accuracy 21.2% and an f1-score 0.414 higher than those of unimodal learning, and an accuracy 11.7% and an f1-score 0.268 higher than those of existing multimodal learning. © 2023 Elsevier B.V.","Classification; Multi-modal; Multimedia; Natural disasters"
"OpenViVQA: Task, dataset, and multimodal fusion models for visual question answering in Vietnamese","2023","Information Fusion","10.1016/j.inffus.2023.101868","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85165528368&doi=10.1016%2fj.inffus.2023.101868&partnerID=40&md5=bcd227967d83c57b34e8fa62c15d3df6","In recent years, visual question answering (VQA) has attracted attention from the research community because of its highly potential applications (such as virtual assistance on intelligent cars, assistant devices for blind people, or information retrieval from document images using natural language as queries) and challenge. The VQA task requires methods that have the ability to fuse the information from questions and images to produce appropriate answers. Neural visual question answering models have achieved tremendous growth on large-scale datasets which are mostly for resource-rich languages such as English. However, available datasets narrow the VQA task as the answers selection task or answer classification task. We argue that this form of VQA is far from human ability and eliminates the challenge of the answering aspect in the VQA task by just selecting answers rather than generating them. In this paper, we introduce the OpenViVQA (Open-domain Vietnamese Visual Question Answering) dataset, the first large-scale dataset for VQA with open-ended answers in Vietnamese, consists of 11,000+ images associated with 37,000+ question–answer pairs (QAs). Moreover, we proposed FST, QuMLAG, and MLPAG which fuse information from images and questions, then use these fused features to construct answers as humans iteratively. Our proposed methods achieve results that are competitive with SOTA models such as SAAA, MCAN, LORA, and M4C. The dataset1 is available to encourage the research community to develop more generalized algorithms including transformers for low-resource languages such as Vietnamese. © 2023","Information fusion; Low-resource languages; Multimodal representation; Vision-language understanding; Visual question answering"
"Explainable and programmable hypergraph convolutional network for imaging genetics data fusion","2023","Information Fusion","10.1016/j.inffus.2023.101950","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85166931170&doi=10.1016%2fj.inffus.2023.101950&partnerID=40&md5=d15a7981fa1fb80412386ecf52d00308","Integrating multi-view information to gain a new understanding of complex disease like Alzheimer's disease (AD) has great clinical value. Hypergraphs have unique advantages in modeling high-order associations, but current deep learning methods cannot fully utilize the structural information in hypergraphs and have limited application value due to the black-box nature. This paper improves the hypergraph learning in interpretability and programmability. Firstly, we fuse multi-view information by constructing brain region-gene hypergraphs. Secondly, a characteristic information aggregation model is constructed based on hypergraph structure, Finally, a characteristic information aggregation hypergraph convolutional network (CIA-HGCN) is proposed based on the idea of graph neural networks. Evaluated by clinical imaging genetics data, CIA-HGCN obtained accuracy of 88.3% in AD identification task and showed superior performance in characteristic extraction. This paper provides a practical and flexible deep learning method for AD research and clinical applications. © 2023 Elsevier B.V.","Alzheimer's disease; Deep learning; Hypergraph convolutional network; Imaging genetics; Multi-view disease data"
"A multi-view clustering algorithm based on deep semi-NMF","2023","Information Fusion","10.1016/j.inffus.2023.101884","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85162236333&doi=10.1016%2fj.inffus.2023.101884&partnerID=40&md5=2d9755c038218f781ac00dec16d9d0a0","Multi-view clustering (MVC) aims to fuse the information among multiple views to achieve effective clustering. Many MVC algorithms based on semi-nonnegative matrix factorization (SNMF) typically have two issues: (1) their optimization schemes are not flexible enough; and (2) the variables are updated only rely on the data but not guided by learning rate. These problems can result in very poor clusters generated. In this paper, we present a multi-view clustering algorithm based on deep SNMF (MCDS) to resolve these issues. Specifically, we first design two types of activation functions to restrict the value domain of the element in the low-dimensional matrix to eliminate the constraint. Then, the SGD algorithm is used to implement element update guided by the learning rate. After obtaining the corresponding weight matrix and bias matrix, we combine them with the activation functions to construct a deep SNMF (DSNMF) network. This network is to update the element in the corresponding low-dimensional matrix for each view and obtain the consensus matrix. To validate the proposed algorithm, numerous experiments are performed on six multi-view datasets including both normal and large-scale datasets. The results demonstrate that MCDS can achieve excellent clustering results and outperform other competitive methods. © 2023 Elsevier B.V.","Deep learning; Multi-view clustering; Multi-view fusion; Semi-nonnegative matrix factorization"
"Effective sample pairs based contrastive learning for clustering","2023","Information Fusion","10.1016/j.inffus.2023.101899","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85164235616&doi=10.1016%2fj.inffus.2023.101899&partnerID=40&md5=c9927d6ebb269d6284698af2267b556b","As an indispensable branch of unsupervised learning, deep clustering is rapidly emerging along with the growth of deep neural networks. Recently, contrastive learning paradigm has been combined with deep clustering to achieve more competitive performance. However, previous works mostly employ random augmentations to construct sample pairs for contrastive clustering. Different augmentations of a sample are treated as positive sample pairs, which may result in false positives and ignore the semantic variations of different samples. To address these limitations, we present a novel end-to-end contrastive clustering framework termed Contrastive Clustering with Effective Sample pairs construction (CCES), which obtains more semantic information by jointly leveraging an effective data augmentation method ContrastiveCrop and constructing positive sample pairs based on nearest-neighbor mining. Specifically, we augment original samples by adopting ContrastiveCrop, which explicitly reduces false positives and enlarges the variance of samples. Further, with the extracted feature representations, we provide a strategy to construct positive sample pairs via a sample and its nearest neighbor for instance-wise and cluster-wise contrastive learning. Experimental results on four challenging datasets demonstrate the effectiveness of CCES for clustering, which surpasses the state-of-the-art deep clustering methods. © 2023 Elsevier B.V.","Contrastive learning; Deep clustering; Nearest neighbor; Representation learning"
"Steering committee management. Expertise, diversity, and decision-making structures","2023","Information Fusion","10.1016/j.inffus.2023.101888","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85162093468&doi=10.1016%2fj.inffus.2023.101888&partnerID=40&md5=1441fcffd4fdd8f7ca649a6a495fe505","This paper proposes to analyze how the differences in expertise, diversity, and group decision procedures affect the quality of the strategic decision of steering committees. Strategic decisions are difficult to anticipate, and performances of the alternatives are often not observable in their entirety, which prevents researchers from obtaining controlled empirical studies. This paper proposes to analyze the performance of steering committees where managers can err in their decisions using the Intentional Bounded Rationality (IBR). The majority procedure improves the committee's performance concerning authority when the level of diversity and expertise increases. However, in situations of low expertise, the gains over authority narrow. This work provides guidance in terms of trade-offs between the mentality of managers, their expertise, group decision procedures, and diversity, which in the empirical works are contradictory. This study contributes to current theorizations of committee management using the IBR methodology, which is new and allows quantifying the contribution of the distinct characteristics of the committee. © 2023 The Author(s)","Decisions; Diversity; Expertise; Intentional bounded rationality; Steering committees"
"Rethinking the necessity of image fusion in high-level vision tasks: A practical infrared and visible image fusion network based on progressive semantic injection and scene fidelity","2023","Information Fusion","10.1016/j.inffus.2023.101870","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85161663632&doi=10.1016%2fj.inffus.2023.101870&partnerID=40&md5=9a8fe380fe35ab0df654dfeb4572ae22","Image fusion aims to integrate complementary characteristics of source images into a single fused image that better serves human visual observation and machine vision perception. However, most existing image fusion algorithms primarily focus on improving the visual appeal of fused images. Although there are some semantic-driven methods that consider semantic requirements of downstream applications, none of them have demonstrated the potential of image-level fusion compared to feature-level fusion, which fulfills high-level vision tasks directly on multi-modal features rather than on a fused image. To overcome these limitations, this paper presents a practical infrared and visible image fusion network based on progressive semantic injection and scene fidelity constraints, termed PSFusion. First of all, the sparse semantic perception branch extracts sufficient semantic features, which are then progressively integrated into the fusion network using the semantic injection module to fulfill the semantic requirements of high-level vision tasks. The scene fidelity path within the scene restoration branch is devised to ensure that the fusion features contain complete information for reconstructing the source images. Additionally, the contrast mask and salient target mask are employed to construct the fusion loss to maintain impressive visual effects of fusion results. In particular, we provide quantitative and qualitative analyses to demonstrate the potential of image-level fusion compared to feature-level fusion for high-level vision tasks. With the rapid advancement of large-scale models, image-level fusion can expeditiously leverage the advantages of multi-modal data and state-of-the-art (SOTA) unimodal segmentation to achieve superior performance. Furthermore, extensive comparative experiments demonstrate the superiority of our PSFusion over SOTA image-level fusion alternatives in terms of visual appeal and high-level semantics. Even under harsh circumstances, our method offers satisfactory fusion results to serve subsequent high-level vision applications. The source code is available at https://github.com/Linfeng-Tang/PSFusion. © 2023 Elsevier B.V.","Feature-level fusion; High-level vision task; Image fusion; Progressive semantic injection; Scene fidelity"
"Semantics lead all: Towards unified image registration and fusion from a semantic perspective","2023","Information Fusion","10.1016/j.inffus.2023.101835","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85160213013&doi=10.1016%2fj.inffus.2023.101835&partnerID=40&md5=13cfe2167f99c57e4b0c0b24c6e278f8","Infrared–visible image registration and fusion are closely related processes, and it is an attractive problem to implement coordinated registration and fusion in a unified framework. The registration accuracy of existing methods fails to satisfy the fusion needs in some scenarios, which affects the fusion visual performance. In addition, as an image preprocessing step, the speed of the network after cascading registration and fusion is not sufficient for more advanced tasks, thus restricting the usability of these methods. To solve the above problems, we propose a network that uses semantics to lead all, termed SemLA, capable of unifying the registration and fusion processes in an efficient and robust way. Our key idea is to explicitly embed semantic information at all stages of the network. In particular, SemLA employs a coordinated approach that involves joint training of registration and semantic features to ensure efficient network operation. The calibration of the semantic-aware maps and the description of their spatial structure information mutually reinforce each other to obtain more accurate registration. Additionally, the semantic-guided fusion process enhances the representation of complementary information within the semantic object while effectively suppressing visual interference caused by overlapping regional demarcation lines of the aligned image. The results of different experiments show that our SemLA has a better tradeoff between performance and efficiency compared to state-of-the-art methods and adapts to the semantic needs of advanced vision tasks. The source code is publicly available at https://github.com/xiehousheng/SemLA. © 2023 Elsevier B.V.","Deep learning; Multimodal image matching; Registration and fusion; Semantic aware; Unified framework"
"A privacy-aware framework for detecting cyber attacks on internet of medical things systems using data fusion and quantum deep learning","2023","Information Fusion","10.1016/j.inffus.2023.101889","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85164279744&doi=10.1016%2fj.inffus.2023.101889&partnerID=40&md5=da06627e096d97629a2058f14426de90","Internet of Medical Things (IoMT) devices and systems are often designed without adequate security, leaving them highly susceptible to cyber threats. Unlike other IoT applications and devices, cyber attacks against IoMT devices will pose significant risks to patient safety. As a result of the progress made in attack detection through machine learning, numerous applications of machine learning are now involved in IoMT. However, how to securely collect and fuse the data from heterogeneous IoMT devices and systems and ensure efficient cyber-attack detection while avoiding the privacy disclosure of the dataset remains challenging for IoMT systems. To fill this gap, a new privacy-aware framework is advised for storing the collected IoMT data in distributed cloud nodes and providing data fusion of heterogeneous IoMT data using differential privacy and deep learning and efficient attack detection using quantum deep learning with maintaining data privacy. Specifically, the proposed privacy-aware framework provides sensitive data privacy protection at multi-levels starting from storing data in distributed cloud nodes with privacy-preserving and then fusing IoMT heterogeneous data using deep contractive autoencoder with differential privacy for protecting the sensitive data through the learning process and then using the output of data fusion which is reduced data dimension as input for a quantum neural network for identifying cyber-attacks. Our experimental results indicate that the proposed framework is highly effective in detecting cyber-attacks. © 2023 Elsevier B.V.","Attack detection; Data fusion; Neural network; Privacy-aware; Quantum deep learning"
"Multi-exposure image fusion via perception enhanced structural patch decomposition","2023","Information Fusion","10.1016/j.inffus.2023.101895","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85163809592&doi=10.1016%2fj.inffus.2023.101895&partnerID=40&md5=5f17013c6d58489992481ffa76ff364a","Multi-exposure image fusion (MEF) is an affordable and convenient option for high-dynamic-range imaging. Current MEF methods are prone to visually unrealistic results since they take no account of perceptual factors. To address this problem, a multi-exposure image fusion method is proposed based on perception enhanced structural patch decomposition, namely PESPD-MEF. An image patch is first decomposed into four components: perceptual gain, signal strength, signal structure, and mean intensity. Then, the enhancement rule is designed for perceptual gain, and the latter three elements are fused independently in different ways. Finally, the fused components are aggregated to generate informative and perception-realistic results. Moreover, the multi-scale framework is adopted to boost the fused performance. The proposed method is also extended to address single low-light image enhancement issue. Experimental results demonstrate that the proposed approach outperforms the state-of-the-art methods by a large margin in terms of perceptual realism. The source code is available at https://github.com/Junchao2018/PESPD-MEF. © 2023 Elsevier B.V.","High dynamic range imaging; Multi-exposure image fusion; Perceptual enhancement; Structural patch decomposition"
"Fusing anomaly detection with false positive mitigation methodology for predictive maintenance under multivariate time series","2023","Information Fusion","10.1016/j.inffus.2023.101957","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85169923194&doi=10.1016%2fj.inffus.2023.101957&partnerID=40&md5=707004ab8728a5329dd514b18db0a4cf","Anomaly detection aims to identify observations that differ significantly from the majority of the data. Time series, which are data with a temporal component, is often used for anomaly detection. Identifying anomalies is not perfect and may produce many false positives, which labels standard data as anomalous. In this context, false positive mitigation is the task of reducing the number of false positives tagged by the anomaly detector, and thus both problems are closely linked. Moreover, current techniques for false positive mitigation are ad-hoc solutions for specific data sets. In this paper, we propose a novel two-stage methodology for Multivariate Anomaly Detection for Time Series and False Positive Mitigation, namely FADFPM methodology, which creates the fusion of two learning models. The first stage is a multivariate anomaly detection stage. The second stage consists of training a new classifier on the false and true positives from the anomaly detector, which refines the observations labeled as anomalous by the anomaly detector to obtain more accurate and higher-quality results. Experiments using two benchmark data sets, as well as a real-world case study have shown the performance and validity of the proposal. © 2023 The Author(s)","Anomaly detection; Deep learning; False positive mitigation; Multivariate time series; Outlier detection; Predictive maintenance"
"Learnable graph convolutional network and feature fusion for multi-view learning","2023","Information Fusion","10.1016/j.inffus.2023.02.013","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85148320476&doi=10.1016%2fj.inffus.2023.02.013&partnerID=40&md5=40c175e10d75f8276dc738daca752f06","In practical applications, multi-view data depicting objects from assorted perspectives can facilitate the accuracy increase of learning algorithms. However, given multi-view data, there is limited work for learning discriminative node relationships and graph information simultaneously via graph convolutional network that has drawn the attention from considerable researchers in recent years. Most of existing methods only consider the weighted sum of adjacency matrices, yet a joint neural network of both feature and graph fusion is still under-explored. To cope with these issues, this paper proposes a joint deep learning framework called Learnable Graph Convolutional Network and Feature Fusion (LGCN-FF), consisting of two modules: feature fusion network and learnable graph convolutional network. The former aims to learn an underlying feature representation from heterogeneous views, while the latter explores a more discriminative graph fusion via learnable weights and a parametric activation function dubbed Differentiable Shrinkage Activation (DSA) function. The proposed LGCN-FF is validated to be superior to various state-of-the-art methods in multi-view semi-supervised classification. © 2023 Elsevier B.V.","Graph convolutional network; Information fusion with deep learning; Multi-view learning; Semi-supervised classification"
"A mathematical programming method based on prospect theory for online physician selection under an R-set environment","2023","Information Fusion","10.1016/j.inffus.2023.01.006","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149756394&doi=10.1016%2fj.inffus.2023.01.006&partnerID=40&md5=614d48ed0eb57c8c51e09d2a129e1c12","This study develops an R-mathematical programming method for multiple attribute group decision-making (MAGDM) problems with assessment values of alternatives and truth degrees of pairwise alternative comparisons represented by R-sets while the decision maker holds subjective bounded rationality. First, a novel scalar multiplication operation and defuzzification of R-sets are proposed to allow the use of R-sets in MAGDM problems. Subsequently, based on prospect theory and R-sets, a new technique is proposed to compute the individual overall prospect value of an alternative by simultaneously considering the positive ideal solution (PIS) and negative ideal solution (NIS). Additionally, the R-group consistency index (R-GCI) and R-group inconsistency index (R-GII) are defined using the individual overall prospect values of alternatives. The decision makers’ weights, attribute weights, PIS, and NIS are estimated by establishing a novel R-mathematical programming model, which is solved by the external archive-based constrained state transition, while the collective overall prospect values are computed to derive the final ranking order of alternatives. Thus, a new R-LINMAP method is developed to solve MAGDM. A practical instance concerning online physician selection is provided with the corresponding sensitive and comparative analyses to verify the applicability, validity, and superiority of the developed method. © 2023","Multi-attribute group decision making; Prospect theory; R-mathematical programming; R-sets"
"An interactively reinforced paradigm for joint infrared-visible image fusion and saliency object detection","2023","Information Fusion","10.1016/j.inffus.2023.101828","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159579532&doi=10.1016%2fj.inffus.2023.101828&partnerID=40&md5=618830258d6235b6ea5204a1c4c09b57","This research focuses on the discovery and localization of hidden objects in the wild and serves unmanned systems. Through empirical analysis, infrared and visible image fusion (IVIF) enables hard-to-find objects apparent, whereas multimodal salient object detection (SOD) accurately delineates the precise spatial location of objects within the picture. Their common characteristic of seeking complementary cues from different source images motivates us to explore the collaborative relationship between Fusion and Salient object detection tasks on infrared and visible images via an Interactively Reinforced multi-task paradigm for the first time, termed IRFS. To the seamless bridge of multimodal image fusion and SOD tasks, we specifically develop a Feature Screening-based Fusion subnetwork (FSFNet) to screen out interfering features from source images, thereby preserving saliency-related features. After generating the fused image through FSFNet, it is then fed into the subsequent Fusion-Guided Cross-Complementary SOD subnetwork (FC2Net) as the third modality to drive the precise prediction of the saliency map by leveraging the complementary information derived from the fused image. In addition, we develop an interactive loop learning strategy to achieve the mutual reinforcement of IVIF and SOD tasks with a shorter training period and fewer network parameters. Comprehensive experiment results demonstrate that the seamless bridge of IVIF and SOD mutually enhances their performance, and highlights their superiority. This code is available at https://github.com/wdhudiekou/IRFS. © 2023 Elsevier B.V.","Image fusion; Infrared and visible image; Interactive loop learning strategy; Interactively reinforced paradigm; Multi-modal salient object detection"
"Incremental unsupervised feature selection for dynamic incomplete multi-view data","2023","Information Fusion","10.1016/j.inffus.2023.03.018","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85152133661&doi=10.1016%2fj.inffus.2023.03.018&partnerID=40&md5=4b2952a7de764674c2b4452976c6a49b","Multi-view unsupervised feature selection has been proven to be efficient in reducing the dimensionality of multi-view unlabeled data with high dimensions. The previous methods assume that all views are complete. However, in real applications, the multi-view data are often incomplete, i.e., some views of instances are missing, which will result in the failure of these methods. Besides, while the data arrive in form of streams, these existing methods will suffer the issues of high storage cost and expensive computation time. To address these issues, we propose an Incremental Incomplete Multi-view Unsupervised Feature Selection method (I2MUFS) on incomplete multi-view streaming data. By jointly considering the consistent and complementary information across different views, I2MUFS embeds the unsupervised feature selection into an extended weighted non-negative matrix factorization model, which can learn a consensus clustering indicator matrix and fuse different latent feature matrices with adaptive view weights. Furthermore, we introduce the incremental learning mechanisms to develop an alternative iterative algorithm, where the feature selection matrix is incrementally updated, rather than recomputing on the entire updated data from scratch. A series of experiments are conducted to verify the effectiveness of the proposed method by comparing with several state-of-the-art methods. The experimental results demonstrate the effectiveness and efficiency of the proposed method in terms of the clustering metrics and the computational cost. © 2023 Elsevier B.V.","Adaptive view fusion; Dynamic incomplete multi-view data; Feature selection; Incremental learning"
"Explainable Crowd Decision Making methodology guided by expert natural language opinions based on Sentiment Analysis with Attention-based Deep Learning and Subgroup Discovery","2023","Information Fusion","10.1016/j.inffus.2023.101821","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85156251741&doi=10.1016%2fj.inffus.2023.101821&partnerID=40&md5=44c1d97dc5fa6e11c154fb2dbd019b3b","There exist a high demand to provide explainability to artificial intelligence systems, where decision making models are included. This paper focuses on crowd decision making using natural language evaluations from social media with the aim to provide explainability. We present the Explainable Crowd Decision Making based on Subgroup Discovery and Attention Mechanisms (ECDM-SDAM) methodology as an a posteriori explainable process that captures the wisdom of crowds that is naturally provided in social media opinions. It extracts the opinions from social media texts using a deep learning based sentiment analysis approach called Attention based Sentiment Analysis Method. The methodology includes a backward process that provides explanations to justify its sense-making procedure by applying mainly the attention mechanism on texts and subgroup discovery on opinions. We evaluate the methodology in the real case study of the TripR-2020Large dataset for restaurant choice. The results show that the ECDM-SDAM methodology provides easy understandable explanations that elucidates the key reasons that support the output of the decision process. © 2023 The Author(s)","Attention mechanisms; Crowd decision making; Explainability; Social media opinions; Subgroup discovery"
"Finite mixture modeling in time series: A survey of Bayesian filters and fusion approaches","2023","Information Fusion","10.1016/j.inffus.2023.101827","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159203151&doi=10.1016%2fj.inffus.2023.101827&partnerID=40&md5=4cf650a6407b62af109baa6a5e793a02","From the celebrated Gaussian mixture, model averaging estimators to the cutting-edge multi-Bernoulli mixture of various forms, finite mixture models offer a fundamental and flexible means to deal with uncertainties arisen in the estimation and learning realm. In the context of recursive estimation, both the uncertainties due to model maneuvering and multi-target data association derive a need for representing the single/multiple-target probability distribution by a finite mixture described by a number of parameters that are iteratively updated over time in the framework of Bayesian inference, which we call generally the Bayesian mixture (BM) filtering. In addition, density fusion between netted agents/sensors may be addressed by linearly combining their local estimations which are often correlated with each other in a complicated means, leading to a fused mixture too. In either case, the final estimate is given by the arithmetic average (AA) of all the weighted components in the mixture, regarding either a single target or multiple targets. Along with this are versatile mixture adaption and optimization strategies which aim to use a small number of components for the best fit to the target distribution. This survey provides a comprehensive overview of representative single/multiple-target BM filters and fusion approaches with the use of either a single sensor or multiple sensors in a unified and coherent fashion. State-of-the-art, relevant adaption and optimization technologies and remaining challenges are discussed. All strive to gain more insights of the approach. © 2023 Elsevier B.V.","Arithmetic average fusion; Bayesian filter; Bayesian model averaging; Finite mixture models; Gaussian mixture; Information fusion; Mixture reduction; Multi-Bernoulli mixture; Particle filter"
"Shapley-based feature augmentation","2023","Information Fusion","10.1016/j.inffus.2023.03.010","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85150435455&doi=10.1016%2fj.inffus.2023.03.010&partnerID=40&md5=959c5dbc1aae7ce796801d60fa0941ae","Improving the predictive performance of machine learning models is the desired goal in many tasks and domains. The predictive performance of the learning algorithm is directly affected by the input features it receives. Feature augmentation is aimed at enhancing the quality of models by adding informative features to the original data. Explainable AI methods are typically used to explain the results of machine learning models. Recently, these methods have also been used to improve models’ predictive performance. In this study, we examine the benefit of incorporating the explanations obtained by an explainable AI method as augmented features. In particular, we propose SFA — Shapley-Based feature augmentation, a two-stage ensemble learning method that uses out-of-fold predictions and their corresponding Shapley values as augmented features for each instance. Shapley values, which are obtained without domain expertise, reflect the importance of the original features to each prediction and consider their interactions with all other features. Experimental results demonstrate the superiority of our proposed method, SFA, against several feature augmentation methods on multiple public datasets with various characteristics. © 2023","Feature augmentation; SHAP; Shapley values; XAI"
"HoLoCo: Holistic and local contrastive learning network for multi-exposure image fusion","2023","Information Fusion","10.1016/j.inffus.2023.02.027","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149175543&doi=10.1016%2fj.inffus.2023.02.027&partnerID=40&md5=260a59d1541c320810c88080c1afbe6c","Multi-exposure image fusion (MEF) targets to integrate multiple shots with different exposures and generates a single higher dynamic image than each. Existing deep learning-based MEF approaches only adopt reference high dynamic images (HDR) as positive samples to guide the training of fusion networks. However, simply relying on these positive samples are difficult to find the optimal parameters for the network as a whole. Thus, the structure or texture information is blurred or missed in the generated HDR results. Moreover, few approaches attempted to prevent illumination degeneration during the fusion process, resulting in poor color saturation on their fused results. To address such limitations, in this paper, we introduce a novel holistic and local constraint built upon contrastive learning, namely HoLoCo, to discover the intrinsic information of both source LDR images and the reference HDR one. In this manner, the generated fused images are pulled to the HDR image and pushed away from the LDR source images in both image-based and path-based latent feature spaces. Besides, inspired by Retinex theory, we propose a color correction module (CCM) to refine illumination features. CCM involves dual streams that can collaborate to ensure the nature of color information and details consistency. Extensive experiments on two datasets show that our HoLoCo can continuously generate visual-appealing HDR results with precise detail and vivid color rendition, performing favorably against the state-of-the-art MEF approaches. Source code is available in github https://github.com/JinyuanLiu-CV/HoLoCo. © 2023","Adversarial learning; Contrastive learning; Illumination correction; Image fusion; Multi-exposure image"
"Color object classification using multi-channel Zernike moments-based rotation invariant bag-of-visual-words and deep convolutional neural networks","2023","Information Fusion","10.1016/j.inffus.2023.101823","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159042970&doi=10.1016%2fj.inffus.2023.101823&partnerID=40&md5=1710e15d4263f50f0bcc4fdceff2a9ca","We propose two rotation-invariant approaches for color object classification and recognition using multi-channel Zernike moments (MZMs)-based bag-of-visual-words (BoVWs) and deep convolutional neural networks (DCNN). The first approach, referred to as MZMs-BoVWs, derives the BoVWs descriptors from a color image and its sub-images after forming its hierarchical sub-divisions and computing the MZMs from each of the sub-images to determine similarity among sub-images to facilitate the construction of BoVWs. The second approach, called DCNN-MZMs, derives the MZMs descriptors from the feature maps of a convolutional layer of a DCNN architecture designed in this paper. A fusion of the descriptors, MZMs-BoVWs and CNN-MZMs, along with the high-performing color histograms (CH) descriptor, i.e., CH+MZMs-BoVWs+CNN-MZMs, is also proposed. The process of the object classification is performed using SVM and its multiple-kernel learning approach. Experimental results show that the proposed approaches outperform the existing state-of-the-art approaches under image-rotation and under limited data for training the CNNs. © 2023","Bag-of-visual-words; Convolutional neural networks; Object classification; Rotation invariance; Zernike moments"
"PCNet: A structure similarity enhancement method for multispectral and multimodal image registration","2023","Information Fusion","10.1016/j.inffus.2023.02.004","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147429137&doi=10.1016%2fj.inffus.2023.02.004&partnerID=40&md5=9d2bb89d0eb6b25a5168cecf9c333072","Multispectral and multimodal images are of important usage in the field of multi-source visual information fusion. Due to the alternation or movement of image devices, the acquired multispectral and multimodal images are usually misaligned, and hence image registration is pre-requisite. Different from the registration of common images, the registration of multispectral or multimodal images is a challenging problem due to the nonlinear variation of intensity and gradient. To cope with this challenge, we propose the phase congruency network (PCNet) to enhance the structure similarity of multispectral or multimodal images. The images can then be aligned using the similarity-enhanced feature maps produced by the network. PCNet is constructed under the inspiration of the well-known phase congruency. The network embeds the phase congruency prior into two simple trainable layers and series of modified learnable Gabor kernels. Thanks to the prior knowledge, once trained, PCNet is applicable on a variety of multispectral and multimodal data such as flash/no-flash and RGB/NIR images without additional further tuning. The prior also makes the network lightweight. The trainable parameters of PCNet is 2400× and 1500×less than the deep-learning registration method deep homography network (DHN) and unsupervised deep homography network (UDHN), while its registration performance surpasses them. Experimental results validate that PCNet outperforms current state-of-the-art conventional multimodal registration algorithms. Besides, PCNet can act as a complementary part of the deep-learning registration methods, which significantly boosts their registration accuracy. On the Columbia imaging and vision laboratory (CAVE) multispectral dataset, the percentage of the number of images under 1 pixel average corner error (ACE) of UDHN is raised from 0.1% to 82.5% after the processing of PCNet. © 2023 Elsevier B.V.","Convolutional neural network; Image registration; Multimodal image; Multispectral image; Phase congruency; Similarity enhancement"
"MOFA: A novel dataset for Multi-modal Image Fusion Applications","2023","Information Fusion","10.1016/j.inffus.2023.03.012","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85151233871&doi=10.1016%2fj.inffus.2023.03.012&partnerID=40&md5=68ae704a8009435fa1b89673e172d093","Multi-modal image fusion is widely used in various fields, especially in military, medical, industrial detection and other fields. Image fusion can integrate redundant and complementary information of two or more multi-modal images into one image, so that the fused image contains more useful information. In this paper, we construct a novel dataset for Multi-modal Image Fusion Applications (MOFA), including four modals: visible, near-infrared (NIR), long-wavelength infrared (LWIR) and polarization. The MOFA dataset contains 1062 images of 118 groups, in which 450 are indoor and 612 are outdoor. The dataset is applied to different image fusion applications, including general multi-modal image fusion, fusion based image super-resolution and image restoration. Multiple image fusion methods are compared and analyzed on this dataset with a qualitative assessment of subjective and objective metrics. Based on the experiments, the advantages and disadvantages of different methods are discussed. Moreover, the challenging problems of image fusion are concluded. © 2023","Image fusion; Long-wavelength infrared (LWIR); Multi-modal dataset; Near-infrared (NIR); Polarization"
"Sleep posture one-shot learning framework based on extremity joint kinematics: In-silico and in-vivo case studies","2023","Information Fusion","10.1016/j.inffus.2023.02.003","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149863819&doi=10.1016%2fj.inffus.2023.02.003&partnerID=40&md5=66a7eb7f33be579990907cf6dc6c3d21","Sleep posture is linked to several health conditions such as nocturnal cramps and more serious musculoskeletal issues. However, in-clinic sleep assessments are often limited to vital signs (e.g. brain waves). Wearable sensors with embedded inertial measurement units have been used for sleep posture classification; nonetheless, previous works consider only few (commonly four) postures, which are inadequate for advanced clinical assessments. Moreover, posture learning algorithms typically require longitudinal data collection to function reliably, and often operate on raw inertial sensor readings unfamiliar to clinicians. This paper proposes a new framework for sleep posture classification based on a minimal set of joint angle measurements. The proposed framework is validated on a rich set of twelve postures in two experimental pipelines: computer animation to obtain synthetic postural data, and human participant pilot study using custom-made miniature wearable sensors. Through fusing raw geo-inertial sensor measurements to compute a filtered estimate of relative segment orientations across the wrist and ankle joints, the body posture was characterised in a way comprehensible to medical experts. The proposed sleep posture learning framework offers plug-and-play posture classification by capitalising on a novel kinematic data augmentation method that requires only one training example per posture. Additionally, a new metric together with data visualisations were employed to extract meaningful insights from the postures dataset, demonstrate the added value of the data augmentation method, and explain the classification performance. The proposed framework attained promising overall accuracy as high as 100% on synthetic data and 92.7% on real data, on par with state of the art data-hungry algorithms available in the literature. © 2023 The Authors","Data augmentation; Human posture; Multi-classifier system; One-shot learning; Sensor fusion; Wearable sensors"
"A visual analytics approach for multi-attribute decision making based on intuitionistic fuzzy AHP and UMAP","2023","Information Fusion","10.1016/j.inffus.2023.03.019","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85151707877&doi=10.1016%2fj.inffus.2023.03.019&partnerID=40&md5=9ae745acc4f89f8d982620127965e05f","Multi-attribute decision making (MADM) has been extensively explored and applied in many real-world problems. However, comprehending the decision-making process and selecting a satisfactory choice from a large set of alternatives characterized by multiple conflicting attributes impose a significant cognitive burden on decision-makers. A visual analytics approach for MADM (MADM-VA) that integrates visual representations of alternatives with the decision-making analysis process is proposed to solve this problem. Firstly, to ensure the final decision meets the actual needs and expectations of decision-makers, an Intuitionistic Fuzzy Analytic Hierarchy Process based on Nonlinear Programming (IFAHP-NLP) is proposed. This approach directly determines the optimal crisp attribute weight vector according to the preferences of decision-makers and avoids information loss and distortion of attribute weights caused by defuzzification. Next, the Uniform Manifold Approximation and Projection (UMAP) is used to map the high-dimensional weighted normalized decision matrix to two-dimensional space, illustrating the distribution of alternatives. The concept of similarity to the ideal solution is introduced to enhance the interpretability of the generated space. Furthermore, the Voronoi diagram is innovatively adopted to assist decision-makers in gaining a better understanding of the decision-making process and help them visually identify the best choice, which is closest to the positive ideal solution and farthest from the negative ideal solution. Finally, experimental results from two case studies verify that MADM-VA is efficient and reliable. © 2023 Elsevier B.V.","Dimensionality reduction; Intuitionistic fuzzy AHP; Multi-attribute decision making; Visual analytics"
"Hybrid multi-model ensemble learning for reconstructing gridded runoff of Europe for 500 years","2023","Information Fusion","10.1016/j.inffus.2023.101807","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85153043563&doi=10.1016%2fj.inffus.2023.101807&partnerID=40&md5=c8169a712d582420e16a258b9809a8f8","Runoff is a crucial water cycle component that contributes to the water resources to sustain human life. Historical trends in runoff, when examining climate change scenarios, provide vital information about past variability and support the design of adaptation measures. However, hydrological models based on climate data, such as the Budyko model, can be biased in estimating annual runoff due to input data uncertainty. Therefore, it is vital to utilize advanced machine learning-based computing models to reduce uncertainty and reconstruct climate variables over a long period of time and sufficiently large spatial coverage, preferably at a continental scale. We propose and test a novel machine learning-based framework called Hybrid Ensemble Multi-Model Framework (HEMMF) to reconstruct the gridded runoff of Europe over a 500-year historical period (1500 to 1999). The HEMMF combines non-parametric extended data pattern recognition and data-driven methods. The extended data patterns are computed using Moran's spatial autocorrelation (SPA) index of the climate variable fields and the Budyko models output, whereas the data-driven methods contain nine different machine learning (ML) algorithms and four ensembles of ML. The extended data patterns are jointly ingested with climate-reconstructed data (precipitation, temperature, Palmer's drought severity index) as predictor variables, which serve as input for the data-driven methods. To assess the impact and contribution of SPA, the runoff is simulated based on three different input training datasets in the HEMMF: (1) a dataset containing only precipitation, temperature, Palmer's drought severity index, and four different estimates of runoff from the Budyko model, (2) a dataset containing only SPA of the first input datasets, and (3) a dataset created by merging the first and second datasets. The HEMMF offers the best reconstruction performance when using the third input dataset. This reconstructed runoff helps to explain the runoff trend, drought propagation, and runoff's link with the climate variables. The proposed methodology has the potential to be applied to past hydroclimatic data and related analyses across different temporal periods, climate scenarios, and geographical scales. © 2023 Elsevier B.V.","Ensemble machine learning; Hybrid Ensemble Multi-Model Framework (HEMMF); Machine learning; Spatial auto-correlation"
"Semantic-Relation Transformer for Visible and Infrared Fused Image Quality Assessment","2023","Information Fusion","10.1016/j.inffus.2023.02.021","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149747849&doi=10.1016%2fj.inffus.2023.02.021&partnerID=40&md5=a68ead1dc5f1b6a28e1c7c42949630b8","Although extensive researches have carried out on visible and infrared images fusion, quality assessment of the fused image is still challenging due to the absence of the reference image. In this paper, a subjective benchmark dataset and a semi-reference objective assessment method based on a Transformer encoder–decoder framework named Semantic-Relation Transformer (SRT), are developed for Visible and Infrared Fused Image Quality Assessment (VIF-IQA). Different with existing Transformers, SRT decoder can extract multi-level source image features and adopts a Multi-Head Self-Evaluation (MHSE) block which is constructed to mine latent relation knowledge between the fused image and source images. The relation knowledge is then injected into 3D-token with deep semantic embedding of receptive regions. Finally, the objective assessment score is obtained from-token through linear mapping of local to global. Moreover, we meticulously select 4,000 fused images from 200 scenes in TNO, MSRS, M3FD and Road Scene datasets and create a Visible and Infrared fuSed qualiTy Assessment (VISTA) dataset, which is guided by Subjective VIF-IQA Specification rigorously. VISTA dataset is utilized to comprehensively validate the proposed SRT. The experimental results demonstrated that the output of SRT is more in keeping with subjective feelings. Moreover, SRT has state-of-the-art performance on quantitative metrics when compared with 12 popular methods and the output of SRT is more in keeping with subjective feelings. VISTA dataset is available at https://github.com/ChangeZH/VISTA-Dataset. © 2023","Image quality assessment; Multi-head self-evaluation; Semantic-relation transformer; Visible and infrared images fusion"
"Deep learning for intra-hour solar forecasting with fusion of features extracted from infrared sky images","2023","Information Fusion","10.1016/j.inffus.2023.02.006","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147990960&doi=10.1016%2fj.inffus.2023.02.006&partnerID=40&md5=764037f37cff250c074f1d8d17a06fa0","The increasing penetration of solar energy leaves power grids vulnerable to fluctuations in the solar radiation that reaches the surface of the Earth due to the projection of cloud shadows. Therefore, an intra-hour solar forecasting algorithm is necessary to reduce power instabilities caused by the impact of moving clouds on energy generation. The most accurate intra-hour solar forecasting methods apply convolutional neural networks to a series of visible light sky images. Instead, this investigation uses data acquired by a novel infrared sky imager on a solar tracker, which is capable of maintaining the Sun in the center of the images throughout the day and, at the same time, reducing the scattering effect produced by the Sun's direct radiation. In addition, infrared sky images allow the derivation and extraction of physical cloud features. The cloud dynamics are analyzed in sequences of images to compute the probability of the Sun intercepting air parcels in the sky images (i.e., voxels). The method introduced in this investigation fuses sky condition information from multiple sensors (i.e., pyranometer, sky imager, solar tracker, weather station) and feature sources using a multi-task deep learning architecture based on recurrent neural networks. The proposed deterministic and Bayesian architectures reduce computation time by avoiding convolutional filters. The proposed intra-hour solar forecasting algorithm reached a forecast skill of 18.6% with a forecasting horizon of 8 min. Consequently, the proposed intra-hour solar forecasting method can potentially reduce the operational costs of power grids with high participation of solar energy. © 2023","Bayesian networks; Bayesian optimization; Deep learning; Girasol dataset; Sky imaging; Solar forecasting"
"Increasing depth of neural networks for life-long learning","2023","Information Fusion","10.1016/j.inffus.2023.101829","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159775593&doi=10.1016%2fj.inffus.2023.101829&partnerID=40&md5=d392684cc6da0a9cc8c485cabfd3a34e","Purpose: We propose a novel method for continual learning based on the increasing depth of neural networks. This work explores whether extending neural network depth may be beneficial in a life-long learning setting. Methods: We propose a novel approach based on adding new layers on top of existing ones to enable the forward transfer of knowledge and adapting previously learned representations. We employ a method of determining the most similar tasks for selecting the best location in our network to add new nodes with trainable parameters. This approach allows for creating a tree-like model, where each node is a set of neural network parameters dedicated to a specific task. The Progressive Neural Network concept inspires the proposed method. Therefore, it benefits from dynamic changes in network structure. However, Progressive Neural Network allocates a lot of memory for the whole network structure during the learning process. The proposed method alleviates this by adding only part of a network for a new task and utilizing a subset of previously trained weights. At the same time, we may retain the benefit of PNN, such as no forgetting guaranteed by design, without needing a memory buffer. Results: Experiments on Split CIFAR and Split Tiny ImageNet show that the proposed algorithm is on par with other continual learning methods. In a more challenging setup with a single computer vision dataset as a separate task, our method outperforms Experience Replay. Conclusion: It is compatible with commonly used computer vision architectures and does not require a custom network structure. As an adaptation to changing data distribution is made by expanding the architecture, there is no need to utilize a rehearsal buffer. For this reason, our method could be used for sensitive applications where data privacy must be considered. © 2023 The Author(s)","Continual learning; Deep learning; Life-long learning; Machine learning"
"An evaluation of ECG data fusion algorithms for wearable IoT sensors","2023","Information Fusion","10.1016/j.inffus.2023.03.017","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85151513195&doi=10.1016%2fj.inffus.2023.03.017&partnerID=40&md5=6a5a66c8324e70c421137a64a1044aad","In wearable sensing, accurate estimation of physiological parameters is paramount, although these signals can be corrupted by noise. The fusion of data from multiple sensor sources has the potential to enhance accuracy, even in the presence of disruptive noise. This paper aims to introduce and compare various existing state-of-the-art and novel data fusion techniques to improve the reliability of heart rate estimation. The comparisons were implemented using the MIT-BIH Arrhythmia database with additive noise signals taken from MIT Noise Stress Test Database. When it comes to the challenging low signal-to-noise ratio (SNR) regions, the Kalman fusion and the α-trim mean filtering approach exhibits the best performance. The Kalman fusion approach dominates when both channels are corrupted, while the α-trim mean filtering elimination algorithm takes the lead when at least one channel is clean. To make the most of these strengths, we have developed an innovative algorithm that can switch between the two fusion methods based on a signal quality indicator (SQI) that serves as a surrogate SNR. This algorithm outperforms the baseline 2-channel RR-interval averaging approach by ≃54% and ≃21% at SNRs of 20dB and −20dB respectively. Moreover, it outperforms other cutting-edge heart rate estimation methods. © 2023 The Authors","Bayesian filtering; Data fusion; Electrocardiography; Heart rate estimation; Kalman fusion; Signal quality indicators"
"The relative roles of different land-use types in bike-sharing demand: A machine learning-based multiple interpolation fusion method","2023","Information Fusion","10.1016/j.inffus.2023.02.033","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149301637&doi=10.1016%2fj.inffus.2023.02.033&partnerID=40&md5=f702d56dd2fc314f09267aa40aa8bd7a","Land use plays a crucial role in promoting the bike-sharing demand. Traditionally, studies on bike-sharing demand (BSD) are mainly focused on its prediction through regression methods, but the influence of MAUP (modifiable areal unit problem) in modeling is ignored. This paper aims to model spatial BSD distribution and prove the driving forces of different land use types to BSD through a machine-learning-based multiple interpolation fusion method. The hotspot detection model is employed to establish sample points covering different land use types in urban areas. In order to capture the differences in adaptations among different urban regions and for different data sizes, six machine learning methods are applied and evaluated to improve BSD estimation by fusing five spatial interpolation algorithms, including Inverse Distance Weight, Spline, Kriging, Natural Neighborhood and Trend. The methodological verification of Beijing City shows that the fusion models improve the estimation performance compared with individual interpolation algorithms, and that GRNN (generalized regression neural network) method is superior to all the others. According to fitting results of all POIs based on the GRNN fusion model, we identify which types of facilities correspond to customers that will have a stronger preference for bike-sharing and demonstrate which facility names are more prominent in each land use type. The conclusions presented here enrich our understanding relationships between land-use and BSD, which provide a valuable foundation for the bike-sharing development. Compared with implementing regression in an analysis zone or a square grid, troubles caused by the MAUP are effectively solved through this method. © 2023 Elsevier B.V.","Bike-sharing demand; Fusion model; Land-use; Machine learning; Relative roles; Spatial interpolation"
"Multimodal pedestrian detection using metaheuristics with deep convolutional neural network in crowded scenes","2023","Information Fusion","10.1016/j.inffus.2023.02.014","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85150869247&doi=10.1016%2fj.inffus.2023.02.014&partnerID=40&md5=46d4a2a63af0c87faacbcd8725b7ad99","Pedestrian detection (PD) is a vital computer vision (CV) problem that is highly employed in several real-time applications, namely autonomous driving methods, robotics, and security observing methods. Simulated by deep learning (DL) approaches to the recognition of generic objects, several investigation mechanisms have attained maximum recognition accuracy for acceptable scale and non-blocked pedestrians. However, the detection efficiency needed to be improved for complex cases like rare pose samples, crowd scenes, and cases with worse visibility due to daytime or weather. Therefore, this study develops a multimodal pedestrian detection system in crowded scenes using metaheuristics and a deep convolutional neural network (MMPD-MDCNN) technique. The MMPD-MDCNN technique's goal is to identify pedestrians in crowd scenes using different deep-learning models effectively. The proposed MMPD-MDCNN technique integrates three deep learning models: the residual network (ResNet-50), Inception v3, and the capsule network (CapsNet). In addition, the Harris Hawks Optimization (HHO) algorithm is applied for optimal hyperparameter tuning of the deep learning models. For pedestrian detection, the MMPD-MDCNN technique uses the long short-term memory (LSTM) model, and its hyperparameters can be adjusted by the shark smell optimization (SSO) algorithm. To demonstrate the superior performance of the MMPD-MDCNN approach, A comprehensive set of simulations on the INRIA and UCSD datasets was performed to illustrate the superior performance of the MMPD-MDCNN approach. The experimental results suggest that the MMPD-MDCNN model performs well on both datasets. © 2023 Elsevier B.V.","Computer vision; Crowded scenes; Deep learning; Hyperparameter tuning; Multi-modal; Pedestrian detection"
"Artificial intelligence for cybersecurity: Literature review and future research directions","2023","Information Fusion","10.1016/j.inffus.2023.101804","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85152146620&doi=10.1016%2fj.inffus.2023.101804&partnerID=40&md5=336dfa4faa8db777fb98d007f8be8db7","Artificial intelligence (AI) is a powerful technology that helps cybersecurity teams automate repetitive tasks, accelerate threat detection and response, and improve the accuracy of their actions to strengthen the security posture against various security issues and cyberattacks. This article presents a systematic literature review and a detailed analysis of AI use cases for cybersecurity provisioning. The review resulted in 2395 studies, of which 236 were identified as primary. This article classifies the identified AI use cases based on a NIST cybersecurity framework using a thematic analysis approach. This classification framework will provide readers with a comprehensive overview of the potential of AI to improve cybersecurity in different contexts. The review also identifies future research opportunities in emerging cybersecurity application areas, advanced AI methods, data representation, and the development of new infrastructures for the successful adoption of AI-based cybersecurity in today's era of digital transformation and polycrisis. © 2023 The Author(s)","Cyberattacks; Detection; Identify; Learning; Protection; Recovery; Response; Taxonomy"
"A framework for generalized monotonicity of fusion functions","2023","Information Fusion","10.1016/j.inffus.2023.101815","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85153473455&doi=10.1016%2fj.inffus.2023.101815&partnerID=40&md5=5646d0c74f4a619dab1a56a6ccecdff4","The relaxation of the property of monotonicity is a trend in the theory of aggregation and fusion functions and several generalized forms of monotonicity have been introduced, most of which are based on the notion of directional monotonicity. In this paper, we propose a general framework for generalized monotonicity that encompasses the different forms of monotonicity that we can find in the literature. Additionally, we introduce various new forms of monotonicity that are not based on directional monotonicity. Specifically, we introduce dilative monotonicity, which requires that the function increases when the inputs have increased by a common factor, and a general form of monotonicity that is dependent on a function T and a subset of the domain Z. This two new generalized monotonicities are the basis to propose a set of different forms of monotonicity. We study the particularities of each of the new proposals and their links to the previous relaxed forms of monotonicity. We conclude that the introduction of dilative monotonicity complements the conditions of weak monotonicity for fusion functions and that (T,Z)-monotonicity yields a condition that is slightly stronger than weak monotonicity. Finally, we present an application of the introduced notions of monotonicity in sentiment analysis. © 2023 The Author(s)","Aggregation function; Fusion function; Generalized monotonicity; Monotonicity; Sentiment analysis; Text classification"
"A new approach based on association rules to add explainability to time series forecasting models","2023","Information Fusion","10.1016/j.inffus.2023.01.021","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147431189&doi=10.1016%2fj.inffus.2023.01.021&partnerID=40&md5=bd5c571147c2769aca050cb1c3bdff44","Machine learning and deep learning have become the most useful and powerful tools in the last years to mine information from large datasets. Despite the successful application to many research fields, it is widely known that some of these solutions based on artificial intelligence are considered black-box models, meaning that most experts find difficult to explain and interpret the models and why they generate such outputs. In this context, explainable artificial intelligence is emerging with the aim of providing black-box models with sufficient interpretability. Thus, models could be easily understood and further applied. This work proposes a novel method to explain black-box models, by using numeric association rules to explain and interpret multi-step time series forecasting models. Thus, a multi-objective algorithm is used to discover quantitative association rules from the target model. Then, visual explanation techniques are applied to make the rules more interpretable. Data from Spanish electricity energy consumption has been used to assess the suitability of the proposal. © 2023 Elsevier B.V.","Association rules; Explainable AI; Interpretability; Machine learning; Time series forecasting"
"Sparse robust subspace learning via boolean weight","2023","Information Fusion","10.1016/j.inffus.2023.03.020","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85151568730&doi=10.1016%2fj.inffus.2023.03.020&partnerID=40&md5=edf13cd1669bbf8c9ff5f29fe7b3a639","Unsupervised feature selection is a hot topic in the field of machine learning, which is more convenient and important because it does not require labeled data. Currently, unsupervised feature selection algorithms based on ℓ2,1-norm are very mature and have certain robustness to outliers, but they still have some problems that cannot be ignored. For example, the sparsity of ℓ2,1-norm is not ideal, they cannot achieve row sparsity but only element sparsity. Second, fine-tuning meaningless regularization parameters increases cost and makes it easy to fall into suboptimal solutions. To release the above problems, we propose an unsupervised feature selection algorithm via Sparse Robust Subspace Learning (SRSL), which combines reconstruction term and variance term so that the model simultaneously preserves reconstruction information and enhances separability. What is more, using the ℓ2,0-norm constraint on transformation matrix makes our model have a row-sparse property. In addition, we design the boolean weight so that the model not only eliminates outliers fundamentally to enhance robustness, but also achieves the effect of anomaly detection. To solve this NP-hard problem, we carefully design an optimization algorithm, which has strict convergence guarantees and obtains a closed-form solution. Experimental results on several real-world datasets demonstrate that our algorithm outperforms other comparison algorithms in both clustering and anomaly detection applications. © 2023 Elsevier B.V.","Abnormal; Boolean weight; Robustness; Sparse subspace"
"IID-MEF: A multi-exposure fusion network based on intrinsic image decomposition","2023","Information Fusion","10.1016/j.inffus.2023.02.031","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149378089&doi=10.1016%2fj.inffus.2023.02.031&partnerID=40&md5=ad1f30b23b271da68c6a9b4fef32c42c","This paper follows the idea of divide and conquer to propose a multi-exposure fusion network for the unsupervised generation of high dynamic range-like images. We develop a new intrinsic image decomposition (IID) network based on our modified IID model to produce the reflectance, shading, and color components from source images, which respectively represent the texture structure, lighting condition, and visible color distribution of the imaging scene. Three fusion sub-networks are then designed to process these different components, producing pleasing images with rich structures, reasonable lighting, and suitable color. Specifically, we first develop a reflectance fusion network to integrate the reflectance components, in which an adaptive pixel-scale selection strategy is adopted to dynamically guide the network to preserve rich scene textures. Then, a shading fusion network with the adaptive global image-scale weighting strategy is designed to fulfill lighting adjustment, which can generate suitable illumination by defining the lighting adjustment as a game between the illumination of source images. Finally, we propose a color fusion network that embeds both pixel-scale and image-scale strategies, which can guarantee a pleasing scene color distribution with a specifically designed color fidelity loss. Extensive experiments demonstrate the superiority of our method over state-of-the-art methods in terms of texture integration, illumination adjustment, and color fidelity. Moreover, our method can be applied to fulfill tasks of the single low-light image enhancement and the single overexposed image correction with promising performance. The code is publicly available at https://github.com/HaoZhang1018/IID-MEF. © 2023 Elsevier B.V.","Color; Image fusion; Multi-exposure; Reflectance; Shading"
"Distributed state-of-charge estimation for lithium-ion batteries with random sensor failure under dynamic event-triggering protocol","2023","Information Fusion","10.1016/j.inffus.2023.02.032","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149329677&doi=10.1016%2fj.inffus.2023.02.032&partnerID=40&md5=de7d0d4d9553513dde137e57be21f164","The state of charge (SOC) performs as an indicator of the remaining capacity of the Lithium-ion batteries (LBs). An accurate SOC estimation of LB is of great significance for its operation optimization and life extension of the battery. In this article, the issue of distributed SOC estimation is addressed for LBs. To design the distributed filter for SOC estimation, the equivalent circuit model comprised of the resistor–capacitor networks, Warburg element, ohmic resistance, battery current and voltage is established. In order to reflect the properties of the random sensor failure (RSF) well, a set of Bernoulli-distributed sequences with known probabilities is introduced. The communication resources over the wireless networks are usually limited, for the purpose of saving communication resources, the dynamic event-triggering mechanism (DETM) is adopted to regulate transmission of the signals. The main objective of this article is to design a distributed SOC estimation approach for LBs subject to RSF under DETM over the sensor networks. The upper bound of the estimation error covariance is first ensured and then such upper bound is minimized by parameterizing the estimator gain. In addition, by virtue of the matrix simplification technique, the issue of sensor network topology's sparseness is effectively tackled. At last, experimental examples are employed to validate the feasibility of the developed distributed SOC estimation algorithm. © 2023 Elsevier B.V.","Distributed filtering; Dynamic event-triggering; Lithium-ion batteries; Random sensor failure; Sensor networks; State-of-charge estimation"
"Adaptive collaborative fusion for multi-view semi-supervised classification","2023","Information Fusion","10.1016/j.inffus.2023.03.002","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85150048702&doi=10.1016%2fj.inffus.2023.03.002&partnerID=40&md5=8089992b84d08c008be6ba2186beeb8d","Multi-view semi-supervised classification is inherently a challenging task in multi-view learning due to the lack of label information. Existing methods generally suffer from insufficient data fusion, expensive computation cost in the solution procedure and fail in tackling unseen samples directly, intensively limiting their applicability and efficiency in real scenarios. To address these issues, we propose an adaptive collaborative fusion method, seeking for an appropriate representation and fusion for multi-view data. The main advantage of the proposed method is that it simultaneously fuses both multiple feature projections and similarity graphs to learn a joint projection subspace as well as a unified similarity graph that fully preserve the correlation and distinction among views. Meanwhile, our method can coalesce different views in an adaptive-weighting manner, making the learned subspace more discriminative and facilitating label propagation on the fused graph. Furthermore, an acceleration strategy has been designed to reduce the computational complexity, thereby making the proposed method scalable to relatively large-scale data. Finally, an alternating optimization has been adopted to solve the formulated objective function. Extensive experiments on synthetic and real-world datasets are conducted to demonstrate the effectiveness and superiority of our proposed method. © 2023 Elsevier B.V.","Adaptive graph fusion; Collaborative fusion; Feature projection; Multi-view data fusion; Semi-supervised multi-view classification"
"An expertise-based consensus reaching process with probability-hesitant fuzzy preference relations and its application in risk assessment in food industry","2023","Information Fusion","10.1016/j.inffus.2023.101809","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85156166976&doi=10.1016%2fj.inffus.2023.101809&partnerID=40&md5=8f5b6717ede9cf0ed5fca2639b63a02e","This paper proposes a novel expertise-based consensus reaching process (CRP) for probability-hesitant fuzzy preference relations (PHFPRs). First, to identify each expert's comprehensive expertise level, an expertise identification function is constructed based on consistency, hesitancy, and discrimination indicators of PHFPRs. Then, we introduce an expected value based expertise induced ordered weighted averaging (E-IOWA) operator for the aggregation of individual PHFPRs. Here, experts’ weights are objectively and dynamically assigned according to their identified expertise levels at each round. To prompt a consensus, this paper presents an expertise-based feedback mechanism so as to provide highly personalized direction rules for experts’ preference adjusting. Finally, a case study of risk assessment in food industry and comparative analysis are conducted to prove the validity of the proposed CRP. © 2023 Elsevier B.V.","Consensus reaching process; Expertise identification; Group decision making; Probability-hesitant fuzzy preference relation"
"HS2P: Hierarchical spectral and structure-preserving fusion network for multimodal remote sensing image cloud and shadow removal","2023","Information Fusion","10.1016/j.inffus.2023.02.002","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149060693&doi=10.1016%2fj.inffus.2023.02.002&partnerID=40&md5=e94b8682c827e7a0f29e8536ccebd4dc","Optical remote sensing images are often contaminated by clouds and shadows, resulting in missing data, which greatly hinders consistent Earth observation missions. Cloud and shadow removal is one of the most important tasks in optical remote sensing image processing. Due to the characteristics of active imaging that enable synthetic aperture radar (SAR) to penetrate cloud cover and other climatic conditions, SAR data are extensively utilized to guide optical remote sensing image cloud and shadow removal. Nevertheless, SAR data are highly corrupted by speckle noise, which generates artifact pollution to spectral features extracted from optical images and makes SAR-optical fusion ill-posed to generate cloud and shadow removal results while retaining high spectral fidelity and reasonable spatial structures. To overcome the aforementioned drawbacks, this paper presents a novel hierarchical spectral and structure-preserving fusion network (HS2P), which can recover cloud and shadow regions in optical remote sensing imagery based on the hierarchical fusion of optical and SAR remote sensing imagery. In HS2P, we present a deep hierarchical architecture with stacked residual groups (ResGroups), which progressively constrains the reconstruction. To pursue the adaptive selection of more informative features for fusion and reduce attention to the features with artifacts brought by clouds and shadows in optical data or speckle noise in SAR data, residual blocks with a channel attention mechanism (RBCA) are recommended. Additionally, a novel collaborative optimization loss function is proposed to preserve spectral features while enhancing structural details. Extensive experiments on the publicly open dataset (i.e., SEN12MS-CR) demonstrate that the proposed method can robustly recover diverse ground information in optical remote sensing imagery with various cloud types. Compared with the state-of-the-art cloud and shadow removal methods, our HS2P achieves significant improvements in terms of quantitative and qualitative results. The source code is publicly available at https://github.com/weifanyi515/HS2P. © 2023 Elsevier B.V.","Multimodal image fusion network; Remote sensing image cloud and shadow removal; Synthetic aperture radar-guided optical image reconstruction"
"An efficient unfolding network with disentangled spatial-spectral representation for hyperspectral image super-resolution","2023","Information Fusion","10.1016/j.inffus.2023.01.018","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147093014&doi=10.1016%2fj.inffus.2023.01.018&partnerID=40&md5=d9774f5fca1749e2a93808b83e3cf830","Hyperspectral image super-resolution (HSI SR) is dramatically impacted by high spectral dimensionality, insufficient spatial resolution, and limited availability of training samples. Current approaches mainly rely on complex data-driven models to address some of these challenges, and the characteristics of HSI are not fully considered in the model design. In this paper, we propose an efficient unfolding network with disentangled spatial-spectral representation (EUNet) for HSI SR by combining domain knowledge (i.e., spectral correlation, degradation model, and structure prior) with deep learning. Specifically, the optimization process of the super-resolution prior-driven Maximum A Posterior (MAP) framework is unfolded into an interpretable multi-stage network, which inherits the advantages of deep learning-based image super-resolution (e.g., feature extraction in low-resolution space) and explicitly imposes the degradation model constraint. To well incorporate the structure prior of HSI, spatial and spectral feature extraction is disentangled by a variant of depthwise separable convolution, and spectral correlation is embedded by a lightweight spectral attention mechanism, so that the difficulty and computational complexity of feature learning are greatly reduced. Experiments on benchmark datasets with different degradation models demonstrate the feasibility and superiority of the proposed EUNet over other state-of-the-art methods in terms of evaluation metrics and computational complexity. The source code is available at https://github.com/denghong-liu/EUNet. © 2023","Disentangled spatial-spectral representation; Hyperspectral image; Super-resolution; Unfolding network"
"Learning invariant and uniformly distributed feature space for multi-view generation","2023","Information Fusion","10.1016/j.inffus.2023.01.011","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146425661&doi=10.1016%2fj.inffus.2023.01.011&partnerID=40&md5=e570954aba895b0b94722bde4a23416b","Multi-view generation from a given single view is a significant, yet challenging problem with broad applications in the field of virtual reality and robotics. Existing methods mainly utilize the basic GAN-based structure to help directly learn a mapping between two different views. Although they can produce plausible results, they still struggle to recover faithful details and fail to generalize to unseen data. In this paper, we propose to learn invariant and uniformly distributed representations for multi-view generation with an “Alignment” and a “Uniformity” constraint (AU-GAN). Our method is inspired by the idea of contrastive learning to learn a well-regulated feature space for multi-view generation. Specifically, our feature extractor is supposed to extract view-invariant representation that captures intrinsic and essential knowledge of the input, and distribute all representations evenly throughout the space to enable the network to “explore” the entire feature space, thus avoiding poor generative ability on unseen data. Extensive experiments on multi-view generation for both faces and objects demonstrate the generative capability of our proposed method on generating realistic and high-quality views, especially for unseen data in wild conditions. © 2023 Elsevier B.V.","Contrastive learning; Generative adversarial networks; Multi-view generation"
"PARIS: Partial instance and training set selection. A new scalable approach to multi-label classification","2023","Information Fusion","10.1016/j.inffus.2023.02.017","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85148538622&doi=10.1016%2fj.inffus.2023.02.017&partnerID=40&md5=ed1fdeed9b0070a705528193883caaee","Multi-label classification has recently attracted research interest as a data mining task. Many current applications in data mining address problems that have instances belonging to more than one class. This requires the development of new efficient methods. Instance selection has been used in multi-label learning to improve the execution time and classification performance of many learning methods. Following the single-label approach, instance selection has been applied by selecting or unselecting the same instances for all labels. In this paper, we present a different and novel approach. An instance might be useful for some labels and harmful for others; therefore, our algorithm allows each instance to be discarded, selected, or only partially selected for use in the classification of certain labels. An extensive comparison using 45 datasets shows the usefulness of our approach in improving the current instance selection methods for multi-label problems, as well as the ability of our algorithm to compete with other more complex multi-label classification methods. © 2023 The Author(s)","Instance selection; Instance-based learning; Multi-label classification; Scaling-up"
"A deep penetration network for sentence classification","2023","Information Fusion","10.1016/j.inffus.2023.02.015","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85148545159&doi=10.1016%2fj.inffus.2023.02.015&partnerID=40&md5=dc0ad4e71048b46864e1acb29a29373b","Sentence classification is an important task in natural language processing. The task makes use of deep networks to enclose a mass of features with different granularities in a sentence. However, the classification usually suffer from severe performance degradation when stacking a large number of networks. The main reason is that, in a deep architecture, the silent feature representations are easily weakened and mixed with noisy information, which is not effective in learning contextual features and constructing semantic dependencies in a sentence. In this paper, a deep penetration network (DPN) is designed to improve deep architectures’ ability to preserve the favourable semantic features. The DPN enables salient features to penetrate through a deeper architecture and to construct long semantic dependencies between them. This approach is evaluated on seven public datasets. Our experiments show that the DPN exhibits a stable performance with deeper architectures. It improves the performance on three types of sentence classification tasks, outperforming the existing state-of-the-art models. © 2023 Elsevier B.V.","Feature extraction; Natural language processing; Sentence classification; Text classification"
"A novel distributed forecasting method based on information fusion and incremental learning for streaming time series","2023","Information Fusion","10.1016/j.inffus.2023.02.023","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85148543130&doi=10.1016%2fj.inffus.2023.02.023&partnerID=40&md5=87f4850ade71aa6736ea21a51d80dbef","Real-time algorithms have to adapt and adjust to new incoming patterns to provide timely and accurate responses. This paper presents a new distributed forecasting algorithm for streaming time series called StreamWNN. StreamWNN starts with an offline stage in which a forecasting model based on tuples of information fusion is created with historical data. In particular, this model consists of the fusion of patterns composed of past values of the time series with the future values of their k-nearest neighbors. Afterwards, streaming data starts to arrive. The model is incrementally updated in the online stage using a buffer with streaming data that more accurately matches the current model patterns. The model can be updated daily, monthly, quarterly or based on error thresholds. The methodology has been applied to Spanish electricity demand time series providing more accurate results when the model is updated incrementally. The best error results are obtained with the daily update of the model, resulting in an error between 2% and 3.5% depending on the prediction horizon. The model provides better error results than other algorithms. © 2023 Elsevier B.V.","Electricity demand; Incremental learning; Real-time forecasting; Streaming time series"
"Large-scale group consensus hybrid strategies with three-dimensional clustering optimisation based on normal cloud models","2023","Information Fusion","10.1016/j.inffus.2023.01.017","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147250110&doi=10.1016%2fj.inffus.2023.01.017&partnerID=40&md5=e8d41530f9fa8dd1fbe143ad55a106b5","Large-scale group decision-making (LSGDM) is characterised by a large number of experts and a complex consensus reaching process. Clustering is used to divide the large group into a number of manageable subgroups; however, the simultaneous presence of all subgroup members at the negotiation process is rare. Thus, the selection of subgroup representatives for a smooth negotiation is necessary. Few LSGDM consensus recommendation optimisation models truly consider the problems of subgroup representative selection in their strategy to reach a consensus. This article proposes LSGDM consensus hybrid strategy framework with three-dimension clustering optimisation based on normal cloud models (NCMs) whose aims are threefold: (1) the use of NCMs to represent the imprecision of linguistic preferences provided in real complex decision scenarios with a large number of experts; (2) to establish a clustering optimisation method to choose subgroup representatives using three sensible criteria: preference similarity level within the subgroup, preference precision level, and preference consistency level; and (3) to establish two consensus recommendation optimisation strategies for individual negotiation-guided and moderator-guided consensus reaching, respectively. The feasibility and applicability of the proposed method are illustrated via a power curtailment policy assessment example, then some sensitive and comparative analyses are conducted to explicit the effectiveness and advantages of the proposed consensus hybrid strategies. © 2023 Elsevier B.V.","Consensus hybrid strategies; Consistency; Normal cloud model; Preference compromise limit; Three-dimensional clustering optimisation"
"Knowledge representation and reasoning using interconnected uncertain rules for describing workflows in complex systems","2023","Information Fusion","10.1016/j.inffus.2023.01.007","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146421572&doi=10.1016%2fj.inffus.2023.01.007&partnerID=40&md5=0e0712a980908e8d1a3ac01682fd2ccf","Knowledge representation and reasoning (KRR) in complex systems (CSs) usually require facts from multiple experts having complementary backgrounds to fuse together. Consequently, such KRR methods should provide universal modeling languages close to human reasoning, with increased expressiveness and efficient capabilities to describe uncertainties. In this context, this paper introduces a new modeling formalism entitled Hybrid Logic-Algebraic Relational Modeling which is based on combining logic, probabilities, numerical information and network representations. The behavior, facts and workflows in a CS can be described using an environment of interconnected models enclosing sets of logical rules with attached probabilistic trust factors and links regarding logical attributes and numerical parameters. The logical and probabilistic inference applied to the modeling environment gives valuable knowledge to designers and decision-makers so that they can develop procedures or take actions in managing the CS. In this article, the proposed approach is completely formalized, from concept to definition and proofs and up to implementation, while its usage is illustrated within a complex economic, logistical, economical and technical scenario. © 2023 Elsevier B.V.","Complex workflows; Knowledge reasoning; Knowledge representation; Probabilistic logic inference; Relational modeling; Trust factors"
"Hybrid-ensemble-based interpretable TSK fuzzy classifier for imbalanced data","2023","Information Fusion","10.1016/j.inffus.2023.101845","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159550901&doi=10.1016%2fj.inffus.2023.101845&partnerID=40&md5=5e6e4453de6a223c0d3324676ae0ab45","Owing to its distinguished nonlinear mapping capability and interpretability, a Takagi–Sugeno–Kang (TSK) fuzzy classifier is always employed to achieve both enhanced generalization and better interpretability on imbalanced datasets. In this study, inspired by ensemble learning, a novel hybrid-ensemble-based imbalanced interpretable TSK fuzzy classifier (HI-TSK-FC) is proposed to integrate an imbalanced global linear regression sub-classifier (IGLRc) and several imbalanced TSK fuzzy sub-classifiers (I-TSK-FCs). According to both human's “wholly coarse to locally fine” cognitive behavior and the stacked generalization principle, the training method of HI-TSK-FC, called imbalanced residual sketch learning (IRSL), is further devised to share the virtues of both deep and wide learning. Concretely, IRSL firstly generates IGLRc by calling a newly proposed imbalanced global-sparse-representation-based regression method (IGSR) on all training samples to achieve a wholly coarse result and identifies the nonlinearly distributed training samples in imbalanced datasets. Subsequently, the nonlinearly distributed training samples can be partitioned into several imbalanced residual sketches with much imbalanced likely by calling the proposed residual-based partition method (RPM). After that, several I-TSK-FCs are generated to achieve locally fine results in a parallel way on the corresponding imbalanced residual sketches. Finally, a new minimal-distance-based voting strategy is taken on the stacked outputs of both IGLRc and all I-TSK-FCs to obtain the final output of HI-TSK-FC. Besides, the proposed minimal-distance-based voting strategy also guarantees an interpretable and clear prediction route of HI-TSK-FC for each testing sample. Consequently, HI-TSK-FC owns both feature-importance-based and linguistic-based interpretabilities. Both experimental and statistical results confirm that except for feature-importance-based interpretability, HI-TSK-FC achieves at least comparable generalization capability, better linguistic interpretability (fewer adopted fuzzy rules and smaller model complexity) and faster running speed on all adopted imbalanced datasets. © 2023 Elsevier B.V.","Ensemble learning; Generalization capability; Hybrid ensemble structure; Imbalanced residual sketch learning; Imbalanced TSK fuzzy classifier; Interpretability"
"Epilepsy detection in 121 patient populations using hypercube pattern from EEG signals","2023","Information Fusion","10.1016/j.inffus.2023.03.022","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85151514467&doi=10.1016%2fj.inffus.2023.03.022&partnerID=40&md5=d417c972798c0e1a2378c3445ee0204a","Background: Epilepsy is one of the most commonly seen neurologic disorders worldwide and has generally caused seizures. Electroencephalography (EEG) is widely used in seizure diagnosis. To detect epilepsy automatically, various machine learning (ML) models have been introduced in the literature, but the used EEG signal datasets for epilepsy detection are relatively small. Our main objective is to present a large EEG signal dataset and investigate the detection ability of a new hypercube pattern-based framework using the EEG signals. Material and method: This study collected a large EEG signal dataset (10,356 EEG signals) from 121 participants. We proposed a new information fusion-based feature engineering framework to get high classification performance from this dataset. The dataset consists of 35 channels, and our proposed feature engineering model extracts features from each channel. A new hypercube-based feature extractor has been proposed to generate two feature vectors in the feature extraction phase. Various statistical parameters of the signals have been used to create a feature vector. Multilevel discrete wavelet transform (MDWT) has been applied to develop a multileveled feature extraction function, and seven feature vectors have been extracted. In this work, we have extracted 245 (=35 × 7) feature vectors, and the most valuable features from these vectors have been selected using the neighborhood component analysis (NCA) selector. Finally, these selected features were fed to the k nearest neighbors (kNN) classifier with the leave one subject out (LOSO) cross-validation (CV) strategy. These results have been voted/fused to obtain the highest classification performance. Results: In this work, we have attained 87.78% classification accuracy using voting these vectors and 79.07% with LOSO CV with the EEG signals. Conclusions: The proposed fusion-based feature engineering model achieved satisfactory classification performance using the largest EEG signal datasets for epilepsy detection. © 2023 Elsevier B.V.","Epilepsy detection; Feature fusion; Feature selection; Fusion-based feature engineering; Hypercube pattern"
"Bilingual word embedding fusion for robust unsupervised bilingual lexicon induction","2023","Information Fusion","10.1016/j.inffus.2023.101818","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159061324&doi=10.1016%2fj.inffus.2023.101818&partnerID=40&md5=93fd25cab79e954650ab1896e1e69e6e","Great progress has been made in unsupervised bilingual lexicon induction (UBLI) by aligning the source and target word embeddings independently trained on monolingual corpora. The common assumption of most UBLI models is that the embedding spaces of two languages are approximately isomorphic (i.e., similar in geometric structure). Therefore, the performance is bound by the degree of isomorphism, especially on etymologically and typologically distant languages. Near-zero UBLI results have been reported for them. To address this problem, we propose a method to increase the isomorphism based on bilingual word embedding fusion. In particular, the features from the source embeddings are integrated into the target embeddings, and vice versa. Therefore, the resulting structures of source and target embeddings are similar to each other. The method does not require any form of supervision and can be applied to any language pair. On a benchmark dataset of bilingual lexicon induction, our approach can achieve competitive or superior performance compared to the state-of-the-art methods, with particularly strong results being found on distant languages. © 2023 The Authors","Embedding fusion; Information fusion; Unsupervised bilingual lexicon induction; Unsupervised learning; Word translation"
"External multi-modal imaging sensor calibration for sensor fusion: A review","2023","Information Fusion","10.1016/j.inffus.2023.101806","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85152633383&doi=10.1016%2fj.inffus.2023.101806&partnerID=40&md5=3e24c2a956f861bdbb37297ac8d062b1","Multi-modal data fusion has gained popularity due to its diverse applications, leading to an increased demand for external sensor calibration. Despite several proven calibration solutions, they fail to fully satisfy all the evaluation criteria, including accuracy, automation, and robustness. Thus, this review aims to contribute to this growing field by examining recent research on multi-modal imaging sensor calibration and proposing future research directions. The literature review comprehensively explains the various characteristics and conditions of different multi-modal external calibration methods, including traditional motion-based calibration and feature-based calibration. Target-based calibration and targetless calibration are two types of feature-based calibration, which are discussed in detail. Furthermore, the paper highlights systematic calibration as an emerging research direction. Finally, this review concludes crucial factors for evaluating calibration methods and provides a comprehensive discussion on their applications, with the aim of providing valuable insights to guide future research directions. Future research should focus primarily on the capability of online targetless calibration and systematic multi-modal sensor calibration. © 2023 The Author(s)","Camera; LiDAR; Mobile mapping; Multi-modal; Sensor calibration; Sensor fusion"
"Ordinal-cardinal consensus analysis for large-scale group decision making with uncertain self-confidence","2023","Information Fusion","10.1016/j.inffus.2023.01.014","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146271439&doi=10.1016%2fj.inffus.2023.01.014&partnerID=40&md5=2ccda81eb2a83528a39762beda47bfba","Consensus analysis is necessary for large-scale group decision making (LSGDM) for ensuring reasonable decision results. This paper offers a new method for LSGDM with uncertain self-confidence that follows ordinal-cardinal consensus analysis. For this purpose, a new interval ranking method is first proposed to compare alternatives. Then, an improved ordinal clustering method on criteria is introduced using the deviation between individual ranking positions. In view of opinion deviation, uncertain self-confidence deviation, and ranking deviation, the weights of decision makers (DMs) are defined. Similarly, the weights of clusters are determined by further combining cluster cardinality. Further, an ordinal-cardinal consensus procedure is offered, which contains two algorithms: the first algorithm is about the ordinal consensus improvement in view of three aspects: ranking adjustment, opinion adjustment, and uncertain self-confidence; the second algorithm studies the cardinal consensus improvement under the ordinal consensus requirement, which also mainly contains three aspects: opinion adjustment, the number of adjusted judgments, and uncertain self-confidence. Moreover, a new algorithm for LSGDM is presented. Finally, an example is provided to check the feasibility and efficiency of the new method, and a comparison analysis is also made. © 2023","LSGDM; Ordinal clustering method; Ordinal-cardinal consensus; Programming model"
"A systematic review of trustworthy and explainable artificial intelligence in healthcare: Assessment of quality, bias risk, and data fusion","2023","Information Fusion","10.1016/j.inffus.2023.03.008","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85151265419&doi=10.1016%2fj.inffus.2023.03.008&partnerID=40&md5=ed8929df202fd77c56bb836cbd97bccd","In the last few years, the trend in health care of embracing artificial intelligence (AI) has dramatically changed the medical landscape. Medical centres have adopted AI applications to increase the accuracy of disease diagnosis and mitigate health risks. AI applications have changed rules and policies related to healthcare practice and work ethics. However, building trustworthy and explainable AI (XAI) in healthcare systems is still in its early stages. Specifically, the European Union has stated that AI must be human-centred and trustworthy, whereas in the healthcare sector, low methodological quality and high bias risk have become major concerns. This study endeavours to offer a systematic review of the trustworthiness and explainability of AI applications in healthcare, incorporating the assessment of quality, bias risk, and data fusion to supplement previous studies and provide more accurate and definitive findings. Likewise, 64 recent contributions on the trustworthiness of AI in healthcare from multiple databases (i.e., ScienceDirect, Scopus, Web of Science, and IEEE Xplore) were identified using a rigorous literature search method and selection criteria. The considered papers were categorised into a coherent and systematic classification including seven categories: explainable robotics, prediction, decision support, blockchain, transparency, digital health, and review. In this paper, we have presented a systematic and comprehensive analysis of earlier studies and opened the door to potential future studies by discussing in depth the challenges, motivations, and recommendations. In this study a systematic science mapping analysis in order to reorganise and summarise the results of earlier studies to address the issues of trustworthiness and objectivity was also performed. Moreover, this work has provided decisive evidence for the trustworthiness of AI in health care by presenting eight current state-of-the-art critical analyses regarding those more relevant research gaps. In addition, to the best of our knowledge, this study is the first to investigate the feasibility of utilising trustworthy and XAI applications in healthcare, by incorporating data fusion techniques and connecting various important pieces of information from available healthcare datasets and AI algorithms. The analysis of the revised contributions revealed crucial implications for academics and practitioners, and then potential methodological aspects to enhance the trustworthiness of AI applications in the medical sector were reviewed. Successively, the theoretical concept and current use of 17 XAI methods in health care were addressed. Finally, several objectives and guidelines were provided to policymakers to establish electronic health-care systems focused on achieving relevant features such as legitimacy, morality, and robustness. Several types of information fusion in healthcare were focused on in this study, including data, feature, image, decision, multimodal, hybrid, and temporal. © 2023","Artificial intelligence; Explainability; Healthcare; Information fusion; Trustworthiness"
"Feature dynamic alignment and refinement for infrared–visible image fusion: Translation robust fusion","2023","Information Fusion","10.1016/j.inffus.2023.02.011","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147902719&doi=10.1016%2fj.inffus.2023.02.011&partnerID=40&md5=2ff7abe32987b1c739169850f4640751","Translational displacement between source images from different sensors is a general phenomenon, which will cause performance degradation on image fusion. To tackle this issue, a straightforward way is to make source images registration first. However, due to the large modality-gap between the infrared image and the visible image, it is too challenging to achieve completely registered images. In this paper, a novel registration-free fusion method is primarily proposed for infrared and visible images with translational displacement, which transforms the problem of image registration to feature alignment in an end-to-end framework. Specifically, we propose a cross-modulation strategy followed by feature dynamic alignment, so that the spatial correlation of shifts is adaptively measured and the aligned features can be dynamically extracted. A feature refinement module is additionally designed based on the local similarity, which enhances the textures related information while suppresses artifacts related information. Thanks to these strategies, our experimental results on infrared–visible images with translational displacement achieve dramatic enhancement compared with state-of-the-arts. To the best of our knowledge, this is the first work on infrared–visible image fusion without strict registration. It does break the constraint of existing image-registration based two-step strategies and provide a simple but efficient way for multi-modal image fusion. The source code will be released at https://github.com/lhf12278/RFVIF. © 2023 Elsevier B.V.","Feature-alignment; Image fusion; Infrared image; Translational misalignment; Visible image"
"A bargaining game based feedback mechanism to support consensus in dynamic social network group decision making","2023","Information Fusion","10.1016/j.inffus.2023.01.004","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146304842&doi=10.1016%2fj.inffus.2023.01.004&partnerID=40&md5=198c0c65feda21d4faae78b45770714d","A bargaining game is used to develop feedback mechanism for dynamic social networks group decision making (SN-GDM). The dynamic trust relationships between experts are updated by the change of their consensus state after each round of interaction. Then, a maximum entropy model based on individual interactive relationship and fairness is established to determine the comprehensive weight of each expert, which considers: (1) the individual weight by influence of expert; (2) the interaction weight by social relationships of experts. Hence, 2-tuple linguistic collective evaluation matrix of the 2-additive Choquet integral under Möbius transform is put forward. Further, the equilibrium solution of two experts in the bargaining game is established, and then this equilibrium recommendation will be accepted by both experts. Consequently, a bargaining game based feedback mechanism driven by trust relationship is proposed to reflect the interaction behaviors between the inconsistent expert and her/his most trusted consistent one, and therefore the recommendation advices are generated for them to promote consensus in SN-GDM. Finally, a sustainable supplier selection example demonstrates the effectiveness of the proposed approach. © 2023 Elsevier B.V.","Bargaining game; Consensus; Feedback mechanism; Group decision making; Social network"
"Multi-criteria group decision making with preference approval structures: A personalized individual semantics approach","2023","Information Fusion","10.1016/j.inffus.2023.03.009","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85150472273&doi=10.1016%2fj.inffus.2023.03.009&partnerID=40&md5=b283e5f537a0c1e0267bb4f132c33df0","Some practical decision making problems need complex preferences. This study deals with a multi-criteria group decision making problem with preference approval structures (PASs). Each decision maker provides multi-criteria assessments in the form of linguistic distributions and a PAS of the alternatives. To ensure that the alternatives’ scores computed from the multi-criteria assessments violate the ranking and approval information in the PAS to the least extent, an optimization model is constructed, and the minimum violation value is obtained. The maximum personalized individual semantics (PISs) and the minimum PISs of linguistic terms corresponding to the minimum violation value are obtained. By using the maximum and the minimum PISs of the linguistic terms, the ranking of the alternatives’ scores is obtained. The approval information of the alternatives is obtained from an optimization model. Based on the ranking and approval information of the alternatives, two sequences of PASs corresponding to the maximum and the minimum PISs are obtained. An optimization model is proposed to fuse individual PASs into a collective PAS. A multi-criteria group decision making model is then proposed and applied in an example. Finally a comprehensive comparison analysis is presented to show the feasibility of the model. © 2023 Elsevier B.V.","Group decision making; Multi-criteria assessments; Personalized individual semantics; Preference approval structure"
"An extension of multi-attribute group decision making method based on quantum-like Bayesian network considering the interference of beliefs","2023","Information Fusion","10.1016/j.inffus.2023.02.018","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85148542081&doi=10.1016%2fj.inffus.2023.02.018&partnerID=40&md5=617124e1eae7b1a80fd9da1280650c06","Multi-attribute group decision making (MAGDM) problem has become one of the most remarkable topics recently. MAGDM is made up of multiple decision makers (DMs) who perform opinions on a set of alternatives and then choose the appropriate one. In the classical decision-making process, the multiple DMs are usually regarded as independent and the opinions usually come from the preference of DMs when determining weights of attributes or giving evaluation of alternatives. However, MAGDM is a complicated cognitive process that involves the diverse and uncertainty cognition of DMs from different backgrounds and fields, and the opinions from DMs are likely to interfere with each other. This paper proposes an extension method based on quantum-like Bayesian network (QLBN) and belief entropy considering the interference of beliefs on the basis of our previous research. The purpose is to model subjectivity sourced from the interference of DMs’ beliefs at different decision-making stages, including the aggregation of attributes probabilities and alternatives probabilities. In this paper, a QLBN for MAGDM problem is constructed firstly. The beliefs of DMs are in a superposition state in it, that is, the opinions of DMs are regarded as wave functions occurring in QLBN. Then the probabilities of attributes and the probabilities of alternatives in QLBN are aggregated across all DMs, and the alternatives are sorted. In the process of aggregation, the beliefs from different DMs will interfere with each other. Belief entropy, an index to calculate the uncertainty of probability is introduced to calculate the interference value. When the interference between DMs is considered only in a certain decision-making stage, the proposed method will degenerate into the existing QLBN methods; and when all DMs are regarded as independent, the QLBN will degenerate into a classical BN. Finally, a supplier selection problem is introduced to illustrate and validate our model. The comparison analyses show that the proposed approach can fully consider the interference between DMs and the ranking result are more reasonable and realistic. © 2023","Belief entropy; Deng entropy maximum method; Interference of beliefs; Multi-attribute group decision making; Quantum-like bayesian network; Subjectivity"
"The registration of visible and thermal images through multi-objective optimization","2023","Information Fusion","10.1016/j.inffus.2023.02.020","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85148538259&doi=10.1016%2fj.inffus.2023.02.020&partnerID=40&md5=15160f72c8eaec686cc5e7c80dba6f0f","Multimodal imaging with visible and thermal sensors attracts much attention due to its robustness under challenging illumination conditions. Due to spectral differences, the visible and thermal images are typically misaligned, where image registration is necessary before high-level vision tasks such as information fusion, multimodal object detection, etc. Contemporary registration methods measure either an angular distance or a linear distance as an objective function to solve affine parameters between visible and thermal images. It is noticeable that both distances have unique advantages in image alignment, which suggests that integrating these measurements may enhance the registration quality. Thus, this paper proposes a new algorithm, namely multi-objective optimization-based image registration (MOIR), to align visible and thermal images. The MOIR comprises a normalized gradient measurement (NGM) that quantifies and normalizes differences of image gradient in both angular and linear aspects, and a regularized stochastic gradient descent (RSGD) that smoothly solves affine parameters. Both quantitative and qualitative results validate the effectiveness and robustness of MOIR for the registration of visible and thermal images in both controlled and real-world scenarios. Some animated examples can be found in https://github.com/jb2849/MOIR. © 2023 Elsevier B.V.","Image registration; Multi-objective optimization; Multimodal imaging; Thermal imaging"
"Non-readily identifiable data collaboration analysis for multiple datasets including personal information","2023","Information Fusion","10.1016/j.inffus.2023.101826","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159188269&doi=10.1016%2fj.inffus.2023.101826&partnerID=40&md5=70ca9d78e64f4e7f6804a8c23416b3da","Multi-source data fusion, in which multiple data sources are jointly analyzed to obtain improved information, has attracted considerable research attention. Data confidentiality and cross-institutional communication are critical for the construction of a prediction model using datasets of multiple medical institutions. In such cases, data collaboration (DC) analysis by sharing dimensionality-reduced intermediate representations without iterative cross-institutional communications may be appropriate. Identifiability of the shared data is essential when analyzing data including personal information. In this study, the identifiability of the DC analysis is investigated. The results reveal that the shared intermediate representations are readily identifiable to the original data for supervised learning. This study then proposes a non-readily identifiable DC analysis only sharing non-readily identifiable data for multiple medical datasets including personal information. The proposed method solves identifiability concerns based on a random sample permutation, the concept of interpretable DC analysis, and usage of functions that cannot be reconstructed. In numerical experiments on medical datasets, the proposed method exhibits non-readily identifiability while maintaining a high recognition performance of the conventional DC analysis. The proposed method exhibits a nine percentage point improvement regarding the recognition performance over the local analysis that uses only local dataset for a hospital dataset. © 2023 The Author(s)","Data collaboration analysis; Dimensionality reduction; Identifiability; Multi-source data fusion; Personal information; Privacy-preserving analysis"
"Visual tracking in complex scenes: A location fusion mechanism based on the combination of multiple visual cognition flows","2023","Information Fusion","10.1016/j.inffus.2023.02.005","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85148445905&doi=10.1016%2fj.inffus.2023.02.005&partnerID=40&md5=f0d9ffcb0f4d6121ddb691d6531a5186","In recent years, deep learning has revolutionized computer vision and has been widely used for monitoring in diverse visual scenes. However, in terms of some aspects such as complexity and explainability, deep learning is not always preferable over traditional machine-learning methods. Traditional visual tracking approaches have shown certain advantages in terms of data collection efficiency, computing requirements, and power consumption and are generally easier to understand and explain than deep neural networks. At present, traditional feature-based techniques relying on correlation filtering (CF) have become common for understanding complex visual scenes. However, current CF algorithms use a single feature to describe the information of the target and locate it accordingly. They cannot fully express changeable target appearances in a complex scene, which can easily lead to inaccurate target locations in time-varying visual scenes. Moreover, owing to the complexity of surveillance scenes, monitoring algorithms can lose their target. The original template update strategy uses each frame with a fixed interval length as a new template, which may lead to unreliable feature extraction and low tracking accuracy. To overcome these issues, in this work, we introduce an original location fusion mechanism based on multiple visual cognition processing streams to achieve real-time and efficient visual monitoring in complex scenes. First, we propose a process for extracting multiple forms of visual cognitive information, and it is periodically used to extract multiple feature information flows of a target of interest. Subsequently, a cognitive information fusion process is employed to fuse the positioning results of different visual cognitive information flows to achieve high-quality visual monitoring and positioning. Finally, a novel feature template memory storage and retrieval strategy is adopted. When the location result is unreliable, the target is retrieved from memory to ensure robust and accurate tracking. In addition, we provide an extensive set of performance results showing that our proposed approach exhibits more robust performance at a lower computational cost compared with 36 state-of-the-art algorithms for visual tracking in complex scenes. © 2023 Elsevier B.V.","Complex scenes; Feature template memory; Location fusion; Multiple visual cognition; Visual monitoring"
"A unified feature-spatial cycle consistency fusion framework for robust image matching","2023","Information Fusion","10.1016/j.inffus.2023.101810","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85157958915&doi=10.1016%2fj.inffus.2023.101810&partnerID=40&md5=72576998aeffcb7db3f276ca63afd822","Robust image matching is a fundamental and long-standing open problem in computer vision. Conventional wisdom has exploited redundancy to improve the robustness of image matching (e.g., from pairwise to multi-image correspondence), which works well in the spatial domain. Inspired by the success of global optimization-based approaches, we propose a novel extension of cycle consistency from multi-image to multi-descriptor matching in this paper, which integrates useful information from the feature domain. More specifically, we build upon previous work of permutation synchronization and construct a novel cycle consistency model for multi-descriptor matching. The construction of cycle consistency model is based on the analogy between multi-image matching and multi-descriptor matching in a virtual universe. It allows us to formulate multi-image and multi-descriptor matching as a constrained global optimization problem. We have developed a spectral relaxation algorithm to solve this optimization problem, admitting an efficient implementation via fast singular value decomposition (SVD). To demonstrate the robustness of the proposed method named Cycle Consistency Fusion (C2F), we have evaluated it in terms of both raw matching accuracy (pairwise or multi-image) and several higher level downstream tasks such as homography and camera pose estimation. Extensive experimental results have shown that our C2F outperforms state-of-the-art methods consistently across different datasets and vision tasks. © 2023 Elsevier B.V.","3D reconstruction; Cycle consistency; Multi-descriptor fusion; Multi-image matching"
"Meta Multi-Instance Multi-Label learning by heterogeneous network fusion","2023","Information Fusion","10.1016/j.inffus.2023.02.010","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147845043&doi=10.1016%2fj.inffus.2023.02.010&partnerID=40&md5=6724352681b34476c3fee6ff37cc0200","Multi-Instance Multi-Label Learning (MIML) models complex objects (bags), each of which is composed with a set of instances and associated with a set of labels. Current MIML solutions still focus on a single-type of bags and assume an independent and identically distribution (IID) of training data. But these bags are linked with objects of other types, which also encode the semantics of bags. In addition, they generally need abundant labeled data for training. To effectively mine MIML objects linked with objects of other types, we propose a heterogeneous network embedding and meta learning based approach (MetaMIML). MetaMIML introduces the context learner with network embedding to learn context representations of bags for structure information extraction, the task learner to extract the meta knowledge for fast adapting to new tasks with scarce training objects, and finally fuses the structural and attribute information to predict the labels of bags/instances. In this way, MetaMIML can not only naturally deal with MIML objects at data level improving, but also exploit the power of meta-learning at the model enhancing. Experiments on benchmark datasets demonstrate that MetaMIML achieves a significantly better performance than state-of-the-art algorithms. © 2023 Elsevier B.V.","Data fusion; Heterogeneous network embedding; Meta learning; Multi-instance learning; Multi-label learning"
"RHPMF: A context-aware matrix factorization approach for understanding regional real estate market","2023","Information Fusion","10.1016/j.inffus.2023.02.001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149059938&doi=10.1016%2fj.inffus.2023.02.001&partnerID=40&md5=26d3fdce285c8bd832afadd7ae7e5a09","The real estate market has a significant impact on people's daily life. Therefore, it is crucial to understand the real estate market from both spatial and temporal perspectives, while there is still a lack of research in real estate industries. In this paper, a regional house price mining and forecasting (RHPMF) framework is proposed to help people intuitively understand the spatial distribution and temporal evolution of the urban estate market based on real-world housing data and urban contexts such as demographics and criminal records. Specifically, the RHPMF framework introduces a context-aware matrix factorization to extract crucial spatial and temporal price factors for revealing the housing market. Meanwhile, the RHPMF can forecast future regional house prices by manipulating the two price factors. Consequently, this study presents extensive exploratory analysis and experiments in Virginia Beach, Philadelphia, and Los Angeles to verify the proposed RHPMF. These case studies indicate that the RHPMF framework can accurately capture the market's spatial distribution and temporal evolution and forecast future regional house prices compared with recent baselines. The experimental results suggest the great potential of the proposed RHPMF for applications in real estate industries. © 2023 Elsevier B.V.","Data fusion; Data mining; Matrix factorization; Real estate; Urban computing"
"ReCoMIF: Reading comprehension based multi-source information fusion network for Chinese spoken language understanding","2023","Information Fusion","10.1016/j.inffus.2023.03.016","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85151307668&doi=10.1016%2fj.inffus.2023.03.016&partnerID=40&md5=0b7d2be8e0eba07bb5d82a786e50a45a","Spoken language understanding (SLU) plays a crucial role in the performance of dialogue systems. It usually includes slot filling and intent detection (SFID) tasks aiming at semantic parsing of utterances. At present, researchers focus mainly on English SLU tasks, while such investigations on Chinese utterances are not sufficient. In this paper, we first propose a reading comprehension based multi-source information fusion network, called ReCoMIF for Chinese SFID tasks by transforming the SLU task into a multi-turn question answering procedure comprising multiple choice for intent detection and span extraction for slot filling. Moreover, we present a TCM_CLS module with a concise architecture composed of TextCNN, MaxPooling, and feed forward network plus the [CLS] representation. Such three TCM_CLS modules are stacked in the proposed ReCoMIF network that can serve as sufficient integration of multi-source information originating from contexts, reading comprehension based queries, and hidden representations concerning intent and slot semantics. Finally, experimental results and ablation studies on three Chinese SLU datasets show that our proposed model can effectively fuse intent and slot information achieved by\ state-of-the-art performance compared with other baseline methods. © 2023 Elsevier B.V.","Chinese spoken language understanding; Intent detection; Machine reading comprehension; Multi-source information fusion; Slot filling"
"Multiscale structural feature transform for multi-modal image matching","2023","Information Fusion","10.1016/j.inffus.2023.02.026","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85150806038&doi=10.1016%2fj.inffus.2023.02.026&partnerID=40&md5=48a2691f6fe078da018c8a8593958949","Robust and reliable multi-modal image matching is an essential and challenging technique in the multi-modality involved scenarios for image fusion, image mosaic, and visual navigation. Existing image matching methods cannot simultaneously solve the scale and rotation distortion caused by different viewpoints and the nonlinear radiation distortion caused by different imaging environments or mechanisms. To address these problems, a multiscale structural feature transform method is proposed for multi-modal image matching, which consists of three blocks: multiscale structural feature detector, symmetric log-polar descriptor, and point matching with position correction. The multiscale structural feature detector constructs the phase congruency map based Difference of Gaussian image pyramid for the scale-invariant feature points detection to tackle the nonlinear radiation distortion. The feature points are detected within 10-neighborhood instead of 26-neighborhood to produce sufficient points on the phase congruency map with very sparse texture. The symmetric log-polar descriptor utilizes the multiscale structure principal direction and symmetric bins to improve the robustness of the descriptor to rotation and nonlinear radiation distortion. At last, the point matching with position correction corrects the position of feature points to compensate the position offset between different images caused by the scale and rotation distortion and the nonlinear radiation distortion, which increases the number of correct matches and improves the transformation consistency between matched points. In the experiment, the proposed method in this paper is compared with seven state-of-the-art methods. Experimental results verify the superiority of the proposed method and its robustness to the scale and rotation distortion and the nonlinear radiation distortion. In addition, we demonstrate the effectiveness of the proposed three blocks by the ablation experiments. © 2023 Elsevier B.V.","Multi-modal image matching; Multiscale structural feature detector (MSFD); Nonlinear radiation distortion (NRD); Point matching with position correction (PMPC); Symmetric log-polar descriptor (SLPD)"
"MFGAD: Multi-fuzzy granules anomaly detection","2023","Information Fusion","10.1016/j.inffus.2023.02.007","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147985211&doi=10.1016%2fj.inffus.2023.02.007&partnerID=40&md5=4b21a663dba286364c46d153b9bed7c3","Unsupervised anomaly detection is an important research direction in the process of unsupervised knowledge acquisition. It has been successfully applied in many fields, such as online fraud identification, loan approval, and medical diagnosis. Multi-granularity thinking is an effective information fusion method for solving problems in a multi-granular environment, which allows people to understand and analyze problems from multiple perspectives. However, there are few studies on building anomaly detection models using the idea of multi-fuzzy granules. To this end, this paper constructs a multi-fuzzy granules anomaly detection method by using a fuzzy rough computing model. In this method, a hybrid metric is first used to calculate the fuzzy relations. Then, two ranking sequences are constructed based on the significance of attributes. Furthermore, forward and reverse multi-fuzzy granules are constructed to define anomaly scores based on the ranking sequences. Finally, a multi-fuzzy granules-based anomaly detection algorithm is designed to detect anomalies. The experimental results compared with existing algorithms show the effectiveness of the proposed algorithm. © 2023 Elsevier B.V.","Fuzzy rough set theory; Granular computing; Hybrid data; Multi-granularity; Unsupervised anomaly detection"
"CFCNN: A novel convolutional fusion framework for collaborative fault identification of rotating machinery","2023","Information Fusion","10.1016/j.inffus.2023.02.012","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147983675&doi=10.1016%2fj.inffus.2023.02.012&partnerID=40&md5=09a1b22e890e555db58b392113220bb3","Sensor techniques and emerging CNN models have greatly facilitated the development of collaborative fault diagnosis. Existing CNN models apply different fusion schemes to achieve reliable fault identification based on multisensor data. Few CNN models, however, take into account both the intrinsic correlations and the distribution gap between different signals, which may result in a limited exploration of multisource data. To address this issue, a novel convolutional fusion framework called a collaborative fusion convolutional neural network (CFCNN) is developed in this paper. More specifically, a multiscale shrinkage denoising module (MSDM) is developed first to extract multilevel modality-specific features from different mechanical signals. Then, drawing inspiration from the intermediate fusion scheme, a central fusion module (CFM) is introduced to explore the intrinsic correlations and integrate cross-modal features. Moreover, an online label smoothing training (OLST) strategy is applied to reduce overfitting and promote better classification performance of CFCNN. The developed CFCNN is expected to shed new light on collaborative fault diagnosis using the intermediate fusion scheme. The efficacy of the developed CFCNN is verified through the cylindrical rolling bearing dataset and the planetary gearbox dataset. © 2023 Elsevier B.V.","Central fusion module (CFM); Fault diagnosis; Multiscale shrinkage denoising module (MSDM); Multisource data; Online label smoothing training (OLST)"
"Privacy protection in intelligent vehicle networking: A novel federated learning algorithm based on information fusion","2023","Information Fusion","10.1016/j.inffus.2023.101824","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159115052&doi=10.1016%2fj.inffus.2023.101824&partnerID=40&md5=f2ee51704ea3ef977becd25d6275ba99","Federated learning is an effective technique to solve the problem of information fusion and information sharing in intelligent vehicle networking. However, most of the existing federated learning algorithms generally have the risk of privacy leakage. To address this security risk, this paper proposes a novel personalized federated learning with privacy preservation (PDP-PFL) algorithm based on information fusion. In the first stage of its execution, the new algorithm achieves personalized privacy protection by grading users’ privacy based on their privacy preferences and adding noise that satisfies their privacy preferences. In the second stage of its execution, PDP-PFL performs collaborative training of deep models among different in-vehicle terminals for personalized learning, using a lightweight dynamic convolutional network architecture without sharing the local data of each terminal. Instead of sharing all the parameters of the model as in standard federated learning, PDP-PFL keeps the last layer local, thus adding another layer of data confidentiality and making it difficult for the adversary to infer the image of the target vehicle terminal. It trains a personalized model for each vehicle terminal by “local fine-tuning”. Based on experiments, it is shown that the accuracy of the proposed new algorithm for PDP-PFL calculation can be comparable to or better than that of the FedAvg algorithm and the FedBN algorithm, while further enhancing the protection of data privacy. © 2023 Elsevier B.V.","Connected cars; Differential privacy; Dynamic convolution; Federated learning; Information fusion; Personalization"
"Feature fusion via multi-target learning for ancient artwork captioning","2023","Information Fusion","10.1016/j.inffus.2023.101811","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85153671988&doi=10.1016%2fj.inffus.2023.101811&partnerID=40&md5=16009f663e5ea90b56a3579e352bb13d","Image captioning has made consistent progress due to the development of computer vision and natural language processing techniques. Current research on image captioning commonly tends to the visual caption of natural images. However, these attempts are not applicable to ancient artwork captioning with different appearance attributes and complex cultural metaphors. In this work, we propose a Multi-target Learning Framework, called MLF, for generating captions for ancient artworks with ceramics as the case study. Our MLF contains three novel data-driven modules, including RTE, MTE, and MFD. To be specific, for a given image, the Regular Target Encoder (RTE) is first used to encode its regular targets related to color, textual, profile, and craftsmanship features. Second, a Metaphorical Target Encoder (MTE) is applied to encode its metaphorical targets related to cultural semantic features. Finally, a Multimodal Fused Decoder (MFD) is utilized to fuse the multimodal feature vectors from RTE and MTE separately, then decode them and generate detailed captions containing both regular and metaphorical information with the guidance by a word distribution map. Both quantitative and qualitative evaluation results on our constructed dataset demonstrate the advantages of our work. © 2023 Elsevier B.V.","Ancient artwork; Feature fusion; Image captioning; Multi-target learning; Multimodal learning"
"Parameter agnostic stacked wavelet transformer for detecting singularities","2023","Information Fusion","10.1016/j.inffus.2023.01.022","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149656471&doi=10.1016%2fj.inffus.2023.01.022&partnerID=40&md5=e3b95546aa832d4feb3dc7a49ffdcc17","Machine learning algorithms especially deep neural networks have seen tremendous growth in their real-world deployment. While these algorithms have to yield high performances for the task at hand, it is of equal importance that they are robust against the different kinds of singularities or adversarial anomalies. Researchers have generally addressed singularity detection independently for each anomaly, however, for the algorithms to be effective in the real world, the singularity detection algorithm must be able to handle a wide variety of attacks whether trained individually on them or not seen at the time of training. With this objective, in this paper, we propose a unique end-to-end transformation domain network to detect a variety of well-known attacks. The proposed architecture utilizes a combination of two different wavelet transformations to simultaneously learn low-level and high-level image features in a deep stacked layer fashion. The proposed method is generalized to handle a broad set of singularities of several computer vision algorithms whether operating in the object recognition domain or biometrics recognition. We showcase the results on a wide range of singularity points including (i) adversarial perturbations which are learned using deep learning networks, (ii) physical presentation attacks on face recognition which aim to produce fake data for the sensor for acquisition, and identification, (iii) synthetic images, and (iv) digital retouching of the images. Even with a zero-day or open-world attack setting, the results of the proposed algorithm show improvement over state-of-the-art results. The proposed architecture is agnostic to parameters, computationally efficient to provide a sustainable detector to resource-constrained institutions, provides robustness to attacks, and supports green computing. © 2023 Elsevier B.V.","Adversarial robustness; Attack detection; Parameter agnostic classifier; Presentation attacks; Singularities"
"A mutually boosting dual sensor computational camera for high quality dark videography","2023","Information Fusion","10.1016/j.inffus.2023.01.013","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146732392&doi=10.1016%2fj.inffus.2023.01.013&partnerID=40&md5=dd7e302dde8101a347e7b9f9d7f71f39","Videos captured under low light conditions suffer from severe noise. A variety of efforts have been devoted to image/video noise suppression and made large progress. However, in extremely dark scenarios, extensive photon starvation would hamper extracting latent structures buried in noise. Instead, developing an imaging system collecting more photons is a more effective way for high-quality video capture in dark environments. In this paper, we propose to build a dual-sensor camera to additionally collect the photons in NIR wavelength, and make use of the correlation between RGB and near-infrared (NIR) spectrum to perform high-quality reconstruction from noisy dark video pairs. In hardware, we build a compact dual-sensor camera capturing parallax-free RGB and NIR videos simultaneously. Computationally, we propose a dual-channel multi-frame attention network (DCMAN) utilizing spatial–temporal-spectral priors to mutually boost the quality of low-light RGB and NIR videos. In addition, we build a high-quality paired RGB and NIR video dataset, based on which the approach can be applied to different sensors easily by training the DCMAN model with simulated noisy input following a physical-process-based CMOS noise model. Both experiments on synthetic and real videos validate the performance of this compact dual-sensor camera design and the corresponding reconstruction algorithm in dark videography. © 2023 Elsevier B.V.","Computational photography; Dark vision; Dual-channel network; Low light video; RGB-NIR; Video denoising"
"Finding hate speech with auxiliary emotion detection from self-training multi-label learning perspective","2023","Information Fusion","10.1016/j.inffus.2023.03.015","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85151256253&doi=10.1016%2fj.inffus.2023.03.015&partnerID=40&md5=2a30868f992ba5ae8e9d3e1fd80d353e","Hate Speech Detection (HSD) aims to identify whether a text contains hate speech content, which often refers to discrimination and is even associated with a hate crime. The mainstream methods jointly train the HSD problem with relevant auxiliary problems, e.g., emotion detection and sentiment analysis, under the paradigm of Multi-Task Learning (MTL). In this paper, we improve HSD by integrating it with emotion detection, since we take inspiration from the potential correlations between hate speech and certain negative emotion states, which have been studied theoretically and empirically. To be specific, we can concatenate their hateful labels and predicted emotion states as pseudo-multiple labels for hate speech samples, formulating a pseudo-Multi-Label Learning (MLL) problem. Beyond the existing MTL-HSD methods, we further incorporate this pseudo-MLL problem and solve it by capturing the correlations between hate speech and negative emotion states, so as to improve the performance of HSD. Based on these ideas, we propose a novel HSD method named the Emotion-correlated Hate Speech DetectOR (EHSOR). We conduct extensive experiments to evaluate EHSOR, and the results show that it can consistently outperform the existing HSD methods across benchmark datasets. © 2023 Elsevier B.V.","Emotion detection; Hate speech detection; Multi-label learning; Multi-task learning"
"A unified speech enhancement approach to mitigate both background noises and adversarial perturbations","2023","Information Fusion","10.1016/j.inffus.2023.02.030","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149361643&doi=10.1016%2fj.inffus.2023.02.030&partnerID=40&md5=9c45f40f61972976f42837bbbf00c4a2","Deep learning has been vastly applied in classification systems of speech signals. However, adversarial examples crafted by adding small perturbations to input speech signals can make those classification systems produce incorrect results. Beyond detecting and discarding adversarial examples when securing the classification systems, we consider to purify the input adversarial examples to normal ones in this paper. Speech enhancement is a technique known as removing background noises to enhance voice quality. By treating adversarial perturbations as noises, we hereby propose a unified speech enhancement approach to mitigate both background noises and adversarial perturbations. The approach is named by Speech Enhancement and Adversarial Defense Network (SEADNet), which performs model-level fusion of conventional speech enhancement and adversarial defenses. In SEADNet, a learnable noise-adding module is firstly created to adaptively putting noises to the input speech to destroy the functions of adversarial perturbations. Subsequently, a speech enhancement network is deployed to reconstruct clean speech from noisy inputs. Finally, an adversarial example detection module is designed as a discriminator to guide the reconstructed speech in the previous speech enhancement network to mitigate adversarial perturbations. The overall network is optimized by minimizing a joint loss function. Experiments are conducted on the tasks of speech enhancement and automatic speaker verification with benchmark datasets. The proposed SEADNet performs well on both tasks of conventional noise mitigation and adversarial defenses compared to the related competitive baselines. © 2023 Elsevier B.V.","Adversarial defense; Automatic speaker verification; Model fusion; Noise mitigation; Speech enhancement"
"Causal inference multi-agent reinforcement learning for traffic signal control","2023","Information Fusion","10.1016/j.inffus.2023.02.009","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147849073&doi=10.1016%2fj.inffus.2023.02.009&partnerID=40&md5=cc3861fa5992dd05c7a515122b4fafab","A primary challenge in multi-agent reinforcement learning for traffic signal control is to produce effective cooperative traffic-signal policies in non-stationary multi-agent traffic environments. However, each agent suffers from its local non-stationary traffic environment caused by the time-varying traffic-signal policies of adjacent agents; At the same time, different agents also produce time-varying traffic-signal policies, which further results in the non-stationarity of the whole traffic environment, so these produced traffic-signal policies may be ineffective. In this work, we propose a Causal Inference Multi-Agent reinforcement learning (CI-MA) algorithm, which can alleviate the non-stationarity of multi-agent traffic environments from both feature representation and optimization, eventually helps to produce effective cooperative traffic-signal policies. Specifically, a Causal-Inference (CI) model is first designed to reason about and tackle the non-stationarity of multi-agent traffic environments by both acquiring feature representation distributions and deriving variational lower bounds (i.e., objective functions); And then, based on the designed CI model, we propose a CI-MA algorithm, in which the feature representations are acquired from the non-stationarity of multi-agent traffic environments at both task level and timestep level, the acquired feature representations are used to produce cooperative traffic-signal policies and Q-values for multiple agents; Finally the corresponding objective functions optimize the whole algorithm from both causal inference and multi-agent reinforcement learning. Experiments are conducted in different non-stationary multi-agent traffic environments. Results show that CI-MA algorithm outperforms other state-of-the-art algorithms, and demonstrate that the proposed algorithm trained in synthetic-traffic environments can be effectively transferred to both synthetic- and real-traffic environments with non-stationarity. © 2023 Elsevier B.V.","Causal inference; Deep reinforcement learning; Graph model; Multi-agent learning; Traffic signal control"
"A conflict evidence fusion method based on the composite discount factor and the game theory","2023","Information Fusion","10.1016/j.inffus.2023.01.009","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147541348&doi=10.1016%2fj.inffus.2023.01.009&partnerID=40&md5=132577c2ca7f3b4c071ebd4973100943","Dempster–Shafer (D–S) evidence theory is widely used in various fields of information fusion. However, it is still an open issue that the D–S evidence theory may produce the counter–intuitive results in fusing high–conflict evidences. Aim at this problem, a novel conflict evidence fusion method based on the composite discount factor and the game theory is proposed in this paper. Firstly, an improved Shafer's conflict measurement formula based on the Jaccard similarity coefficient is devised, and combined with the Jousselme distance into a novel binary function to measure the global conflict between evidences as the evidence falsity. Then, the local conflict between evidences and the information volume of evidences are measured by using the Jousselme distance and belief entropy to indicate the credibility and uncertainty of evidences. Next, based on the game theory, the falsity, credibility and uncertainty are weighted and combined into the composite discount factors to correct each body of evidence (BOE). Ultimately, all corrected evidences are fused by Dempster's combination rule to obtain the final result. Two numerical examples are given to verify that the proposed method is effective and feasible, which outperforms the previous methods in handling the conflict evidences. © 2023 Elsevier B.V.","Binary conflict measurement; Composite discount factor; Dempster–Shafer evidence theory; Game theory; Jaccard similarity coefficient"
"A Stackelberg game model for large-scale group decision making based on cooperative incentives","2023","Information Fusion","10.1016/j.inffus.2023.03.013","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85151019874&doi=10.1016%2fj.inffus.2023.03.013&partnerID=40&md5=27ccff740b44cacae4f3f951575f3a7a","With the rapid development of novel technological paradigms such as e-democracy, e-government, and collective intelligence, large-scale group decision making (LSGDM) has become an emerging topic. In LSGDM, a clustering algorithm is usually adopted to cluster experts into multiple subgroups with the aim of reducing the dimension of the problem. Because of the clustering process, a large group spans three hierarchies of a moderator, multiple subgroup spokesmen, and corresponding experts in each subgroup. The moderator first proposes an incentive to encourage subgroups to modify their opinions to reach an expected degree of consensus. Then, in each subgroup, the spokesman invokes sub-games with involved experts to negotiate the number of changed opinions through allocating incentives. Considering such a hierarchical decision-making structure, this study introduces a hierarchical Stackelberg game model to address the interactions between different players. A critical value is proposed to define the reward or punishment according to the degree of cooperativeness of experts and subgroups. The existence and uniqueness of the Stackelberg equilibrium is verified. We also put forward a consensus model for group decision making based on the Stackelberg equilibrium. A numerical example is provided to demonstrate the applicability of the model, and numerical studies are given to investigate the influence of some parameters. © 2023 Elsevier B.V.","Consensus; Cooperativeness; Hierarchical stackelberg game; Incentive; Large-scale group decision making"
"Competitive targeted marketing in social networks with switching topology: Seed selection and consensus shaping","2023","Information Fusion","10.1016/j.inffus.2023.02.022","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149333953&doi=10.1016%2fj.inffus.2023.02.022&partnerID=40&md5=9ae2908544815d8c6a792ba026f26998","The boom of social network platforms has greatly enriched people's platform choices for social interactions, which may cause people to switch frequently in different social networks to chase hot points. Meanwhile, as an advertisement integrator, the social network platform enables firms to implement targeted marketing campaigns to steer people's opinions in their own favor. Identifying the seed set and devising targeted marketing strategies emerge as the key points for firms' success. To tackle such a problem, we develop a game-theoretical framework for targeting marketing resources to network agents with switching topology based on their competitive opinion dynamics. In the framework, the dynamics of agents' opinions are driven by not only the targeted marketing behaviors of competing firms but also the social interactions of agents with switching topology. With capturing these features, we determine the consensus condition and weight property in such dynamics. On this basis, the optimal targeted marketing strategies are derived that firms only need to invest the overlapped opinion leaders of switching networks. And specifically, such a leader with more weight in consensus will gain more marketing resources from firms. Besides that, we further carry out comparative static analysis of relevant factors and discuss the equilibrium strategies with no consensus. Finally, two examples are presented to illustrate our theoretical results. In spite of the mathematical characterization, our paper additionally provides some insights into marketing management. © 2023","Competition; Consensus; Opinion dynamics; Switching networks; Targeted marketing"
"Disambiguation-based partial label feature selection via feature dependency and label consistency","2023","Information Fusion","10.1016/j.inffus.2023.01.019","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149799367&doi=10.1016%2fj.inffus.2023.01.019&partnerID=40&md5=bedf665abad191bf36bcead9fe69e57d","Partial label learning refers to the issue that each training sample corresponds to a candidate label set containing only one valid label. Feature selection can be viewed as an effective pre-processing technology to improve the generalization performance of learning models, while the partial label feature selection task is challenging due to ambiguous labeling information. To this end, this paper utilizes granular ball computing and neighborhood rough sets to put forward a disambiguation-based partial label feature selection algorithm via feature dependency and label consistency. Firstly, the proposed algorithm performs an adaptive neighbor aggregation based on granular balls to disambiguate candidate labels. Adaptive neighbors are flexible to make more efficient learning performance. Then, considering the labeling confidence induced by disambiguation, the significance of each feature is evaluated by fusing the feature dependency from the neighborhood granularity and the label consistency among the nearest neighbors. Neighborhood rough sets directly handle continuous features that can reduce the adverse impact of data discretization on feature selection. The label consistency among adjacent samples is important for measuring feature discrimination. The fusion of feature dependency and label consistency can facilitate performance improvement. Finally, experiments conducted on eight controlled UCI and five real-world partial label datasets demonstrate that the proposed algorithm can improve the generalization performance of partial label learning and achieve superior performance compared to the partial label feature selection methods. © 2023 Elsevier B.V.","Feature selection; Granular computing; Label disambiguation; Noisy label learning; Partial label learning"
"Multitask deep label distribution learning for blood pressure prediction","2023","Information Fusion","10.1016/j.inffus.2023.02.019","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149759591&doi=10.1016%2fj.inffus.2023.02.019&partnerID=40&md5=dbc8aef3b2b2b0c6bb0fbe1bf69d12e0","Cuffless continuous blood pressure (BP) monitoring is of vital importance for personal health management. Currently, there are extensive studies devoted to cuffless BP prediction based on advanced machine learning techniques and by fusing a variety of physiological signals such as Photoplethysmogram (PPG) and Electrocardiogram (ECG) signals. However, the prediction accuracy still cannot meet the requirements, and it is inconvenient to collect multiple signals at the cost of additional sensors, which limits its potential application scenarios. Different from the conventional routine of modeling BP prediction as a classification or regression question, we model BP prediction as a label distribution learning question (sample level information fusion) for the first time and an end-to-end model is trained based on the proposed adaptive multitask weighted loss to predict systolic BP (SBP), diastolic BP (DBP) and mean BP (MBP) in parallel (task level information fusion), with only PPG signal as input. Resultly, not only precise BP but also predictive confidence interval are reported, and the normalize target technique usually used in regression modeling is no longer needed. To fully delve useful information for BP prediction from the only PPG signal, an end-to-end network is proposed for learning and fusing information from different modalities (original signal and its derivatives, time domain and time–frequency domain) of the signal (feature fusion). Besides, taking into account the varying informativeness of each learned feature accounting for different prediction tasks, task-specific attention module is introduced to learn the varied importance of each feature learned to different prediction tasks, under the hard parameter sharing mode of multitask learning (MTL) network. Extensive experiments on a publicly available database indicate that: (1) The proposed MTL model achieves superior performance over the corresponding single-task learning (STL) model at the cost of only about 1/3 times the amount of parameters. (2) The distribution learning mode enables superior generalization ability of the model over the regression modeling mode in both MTL and STL settings. (3) Compared with regression modeling, the distribution learning mode can alleviates the predictive bias of the trained model due to skewed distribution in dataset, given TFNet as feature learner. (4) The fusion of information of different modalities of PPG signal can significantly improve the generalization ability of the prediction model. (5) The proposed model has achieved superior performance over several representative methods/systems, while using only PPG signal and no any calibration procedure is required. © 2023 Elsevier B.V.","Blood pressure; Information fusion; Label distribution learning; Multitask learning; Photoplethysmogram (PPG)"
"A multimodal hyper-fusion transformer for remote sensing image classification","2023","Information Fusion","10.1016/j.inffus.2023.03.005","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85150227837&doi=10.1016%2fj.inffus.2023.03.005&partnerID=40&md5=60e5e55f1e22b70c2ad03bea0c19037a","The multispectral (MS) and the panchromatic (PAN) images represent complementary and synergistic spatial spectral information, how to make optimal use of the advantages of them has become a hot research topic. This paper proposes a selectable Transformer and Gist CNN network (STGC-Net). It designs a subspace similar recombination module (SSR-Module) based on non-negative matrix factorization (NMF) and the self-attention mechanism for feature decomposition. This can alleviate the redundant information of multi-modal data and extract their own singular and common features. Considering that the MS and the PAN images exhibit different advantageous properties, a selectable self-attention spectral feature extraction module (S3FE-Module) and a multi-stream Gist spatial feature extraction module (MGSFE-Module) are proposed for the different singular features. The former can refine the Transformer's input and simultaneously characterize the sequence information between channels for the MS image. The latter introduces the positional relationship between local features while extracting spatial features for the PAN image, thereby improving the accuracy of scene classification. Experimental results indicate that the proposed method performs better than the other methods. The relevant code of this paper is provided at: https://github.com/ru-willow/ST-GC-Net. © 2023 Elsevier B.V.","Deep learning; Fusion classification; Gist feature; Multi-modal remote sensing; Transformer"
"A complementary dual-backbone transformer extracting and fusing weak cues for object detection in extremely dark videos","2023","Information Fusion","10.1016/j.inffus.2023.101822","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159103283&doi=10.1016%2fj.inffus.2023.101822&partnerID=40&md5=e828c1533c60636eb1309c03c183d5b6","Reliable object detection under dark environment is of wide applications but severely challenged by heavy noise washing out informative features and uneven radiance caused by nighttime illuminations. These unique features of dark videos would largely degenerate the performance of existing detectors. To address this issue, specially designed algorithms being able to extract and fuse the weak features buried in the low-quality videos are of vital importance. Bearing these in mind, we propose illumination-aware spatio-temporal feature fusion modules for low-light video object detection and implement a Dark Video Detector under a TRansformer network structure, dubbed as DVD-TR. Firstly, we use a dual-backbone Transformer to extract separate complementary features and fuse them to strengthen the network's feature extraction capability. Secondly, we incorporate a spatio-temporal sampling mechanism to aggregate features from multiple frames, which can enhance detection accuracy in dark videos. Thirdly, we use a small encoder–decoder network to obtain irradiance distribution which is further incorporated for illumination-aware feature fusion. Extensive experiments on large-scale multi-illuminance dark video benchmark show that DVD-TR outperforms state-of-the-art video detectors by a large margin and validate the effectiveness of the proposed approach. © 2023 Elsevier B.V.","Feature aggregation; Feature fusion; Low-light video; Object detection; Transformer"
"Supervised learning for more accurate state estimation fusion in IoT-based power systems","2023","Information Fusion","10.1016/j.inffus.2023.03.001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85150872298&doi=10.1016%2fj.inffus.2023.03.001&partnerID=40&md5=a8bf79e5bdc794c109a7a0cb12e59d4a","Concerned with deploying zero-emission energy sources, reducing energy wasted through transmission lines, and managing power supply and demand, monitoring and controlling microgrids have found utter importance. Accordingly, this paper aims to investigate the efficacy of state estimation fusion for a synchronous generator as well as an induction motor in order to ameliorate system monitoring. A third-order nonlinear state-space model, that operates based on actual input data taken from the Smart Microgrid Laboratory, is assumed for each of the electrical machines. The model parameters are set according to the parameters of the electrical machines. A fusion structure based on the internet of things communication network, which is modified to increase uncertainty, is presented for fusing the state estimates. The data fusion topology is distributed and relies on two data fusion models. The first model is a set of state estimators, referred to as data input-feature output model. The second one fuses the estimators’ outputs based on supervised machine learning methods, referred to as feature input-feature output model. The simulation results in MATLAB and Python show the efficiency of linear regression methods compared with other leveraged methods for data fusion. By comparing the results obtained from both simple and complex estimation filters, it can be deduced that combining simple filters, extended Kalman filter in this case, with simple data fusion methods, linear regression in this case, can produce much more accurate results in a short period of time. Besides, this study shows that the averaging operators are unsuitable for estimation fusion by referring to their convexity condition. © 2023","Distributed data fusion; Estimation fusion; Internet of things; Kalman filtering; Nonlinear state estimation; Particle filtering; Power systems; Supervised machine learning"
"A consensus model under framework of prospect theory with acceptable adjustment and endo-confidence","2023","Information Fusion","10.1016/j.inffus.2023.101808","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85154535602&doi=10.1016%2fj.inffus.2023.101808&partnerID=40&md5=40596ac6ef63caa41da7f064f31e0269","Consensus is an important issue in group decision making to make a reliable and scientific decision, and it has become a hot topic recently. Due to the complexity and uncertainty of decision-making problems, several aspects of alternatives should be considered in decision-making process. Also, the bounded rational characteristics of decision makers (DMs) may significantly affect the decision results. This paper proposes a multi-criteria consensus model based on prospect theory (PT) to consider the unsymmetrical risk attitudes of DM for gain or loss and on endo-confidence (confidence which is derived by DMs’ evaluation information) levels of DMs to determine their weights. First, the reference point in PT is selected and how to measure the prospect consensus degree is presented. Then, the way to identify the expert who need to modify his/her evaluation is given and two programming models are proposed to obtain the updated evaluation. Subsequently, both the overall difference and the endo-confidence level of the DM are used to determine the weights of DMs. Finally, an illustrative example and the comparative analysis are used to demonstrate the feasibility of the proposed model. © 2023 Elsevier B.V.","Consensus; Endo-confidence level; Programming model; Prospect theory; Reference point"
"Neighbor-aware deep multi-view clustering via graph convolutional network","2023","Information Fusion","10.1016/j.inffus.2023.01.001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146265708&doi=10.1016%2fj.inffus.2023.01.001&partnerID=40&md5=69014f3a23eb44c39eee2114364415db","Multi-view clustering (MVC) enhances the clustering performance of data by combining correlation information from different views. However, most existing MVC approaches process each sample independently and ignore the correlation amongst samples, resulting in reduced clustering performance. Although graph convolution network (GCN) can naturally capture correlation amongst samples by integrating the neighbors and structural information into representation learning, it is used in the semi-supervised learning scenario. In this paper, we propose a neighbor-aware deep MVC framework based on GCN (NMvC-GCN) for clustering multi-view samples and training GCN in a fully unsupervised manner. In addition, we design a consensus regularization to learn the common representations and introduce a clustering embedding layer to jointly optimize the clustering task and representation learning, so that the correlation amongst samples and that between the clustering task and representation learning can be fully explored. Extensive experiments on 10 datasets illustrate that NMvC-GCN significantly outperforms the state-of-the-art MVC methods. Our code will be released at https://github.com/dugzzuli/NMvC-GCN. © 2023 Elsevier B.V.","Consensus regularization; Graph convolutional network; Multi-view clustering; Representation learning"
"Multi-modal policy fusion for end-to-end autonomous driving","2023","Information Fusion","10.1016/j.inffus.2023.101834","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159776762&doi=10.1016%2fj.inffus.2023.101834&partnerID=40&md5=b0f00502d75a4bf7611acb820aa35f02","Multi-modal learning has made impressive progress in autonomous driving by leveraging information from multiple sensors. Existing feature fusion methods make decisions by integrating perceptions from different sensors. However, autonomous driving systems could be risky since the fused feature are unreliable when one of the sensors fails. Moreover, these methods require either sophisticated geometric designs to align features or complex neural networks to effectively fuse features, significantly increasing the training cost. In this paper, we propose PolicyFuser, a policy fusion method for end-to-end autonomous driving to address these issues. PolicyFuser retains an independent decision for each sensor, and no feature alignment or complex neural networks are required. To focus on the best policy, we use reinforcement learning to select the action with the highest Q-value as the primary decision, and the remaining actions as the secondary decisions. Then the secondary decisions are used to fine-tune the primary decision through a primary and secondary policy fusion (PSF) module. To bridge the gap between the decisions from different sensors and improve the stability of policy fusion, we use a conditional variational autoencoder (CVAE) to generate pseudo-expert decisions. We demonstrate the effectiveness of our method in CARLA, and our method achieves the highest driving scores and handles sensor failures with excellence. © 2023 Elsevier B.V.","Autonomous driving; Multi-modal policy fusion; Reinforcement learning; Robust fused policy"
"Characteristic evaluation via multi-sensor information fusion strategy for spherical underwater robots","2023","Information Fusion","10.1016/j.inffus.2023.02.024","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149974519&doi=10.1016%2fj.inffus.2023.02.024&partnerID=40&md5=08a36a75c3df6f8f06e52a1fce41c40a","Currently, most of the existing fusion methods ignore the rich multi-source information of different types of sensor nodes in the underwater unknown environment, which makes it challenging for Autonomous Underwater Vehicles (AUVs) to accurately perceive the external environment and make actionable decisions. Considering the key issues such as attitude estimation, positioning and obstacle avoidance involved in performing AUV tasks, this paper proposed a Multi-Source Information Fusion (MSIF) model for Spherical Underwater Robots (SURs) we developed based on various low-cost sensors. Multi-source information from an Inertial Measurement Unit (IMU), Pressure Sensor Array (PSA), Obstacle Avoidance Sensor Array (OASA), Depth Sensor (DS), Looking-Down Camera (LDC) and Acoustic Communication System (ACS) were fused to enable SUR to obtain high-precision estimated data for attitude estimation, positioning and obstacle avoidance, etc. More precisely, according to the correlation between the sensors, the optimized model was constructed to compensate for angle errors, velocity errors, orientation errors, etc. Subsequently, a machine learning method using Back Propagation Neural Network (BPNN) was proposed to improve the accuracy and effectiveness of the MSIF model through feature selection, data training, and feature estimation, etc. Finally, a series of experiments were performed under different scenarios, such as motion and obstacle avoidance experiments. The theoretical derivation and comprehensive evaluations demonstrated the effectiveness and feasibility of the proposed model, which provided a new reference value for solving issues such as attitude estimation, positioning and obstacle avoidance of AUVs. © 2023 Elsevier B.V.","Attitude estimation; BPNN method; Multi-source information fusion (MSIF); Obstacle avoidance; Positioning; Spherical underwater robots (SURs)"
"Multiscale spatial–spectral transformer network for hyperspectral and multispectral image fusion","2023","Information Fusion","10.1016/j.inffus.2023.03.011","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85151456432&doi=10.1016%2fj.inffus.2023.03.011&partnerID=40&md5=922959297a5695d2952440a2e70d2fd6","Fusing hyperspectral images (HSIs) and multispectral images (MSIs) is an economic and feasible way to obtain images with both high spectral resolution and spatial resolution. Due to the limited receptive field of convolution kernels, fusion methods based on convolutional neural networks (CNNs) fail to take advantage of the global relationship in a feature map. In this paper, to exploit the powerful capability of Transformer to extract global information from the whole feature map for fusion, we propose a novel Multiscale Spatial–spectral Transformer Network (MSST-Net). The proposed network is a two-branch network that integrates the self-attention mechanism of the Transformer to extract spectral features from HSI and spatial features from MSI, respectively. Before feature extraction, cross-modality concatenations are performed to achieve cross-modality information interaction between the two branches. Then, we propose a spectral Transformer (SpeT) to extract spectral features and introduce multiscale band/patch embeddings to obtain multiscale features through SpeTs and spatial Transformers (SpaTs). To further improve the network's performance and generalization, we proposed a self-supervised pre-training strategy, in which a masked bands autoencoder (MBAE) and a masked patches autoencoder (MPAE) are specially designed for self-supervised pre-training of the SpeTs and SpaTs. Extensive experiments on simulated and real datasets illustrate that the proposed network can achieve better performance when compared to other state-of-the-art fusion methods. The code of MSST-Net will be available at http://www.jiasen.tech/papers/ for the sake of reproducibility. © 2023 Elsevier B.V.","Hyperspectral image (HSI); Image fusion; Multispectral image (MSI); Pre-training; Spectral multi-head self-attention; Transformer"
"Multi-modal multi-task feature fusion for RGBT tracking","2023","Information Fusion","10.1016/j.inffus.2023.101816","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159082421&doi=10.1016%2fj.inffus.2023.101816&partnerID=40&md5=d5ffadfaf15184e6c027e62faa509293","RGBT tracking has received more and more attention in recent years, and in this paper, we propose a multi-task auxiliary learning framework for RGBT tracking. Specifically, we simplify the tracking task to an instance classification task and make it the primary task of the framework. We designed three auxiliary tasks and used a hard-parameter sharing approach to jointly train multiple tasks, hoping that the primary task would benefit from them. The three auxiliary tasks are contrastive instance discrimination, one-shot instance segmentation, and instance semantic matching. The contrastive instance discrimination method promotes the classification process of the primary task by constraining the features in the representation space. One-shot instance segmentation trains the network in a weakly supervised way to focus on more fine-grained features. In addition, in order to make the network pay more attention to the invariant features of instance target during tracking, we introduce a semantic matching task to alleviate the model drift problem caused by time change. Based on the results on three RGBT tracking benchmarks, the proposed framework is not inferior to the state-of-the-art trackers. © 2023 Elsevier B.V.","Auxiliary learning; Contrastive learning; Instance segmentation; RGBT tracking; Semantic matching"
"Matrix decomposition approaches for mutual information approximation with applications to covariance intersection techniques","2023","Information Fusion","10.1016/j.inffus.2023.03.003","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85150860357&doi=10.1016%2fj.inffus.2023.03.003&partnerID=40&md5=53cdd07705a16ee7a18fdb052aee6d4f","Fusing information provided by measurements from separate sensors is a common problem in multiple scientific and engineering disciplines, one with many potential solutions that can be found in literature. However, many of these solutions employ schemes that competitively weight these information sources and could potentially bias the fused solution towards a specific piece of information. In contrast, other solution methods attempt to cooperatively fuse the available information at the cost of maintaining the appropriate lower (consistent) and upper (tight) bounds. The present work derives a fusion methodology that preserves both consistency and tightness while cooperatively fusing the information provided by two information sources A and B. Additionally, upper and lower bounds on a scaling parameter, Ω, are also derived and proved analytically to maintain consistency and tightness of the presented fusion solution. The derived solution is then compared to current state-of-the-art solution and shown to provide tighter approximations of the optimal solution while keeping the optimal solution as the ultimate lower bound. © 2023 Elsevier B.V.","Covariance intersection; Cross correlation; Mutual information; Sensor fusion"
"Collaborative structure and feature learning for multi-view clustering","2023","Information Fusion","10.1016/j.inffus.2023.101832","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159630650&doi=10.1016%2fj.inffus.2023.101832&partnerID=40&md5=b40e0154d5b43856729af7ada5276530","Multi-view clustering divides similar objects into the same class through using the fused multiview information. Most multi-view clustering methods obtain clustering result by only analyzing structure relationship among samples, ignoring the analysis of intrinsic features of each sample, while a few methods operate the original feature on the corresponding high-dimensional kernel matrices. However, noisy and redundant features of samples are inevitably mixed in original multi-view data or high-dimensional kernel matrices. To address this problem, we propose a novel multiview clustering method, which unifies structure learning and feature learning to a framework. Specifically, we obtain a consensus structure information from multiple views via sparse subspace structure learning with weight tensor nuclear norm constraint. Then our feature learning seeks projection directions to obtain data representation by data pseudo labels, which are obtained via the fused consensus structure information. Furthermore, we use the manifold regularization term to establish the relationship between data structure information and learnt data presentation. At last, the two subtasks are alternately iterated and optimized to acquire accurate structure and discriminative data presentation. Experimental results on different datasets validate the proposed method is superior to the state-of-the-art methods. © 2023 Elsevier B.V.","Feature learning; Multiview clustering; Multiview fusion; Structure learning"
"From degrade to upgrade: Learning a self-supervised degradation guided adaptive network for blind remote sensing image super-resolution","2023","Information Fusion","10.1016/j.inffus.2023.03.021","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85152094157&doi=10.1016%2fj.inffus.2023.03.021&partnerID=40&md5=682a16abebe098e78306c5be061987b5","Over the past few years, single image super-resolution (SR) has become a hotspot in the remote sensing area, and numerous methods have made remarkable progress in this fundamental task. However, they usually rely on the assumption that images suffer from a fixed known degradation process, e.g., bicubic downsampling. To save us from performance drop when real-world distribution deviates from the naive assumption, blind image super-resolution for multiple and unknown degradations has been explored. Nevertheless, the lack of a real-world dataset and the challenge of reasonable degradation estimation hinder us from moving forward. In this paper, a self-supervised degradation-guided adaptive network is proposed to mitigate the domain gap between simulation and reality. Firstly, the complicated degradations are characterized by robust representations in embedding space, which promote adaptability to the downstream SR network with degradation priors. Specifically, we incorporated contrastive learning to blind remote sensing image SR, which guides the reconstruction process by encouraging the positive representations (relevant information) while punishing the negatives. Besides, an effective dual-wise feature modulation network is proposed for feature adaptation. With the guide of degradation representations, we conduct modulation on feature and channel dimensions to transform the low-resolution features into the desired domain that is suitable for reconstructing high-resolution images. Extensive experiments on three mainstream datasets have demonstrated our superiority against state-of-the-art methods. Our source code can be found at https://github.com/XY-boy/DRSR © 2023","Blind super-resolution; Contrastive learning; Deep learning; Remote sensing image; Self-supervised"
"Optimal symbolic entropy: An adaptive feature extraction algorithm for condition monitoring of bearings","2023","Information Fusion","10.1016/j.inffus.2023.101831","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159609173&doi=10.1016%2fj.inffus.2023.101831&partnerID=40&md5=4ec72ef461b386d16298fdb86bb354d1","Due to their effectiveness in vibration-based fault feature extraction from bearings, entropy-based methods have become a hot research topic. Symbolic dynamic filtering reduces background noise in bearing signals, making it ideal for entropy analysis. However, the partitioning approach selection of symbolic dynamic filtering mainly depends on experience, which may bring over-track and under-track phenomena. The optimal symbolic entropy (OSE) method proposes a solution by using mean spectral kurtosis to evaluate the symbolization performance of partitioning approaches. This method improves the identification of bearing faults through steps such as evaluating frequency and amplitude preservation, selecting the optimal symbolization approach, and using the OSE method with multiscale analysis. Simulative and experimental data analysis demonstrates its superior ability to extract bearing fault characteristics, with better performance and robustness than existing methods. © 2023 Elsevier B.V.","Bearings; Fault diagnosis; Mean spectral kurtosis; Optimal symbolic entropy; Symbolic dynamic filtering; Weak fault feature extraction"
"A systematic review on multi-criteria group decision-making methods based on weights: Analysis and classification scheme","2023","Information Fusion","10.1016/j.inffus.2023.03.004","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149811741&doi=10.1016%2fj.inffus.2023.03.004&partnerID=40&md5=718161691c8c4de160965bddc35467b7","Interest in group decision-making (GDM) has been increasing prominently over the last decade. Access to global databases, sophisticated sensors which can obtain multiple inputs or complex problems requiring opinions from several experts have driven interest in data aggregation. Consequently, the field has been widely studied from several viewpoints and multiple approaches have been proposed. Nevertheless, there is a lack of general framework. Moreover, this problem is exacerbated in the case of experts’ weighting methods, one of the most widely-used techniques to deal with multiple source aggregation. This lack of general classification scheme, or a guide to assist expert knowledge, leads to ambiguity or misreading for readers, who may be overwhelmed by the large amount of unclassified information currently available. To invert this situation, a general GDM framework is presented which divides and classifies all data aggregation techniques, focusing on and expanding the classification of experts’ weighting methods in terms of analysis type by carrying out an in-depth literature review. Results are not only classified but analysed and discussed regarding multiple characteristics, such as MCDMs in which they are applied, type of data used, ideal solutions considered or when they are applied. Furthermore, general requirements supplement this analysis such as initial influence, or component division considerations. As a result, this paper provides not only a general classification scheme and a detailed analysis of experts’ weighting methods but also a road map for researchers working on GDM topics or a guide for experts who use these methods. Furthermore, six significant contributions for future research pathways are provided in the conclusions. © 2023 The Author(s)","Expert weights; Group decision-making; MAGDM; MCGDM; Multiple criteria group decision-making"
"Binarized multi-gate mixture of Bayesian experts for cardiac syndrome X diagnosis: A clinician-in-the-loop scenario with a belief-uncertainty fusion paradigm","2023","Information Fusion","10.1016/j.inffus.2023.101813","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85154036612&doi=10.1016%2fj.inffus.2023.101813&partnerID=40&md5=76dcaaaeceb6b1fc17cd31eaad24dfb7","Cardiac Syndrome X (CSX) is a very dangerous cardiovascular disease characterized by angina-like chest discomfort and pain on effort despite normal epicardial coronary arteries at angiography. In this study, we used a CSX dataset from the coronary angiography registry of Tehran's Heart Center at Tehran University of Medical Sciences in Iran to develop several machine learning (ML) methods combined with uncertainty quantification of the obtained results. Uncertainty quantification plays a significant role in both traditional machine learning (ML) and deep learning (DL) studies allowing researchers to create trustable clinical detection systems. We propose a novel Mixture-of-Experts (MoE) model, called Binarized Multi-Gate Mixture of Bayesian Experts (MoBE), which is an effective ensemble technique for accurately classifying CSX data. The proposed binarized multi-gate model relies on a double quantified uncertainty strategy at the feature selection and decision making stages. First, we use a clinician-in-the-loop scenario with a belief-uncertainty paradigm at the feature selection stage. Second, we use Bayesian neural networks (BNNs) as experts in MoBE and Monte Carlo (MC) dropout for gates at the decision making uncertainty quantification stage. The proposed binarized multi-gate model reaches an accuracy of 85% when applied to our benchmark CSX dataset from Tehran's Heart Center. © 2023 Elsevier B.V.","Bayesian neural networks (BNNs); Cardiac syndrome X (CSX); Cardiovascular disease (CVD); Deep learning; Mixture of experts (moE); Uncertainty Quantification (UQ)"
"Multisource information fusion-based environment perception and dynamic model of underwater vehicle in irregular ocean environment","2023","Information Fusion","10.1016/j.inffus.2023.02.008","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147852901&doi=10.1016%2fj.inffus.2023.02.008&partnerID=40&md5=9c7583e3daa65d013fa43db75bcee464","The irregular ocean environment brings difficulties to observation and affects the movement state of underwater vehicles. Multisource information fusion can provide more reliable results on information-rich datasets. This paper proposes a multisource information fusion-based environment perception and dynamics model for underwater vehicles in irregular ocean environments. First, the multisource observation data is decomposed by the latent feature disentanglement learning model into the latent stable and dynamical features. The dynamical feature is predicted by the retrospect regression method and then integrated with the latent stable feature to predict the ocean field. After that, the environment-vehicle coupling effect is explored by thermodynamics and statics simulation. Then, a real-time dynamic model of the underwater vehicle is constructed by combining multisource information from physical principles, environmental perception, and sensor observations. Finally, extensive experiments are performed on a novel underwater glider and a publicly available South China Sea dataset to verify the proposed method. © 2023 Elsevier B.V.","Dynamic model; Feature disentanglement; Information fusion; Ocean environment; Underwater vehicle"
"BCINet: Bilateral cross-modal interaction network for indoor scene understanding in RGB-D images","2023","Information Fusion","10.1016/j.inffus.2023.01.016","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146914745&doi=10.1016%2fj.inffus.2023.01.016&partnerID=40&md5=e79b7dda3110a3d8da95364f931b07d9","Depth cue has proven to be useful information in the indoor scene understanding of RGB-D images for providing a geometric counterpart to RGB representation. However, because of the differences between RGB-D image pairs, utilizing cross-modal data effectively is a key issue. Most methods exclusively leverage depth data to unilaterally complement RGB data for better feature representation; they invariably ignore the fact that RGB and depth data can bilaterally complement each other. Herein, a novel RGB-D scene-understanding network called BCINet is presented, in which RGB and depth data bilaterally complement each other via a proposed bilateral cross-modal interaction module (BCIM). The BCIM helps to capture cross-modal complementary cues by crossly fusing enhanced features from one modality to the counterpart modality through a feature enhanced module. Meanwhile, exploiting the long-range dependencies of RGB-D features is also significant for accurate scene understanding. Specifically, we design a hybrid pyramid dilated convolution module to enlarge the receptive fields along both the vertical and horizontal spatial directions to adaptively capture diverse contexts with different shapes. Additionally, we propose a context-guided module to aggregate these diverse higher-level contexts with lower-level features in the encoder to guide the information flow for progressively refining the segmentation map. Experimental results on two indoor scene datasets demonstrate the superiority and effectiveness of the proposed BCINet over several state-of-the-art approaches. © 2023 Elsevier B.V.","Bilateral cross-modal interaction; Deep learning; Hybrid pyramid dilated convolution; RGB-D; Scene understanding"
"Non-contact diagnosis for gearbox based on the fusion of multi-sensor heterogeneous data","2023","Information Fusion","10.1016/j.inffus.2023.01.020","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147090735&doi=10.1016%2fj.inffus.2023.01.020&partnerID=40&md5=f9a63f224f4f8408dad8f22d0af59193","Non-contact sensing technology plays an important role in the health monitoring of the gearbox. However, a single non-contact measurement is challenging to achieve the simultaneous monitoring of both structural and non-structural damages. In order to explore the fusion mechanism of multi-sensor heterogeneous measurements, acoustic and thermal characteristics of the gearbox under typical fault states are analyzed, and it is verified the fusion of infrared thermal (IRT) images and acoustic data integrates complementary fault information. In this paper, an attention-enhanced information fusion diagnosis network (AIFN-IA) is proposed for the complementary fusion of IRT images and acoustic data. Firstly, the acoustic data is converted into images by the non-hyperparameter encoding method and then fused with IRT images in data-level. Secondly, the limited shuffle attention module is designed to adaptively focus on the fault elements hidden in the complex fusion features. Finally, experimental data verify the effectiveness of the proposed AIFN-IA method in recognizing six structural and non-structural damages of the gearbox. Compared with seven state-of-the-art methods, the proposed AIFN-IA method performs best in extracting discriminating features with the highest diagnosis accuracy. Moreover, the proposed AIFN-IA method can still achieve satisfactory results under the challenges of small sample datasets and strong noise interference, which is more competitive in real industrial applications. © 2023","Information fusion; Multi-sensor heterogeneous data; Noise resistance; Non-contact fault diagnosis; Non-structural damage"
"Recursive state estimation for state-saturated systems with two groups of measurements: Handling delayed and degraded sensors","2023","Information Fusion","10.1016/j.inffus.2023.101814","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85153868604&doi=10.1016%2fj.inffus.2023.101814&partnerID=40&md5=0665e422a92c0825be0c45ba74fa5293","In this paper, the recursive fusion estimation problem is investigated for a class of state-saturated systems with two groups of sensors, one with instantaneous measurements and the other with delayed measurements. The phenomena of sensor gain degradations and sensor measurement delays are regulated by a number of mutually independent random variables that are uniformly distributed over known intervals. First, an equivalent model to the original measurement system is constructed by reorganizing the instantaneous and delayed measurements. Then, by turning to a constrained variance method, we construct an upper bound of the estimation error covariance by solving two Riccati-like recursive equations whose dimension is the same as that of the original system. Subsequently, the estimator gain matrix is computed through minimizing the constructed upper bound, and the boundedness of the acquired upper bound is also discussed. Finally, we provide a simulation example to verify the usefulness of our designed fusion estimation algorithm. © 2023 Elsevier B.V.","Delayed measurements; Fusion estimation; Recursive estimation; Sensor gain degradation; State-saturated system"
"Managing non-cooperative behaviors in large-scale group decision making based on trust relationships and confidence levels of decision makers","2023","Information Fusion","10.1016/j.inffus.2023.101820","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85158843883&doi=10.1016%2fj.inffus.2023.101820&partnerID=40&md5=24cf29ee2a32ef5632d605b6688c7036","In large-scale group decision making events, diverse backgrounds of decision makers (DMs) may result in various non-cooperative behaviors as they pursue personal interests, thereby causing significant harm to the decision making process. Instead of solely analyzing DMs’ evaluations in detecting traditional non-cooperative behaviors, this study defines three new categories of non-cooperative behaviors by integrating DMs’ evaluations with their personal attributes, such as confidence levels and trust relationships. These new behaviors include bribery behavior, passive participation behavior, and potential conflict behavior. To address these behaviors, this research proposes a confidence and trust-based consensus reaching process (CT-CRP). Within CT-CRP, three distinct acceptance functions for DMs are introduced, which are utilized to describe the likelihood of DMs accepting recommended plans and determining an optimal modification rate. Lastly, an illustrative example and several experiments are provided to demonstrate the effectiveness and validity of CT-CRP in enhancing consensus among DMs. © 2023 Elsevier B.V.","Acceptance functions; Consensus reaching process; Large-scale group decision making; Non-cooperative behaviors"
"Consensus reaching in multi-criteria social network group decision making: A stochastic multicriteria acceptability analysis-based method","2023","Information Fusion","10.1016/j.inffus.2023.101825","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85154548445&doi=10.1016%2fj.inffus.2023.101825&partnerID=40&md5=543a9a1ecb5ff92dea661079930623ad","Multi-criteria social network group decision making (SNGDM) that allows decision makers (DMs) to interact with each other has attracted increasing attention in the field of decision analysis. In this paper, we take stochastic multicriteria acceptability analysis (SMAA) into account to study consensus reaching processes in multi-criteria SNGDM problems with manipulative behaviors. First, we propose a SMAA-based method to transform decision matrices into fuzzy preference relations to detect manipulators in multi-criteria SNGDM. Then, we design a new consensus determining mechanism using the weight stability interval and SMAA methods, which does not require a consensus threshold to be determined in advance. Based on this, we propose a two-stage feedback process to help DMs reach consensus. Then, we propose an algorithm to summarize the main steps of the proposed method. Finally, we use a case study of nursing home location selection to illustrate the effectiveness of the proposed method. © 2023 Elsevier B.V.","Consensus reaching process; Manipulative behavior; Social network group decision making; Stochastic multicriteria acceptability analysis"
"TFSFB: Two-stage feature selection via fusing fuzzy multi-neighborhood rough set with binary whale optimization for imbalanced data","2023","Information Fusion","10.1016/j.inffus.2023.02.016","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85148323318&doi=10.1016%2fj.inffus.2023.02.016&partnerID=40&md5=573abb3c3dbc2af79782a97f930a66d7","Obtaining informative features is crucial in imbalanced classification. However, existing neighborhood rough set-based feature selection approaches easily overlook the diversity and complexity of data distributions, and it is difficult to obtain this global optimal feature subset from imbalanced and high-dimensional datasets. To tackle these limitations, we construct a new two-stage feature subset selection scheme by fusing the fuzzy multi-neighborhood rough set (FMRS) with the binary whale optimization algorithm (BWOA) for imbalanced data. First, to evaluate those distributions of different features, this standard deviation coefficient is introduced to construct a fuzzy multi-neighborhood radius set. Then, the fuzzy multi-neighborhood granule and fuzzy membership degree are presented to establish the novel FMRS, and the feature significance measure in the view of algebra is developed to balance the approximate properties and influences of different features in the negative and positive classes. Second, fuzzy multi-neighborhood conditional entropy is defined to maximize information quantity of class- imbalanced data from the information view, and then by fusing the two evaluation perspectives above, this mixed metric is provided to fully assess this uncertainty of class-imbalanced datasets. These internal and external significant metrics are designed to obtain this preselected candidate set of features based on the filter FMRS model at this first stage. Third, a control factor can be developed to dominate the whale position update, and a novel fitness function will be constructed when fusing the dependency degree and entropy measure with the reduction ratio to evaluate this optimal subset of features. Adopting population partitioning and local interference schemes can prevent the BWOA from becoming trapped within a local optimum. To reduce this search space of evolution, the dynamic bitmask is used to improve the BWOA, and then an optimal subset of features is acquired through continuous iterations of this wrapper BWOA at this second stage. Finally, a new two-stage algorithm for feature subset selection by fusing FMRS and BWOA is provided to process class-imbalanced data, where this particle swarm optimization algorithm confirms those optimized parameters. Experiments on 31 datasets show that our algorithm is efficient and can achieve excellent classification efficiency for binary and multiclass imbalanced data. © 2023 Elsevier B.V.","Binary whale optimization; Feature selection; Feature significance; Fuzzy multi-neighborhood; Imbalanced classification"
"UPLP-SLAM: Unified point-line-plane feature fusion for RGB-D visual SLAM","2023","Information Fusion","10.1016/j.inffus.2023.03.006","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85150263874&doi=10.1016%2fj.inffus.2023.03.006&partnerID=40&md5=0d145275cc9ca5d34ab13285218172c7","Most of the existing RGB-D simultaneous localization and mapping (SLAM) systems are based on point features or point-line features or point-plane features. However, the existing multi- feature fusion SLAM methods based on the filter framework are not accurate and robust. And the fusion methods based on the optimization framework process different kinds of features separately and integrate them loosely. In the optimization-based framework, how to tightly fuse various kinds of features for achieving more accurate and robust pose estimation has been rarely considered. In this paper, we propose a unified point-line-plane fusion RGB-D visual SLAM method for navigation of mobile robots in structured environments, making full use of the information of three kinds of geometric features. Specifically, it extracts point, line, and plane features using images captured by the RGB-D camera and expresses them in a uniform way. Then, a mutual association scheme is designed for data association of point, line and plane features, which not only considers the correspondence of homogeneous features, i.e., point-point, line-line and plane-plane pairs, but also includes the association of heterogeneous features, i.e., point- line, point-plane and line-plane pairs. Afterwards, the matching errors between homogeneous features and the association errors between heterogeneous features are uniformly represented and jointly optimized to estimate the camera pose and feature parameters for accurate and consistent localization and map building. It is worth pointing out that the proposed unified framework contains two levels. From the system framework perspective, all the main components of the SLAM system, i.e., feature representation, feature association and error function are handled in a unified manner, which increases the accuracy and compactness of the multi-feature SLAM system. From the feature processing perspective, both homogeneous features and heterogeneous features are uniformly used, which provides more spatial constraints on pose estimation. Finally, the accuracy and robustness of the proposed method are verified by experiment comparisons with state-of-the-art visual SLAM systems on public datasets and in real-world environments © 2023 Elsevier B.V.","ASssociation joint optimization; Point-line-plane fusion; Simultaneous localization and mapping (SLAM); Uniform representation mutual"
"A three-way consensus model with regret theory under the framework of probabilistic linguistic term sets","2023","Information Fusion","10.1016/j.inffus.2023.02.029","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149167776&doi=10.1016%2fj.inffus.2023.02.029&partnerID=40&md5=4a7ae14e9100c7c9d1f101d85d663bf7","For multi-attribute group decision-making (MAGDM) problems, this paper proposes a three-way consensus model based on regret theory (RT) under the framework of probabilistic linguistic term sets (PLTSs), i.e., the PL-RT-GTWD model. Specifically, the PL-RT-GTWD model mainly consists of the following two components: (1) The consensus measurement considering the relativity among decision-makers (DMs); (2) A three-way consensus feedback mechanism with the minimum adjustment. First, the relative relationship between DMs is supplemented, and the consensus degree of the DM evaluation matrix is measured by a newly developed distance measure. Second, an optimization model with the minimum adjustment for all DMs to modify and reach the final desired goal (group consensus opinions) is constructed, so that DMs can achieve a balance between reaching consensus and maintaining individual independence. Then, taking the minimum adjustment before and after the adjustment as the objective function, the increase of consensus degrees and the initial range of adjustment parameters as constraints, the goal programming on adjustment parameters is constructed. It is noteworthy that the initial range of adjustment parameters is divided via three-way decision (TWD) tools that consider the regret generated during the adjustment, so as to avoid the subjectivity of the adjustment and reduce adjustment costs. Finally, comparative and sensitivity analyses are carried out to verify the feasibility and superiority of the constructed model. © 2023 Elsevier B.V.","Consensus reaching process; Multi-attribute group decision-making; Probabilistic linguistic term set; Regret theory; Three-way decision"
"An ELICIT information-based ORESTE method for failure mode and effect analysis considering risk correlation with GRA-DEMATEL","2023","Information Fusion","10.1016/j.inffus.2023.01.012","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146438513&doi=10.1016%2fj.inffus.2023.01.012&partnerID=40&md5=4f504cd7b26bd4438c0964da6a452a45","Failure mode and effect analysis (FMEA) is one of the most powerful reliability analysis techniques for identifying and preventing potential risks across various fields. Current FMEA methods, while effective, still present several shortcomings. For example, using experts’ subjective pairwise comparisons of risk factors to determine their weights reduces the stability of the result; different relationships among failure modes are often ignored. To improve the performance of FMEA, multi-criteria decision-making (MCDM) methods have been employed to support risk evaluation and prioritization in recent years. This paper proposes a novel FMEA method by exploring several MCDM techniques. First, the Extended Comparative Linguistic Expressions with Symbolic Translation (ELICIT) are utilized to generate group risk assessments under uncertainty. Then, grey relation analysis (GRA) is incorporated into the decision-making trial and evaluation laboratory (DEMATEL) method to objectively determine the weight of risk factors. Afterward, the traditional ORESTE (organísation, rangement et Synthèse de données relarionnelles (in French)) method is generalized to the ELICIT environment to prioritize the failure modes, in which the Besson's ranking is replaced by deviation measure for more accurate ranking results. Finally, a case study of FMEA for electro-mechanical actuators is presented to illustrate the effectiveness of the proposed method. The results indicate that our approach can express risk information more flexibly, determine the weight of risk factors more objectively, and prioritize failure modes more reasonably. © 2023 The Author(s)","ELICIT information; Failure mode and effect analysis (FMEA); Multi-criteria decision making (MCDM); ORESTE method"
"A large-scale group consensus reaching approach considering self-confidence with two-tuple linguistic trust/distrust relationship and its application in life cycle sustainability assessment","2023","Information Fusion","10.1016/j.inffus.2023.01.026","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147329546&doi=10.1016%2fj.inffus.2023.01.026&partnerID=40&md5=0d3357e3d60c686ef9aebc382e4bc79a","Large-scale group decision making (LSGDM) is very common in real world, and especially how to reach a relatively consensus status in a social network is a hot topic. In this paper, we propose a concept of two-tuple linguistic trust/distrust relationship (LTR) which could present both trust and distrust degrees by semantics. The trust/distrust representation scheme can unburden individuals from providing numerical trust or distrust degree to just presenting linguistic variables. Transformation rule from two-tuple LTR to numerical trust degree is then analyzed, followed by the propagation operator of indirect trust/distrust relationships. The advantage of the propagation operator lies in that ignorance in trust/distrust relationships can be tackled rationally. As for the consensus reaching process (CRP), three-level identification and adjustment mechanisms are proposed under the condition that individuals express their preferences in an uncertain distribution form. Trust relationship, consensus degree and reliability of individuals’ judgments are all addressed comprehensively to narrow the opinion divergence. Self-confidence extent is utilized as a factor to adjust the opinions of non-consensus experts. The proposed method is further implemented in life cycle sustainability assessment to demonstrate the validity and effectiveness in dealing with realistic GDM problems. © 2023 Elsevier B.V.","Large-scale group decision making; Life cycle sustainability assessment; Linguistic trust/distrust relationship; Self-confidence; Trust propagation"
"Human-centered neural reasoning for subjective content processing: Hate speech, emotions, and humor","2023","Information Fusion","10.1016/j.inffus.2023.01.010","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147249322&doi=10.1016%2fj.inffus.2023.01.010&partnerID=40&md5=da7384f847b03f686a9f5ce54e7b9b09","Some tasks in content processing, e.g., natural language processing (NLP), like hate or offensive speech and emotional or funny text detection, are subjective by nature. Each human may perceive some content individually. The existing reasoning methods commonly rely on agreed output values, the same for all recipients. We propose fundamentally different — personalized solutions applicable to any subjective NLP task. Our five new deep learning models take into account not only the textual content but also the opinions and beliefs of a given person. They differ in their approaches to learning Human Bias (HuBi) and fusion with content (text) representation. The experiments were carried out on 14 tasks related to offensive, emotional, and humorous texts. Our personalized HuBi methods radically outperformed the generalized ones for all NLP problems. Personalization also has a greater impact on reasoning quality than commonly explored pre-trained and fine-tuned language models. We discovered a high correlation between human bias calculated using our dedicated formula and that learned by the model. Multi-task solutions achieved better outcomes than single-task architectures. Human and word embeddings also provided additional insights. © 2023","Content perception; Emotion recognition; Hate speech; Human bias; Humor detection; Information fusion; Learning human representations; NLP; Offensive content; Personalized NLP; Subjective NLP tasks; Text classification"
"Multi-level feature fusion for multimodal human activity recognition in Internet of Healthcare Things","2023","Information Fusion","10.1016/j.inffus.2023.01.015","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149732860&doi=10.1016%2fj.inffus.2023.01.015&partnerID=40&md5=13ced78245461d176e837b089d7daece","Human Activity Recognition (HAR) has become a crucial element for smart healthcare applications due to the fast adoption of wearable sensors and mobile technologies. Most of the existing human activity recognition frameworks deal with a single modality of data that degrades the reliability and recognition accuracy of the system for heterogeneous data sources. In this article, we propose a multi-level feature fusion technique for multimodal human activity recognition using multi-head Convolutional Neural Network (CNN) with Convolution Block Attention Module (CBAM) to process the visual data and Convolutional Long Short Term Memory (ConvLSTM) for dealing with the time-sensitive multi-source sensor information. The architecture is developed to be able to analyze and retrieve channel and spatial dimension features through the use of three branches of CNN along with CBAM for visual information. The ConvLSTM network is designed to capture temporal features from the multiple sensors’ time-series data for efficient activity recognition. An open-access multimodal HAR dataset named UP-Fall detection dataset is utilized in experiments and evaluations to measure the performance of the developed fusion architecture. Finally, we deployed an Internet of Things (IoT) system to test the proposed fusion network in real-world smart healthcare application scenarios. The findings from the experimental results reveal that the developed multimodal HAR framework surpasses the existing state-of-the-art methods in terms of multiple performance metrics. © 2023 Elsevier B.V.","Convolutional block attention module; Convolutional long short term memory; Human activity recognition; Internet of things; Multi-head convolutional neural network"
"Mining and reasoning of data uncertainty-induced imprecision in deep image classification","2023","Information Fusion","10.1016/j.inffus.2023.03.014","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85151264163&doi=10.1016%2fj.inffus.2023.03.014&partnerID=40&md5=5ed0c7261721ec81c290ef6f33c774ba","Existing deep image classification techniques strive to suppress data uncertainty for various reasons such as blur, occlusion, noise, and label error and advance to higher accuracy. However, they ignore data uncertainty-induced imprecision and thus do not work as intended. In this paper, we propose a deep open-source framework to mine and reason the imprecision of such training and test sets, which can present better performance and reduce the risk of misclassification. First, we design a label reassignment mechanism. It allows the network to reassign training labels and allow imperfect training samples with multiple labels. As a result, they are removed from the original classes and considered new imprecise samples to represent partial ignorance. Second, we propose a new imbalanced data enhancement architecture to learn a generalized representation of each (precise and imprecise) class. It helps the network fuse the auxiliary information from both precise and imprecise classes, which is beneficial to extract more distinctive class features from single-labeled samples and characterize uncertainty-induced imprecision in the test set by imprecise test samples. Afterward, methodological analyses and empirical evaluations are conducted. The proposed framework is demonstrated to present better performance on different typical networks (Resnet50, MobileNetV2, DenseNet121, EfficientNetB0, ShuffleNetV2, SENet, SqueezeNet, Xception) based on five publicly available datasets (Imagewoof-5, Flowers, Monkey, Butterfly, and Cifar-10). In addition, several targeted deep techniques for uncertain images or imprecise results are also employed as comparisons to prove the superiority of the proposed framework. © 2023 Elsevier B.V.","Data uncertainty; Deep techniques; Image classification; Imprecision; Multiple labels"
"Large-group failure mode and effects analysis for risk management of angle grinders in the construction industry","2023","Information Fusion","10.1016/j.inffus.2023.101803","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85152600593&doi=10.1016%2fj.inffus.2023.101803&partnerID=40&md5=dd03531aaa07ad627688d7322a2e0c9d","Accidents associated with the use of construction equipment are among the leading causes of fatal injuries in the construction industry. In particular, angle grinders are associated with a significant number of occupational injuries every year. However, practitioners and researchers have paid limited attention to this issue. To facilitate the development of more sophisticated plans and guidelines to prevent angle grinder-related accidents, failure mode and effects analysis (FMEA) is employed for risk management in such a context. The conventional FMEA method is extensively used for examining potential failure in many industries, but has been criticized much in the literature for its various limitations. This study presents a novel large-group FMEA (LGFMEA) model, which integrates a clustering analysis for handling experts at large scale, a consensus reaching process with relative basic uncertain linguistic information (RBULI) to manage opinion diversity among experts, and the behavioral TOPSIS method to rank failure modes. The assessment information is characterized by the RBULI, a novel information representation construction method applied to handle complex evaluations under uncertainty. Finally, the proposed LGFMEA approach is performed for risk analysis related to angle grinder use to obtain insights into risk mitigation, and the sensitive and comparative analyses are performed to verify the rationality and feasibility of the model. © 2023 Elsevier B.V.","Angle grinder; Consensus reaching process; Construction equipment; Large-group failure mode and effects analysis; Relative basic uncertain linguistic information"
"Vision-knowledge fusion model for multi-domain medical report generation","2023","Information Fusion","10.1016/j.inffus.2023.101817","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85153521326&doi=10.1016%2fj.inffus.2023.101817&partnerID=40&md5=3eadfddd8fd4fe561d8f31d85a58eb69","Medical report generation with knowledge graph is an essential task in the medical field. Although the existing knowledge graphs have many entities, their semantics are not sufficient due to the challenge of uniformly extracting and fusing the expert knowledge from different diseases. Therefore, it is necessary to automatically construct specific knowledge graph. In this paper, we propose a vision-knowledge fusion model based on medical images and knowledge graphs to fully utilize high-quality data from different diseases and languages. Firstly, we give a general method to automatically construct every domain knowledge graph based on medical standards. Secondly, we design a knowledge-based attention mechanism to effectively fuse image and knowledge. Then, we build a triples restoration module to obtain fine-grained knowledge, and the knowledge-based evaluation metrics are first proposed which are more reasonable and measurable from different dimensions. Finally, we conduct experiments to verify the effectiveness of our model on two different diseases datasets: the IU-Xray chest radiograph public dataset and the NCRC-DS dataset of Chinese dermoscopy reports we compiled. Our model outperforms previous benchmark methods and achieves excellent evaluation scores on both datasets. Additionally, interpretability and clinical usefulness of the model are validated and our method can be generalized to multiple domains and different diseases. © 2023 Elsevier B.V.","Graph neural network; Knowledge graph; Medical report generation; Multi-modal fusion"
"A behavioural hierarchical analysis framework in a smart home: Integrating HMM and probabilistic model checking","2023","Information Fusion","10.1016/j.inffus.2023.02.025","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149827138&doi=10.1016%2fj.inffus.2023.02.025&partnerID=40&md5=a0acb37f17819c4717af8323b15d4ed6","Smart homes offer great convenience for people living alone and assistance for physically impaired inhabitants. Robust behavioural analysis technology is one of the keys to maximizing the role of the Smart Home. Typically, when it comes to the behavioural analysis of its inhabitants, most researchers have acquired it through data collection from sensors, cameras, and portable Bluetooth sensors. However, a gap in research exists concerning activity recognition in the context of the users physical location in the environment. In this paper, we propose a hierarchical framework based on Hidden Markov Model (HMM) and suggest dividing the behavioural sequence analysis into two layers: spatial transfer and sensor transfer. In addition, we apply probabilistic model checking to verify the properties of each module's state transfer and obtain the probability of occurrence of the corresponding behavioural sequence. By integrating an implicit Markov model and probabilistic model checking, we effectively analyse the composition and probability of occurrence of three arbitrary sequences of complex behaviours. Finally, anomaly detection and behavioural guidance are discussed based on the proposed behavioural analysis methods. © 2023 Elsevier B.V.","Behavioural analysis; Hidden Markov model; Probabilistic model checking; Smart home"
"Instance-wise multi-view representation learning","2023","Information Fusion","10.1016/j.inffus.2022.11.006","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142173441&doi=10.1016%2fj.inffus.2022.11.006&partnerID=40&md5=d715d753c7e7b2461190805cb518a7b8","Multi-view representation learning aims to integrate multiple data information from different views to improve the task performance. The information contained in multi-view data is usually complex. Not only do different views contain different information, but also different samples of the same view contain different information. In the multi-view representation learning, most existing methods either simply treat each view/sample with equal importance, or set fixed or dynamic weights for different views/samples, which is not accurate enough to capture the information of dimensions of each sample and causes information redundancy, especially for high-dimensional samples. In this paper, we propose a novel unsupervised multi-view representation learning method based on instance-wise feature selection. A main advantage of instance-wise feature selection in this paper is that one can dynamically select dimensions that favor both view-specific representation learning and view-shared representation learning for each sample, thereby improving the performance from the perspective of model input. The proposed method consists of selector network, view-specific network and view-shared network. Specifically, selector network is used to obtain the selection template, which selects different number of dimensions conducive to representation learning from different samples to solve the sample heterogeneity problem; the view-specific network and view-shared network are used to extract the view-specific and view-shared representations, respectively. The selector network, view-shared network, and view-specific network are optimized alternately. Extensive experiments on various multi-view datasets with clustering and multi-label classification tasks demonstrate that the proposed method outperforms the state-of-the-art multi-view learning methods. © 2022 Elsevier B.V.","Instance-wise selection; Multi-view representation learning; View-shared; View-specific"
"Soft labelling based on triangular distributions for ordinal classification","2023","Information Fusion","10.1016/j.inffus.2023.01.003","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146099598&doi=10.1016%2fj.inffus.2023.01.003&partnerID=40&md5=b29e58a4f9005611c85769141e368e5c","Recently, solving ordinal classification problems using machine learning and deep learning techniques has acquired important attention. There are many real-world problems in different areas of knowledge where a categorical variable needs to be predicted, and the existing categories follow an order associated with the nature of the problem: e.g. medical diagnosis with different states of a disease, or industrial quality assessment with different levels of quality. In these problems, it is quite common that the final label for each sample is determined by a group of experts with different opinions, and all opinions are usually summarised in a single crisp label by means of a given statistic (e.g. the median or the mode). Applying standard ordinal classifiers to these crisp labels could result in overfitting, as the labelling information is considered as totally certain. In this work, we propose a unimodal regularisation approach based on soft labelling, i.e. the ordinal information is used to introduce the inherent uncertainty of the label fusion. Specifically, said regularisation is based on using triangular distributions to simulate the aforementioned fusion of the expert opinions, where a parameter is used to decide the amount of probability that is assigned to the target category and the adjacent ones (according to the ordinal scale). The strategy could be applied to the loss function used by any ordinal classification learning algorithm, but we focus on deep learning in this paper. The proposal is compared to a baseline approach for nominal classification tasks and other state-of-the-art unimodal regularisation methods, and the experimental validation includes six benchmark datasets and five performance metrics. The results along with the statistical analysis show that the proposed methodology significantly outperforms the rest of the methods. © 2023 Elsevier B.V.","Deep learning; Ordinal loss; Triangular distribution; Unimodal regularisation"
"Enhanced Frequency Fusion Network with Dynamic Hash Attention for image denoising","2023","Information Fusion","10.1016/j.inffus.2022.12.015","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85145656212&doi=10.1016%2fj.inffus.2022.12.015&partnerID=40&md5=3726d54e06510ba25c9601d90e4b85c8","Recently, Transformer-based image denoising methods have achieved great progress in the image denoising task. However, these methods also lead to two problems: (a) Since noise can destroy texture or details in the image, the resulting tokens with low weight values may have a negative impact on the reconstructed denoised image (i.e., there are artifacts in the reconstructed image, etc); (b) Frequencies in different domains are ignored, leading to the missing of textural details in the reconstructed image. To this end, we propose an Enhanced Frequency Fusion Network (EFF-Net) with dynamic hash attention for image denoising, called EFF-Net. Specifically, to alleviate the impact of problem (a), we present the Dynamic Hash Attention (DHA) module, which aims to effectively mitigate the negative impact of tokens with low weight values on image denoising performance; Furthermore, we start from the frequency perspective and design the Enhanced Frequency Fusion (EFF) module with Decomposition Frequency (DF) as the core component, which aims to achieve the separation and fusion of noisy image content in the frequency domain, and appropriately reconstruct the image content of different frequency components at different locations. The DHA and EFF modules are integrated into plug-and-play Adaptive Frequency Enhancement (AFE) transformer blocks to selectively recover different frequencies based on long-range pixel dependency. The extensive experiments endorse the effective, and superior performance of our EFF-Net for image denoising. © 2022 Elsevier B.V.","Decomposition frequency; Dynamic hash attention; Enhanced frequency fusion; Image denoising; Transformer"
"Zonotopic distributed fusion for nonlinear networked systems with bit rate constraint","2023","Information Fusion","10.1016/j.inffus.2022.09.014","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139033620&doi=10.1016%2fj.inffus.2022.09.014&partnerID=40&md5=5ecfe5b2fe74ee1de7658d3c63f17b2a","In this paper, the distributed fusion estimation problem is studied for a class of nonlinear networked systems subject to unknown-but-bounded (UBB) noises. A bit rate constraint is introduced to quantify the limited bandwidth of the communication channel, under which a bit rate allocation protocol is further designed by solving a certain off-line optimization problem. Based on the received data from the network, several local extended-Kalman-type estimators are constructed and zonotopic sets confining local estimation errors are then obtained. By designing the local estimator parameters, the F-radii of the obtained zonotopic sets are minimized. Subsequently, with the calculated local estimates and zonotopic sets, a zonotopes-based distributed fusion estimator is put forward by means of the matrix-weighted fusion method, and the global zonotope (i.e., the zonotope encompassing the error between the system state and the fused estimate) is derived. Moreover, under the proposed zonotopes-based fusion framework, the distributed fusion estimators are designed based on, respectively, the scalar-weighted fusion method and the diagonal-matrix-weighted fusion method. Finally, the effectiveness of the proposed distributed fusion method is illustrated through a numerical example. © 2022 Elsevier B.V.","Bit rate constraint; Distributed fusion; Nonlinear networked systems; Set-membership state estimation; Zonotopes"
"LRINet: Long-range imaging using multispectral fusion of RGB and NIR images","2023","Information Fusion","10.1016/j.inffus.2022.11.020","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144087462&doi=10.1016%2fj.inffus.2022.11.020&partnerID=40&md5=33682c7c41f5df138a1ab44ec0b3a4f0","When imaging at a long distance by ordinary visible cameras, the wavelength of visible light is easily interfered by fog or atmospheric effects, resulting in blurry or lost details in RGB images. However, NIR cameras are robust to the long distance imaging without color. In this paper, we propose long-range imaging using multispectral fusion of RGB and NIR images, called LRINet. We adopt unsupervised learning for the fusion to solve the absence of ground truth. LRINet is an end-to-end network based on convolutional neural networks (CNNs) that consists of three steps for the multispectral fusion: feature extraction, fusion and reconstruction. To align unpaired data and treat the discrepancy between RGB and NIR images, we construct WarpingNet to warp NIR features, and add it into the feature extraction. Since dark channel prior (DCP) provides distance from the camera by light transmission degree, we combine it with structure loss as the weight for fusion. To ensure the color fidelity, LRINet operates the fusion on the input of the RGB luma channel and NIR image. Experimental results show that LRINet produces natural-looking color images with clear details by successfully treating discrepancy between RGB and NIR images and outperforms state-of-art fusion models in term of both visual quality and quantitative measurements. © 2022 Elsevier B.V.","Deep learning; Image fusion; Long-range imaging; Near infrared; Neural networks"
"Prediction of Alzheimer's progression based on multimodal Deep-Learning-based fusion and visual Explainability of time-series data","2023","Information Fusion","10.1016/j.inffus.2022.11.028","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144325712&doi=10.1016%2fj.inffus.2022.11.028&partnerID=40&md5=3a6ad2c35531f2febdb13cb301616873","Alzheimer's disease (AD) is a neurological illness that causes cognitive impairment and has no known treatment. The premise for delivering timely therapy is the early diagnosis of AD before clinical symptoms appear. Mild cognitive impairment is an intermediate stage in which cognitively normal patients can be distinguished from those with AD. In this study, we propose a hybrid multimodal deep-learning framework consisting of a 3D convolutional neural network (3D CNN) followed by a bidirectional recurrent neural network (BRNN). The proposed 3D CNN captures intra-slice features from each 3D magnetic resonance imaging (MRI) volume, whereas the BRNN module identifies the inter-sequence patterns that lead to AD. This study is conducted based on longitudinal 3D MRI volumes collected over a six-months time span. We further investigate the effect of fusing MRI with cross-sectional biomarkers, such as patients’ demographic and cognitive scores from their baseline visit. In addition, we present a novel explainability approach that helps domain experts and practitioners to understand the end output of the proposed multimodal. Extensive experiments reveal that the accuracy, precision, recall, and area under the receiver operating characteristic curve of the proposed framework are 96%, 99%, 92%, and 96%, respectively. These results are based on the fusion of MRI and demographic features and indicate that the proposed framework becomes more stable when exposed to a more complete set of longitudinal data. Moreover, the explainability module provides extra support for the progression claim by more accurately identifying the brain regions that domain experts commonly report during diagnoses. © 2022 Elsevier B.V.","3D CNN; AD progression detection; Explainable AI; Multimodal information fusion; Time-series data analysis"
"A Novel Degraded Document Binarization Model through Vision Transformer Network","2023","Information Fusion","10.1016/j.inffus.2022.12.011","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85145968337&doi=10.1016%2fj.inffus.2022.12.011&partnerID=40&md5=a05f360badf5fa194500cc3ce72dcc38","Degraded document binarization has received keen attention due to its vital influence on subsequent document analysis tasks. In this study, we propose a novel Degraded Document Binarization model through the vision transFormer framework, termed D2BFormer. Thanks to its end-to-end trainable fashion, the D2BFormer model is able to autonomously optimize its parameterized configuration of the entire learning pipeline without incurring the intensity-to-binary value conversion phase, resulting in an improved binarization quality. In addition, we propose a novel dual-branched encoding feature fusion module, which combines architectural components from the vision transformer framework and deep convolutional neural networks. The resulting encoding module can extract features from an input document that are sensitive to both global and local characteristics. Meanwhile, the proposed encoding feature extraction module can operate internally at a much lower spatial resolution than that of a raw input document, leading to reduced computational complexity. Furthermore, we propose a novel progressively merged decoding feature fusion module through carefully introduced skip connections both inside and outside the decoding network. The resulting decoding module progressively combines counterpart features derived from the corresponding layers of the encoding network with comparable spatial resolutions and up-sampled features generated from previous layers in the decoding network. Finally, the experiments conducted on ten public datasets demonstrate that the proposed D2BFormer model gains promising performance in terms of four metrics. © 2022 Elsevier B.V.","Convolutional neural network; Degraded document binarization; Feature fusion; Vision transformer network"
"Fusion of tactile and visual information in deep learning models for object recognition","2023","Information Fusion","10.1016/j.inffus.2022.11.032","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144304852&doi=10.1016%2fj.inffus.2022.11.032&partnerID=40&md5=1518002e4893a3542abd04dec83710e1","Humans use multimodal sensory information to understand the physical properties of their environment. Intelligent decision-making systems such as the ones used in robotic applications could also utilize the fusion of multimodal information to improve their performance and reliability. In recent years, machine learning and deep learning methods are used at the heart of such intelligent systems. Developing visuo-tactile models is a challenging task due to various problems such as performance, limited datasets, reliability, and computational efficiency. In this research, we propose four efficient models based on dynamic neural network architectures for unimodal and multimodal object recognition. For unimodal object recognition, TactileNet and VisionNet are proposed. For multimodal object recognition, the FusionNet-A and the FusionNet-B are designed to implement early and late fusion strategies, respectively. The proposed models have a flexible structure and are able to change at the train or test phase to accommodate the amount of available information. Model confidence calibration is employed to enhance the reliability and generalization of the models. The proposed models are evaluated on MIT CSAIL large-scale multimodal dataset. Our results demonstrate accurate performance in both unimodal and multimodal scenarios. It has been illustrated that by using different fusion strategies and augmenting the tactile-based models with visual information, the top-1 error rate of the single-frame tactile model was reduced by 78% and the mean average precision was increased by 2.19 times. Although the focus has been on the fusion of tactile and visual modalities, the proposed design methodology can be generalized to include more modalities. © 2022 Elsevier B.V.","Data fusion; Deep learning; Multimodal learning; Object recognition; Tactile sensing; Visuo-tactile models"
"A multi-view-based noise correction algorithm for crowdsourcing learning","2023","Information Fusion","10.1016/j.inffus.2022.11.002","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141928800&doi=10.1016%2fj.inffus.2022.11.002&partnerID=40&md5=df51a4840c4b95d6d165e17343226260","Crowdsourcing services provide a way to obtain large amounts of labeled data, which is inexpensive and effective. In crowdsourcing scenarios, the integrated labels of instances can be deduced by implementing ground truth inference algorithms. However, those labels often contain substantial noise and, to mitigate the effects of noise, label noise handling techniques are needed. This paper proposes a novel multi-view-based noise correction algorithm (MVNC). MVNC introduces the idea of multi-view learning to make better use of the information from crowdsourced data. It adds a new view composed of multiple noise labels and then trains classifiers on two views respectively to correct noise instances. In this process, different information between the views is fully utilized to generate the disagreement between two classifiers, so that the classifiers can complement each other and make more reliable predictions for noise instances. Experimental results on 38 benchmark data sets and 6 real-world data sets show that the new view significantly enhances the effect of noise correction. © 2022 Elsevier B.V.","Crowdsourcing learning; Instance selection; Multi-view; Noise correction"
"Shape-Former: Bridging CNN and Transformer via ShapeConv for multimodal image matching","2023","Information Fusion","10.1016/j.inffus.2022.10.030","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141464419&doi=10.1016%2fj.inffus.2022.10.030&partnerID=40&md5=8f0ac18b276bccffac116a48d2220142","As with any data fusion task, the front-end of the pipeline for image fusion, aiming to collect multitudinous physical properties from multimodal images taken by different types of sensors, requires registering the overlapped content of two images via image matching. In other words, the accuracy of image matching will influence directly the subsequent fusion results. In this work, we propose a hybrid correspondence learning architecture, termed as Shape-Former, which is capable of solving matching problems such as multimodal, and multiview cases. Existing attempts have trouble capturing intricate feature interactions for seeking good correspondence, if the image pairs simultaneously suffer from geometric and radiation distortion. To address this, our key is to take advantage of convolutional neural network (CNN) and Transformer for enhancing structure consensus representation ability. Specifically, we introduce a novel ShapeConv so that CNN and Transformer can be generalized to sparse matches learning. Furthermore, we provide a robust soft estimation of outliers mechanism for filtering the response of outliers before capturing shape features. Finally, we also propose coupling multiple consensus representations to further solve the context conflict problems such as local ambiguity. Experiments with variety of datasets reveal that our Shape-Former outperforms state-of-the-art on multimodal image matching, and shows promising generalization ability to different types of image deformations. © 2022 Elsevier B.V.","Deep learning; Feature matching; Multimodal image matching; Registration and fusion; Shape-Former"
"EmoMV: Affective music-video correspondence learning datasets for classification and retrieval","2023","Information Fusion","10.1016/j.inffus.2022.10.002","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140338394&doi=10.1016%2fj.inffus.2022.10.002&partnerID=40&md5=bd591c8da8c1003da701bb884b3431db","Studies in affective audio–visual correspondence learning require ground-truth data to train, validate, and test models. The number of available datasets together with benchmarks, however, is still limited. In this paper, we create a collection of three datasets (called EmoMV) for affective correspondence learning between music and video modalities. The first two datasets (called EmoMV-A, and EmoMV-B, respectively) are constructed by making use of music video segments from other available datasets. The third one called EmoMV-C is created from music videos that we self-collected from YouTube. The music-video pairs in our datasets are annotated as matched or mismatched in terms of the emotions they are conveying. The emotions are annotated by humans in the EmoMV-A dataset, while in the EmoMV-B and EmoMV-C datasets they are predicted using a pretrained deep neural network. A user study is carried out to evaluate the accuracy of the “matched” and “mismatched” labels offered in the EmoMV dataset collection. In addition to creating three new datasets, a benchmark deep neural network model for binary affective music-video correspondence classification is also proposed. This proposed benchmark model is then modified to adapt to affective music-video retrieval. Extensive experiments are carried out on all three datasets of the EmoMV collection. Experimental results demonstrate that our proposed model outperforms state-of-the-art approaches on both the binary classification and retrieval tasks. We envision that our newly created dataset collection together with the proposed benchmark models will facilitate advances in affective computing research. © 2022 Elsevier B.V.","Affective audio–visual correspondence learning; Affective computing; Affective music-video retrieval; EmoMV dataset collection; Emotion-based matching; Multi-task learning deep neural networks"
"NAPS Fusion: A framework to overcome experimental data limitations to predict human performance and cognitive task outcomes","2023","Information Fusion","10.1016/j.inffus.2022.09.016","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144085605&doi=10.1016%2fj.inffus.2022.09.016&partnerID=40&md5=a7d3d8daf853c28d90c1242ad03f4ec6","In the area of human performance and cognitive research, machine learning (ML) problems become increasingly complex due to limitations in the experimental design, resulting in the development of poor predictive models. More specifically, experimental study designs produce very few data instances, have large class imbalances and conflicting ground truth labels, and generate wide data sets due to the diverse amount of sensors. From an ML perspective these problems are further exacerbated in anomaly detection cases where class imbalances occur and there are almost always more features than samples. Typically, dimensionality reduction methods (e.g., PCA, autoencoders) are utilized to handle these issues from wide data sets. However, these dimensionality reduction methods do not always map to a lower dimensional space appropriately, and they capture noise or irrelevant information. In addition, when new sensor modalities are incorporated, the entire ML paradigm has to be remodeled because of new dependencies introduced by the new information. Remodeling these ML paradigms is time-consuming and costly due to lack of modularity in the paradigm design, which is not ideal. Furthermore, human performance research experiments, at times, creates ambiguous class labels because the ground truth data cannot be agreed upon by subject-matter experts annotations, making ML paradigm nearly impossible to model. This work pulls insights from Dempster–Shafer theory (DST), stacking of ML models, and bagging to address uncertainty and ignorance for multi-classification ML problems caused by ambiguous ground truth, low samples, subject-to-subject variability, class imbalances, and wide data sets. Based on these insights, we propose a probabilistic model fusion approach, Naive Adaptive Probabilistic Sensor (NAPS), which combines ML paradigms built around bagging algorithms to overcome these experimental data concerns while maintaining a modular design for future sensor (new feature integration) and conflicting ground truth data. We demonstrate significant overall performance improvements using NAPS (an accuracy of 95.29%) in detecting human task errors (a four class problem) caused by impaired cognitive states and a negligible drop in performance with the case of ambiguous ground truth labels (an accuracy of 93.93%), when compared to other methodologies (an accuracy of 64.91%). This work potentially sets the foundation for other human-centric modeling systems that rely on human state prediction modeling. © 2022 Elsevier B.V.","Experimental data variability; Human performance prediction; Sensor fusion; Small experimental sample size; Uncertain ground truth; Uncertainty modeling"
"Seeking commonness and inconsistencies: A jointly smoothed approach to multi-view subspace clustering","2023","Information Fusion","10.1016/j.inffus.2022.10.020","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141236962&doi=10.1016%2fj.inffus.2022.10.020&partnerID=40&md5=cc06c00008770fbd72636caba7ccc92d","Multi-view subspace clustering aims to discover the hidden subspace structures from multiple views for robust clustering, and has been attracting considerable attention in recent years. Despite significant progress, most of the previous multi-view subspace clustering algorithms are still faced with two limitations. First, they usually focus on the consistency (or commonness) of multiple views, yet often lack the ability to capture the cross-view inconsistencies in subspace representations. Second, many of them overlook the local structures of multiple views and cannot jointly leverage multiple local structures to enhance the subspace representation learning. To address these two limitations, in this paper, we propose a jointly smoothed multi-view subspace clustering (JSMC) approach. Specifically, we simultaneously incorporate the cross-view commonness and inconsistencies into the subspace representation learning. The view-consensus grouping effect is presented to jointly exploit the local structures of multiple views to regularize the view-commonness representation, which is further associated with the low-rank constraint via the nuclear norm to strengthen its cluster structure. Thus the cross-view commonness and inconsistencies, the view-consensus grouping effect, and the low-rank representation are seamlessly incorporated into a unified objective function, upon which an alternating optimization algorithm is performed to achieve a robust subspace representation for clustering. Experimental results on a variety of real-world multi-view datasets confirm the superiority of our approach. Code available:. © 2022 Elsevier B.V.","Data clustering; Multi-view clustering; Multi-view subspace clustering; Smooth regularization; View-consensus grouping effect"
"Refining fine-tuned transformers with hand-crafted features for gender screening on question-answering communities","2023","Information Fusion","10.1016/j.inffus.2022.12.003","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143860709&doi=10.1016%2fj.inffus.2022.12.003&partnerID=40&md5=55d0aff3932f34dd62b92a2678db7f9b","Machine learning and demographic analysis are a cornerstone for making community Question Answering (cQA) platforms more egalitarian and vibrant, safer as well. For instance, the two cooperate on successfully detecting suspicious/malicious activity and on stirring up the interest of community fellows to learn by exploring new topics. In this sense, both research fields play a vital role in reducing gender disparity across categories, when promoting unresolved questions to potential answerers. Current state-of-the-art artificial intelligence architectures, such as pre-trained transformers, train complex goals and million of parameters as a means of inferring and encoding knowledge from massive corpora. Fine-tuning is the process that allows later to transfer this encrypted information to a downstream task (e.g., gender classification). Needless to say, these pre-trained encoders also suffer from multiple disadvantages. To give an example, they are sensitive to irrelevant and misleading words, bringing about overfitting, usually on small datasets. This work offers a fresh look at this kind of technique by introducing PTM-SFFS, a novel approach that effectively pairs frontier transformers with linguistic properties via the use of traditional classifiers. Based on a feature wrapper (SFFS), PTM-SFFS refines the scores produced by a fine-tuned model via seeking for an array of mostly linguistic features to build a conventional statistical classifier (e.g., Bayes and MaxEnt). And as a result, this new discriminant function enhances the overall prediction rate by optimizing the synergy between both sorts of strategies. When applied to automatic gender recognition on cQA sites, PTM-SFFS increased the accuracy of seven fine-tuned state-of-the-art encoders up to 10% (XLNet). Thanks to its interpretability, we discover that it capitalizes on dependency parsing and metadata for improving the transference of lexicalized information to the target domain. © 2022 Elsevier B.V.","Community question answering; Gender recognition; Natural language processing; Pre-trained models; Statistical classifiers; User analysis"
"A comprehensive study on codebook-based feature fusion for gait recognition","2023","Information Fusion","10.1016/j.inffus.2022.12.001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143664502&doi=10.1016%2fj.inffus.2022.12.001&partnerID=40&md5=417dec4251f482c6d6008f2676561cf0","Vision-based person identification using gait is one of the important and challenging tasks in the fields of computer vision and machine learning. It has received significant research efforts in the past two decades due to its several benefits. It is non-invasive and can be performed at a distance without active collaboration from users. The identification can be performed from low-resolution videos using simple instrumentation. The conventional gait recognition approaches usually operate on the sequence of extracted human silhouettes. They derive several gait-related features from the segmented binary energy maps of the walker. However, such processes are sensitive to variations in the silhouette shapes, thus limiting their efficacy. Codebook-based feature encoding techniques have been proven to be effective and reported state-of-the-art recognition results on several visual datasets such as action recognition, image, and video classification, etc. The whole process usually follows the pipeline of pattern recognition which mainly consists of five steps: (i) local feature extraction, (ii) feature pre-processing, (iii) codebook computation, (iv) feature encoding, and (v) classification. Each step in the pipeline plays a crucial role in recognition accuracy. Since the visual gait sequences comprise different walking patterns of the subjects due to variations in their static appearance and motion dynamics, several features are extracted to encode this information. Finally, they are fused to recognize the identity of the subject. This paper presents a comprehensive study of codebook-based approaches, explains all the steps in the encoding of visual gait sequences, and uncovers some good practices to obtain state-of-the-art recognition results. In particular, we investigated two different local features to encode the static appearance and motion information of the walker, and twelve kinds of feature encoding methods. An extensive evaluation of these encoding methods is carried out on a large benchmark CASIA-B gait database and their performance comparison is presented. © 2022 Elsevier B.V.","Bag-of-visual-words; Biometrics; Codebook; Gait; Person recognition; Visual surveillance"
"A sensor fusion approach to MARG module orientation estimation for a real-time hand tracking application","2023","Information Fusion","10.1016/j.inffus.2022.09.017","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139357163&doi=10.1016%2fj.inffus.2022.09.017&partnerID=40&md5=0b9d496c605b1fb9c386c12198c80c58","This paper introduces a new algorithm (Gravity & Magnetic North Vector correction — Double SLERP, or “GMV-D”) to estimate the orientation of a MEMS Magnetic/Angular-Rate/Gravity (MARG) sensor module using sensor fusion in the context of a real-time hand tracking application, for human–computer interaction purposes. Integrated MEMS MARG modules are affordable, small, light and consume minimal power. As such, there is interest in using them for monitoring the orientation of various body segments, to which they can be attached (e.g., the finger segments of a gloved hand). However, each of the 3 types of signals they provide has proven insufficient to yield robust orientation estimates, particularly in regions of space where the geomagnetic field is distorted. The significance (main contribution) of the approach we present is the computation of a final orientation estimate that uses all the signals generated by inexpensive (e.g., less than 20 USD, in large quantities) integrated MEMS MARG modules but weighs their contributions with simple, real-time-updatable parameters that prevent erroneous corrections when the pre-conditions for their valid use are not met. This will enable the use of inexpensive integrated MEMS MARG modules for hand tracking applications in human–computer interaction and other areas of work where tracking the orientation of body segments in real-time is important. In each iteration, GMV-D defines an initial orientation estimate from integration of gyroscopic signals (“dead reckoning”), and also calculates accelerometer-based and magnetometer-based corrections. These corrections are defined on the assumptions that the module is near static and affected by an undistorted geomagnetic field. Because these assumptions are seldom fully met simultaneously, the information fusion challenge is to apply each correction only to the extent that its corresponding pre-conditions are met, as inappropriate corrections will introduce significant error in the future orientation estimates. To achieve this, GMV-D develops an accelerometer correction trustworthiness parameter, 0 ≤α≤ 1, and a magnetometer correction trustworthiness parameter, 0 ≤μ≤ 1, both of which are updated on a sample-by-sample basis and are available at each iteration of the algorithm. The information fusion phase of the algorithm implements the corrections in a two-tiered application of Spherical Linear Interpolation (SLERP) of the quaternions representing the initial dead reckoning estimate and the available corrections, scaled according to their corresponding levels of trustworthiness. GMV-D was evaluated in comparison to 2 other orientation correction approaches (Kalman Filtering and GMV-S) and contrasted with 2 contemporary complementary filter approaches (Madgwick, Mahony). The results confirm that GMV-D displayed better orientation estimation performance when the algorithms operated in an area with known distortion of the geomagnetic field. © 2022 Elsevier B.V.","Dead reckoning; Drift correction algorithm; Gyroscope drift; Hand motion tracking; Inertial measurement unit; Magnetic distortion; MARG; Quaternion correction"
"A distributed evolutionary fuzzy system-based method for the fusion of descriptive emerging patterns in data streams","2023","Information Fusion","10.1016/j.inffus.2022.10.028","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141534621&doi=10.1016%2fj.inffus.2022.10.028&partnerID=40&md5=6b3b157140f45763d1c37e92007942d7","Nowadays the amount of networks of devices and sensors, such as smart homes or smart cities, is rapidly increasing. Each of these devices generates massive amounts of data on a continuous basis where an interpretable description of its state is interesting for the experts. This knowledge can be extracted by means of emerging pattern mining techniques. In fact, it can be extracted locally on each device and joined together afterwards in order to obtain a global vision of the system without transferring any data. However, the traditional massive data processing frameworks are focused on the extraction of this global model, which produces huge amounts of data transfers throughout the network. This paper proposes a distributed method based on evolutionary fuzzy systems for both the extraction and subsequent fusion of descriptive emerging patterns in data streams from different sources of the same kind. First, an evolutionary algorithm following an informed approach for efficient data processing is presented for the extraction of emerging patterns on the data stream generated by each device, in order to obtain a local model for each stream. Then, several fusion methods are proposed for the aggregation of these patterns in order to extract the global model. A wide experimental study has been carried out to analyse the suitability of the evolutionary algorithm for the extraction of high-quality emerging patterns and its capacity to deal with concept drift. Finally, the quality of the proposed fusion methods is also analysed. © 2022 Elsevier B.V.","Data stream mining; Distributed computing; Evolutionary fuzzy systems; Fuzzy rule-based systems"
"A perceptual framework for infrared–visible image fusion based on multiscale structure decomposition and biological vision","2023","Information Fusion","10.1016/j.inffus.2022.12.022","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85145977989&doi=10.1016%2fj.inffus.2022.12.022&partnerID=40&md5=e13a30c94eafed34a60d886adcad99c5","Infrared–visible image fusion is of great value in many applications due to their highly complementary information. However, it is hard to obtain high-quality fused image for current fusion algorithms. In this paper, we reveal an underlying deficiency in current fusion framework limiting the quality of fusion, i.e., the visual features used in the fusion can be easily affected by external physical conditions (e.g., the characteristics of different sensors and environmental illumination), indicating that those features from different sources have not been ensured to be fused on a consistent basis during the fusion. Inspired by biological vision, we derive a framework that transforms the image intensities into the visual response space of human visual system (HVS), within which all features are fused in the same perceptual state, eliminating the external physical factors that may influence the fusion process. The proposed framework incorporates some key characteristics of HVS that facilitate the simulation of human visual response in complex scenes, and is built on a new variant of multiscale decomposition, which can accurately localize image structures of different scales in visual-response simulation and feature fusion. A bidirectional saliency aggregation is proposed to fuse the perceived contrast features within the visual response space of HVS, along with an adaptive suppression of noise and intensity-saturation in this space prior to the fusion. The final fused image is obtained by transforming the fusion results in human visual response space back to the physical domain. Experiments demonstrate the significant improvement of fusion quality brought about by the proposed method. © 2022 Elsevier B.V.","Human visual system; Infrared and visible image fusion; Multiscale structure decomposition; Perceptual fusion framework; Saliency aggregation"
"MUFusion: A general unsupervised image fusion network based on memory unit","2023","Information Fusion","10.1016/j.inffus.2022.11.010","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143543582&doi=10.1016%2fj.inffus.2022.11.010&partnerID=40&md5=b17edd6263b6d4b78299d18b5464f426","Existing image fusion approaches are committed to using a single deep network to solve different image fusion problems, achieving promising performance in recent years. However, devoid of the ground-truth output, in these methods, only the appearance from source images can be exploited during the training process to generate the fused images, resulting in suboptimal solutions. To this end, we advocate a self-evolutionary training formula by introducing a novel memory unit architecture (MUFusion). In this unit, specifically, we utilize the intermediate fusion results obtained during the training process to further collaboratively supervise the fused image. In this way, our fusion results can not only learn from the original input images, but also benefit from the intermediate output of the network itself. Furthermore, an adaptive unified loss function is designed based on this memory unit, which is composed of two loss items, i.e., content loss and memory loss. In particular, the content loss is calculated based on the activity level maps of source images, which can constrain the output image to contain specific information. On the other hand, the memory loss is obtained based on the previous output of our model, which is utilized to force the network to yield fusion results with higher quality. Considering the handcrafted activity level maps cannot consistently reflect the accurate salience judgement, we put two adaptive weight items between them to prevent this degradation phenomenon. In general, our MUFusion can effectively handle a series of image fusion tasks, including infrared and visible image fusion, multi-focus image fusion, multi-exposure image fusion, and medical image fusion. Particularly, the source images are concatenated in the channel dimension. After that, a densely connected feature extraction network with two scales is used to extract the deep features of the source images. Following this, the fusion result is obtained by two feature reconstruction blocks with skip connections from the feature extraction network. Qualitative and quantitative experiments on 4 image fusion subtasks demonstrate the superiority of our MUFusion, compared to the state-of-the-art methods. © 2022","Deep learning; General model; Image fusion; Memory unit; Unsupervised learning"
"Dependency parsing with bottom-up Hierarchical Pointer Networks","2023","Information Fusion","10.1016/j.inffus.2022.10.023","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141765122&doi=10.1016%2fj.inffus.2022.10.023&partnerID=40&md5=d5da573ab8c94c215c89730c0fdd6442","Dependency parsing is a crucial step towards deep language understanding and, therefore, widely demanded by numerous Natural Language Processing applications. In particular, left-to-right and top-down transition-based algorithms that rely on Pointer Networks are among the most accurate approaches for performing dependency parsing. Additionally, it has been observed for the top-down algorithm that Pointer Networks’ sequential decoding can be improved by implementing a hierarchical variant, more adequate to model dependency structures. Considering all this, we develop a bottom-up oriented Hierarchical Pointer Network for the left-to-right parser and propose two novel transition-based alternatives: an approach that parses a sentence in right-to-left order and a variant that does so from the outside in. We empirically test the proposed neural architecture with the different algorithms on a wide variety of languages, outperforming the original approach in practically all of them and setting new state-of-the-art results on the English and Chinese Penn Treebanks for non-contextualized and BERT-based embeddings. © 2022 The Authors","Computational linguistics; Deep learning; Dependency parsing; Natural language processing; Neural network; Parsing"
"FusionFedBlock: Fusion of blockchain and federated learning to preserve privacy in industry 5.0","2023","Information Fusion","10.1016/j.inffus.2022.09.027","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139072277&doi=10.1016%2fj.inffus.2022.09.027&partnerID=40&md5=980e47b6780518ec8bb9a217a7a505ae","Nowadays, Industries are experiencing rapid changes in the digital environment, referred to as Industry 5.0. The Internet of Things (IoT) and advanced technologies are essential in the industrial environment. Technological advancements can collect, transfer, and analyze vast amounts of data in the industry via promising technologies. Still, IoT has various issues when applied to industrial infrastructures, such as centralization, privacy preservation, latency, and security. This article proposes a scheme as FusionFedBlock: Fusion of Blockchain and Federated Learning to Preserve Privacy in Industry 5.0 to address the aforementioned issues. At the federated layer, the industry's departments (Production, Quality Control, Distribution) allow local learning updates with network automation and communicate to the global model, which miners verify in the Blockchain networks. Federated-Learning offers privacy preservation between various mentioned departments in industries. Decentralized secure storage is provided by the Distributed Hash Table (DHT) at the cloud layer. The validation outcomes of the proposed scheme demonstrate excellent performance as the accuracy of 93.5% in a 50% active node for Industry 5.0 compared to existing frameworks. © 2022 Elsevier B.V.","Blockchain; Federated learning; Industrial IoT; Industry 5.0; Information fusion; Privacy-preservation; Security"
"A pipeline architecture for feature-based unsupervised clustering using multivariate time series from HPC jobs","2023","Information Fusion","10.1016/j.inffus.2022.12.017","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144624363&doi=10.1016%2fj.inffus.2022.12.017&partnerID=40&md5=0b78484f665ad971891cd7dde4d4283d","Time series are key across industrial and research areas for their ability to model behaviour across time, making them ideal for a wide range of use cases such as event monitoring, trend prediction or anomaly detection. This is even more so due to the increasing monitoring capabilities in many areas, with the subsequent massive data generation. But it is also interesting to consider the potential of time series for Machine Learning processing, often fused with Big Data, to search for useful information and solve real-world problems. However, time series can be studied individually, representing a single entity or variable to be analysed, or in a grouped fashion, to study and represent a more complex entity or scenario. In this latter case we are dealing with multivariate time series, which usually imply different approaches when dealt with. In this paper, we present a pipeline architecture to process and cluster multiple groups of multivariate time series. To implement this, we apply a multi-process solution composed by a feature-based extraction stage, followed by a dimension reduction, and finally, several clustering algorithms. The pipeline is also highly configurable in terms of the stage techniques to be used, allowing to perform a search with several combinations for the most promising results. The pipeline has been experimentally applied to batches of HPC jobs from different users of a supercomputer, with the multivariate time series coming from the monitoring of several node resource metrics. The results show how it is possible to apply this multi-process information fusion to create different meaningful clusters from the batches, using only the time series, without any labelling information, thus being an unsupervised scenario. Optionally, the pipeline also supports an outlier detection stage to find and separate jobs that are radically different when compared to others on a dataset. These outliers can be removed for a better clustering, and later reviewed looking for anomalies, or if numerous, fed back to the pipeline to identify possible groupings. The results also include some outliers found in the experiments, as well as scenarios where they are clustered, or ignored and not removed at all. In addition, by leveraging Big Data technologies like Spark, the pipeline is proven to be scalable by working with up to hundreds of jobs and thousands of time series. © 2022 The Authors","Anomaly detection; Feature extraction; HPC jobs; Multivariate time series; Unsupervised clustering"
"TSK fuzzy system fusion at sensitivity-ensemble-level for imbalanced data classification","2023","Information Fusion","10.1016/j.inffus.2022.12.014","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144290300&doi=10.1016%2fj.inffus.2022.12.014&partnerID=40&md5=a6df2e8487715c03f806df3994911e41","Previous studies have shown that the performance of a classifier on imbalanced data heavily relies on informative objects lying in borderline or overlapping areas. In this study, we adopt objective sensitivity to detect the most informative objects based on 0-order Takagi-Sugeno-Kang Fuzzy System (0-TSK-FS), and accordingly propose a novel TSKfuzzy system fusion framework at interpretable sensitivity-ensemble-level (ISE-TSK-FS) to achieve both promising classification performance and reasonable interpretability on imbalanced datasets. Specifically, we assume that a small perturbation of an input object can be interpreted as its neighboring future testing objects. Therefore, object sensitivity w.r.t 0-TSK-FS can be evaluated by the expectation of squared output differences between the input object and the objects in its neighborhood. Being guided by such object sensitivity, we partition the majority class using clustering into different blocks and then construct an ensemble under-sampling process to select the most informative objects from each block iteratively. Moreover, to avoid overfitting issues in assembling, a self-paced factor is introduced to constrain the number of low-sensitive objects but still keep their “skeleton” contribution. Extensive experiments on 7 synthetic datasets, 30 UCI datasets and one real medical case demonstrate ISE-TSK-FS's promising performance and good interpretability on imbalanced data. © 2022 Elsevier B.V.","Ensemble learning; Imbalanced classification; Interpretability; Object sensitivity; TSK fuzzy system"
"Zonotopic multi-sensor fusion estimation with mixed delays under try-once-discard protocol: A set-membership framework","2023","Information Fusion","10.1016/j.inffus.2022.11.012","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85145664368&doi=10.1016%2fj.inffus.2022.11.012&partnerID=40&md5=72083ea80f4666057dc2c109dadbd51e","In this paper, the fusion estimation problem is investigated for a class of multi-sensor networked systems with unknown-but-bounded noises and mixed time-delays under try-once-discard protocols (TODPs). The measurements of multiple sensor nodes are sent to the remote fusion center through individual network channels, where the TODP is implemented in each channel to schedule the signal transmissions for the purpose of avoiding data collisions. To fuse the information collected from all channels, a sequential estimator is proposed whose estimator parameters are designed such that the estimation error (after each measurement update) is restrained into a zonotope with minimum F-radius at each moment. First, by using the properties of zonotopes, desired zonotopes are obtained that contain the estimation errors, and the F-radii of these zonotopes are subsequently minimized by appropriately designing the estimator parameters. It is shown that, under the proposed zonotopes-based fusion rule, the designed sequential estimator leads to the same estimation accuracy as that of the widely utilized parallel estimator. Finally, an illustrative example is provided to verify the validity of the developed fusion estimation method. © 2022 Elsevier B.V.","Fusion estimation; Mixed time-delays; Networked systems; Try-once-discard protocols; Unknown-but-bounded noises; Zonotopic set-membership state estimation"
"Analytic solution of the exact Daum–Huang flow equation for particle filters","2023","Information Fusion","10.1016/j.inffus.2022.11.027","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143775094&doi=10.1016%2fj.inffus.2022.11.027&partnerID=40&md5=f310589c9908ad56ea1356cbd253a24f","State estimation for nonlinear systems, especially in high dimensions, is a generally intractable problem, despite the ever-increasing computing power. Efficient algorithms usually apply a finite-dimensional model for approximating the probability density of the state vector or treat the estimation problem numerically. In 2007 Daum and Huang introduced a novel particle filter approach that uses a homotopy-induced particle flow for the Bayesian update step. Multiple types of particle flows were derived since with different properties. The exact flow considered in this work is a first-order linear ordinary time-varying inhomogeneous differential equation for the particle motion. An analytic solution in the interval [0,1] is derived for the scalar measurement case, which enables significantly faster computation of the Bayesian update step for particle filters. © 2022 Elsevier B.V.","Log-homotopy; Nonlinear filtering; Particle filter; Particle flow; State estimation"
"Fusion of statistical importance for feature selection in Deep Neural Network-based Intrusion Detection System","2023","Information Fusion","10.1016/j.inffus.2022.09.026","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139984806&doi=10.1016%2fj.inffus.2022.09.026&partnerID=40&md5=e638ec4622cf9d558baea8dc1a3677b8","Intrusion Detection System (IDS) is an essential part of network as it contributes towards securing the network against various vulnerabilities and threats. Over the past decades, there has been comprehensive study in the field of IDS and various approaches have been developed to design intrusion detection and classification system. With the proliferation in the usage of Deep Learning (DL) techniques and their ability to learn data extensively, we aim to design Deep Neural Network (DNN)-based IDS. In this study, we aim to focus on enhancing the performance of DNN-based IDS by proposing a novel feature selection technique that selects features via fusion of statistical importance using Standard Deviation and Difference of Mean and Median. Here, in the proposed approach, features are pruned based on their rank derived using fusion of statistical importance. Moreover, fusion of statistical importance aims to derive relevant features that possess high discernibility and deviation, that assists in better learning of data. The performance of the proposed approach is evaluated using three intrusion detection datasets, namely, NSL-KDD, UNSW_NB-15, and CIC-IDS-2017. Performance analysis is presented in terms of different evaluation metrics such as accuracy, precision, recall, f-score, and False Positive Rate (FPR) and the results are compared with existing feature selection techniques. Apart from evaluation metrics, performance comparison is also presented in terms of execution time. Moreover, results achieved are also statistically tested using Wilcoxon Signed Rank test. © 2022 Elsevier B.V.","Deep Learning; Deep Neural Network; Filter-based feature selection; Fusion of statistical importance; Intrusion Detection System; Standard deviation"
"A quaternion-based sensor fusion approach using orthogonal observations from 9D inertial and magnetic information","2023","Information Fusion","10.1016/j.inffus.2022.08.020","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139216207&doi=10.1016%2fj.inffus.2022.08.020&partnerID=40&md5=2a80b1bc1053e2a5db4f1f874da2cbb0","The micro-electro-mechanical technology facilitates the development of low-cost orientation estimation solutions using inertial and magnetic sensors. However, the magnetic disturbances challenge the robust pitch and roll measurements on some occasions, such as the quadrotor, ship, and railway. This work analyzes the coupling mechanism of the magnetic information on the roll and pitch estimates. Subsequently, it proposes a quaternion-based decoupled sensor fusion approach under the frame of an extended Kalman filter by taking the orthogonal gravitational vector and horizontal magnetic vector as absolute observation references. Three experimental tests validated its performances in robust roll and pitch measurements under magnetic disturbances, static and dynamic robotic motion estimation, and human upper body pose tracking. Results show that the proposed sensor fusion approach could keep the roll and pitch immune to the magnetic disturbances, and provide reliable static and dynamic orientation estimation accuracy. Moreover, it is promising to provide feedback for rehabilitation training. © 2022 Elsevier B.V.","Decoupled sensor fusion approach; Extended Kalman filter; Orthogonal observation references; Pose feedback; Quaternion"
"Rethinking multi-exposure image fusion with extreme and diverse exposure levels: A robust framework based on Fourier transform and contrastive learning","2023","Information Fusion","10.1016/j.inffus.2022.12.002","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85145661655&doi=10.1016%2fj.inffus.2022.12.002&partnerID=40&md5=95867541d03d11ecad904d7954c2a049","Multi-exposure image fusion (MEF) is an important technique for generating high dynamic range images. However, most existing MEF studies focus on fusing a moderately over-exposed image and a moderately under-exposed image, and they are not robust in fusing images with extreme and diverse exposure levels. In this paper, we propose a robust MEF framework based on Fourier transform and contrastive learning. Specifically, we develop a Fourier transform-based pixel intensity transfer strategy to synthesize images with diverse exposure levels from normally exposed natural images and train an encoder–decoder network to reconstruct the original natural image. In this way, the encoder and decoder can learn to extract features from images with diverse exposure levels and generate fused images with normal exposure. We propose a contrastive regularization loss to further enhance the capability of the network in recovering normal exposure levels. In addition, we construct an extreme MEF benchmark dataset and a random MEF benchmark dataset for a more comprehensive evaluation of MEF algorithms. We extensively compare our method with fifteen competitive traditional and deep learning-based MEF algorithms on three benchmark datasets, and our method outperforms the other methods in both subjective visual effects and objective evaluation metrics. Our code, datasets and all fused images will be released. © 2022","Contrastive learning; Deep learning; Fourier transform; Multi-exposure image fusion"
"Deep and statistical learning in biomedical imaging: State of the art in 3D MRI brain tumor segmentation","2023","Information Fusion","10.1016/j.inffus.2022.12.013","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85145647568&doi=10.1016%2fj.inffus.2022.12.013&partnerID=40&md5=92cb64c1fbe99aaf1dfadbb3f4ee21d0","Clinical diagnosis and treatment decisions rely upon the integration of patient-specific data with clinical reasoning. Cancer presents a unique context that influences treatment decisions, given its diverse forms of disease evolution. Biomedical imaging allows non-invasive assessment of diseases based on visual evaluations, leading to better clinical outcome prediction and therapeutic planning. Early methods of brain cancer characterization predominantly relied upon the statistical modeling of neuroimaging data. Driven by breakthroughs in computer vision, deep learning has become the de facto standard in medical imaging. Integrated statistical and deep learning methods have recently emerged as a new direction in the automation of medical practice unifying multi-disciplinary knowledge in medicine, statistics, and artificial intelligence. In this study, we critically review major statistical, deep learning, and probabilistic deep learning models and their applications in brain imaging research with a focus on MRI-based brain tumor segmentation. These results highlight that model-driven classical statistics and data-driven deep learning is a potent combination for developing automated systems in clinical oncology. © 2022 Elsevier B.V.","Brain tumor segmentation; Deep learning; Medical imaging; Probabilistic deep learning; Statistical modeling"
"Brain tumor segmentation based on the fusion of deep semantics and edge information in multimodal MRI","2023","Information Fusion","10.1016/j.inffus.2022.10.022","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141239861&doi=10.1016%2fj.inffus.2022.10.022&partnerID=40&md5=dd2d9c7c9097d6b034730cfbf3ca71c3","Brain tumor segmentation in multimodal MRI has great significance in clinical diagnosis and treatment. The utilization of multimodal information plays a crucial role in brain tumor segmentation. However, most existing methods focus on the extraction and selection of deep semantic features, while ignoring some features with specific meaning and importance to the segmentation problem. In this paper, we propose a brain tumor segmentation method based on the fusion of deep semantics and edge information in multimodal MRI, aiming to achieve a more sufficient utilization of multimodal information for accurate segmentation. The proposed method mainly consists of a semantic segmentation module, an edge detection module and a feature fusion module. In the semantic segmentation module, the Swin Transformer is adopted to extract semantic features and a shifted patch tokenization strategy is introduced for better training. The edge detection module is designed based on convolutional neural networks (CNNs) and an edge spatial attention block (ESAB) is presented for feature enhancement. The feature fusion module aims to fuse the extracted semantic and edge features, and we design a multi-feature inference block (MFIB) based on graph convolution to perform feature reasoning and information dissemination for effective feature fusion. The proposed method is validated on the popular BraTS benchmarks. The experimental results verify that the proposed method outperforms a number of state-of-the-art brain tumor segmentation methods. The source code of the proposed method is available at https://github.com/HXY-99/brats. © 2022 Elsevier B.V.","Brain tumor segmentation; Convolutional neural networks; Edge feature; Feature fusion; Transformer"
"Information loss challenges in surgical navigation systems: From information fusion to AI-based approaches","2023","Information Fusion","10.1016/j.inffus.2022.11.015","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142673908&doi=10.1016%2fj.inffus.2022.11.015&partnerID=40&md5=d5a94cb244d2c9480527008f6c8136e0","Surgical navigation technology provides minimally invasive surgery (MIS) with the relative pose relationships amongst medical images, surgical instruments, and lesions. On the other hand, traditional operation procedures depend heavily on direct surgical field exposure. Consequently, introducing surgical navigation can enable surgeons to operate more accurately and efficiently. A tracking system is a core enabling technology of a surgical navigation system. In this paper, after reviewing the tracking technologies, we compare and analyze their pros and cons, and find that information loss is a common challenge. The information loss problem is an inherent drawback in mono-modality surgical navigation systems. It is characterized by physical constraints, attenuation, breakdown of signal, and accuracy instability of the tracking algorithms. This review focuses on the information loss problem in tracking technologies for surgical navigation systems. Furthermore, we survey the existing solutions that aim at tackling the information loss problem, especially in the information fusion of surgical tracking technologies, and we also summarize their key improvements and limitations. Particular attention has been given to the modalities, approaches, objectives, and surgical application scenarios, which can improve the accuracy, precision, and stability of surgical navigation systems. Finally, future research trends directed at improving the information loss problem are discussed, i.e., tight integration of sensing technology, augmented reality for visualization in surgical tracking, stable high-speed 5G networks for telesurgery, strong intelligence and affordable service. © 2022 Elsevier B.V.","Information fusion; Information loss; Surgical navigation; Tracking technology"
"Local minimum adjustment for the consensus model with distribution linguistic preference relations considering preference reliability","2023","Information Fusion","10.1016/j.inffus.2022.12.018","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144608589&doi=10.1016%2fj.inffus.2022.12.018&partnerID=40&md5=d6a3f014dbd20fe4dc8117125ecdd98e","Preference reliability analysis for preference relations reflected by the ordinal consistency and the cardinal consistency was intensively studied. The ordinal consistency is a minimum condition to guarantee that the decision maker's pairwise comparison preferences between any triple alternatives are transitive. These issues for group decision-making with distribution linguistic preference relations have not been well addressed. This paper aims to provide a consensus model with distribution linguistic preference relations that controls both the cardinal consistency and the ordinal consistency. To do so, a new ordinal consistency for the distribution linguistic preference relations is defined, which is based on the transformation from the distribution linguistic preference relations to its expectation-based matrixes and then to its numerical scale matrixes. Two mixed integer linear programming models are respectively designed to eliminate the ordinal inconsistencies, and to simultaneously control the ordinal and cardinal consistencies so as to ensure the rationality of individual preference relations. Then, a consensus optimization model is developed in which only the individuals with consensus levels lower than the given threshold are allowed to modify their preferences. Preference reliability is also analyzed in the proposed consensus model. Finally, some classical examples are given to illustrate the proposed models. Comparative analysis validates the feasibility and effectiveness of the proposed approaches. © 2022 Elsevier B.V.","Cardinal consistency; Consensus reaching processes; Distribution linguistic preference relations; Optimization models; Ordinal consistency"
"Fusion of multivariate EEG signals for schizophrenia detection using CNN and machine learning techniques","2023","Information Fusion","10.1016/j.inffus.2022.12.019","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144606442&doi=10.1016%2fj.inffus.2022.12.019&partnerID=40&md5=6421b277aeb9be70dce493ec6c0ad4b6","Schizophrenia is a severe mental disorder that has adverse effects on the behavior of an individual such as disorganized speech and delusions. Electroencephalography (EEG) signals are widely used for its identification as they are non-invasive and have high temporal resolution. EEG signals may be captured using wearable devices but transmission of complete data from all channels is both battery and data consuming. Several studies on Schizophrenia have either used all channels or relied on sophisticated feature extraction algorithms to find the most relevant EEG channels for further processing. That too, however, needs data from all channels beforehand to identify the most relevant features. In this study, a publicly available multi-channel EEG signals dataset from the institute of Psychiatry and Neurology in Warsaw, Poland is studied for an automated identification of Schizophrenia using only a subset of data from selected channels. To achieve this, we device a channel selection mechanism based on a rigorous performance analysis of the Convolutional Neural Network (CNN) while considering the individual EEG channels at different brain regions. The selected channels are combined, and we use a fusion of CNN and different machine learning (ML) classifiers to train the classification model. Our experiments show that a combination of three channels namely, T4, T3, and Cz achieves 90% and 98% accuracies on subject-based and non-subject based testing, respectively, using a hybridization of CNN and logistic regression (LR). © 2022 Elsevier B.V.","Convolutional neural network (CNN); Electroencephalography (EEG); Logistic regression; Schizophrenia"
"WikiDes: A Wikipedia-based dataset for generating short descriptions from paragraphs","2023","Information Fusion","10.1016/j.inffus.2022.09.022","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139288969&doi=10.1016%2fj.inffus.2022.09.022&partnerID=40&md5=717fb92e2add7d7349566a30643a44ca","As free online encyclopedias with massive volumes of content, Wikipedia and Wikidata are key to many Natural Language Processing (NLP) tasks, such as information retrieval, knowledge base building, machine translation, text classification, and text summarization. In this paper, we introduce WikiDes, a novel dataset to generate short descriptions of Wikipedia articles for the problem of text summarization. The dataset consists of over 80k English samples on 6987 topics. We set up a two-phase summarization method — description generation (Phase I) and candidate ranking (Phase II) — as a strong approach that relies on transfer and contrastive learning. For description generation, T5 and BART show their superiority compared to other small-scale pre-trained models. By applying contrastive learning with the diverse input from beam search, the metric fusion-based ranking models outperform the direct description generation models significantly up to ≈ 22 ROUGE in topic-exclusive split and topic-independent split. Furthermore, the outcome descriptions in Phase II are supported by human evaluation in over 45.33% chosen compared to 23.66% in Phase I against the gold descriptions. In the aspect of sentiment analysis, the generated descriptions cannot effectively capture all sentiment polarities from paragraphs while doing this task better from the gold descriptions. The automatic generation of new descriptions reduces the human efforts in creating them and enriches Wikidata-based knowledge graphs. Our paper shows a practical impact on Wikipedia and Wikidata since there are thousands of missing descriptions. Finally, we expect WikiDes to be a useful dataset for related works in capturing salient information from short paragraphs. The curated dataset is publicly available at: https://github.com/declare-lab/WikiDes. © 2022 Elsevier B.V.","Contrastive learning; Metric fusion; Sentiment analysis; Text summarization; Wikidata; Wikipedia"
"P2Sharpen: A progressive pansharpening network with deep spectral transformation","2023","Information Fusion","10.1016/j.inffus.2022.10.010","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140316582&doi=10.1016%2fj.inffus.2022.10.010&partnerID=40&md5=419e1a820d3c4eacf0cf6b97bc7e7b11","Most existing deep learning-based methods for pansharpening task solely rely on the supervision of pseudo-ground-truth multi-spectral images, which exhibits two limitations in producing high-quality images. On the one hand, it is uncontrollable to regulate the full-resolution performance due to the fact that their whole training process only remain at the scale of reduced resolution. On the other hand, they ignore the accurate spatial information reference of high-resolution panchromatic images for supervision, resulting in insufficient spatial structure details. To address these challenges, we propose a progressive pansharpening network with deep spectral transformation, termed as P2Sharpen, where we balance the performance in different resolutions and make full use of the observed satellite data to improve the quality of fused results. First, we design a spectral transformation network (STNet) to cross the modality difference between multi-spectral data and panchromatic data, which establishes an accurate mapping function from MS to PAN images. Second, we propose a progressive pansharpening network (P2Net), in which the optimization of pansharpening at reduced and full resolutions is considered in a two-stage manner, balancing the performance at two scales effectively. In addition, we introduce the trained STNet to construct the consistency constraint between the sharpened result and PAN image at both reduced-resolution stage and full-resolution stage, which further improves the ability of P2Net for preserving spatial textures. Extensive experiments demonstrate that our method shows excellent performance over the state-of-the-arts on the sharpening quality and the spectral response consistency in both reduced and full resolutions. Moreover, the proposed method can be applied to generate the high-resolution normalized difference vegetation index with promising accuracy. © 2022 Elsevier B.V.","Deep learning; Deep spectral transformation; Image fusion; Pansharpening; Progressive fusion strategy"
"A large scale group decision making system based on sentiment analysis cluster","2023","Information Fusion","10.1016/j.inffus.2022.11.009","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142324149&doi=10.1016%2fj.inffus.2022.11.009&partnerID=40&md5=ec954c28b2a17e516dae0e9a881b91a7","Nowadays, group decision making is an everyday occurrence in different scenarios, such as marketing or social networks. These social networks have facilitated communication between experts because they do not need to meet in person. However, communication between experts through the internet generates three problems: the management of large amounts of information, the fact that experts often provide their information using natural language, and the lack of analysis of experts’ intentions. In this paper, we propose a novel large scale group decision making method to manage the information generated by a large number of experts, using the natural language processing approach, specifically sentiment analysis. This approach makes it possible to detect the degree of positivity and aggressiveness of each expert and thus proceed to a classification. Once the behaviours are detected, the experts are grouped according to them and, for each group, a weight and a unique preference relation is obtained. In addition, we propose an optimised consensus analysis process, in which it is not necessary to compare all experts with each other, but only groups of experts. © 2022 Elsevier B.V.","Classification; Large scale group decision making; Natural language processing; Sentiment analysis"
"A deep journey into image enhancement: A survey of current and emerging trends","2023","Information Fusion","10.1016/j.inffus.2022.12.012","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144625126&doi=10.1016%2fj.inffus.2022.12.012&partnerID=40&md5=3f5d4392b766a6e02caa6d610969e341","Image captured under poor-illumination conditions often display attributes of having poor contrasts, low brightness, a narrow gray range, colour distortions and considerable interference, which seriously affect the qualitative visual effects on human eyes and severely restrict the efficiency of several machine vision systems. In addition, underwater images often suffer from colour shift and contrast degradation because of an absorption and scattering of light while travelling in water. These unpleasant effects limits visibility, reduce contrast and even generate colour casts that limits the use of underwater images and videos in marine archaeology and biology. In medical imaging applications, medical images are important tools for detecting and diagnosing several medical conditions and ailments. However, the quality of medical images can often be degraded during image acquisition due to factors such as noise interference, artefacts, and poor illumination. This may lead to the misdiagnosis of medical conditions, which can further aggravate life threatening situations. Image enhancement is one of the most important technologies in the field of image processing, and its purpose is to improve the quality of images for specific applications. In general, the basic principle of image enhancement is to improve the quality and visual interpretability of an image so that it is more suitable for the specific applications and the observers. Over the last few decades, numerous image enhancement techniques have been proposed in the literature This study covers a systematic survey on existing state-of-the-art image enhancement techniques into broad classification of their algorithms. In addition, this paper summarises the datasets utilised in the literature for performing the experiments. Furthermore, an attention has been drawn towards several evaluation parameters for quantitative evaluation and compared different state-of-the-art algorithms for performance analysis on benchmark datasets. In addition, we discussed the recent areas of applications in image enhancement in detail. Lastly, we have also discussed numerous unresolved open problems and suggested possible future research directions. We believe that by putting forth all our efforts this study may presents a comprehensive resource for the future research. © 2022 Elsevier B.V.","Applications; Convolutional neural networks (CNNs); Deep learning; Fuzzy theory; Generative adversarial networks (GANs); Image enhancement; Quality assessment criteria; Retinex theory; Review; Survey"
"SAIRUS: Spatially-aware identification of risky users in social networks","2023","Information Fusion","10.1016/j.inffus.2022.11.029","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85145658853&doi=10.1016%2fj.inffus.2022.11.029&partnerID=40&md5=2cc66feb9d6f95144445ffa47e3c14e5","The massive spread of social networks provided a plethora of new possibilities to communicate and interact worldwide. On the other hand, they introduced some negative phenomena related to social media addictions, as well as additional tools for cyberbullying and cyberterrorism activities. Therefore, monitoring operations on the posted contents and on the users behavior has become essential to guarantee a safe and correct use of the network. This task is even more challenging in presence of borderline users, namely users who appear risky according to their posts, but not according to other perspectives. In this context, this paper contributes towards an automated identification of risky users in social networks. Specifically, we propose a novel system, called SAIRUS, that solves node classification tasks in social networks by exploiting and combining the information conveyed by three different perspectives: the semantics of the textual content generated by users, the network of user relationships, and the users’ spatial closeness, derived from the geo-tagging data associated with the posted contents. Contrary to existing approaches that typically inject features built from one perspective into the other, we learn three separate models that exploit the peculiarity of each kind of data, and then learn a model to fuse their contribution using a stacked generalization approach. Our extensive experimental evaluation, performed on two variants of a real-world Twitter dataset, revealed the superiority of the proposed method, in comparison with 15 competitors based on one of the considered perspectives alone, or on a combination thereof. Such a superiority is also clear when specifically focusing on borderline users, confirming the applicability of SAIRUS in real-world social networks, which are potentially affected by noisy data. © 2022 Elsevier B.V.","Node classification; Social Network Analysis; Spatial analysis; User risk identification"
"DIVFusion: Darkness-free infrared and visible image fusion","2023","Information Fusion","10.1016/j.inffus.2022.10.034","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141788826&doi=10.1016%2fj.inffus.2022.10.034&partnerID=40&md5=a4046f3eec9e7007161803a26cfb01f2","As a vital image enhancement technology, infrared and visible image fusion aims to generate high-quality fused images with salient targets and abundant texture in extreme environments. However, current image fusion methods are all designed for infrared and visible images with normal illumination. In the night scene, existing methods suffer from weak texture details and poor visual perception due to the severe degradation in visible images, which affects subsequent visual applications. To this end, this paper advances a darkness-free infrared and visible image fusion method (DIVFusion), which reasonably lights up the darkness and facilitates complementary information aggregation. Specifically, to improve the fusion quality of nighttime images, which suffer from low illumination, texture concealment, and color distortion, we first design a scene-illumination disentangled network (SIDNet) to strip the illumination degradation in nighttime visible images while preserving informative features of source images. Then, a texture–contrast enhancement fusion network (TCEFNet) is devised to integrate complementary information and enhance the contrast and texture details of fused features. Moreover, a color consistency loss is designed to mitigate color distortion from enhancement and fusion. Finally, we fully consider the intrinsic relationship between low-light image enhancement and image fusion, achieving effective coupling and reciprocity. In this way, the proposed method is able to generate fused images with real color and significant contrast in an end-to-end manner. Extensive experiments demonstrate that DIVFusion is superior to state-of-the-art algorithms in terms of visual quality and quantitative evaluations. Particularly, low-light enhancement and dual-modal fusion provide more effective information to the fused image and boost high-level vision tasks. Our code is publicly available at https://github.com/Xinyu-Xiang/DIVFusion. © 2022 Elsevier B.V.","Image fusion; Low-light image enhancement; Scene-illumination disentangled; Texture–contrast enhancement"
"Human activity recognition based on multienvironment sensor data","2023","Information Fusion","10.1016/j.inffus.2022.10.015","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140756781&doi=10.1016%2fj.inffus.2022.10.015&partnerID=40&md5=65cbe5766ed227404e4297ed16c6cb3b","With the development of artificial intelligence and the broad application of sensors, human activity recognition (HAR) technologies based on noninvasive environmental sensors have received extensive attention and have shown great application value. Owing to the initiative of human activities and machine learning-based methods relying on domain knowledge, obtaining a uniform model to understand the daily behaviors of different residents is difficult. From the perspective of data feature constraints to recognition methods, we constructed a methodology for single user's daily behavior recognition that can adaptively constrain the sensor noise during human activities in multitenant smart home scenarios. We propose a sensor data contribution significance analysis (CSA) method based on the sensor status frequency-inverse type frequency for HAR. This method is employed to measure the contribution of a particular type of sensor to a certain type of behavior recognition. We then build a spatial distance matrix based on the layout of environmental sensors for context-awareness and reducing data noise. Finally, we propose a HAR algorithm based on wide time-domain convolutional neural network and multienvironment sensor data (HAR_WCNN) for daily behavior recognition. Comparative experiment results on the CASAS dataset show that the proposed HAR_WCNN outperforms the compared state-of-the-art methods in terms of HAR accuracy and time consumption. © 2022","Data constraint; Environmental sensor; Human activity recognition; Neural network; Smart home"
"Lattice curved surface array based collaborative fusion for intelligent diagnosis","2023","Information Fusion","10.1016/j.inffus.2022.12.021","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144628597&doi=10.1016%2fj.inffus.2022.12.021&partnerID=40&md5=5cbd7cd62f141eabff9405de25982103","A new concept of lattice curved surface array is proposed in this paper to represent multi-source medical examination data for getting precise conclusions of intelligent pneumonia diagnosis through reliable collaborative fusion. To this end, the quantum phase based lattice curved surfaces of all source datasets are constructed to form a lattice curved surface array which provides the precise division and fusion space for all entity nodes. Based on the horizontal category degrees and vertical collaborative degrees between entity nodes, the constructed lattice curved surface array is segmented into different subset arrays, and the entity nodes in each subset array are fused into a single object entity node according to the weights of their included part nodes. The experimental data evaluation shows that, compared with the homogeneous fusion methods, this new concept based collaborative fusion method is impressively effective with a preciseness of 95.52% achieved in the reliable fusion results based pneumonia diagnosis. © 2022 Elsevier B.V.","Collaborative fusion; Lattice curved surface array; Multi-source medical examination data; Precise pneumonia diagnosis; Reliability evaluation"
"Missing data reconstruction in attitude for quadrotor unmanned aerial vehicle based on deep regression model with different sensor failures","2023","Information Fusion","10.1016/j.inffus.2023.01.002","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85145981210&doi=10.1016%2fj.inffus.2023.01.002&partnerID=40&md5=f281eeb143048d57359831b27aa80633","Forming a UAV cluster with multiple UAVs to collaborate in accomplishing tasks is the future development of battlefield. The UAV cluster can collaborate by communicating through inter-aircraft links and can quickly and accurately perform complex tasks such as path planning, collaborative reconnaissance, collaborative sensing and attack. In the process of Unmanned Aerial Vehicle (UAV) cooperative operation, obtaining the real-time attitude information of each UAV is preliminary to implement collaborative cooperation. However, in practice, due to the internal malfunction of sensors and mutual interference among UAVs, the acquired attitudes often suffer from data missing. This paper proposed a novel missing data reconstruction method for UAV's attitude in the case of sensor failures. The attitude data of UAV is obtained through an advanced UAV simulation platform AirSim. Through fusing the temporal convolutional network (TCN) and Bi-directional long short-term memory (Bi-LSTM), a deep regression framework is established for missing data construction. In addition, we evaluate the reliability of the proposed method by comparing with different baseline models and different combinations of data missing. The performance of our method is quantified using metrics of root-mean-square-error (RMSE), mean absolute error (MAE), determination coefficient (DC), mean absolute percentage error (MAPE), and symmetric mean absolute percentage error (SMAPE) score. The averaged performance values of our proposed method outperform other baseline algorithms. The results of the experiment show that the study could well-address the issue of missing data reconstruction and provide reliable attitude data. © 2023 Elsevier B.V.","Long short-term memory; Missing data reconstruction; Temporal convolutional network; Time series; UAV"
"Coupled adversarial learning for fusion classification of hyperspectral and LiDAR data","2023","Information Fusion","10.1016/j.inffus.2022.12.020","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85145019689&doi=10.1016%2fj.inffus.2022.12.020&partnerID=40&md5=8a6aab3664157037328d8704a23ec95d","Hyperspectral image (HSI) provides rich spectral–spatial information and the light detection and ranging (LiDAR) data reflect the elevation information, which can be jointly exploited for better land-cover classification. However, due to different imaging mechanisms, HSI and LiDAR data always present significant image difference, current pixel-wise feature fusion classification methods relying on concatenation or weighted fusion are not effective. To achieve accurate classification result, it is important to extract and fuse similar high-order semantic information and complementary discriminative information contained in multimodal data. In this paper, we propose a novel coupled adversarial learning based classification (CALC) method for fusion classification of HSI and LiDAR data. In specific, a coupled adversarial feature learning (CAFL) sub-network is first trained, to effectively learn the high-order semantic features from HSI and LiDAR data in an unsupervised manner. On one hand, the proposed CAFL sub-network establishes an adversarial game between dual generators and discriminators, so that the learnt features can preserve detail information in HSI and LiDAR data, respectively. On the other hand, by designing weight-sharing and linear fusion structure in the dual generators, we can simultaneously extract similar high-order semantic information and modal-specific complementary information. Meanwhile, a supervised multi-level feature fusion classification (MFFC) sub-network is trained, to further improve the classification performance via adaptive probability fusion strategy. In brief, the low-level, mid-level and high-level features learnt by the CAFL sub-network lead to multiple class estimation probabilities, which are then adaptively combined to generate a final accurate classification result. Both the CAFL and MFFC sub-networks are collaboratively trained by optimizing a designed joint loss function, which consists of unsupervised adversarial loss and supervised classification loss. Overall, by optimizing the joint loss function, the proposed CALC network is pushed to learn highly discriminative fusion features from multimodal data, leading to higher classification accuracies. Extensive experiments on three well-known HSI and LiDAR data sets demonstrate the superior classification performance by the proposed CALC method than several state-of-the-art methods. The source code of the proposed method will be made publicly available at https://github.com/Ding-Kexin/CALC. © 2022 Elsevier B.V.","Adversarial learning; Feature fusion; Hyperspectral image; Light detection and ranging; Multimodal data classification"
"Multitask learning for multilingual intent detection and slot filling in dialogue systems","2023","Information Fusion","10.1016/j.inffus.2022.09.029","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140879679&doi=10.1016%2fj.inffus.2022.09.029&partnerID=40&md5=b1d3121a9800ad031b80535efcba9304","Dialogue systems are becoming an ubiquitous presence in our everyday lives having a huge impact on business and society. Spoken language understanding (SLU) is the critical component of every goal-oriented dialogue system or any conversational system. The understanding of the user utterance is crucial for assisting the user in achieving their desired objectives. Future-generation systems need to be able to handle the multilinguality issue. Hence, the development of conversational agents becomes challenging as it needs to understand the different languages along with the semantic meaning of the given utterance. In this work, we propose a multilingual multitask approach to fuse the two primary SLU tasks, namely, intent detection and slot filling for three different languages. While intent detection deals with identifying user's goal or purpose, slot filling captures the appropriate user utterance information in the form of slots. As both of these tasks are highly correlated, we propose a multitask strategy to tackle these two tasks concurrently. We employ a transformer as a shared sentence encoder for the three languages, i.e., English, Hindi, and Bengali. Experimental results show that the proposed model achieves an improvement for all the languages for both the tasks of SLU. The multi-lingual multi-task (MLMT) framework shows an improvement of more than 2% in case of intent accuracy and 3% for slot F1 score in comparison to the single task models. Also, there is an increase of more than 1 point intent accuracy and 2 points slot F1 score in the MLMT model as opposed to the language specific frameworks. © 2022 Elsevier B.V.","Deep learning; Information fusion; Intent detection; Multilingual analysis; Multitask learning; Slot filling"
"Multi-gas source localization and mapping by flocking robots","2023","Information Fusion","10.1016/j.inffus.2022.11.001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142326851&doi=10.1016%2fj.inffus.2022.11.001&partnerID=40&md5=1e11988b80e83192dae6a46dfec065e7","Multi-Gas source localization and mapping is a challenging problem because multiple measurements must be taken to ensure accurate localization. This paper presents a novel flocking control strategy for multi-robot exploration and gas field mapping to address this problem. The algorithm includes an active sensing mechanism for driving a flock of agents towards target measurement locations that optimize the posterior probability density and a collaborative sequential Monte Carlo information fusion approach for estimating gas fields. We tested the performance of our system on Jackal mobile robots in a chemical leak scenario with two gas leakage sources. Through a series of comparison experiments, we demonstrate that our proposed strategy has superior performance to recent single-agent and centralized sequential Monte Carlo-based gas concentration mapping in terms of the estimate accuracy, the convergence time, and the mapping error. © 2022 Elsevier B.V.","Gas source localization; Obstacle avoidance; Particle filter; Robotic flock; Sensor fusion"
"ZMFF: Zero-shot multi-focus image fusion","2023","Information Fusion","10.1016/j.inffus.2022.11.014","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143848758&doi=10.1016%2fj.inffus.2022.11.014&partnerID=40&md5=44a3adb219de47d28370431e48276fe2","Multi-focus image fusion (MFF) is an effective way to eliminate the out-of-focus blur generated in the imaging process. The difficulties in distinguishing different blur levels and the lack of real supervised data make multi-focus image fusion remain a challenging task after decades of research. According to deep image prior (DIP) (Ulyanov et al., 2018), a neural network itself can capture the low-level statistics of a single image and is successfully used as a prior for solving many inverse problems without the need for handmade priors or priors learned from large-scale datasets. Motivated by this idea, we propose a novel multi-focus image fusion framework named ZMFF comprised of a deep image prior network to model the deep prior of the fused image and a deep mask prior network to model the deep prior of the focus map corresponding to each source image. Without the labor-intensive training pair collection, our method achieves zero-shot learning and avoids the domain shifting problem due to the inconsistency between the manually degraded multi-focus images and the real ones. As far as we know, it is the first unsupervised and untrained deep model for the MFF task. Extensive experiments on both synthetic and real-world datasets demonstrate the promising performance, generalization and flexibility of our approach. Source code is available at https://github.com/junjun-jiang/ZMFF. © 2022 Elsevier B.V.","Deep convolutional neural network; Deep image prior; Multi-focus image fusion"
"TFUN: Trilinear Fusion Network for Ternary Image-Text Retrieval","2023","Information Fusion","10.1016/j.inffus.2022.10.013","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140953576&doi=10.1016%2fj.inffus.2022.10.013&partnerID=40&md5=e226e9826ad07d95ec8d95041ee448f8","Recently, a particular type of image-text retrieval task named Ternary Image-Text Retrieval (TITR) has drawn increasing attention. In this task, the total inputs of query and target consist of three components, rather than two inputs in the widely-studied retrieval case. The typical TITR scenarios include recipe retrieval (e.g., ingredients text, instructions text and food images) and fashion search (e.g., original images, text and modified images). A few recently proposed TITR methods mainly focus on learning the semantic correlations of two modality data by projecting them to the same embedding space to capture the alignment between image and text modalities. Nevertheless, two limitations still exist in these methods: 1) the underlying difference between data in the same modality (e.g., ingredients and instructions) is neglected; and 2) the trilinear interaction among the three inputs is implicitly captured. To this end, we propose a novel fusion framework named Trilinear FUsion Network (TFUN) to utilize high-level associations between these three inputs simultaneously and learn an accurate cross-modal similarity function via bi-directional triplet loss explicitly, which is generic for the TITR task. To reduce the model complexity, we introduce the advanced method of tensor decomposition to ensure computational efficiency and accessibility. We also develop a three-stage hard triplet sampling scheme to ensure fast convergence. Extensive experiments on three large-scale TITR datasets Recipe1M, Fashion200k and FashionIQ demonstrate the superiority of our proposed TFUN model compared to the state-of-the-art approaches. The implementation code and additional instructions are provided at https://github.com/CFM-MSG/Code_TFUN. © 2022 Elsevier B.V.","Image-text retrieval; Multimodal fusion; Tensor decomposition; Trilinear fusion"
"PointGS: Bridging and fusing geometric and semantic space for 3D point cloud analysis","2023","Information Fusion","10.1016/j.inffus.2022.10.016","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143832187&doi=10.1016%2fj.inffus.2022.10.016&partnerID=40&md5=695ec17203fc9ec59c79d23b40ec3612","Directly processing 3D point cloud data becomes dominant in classification and segmentation tasks. Present mainstream point based methods usually focus on learning in either geometric space (i.e. PointNet++) or semantic space (i.e. DGCNN). Owing to the irregular and unordered data property of point cloud, these methods still suffer from drawbacks of either ambiguous local features aggregation in geometric space or poor global features extraction in semantic space. While few prior works address these two defects simultaneously by fusing information from the dual spaces, we make a first attempt to develop a synergistic framework, called PointGS. Leveraging both the strength of geometric structure and semantic representation, PointGS establishes a mutual supervision mechanism that can bridge the two spaces and fuse complementary information for better analyzing 3D point cloud data. Compared with existing popular networks, our work attains obvious performance improvement on all three mainstream tasks without any sophisticated operations. © 2022 Elsevier B.V.","Geometric space learning; Information fusion; Point cloud; Semantic space learning"
"Analysis and evaluation of hemiplegic gait based on wearable sensor network","2023","Information Fusion","10.1016/j.inffus.2022.10.003","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139877289&doi=10.1016%2fj.inffus.2022.10.003&partnerID=40&md5=c24299f245889fb2979777a1740abe68","Hemiplegia is a common symptom of acute cerebrovascular disease, and most patients with hemiplegia have abnormal gaits. Descriptive evaluation methods are commonly used in clinical for gait analysis, and outcomes are overly reliant on observation by rehabilitation physicians. The quantitative analysis of hemiplegia gait is urgently required to guide patients' rehabilitation training. This paper presents a quantitative analysis and evaluation method of hemiplegic gait based on inertial measurement units (IMUs). The wearable nodes are worn on the subjects’ waist and lower limbs to record data when they walked in a straight line. After the recorded data has been processed, the gradient descent algorithm (GDA) is used for attitude calculation, and the walking process of hemiplegic patients is reconstructed for gait analysis. Combined with kinematic analysis, three types of joint angles during walking are calculated, i.e., hip angle, knee angle, and ankle angle, and their comparison with the joint angles of normal gait is conducted. In terms of the joint angles, the phase variation of hemiplegic gait is analyzed first, then the gait difference between hemiplegic and normal subjects is measured by using a weighted dynamic time warping (WDTW) algorithm, and finally the gait distortion is evaluated quantitatively based on the WDTW distance. Experimental results demonstrate that the GDA-based gait reconstruction method and the WDTW-based gait evaluation method presented in this paper can quantify the abnormality of hemiplegic gait, and thereby monitor the rehabilitation process of patients' walking ability. © 2022 Elsevier B.V.","Body sensor network; Dynamic time warping (DTW); Gait analysis; Hemiplegia; Multi-sensor fusion"
"Ensemble diverse hypotheses and knowledge distillation for unsupervised cross-subject adaptation","2023","Information Fusion","10.1016/j.inffus.2022.12.023","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146055105&doi=10.1016%2fj.inffus.2022.12.023&partnerID=40&md5=14868426d26867cdf18945741f1795ce","Human intent prediction (HIP) and human activity recognition (HAR) are important for human–robot interactions. However, human–robot interface signals are user-dependent. A classifier trained on labeled source subjects performs poorly on unlabeled target subjects. Besides, previous methods used a single learner, which may only learn a subset of features and degrade their performance on target subjects. Last, HIP and HAR require real-time computing on edge devices whose computational capabilities limit the model size. To address these issues, this paper designs an ensemble diverse hypotheses (EDH) and knowledge distillation (EDHKD) method. EDH mitigates the cross-subject divergence by training feature generators to minimize the upper bound of the classification discrepancy among multiple classifiers. EDH also maximizes the discrepancy among multiple feature generators to learn diverse and complete features. After training EDH, a lightweight student network (EDHKD) distills the knowledge from EDH to a single feature generator and classifier to significantly decrease the model size but remain accurate. The performance of EDHKD is theoretically demonstrated and experimentally validated. Results show that EDH can learn diverse features and adapt well to unknown target subjects. With only soft labels provided by EDH, the student network (EDHKD) can inherit the knowledge learned by EDH and classify unlabeled target data of a 2D moon dataset and two human locomotion datasets with the accuracy at 96.9%, 94.4%, and 97.4%, respectively, in no longer than 1 millisecond. Compared to the benchmark method, EDHKD lifts the target-domain classification accuracy by 1.3% and 7.1% in the two human locomotion datasets. EDHKD also stabilizes learning curves. Therefore, EDHKD significantly increases the generalization ability and efficiency of the HIP and HAR. © 2022 Elsevier B.V.","Ensemble learning; Human activity recognition; Human intent prediction; Knowledge distillation; Unsupervised cross-subject adaptation; Wearable robots"
"An evidential combination method with multi-color spaces for remote sensing image scene classification","2023","Information Fusion","10.1016/j.inffus.2022.12.025","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85145972874&doi=10.1016%2fj.inffus.2022.12.025&partnerID=40&md5=4cbb07f0913edd101bd531ceae706320","Remote sensing image scene classification aims to commit the semantic labels according to the content of images. Convolutional Neural Network (CNN) is often used here to extract deep discriminative feature of remote sensing images for classification. In practice, CNN is usually trained by images in the Red Green Blue (RGB) color space. Whereas, CNN also can be trained by images in some other color spaces, e.g., Hue Saturation Value. The CNN models trained by images in diverse color spaces will perform differently because different color spaces often emphasize diverse color information. Thus, we present an Evidential Combination method with Multi-color Spaces (ECMS) to integrate the complementary information of different color spaces for classification performance improvement. In ECMS, labeled remote sensing images in the RGB color space are first converted into other color spaces, and then they are used to train CNN models, respectively. The soft classification results (of query images) yielded by these CNN models are combined by evidence theory. During fusion, the reliabilities/weights of these outputs of different CNN models are usually different, so they should not be equally treated for combination. In our approach, the weights are learnt by minimizing the mean squared error between the combination results and ground truth on labeled images. By doing this, weighted evidence combination of soft classification results is employed to make scene class decision. We conducted experiments on several datasets to verify the effectiveness of ECMS, and the results show ECMS can significantly improve classification accuracy compared with many existing methods. © 2023 Elsevier B.V.","Belief functions; Convolutional neural network; Deep learning; Evidence theory; Information fusion; Multiple color spaces; Remote sensing image scene classification"
"GRACE PLUS: A data fusion-based approach to improve GRACE score in the risk assessment of Acute Coronary Syndrome","2023","Information Fusion","10.1016/j.inffus.2022.10.019","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141223944&doi=10.1016%2fj.inffus.2022.10.019&partnerID=40&md5=e6bc06bbf0285f232ea652e842882fbb","Cardiovascular Diseases (CVDs) are the world's leading cause of morbidity and mortality, being responsible for almost 17 million deaths each year. In Europe, let alone it is estimated that 20% of all citizens suffer from one form of CVD, namely cerebrovascular disease or heart failure and Coronary Artery Disease (CAD). Among the latter, Acute Coronary Syndrome (ACS) is of particular importance since it is deadly and, hence, requires a prompt diagnosis and immediate medical attention. Aiming to deal with prognostication and promote consistency in managing patients with ACS, the Global Registry of Acute Coronary Events (GRACE) risk score has been proposed. This tool is based on eight independent risk factors roughly accounting for 89.9% of prognostic information. Nevertheless, as some other risk factors, not included in GRACE, are also known to be important vectors in the stratification of patients, namely haemoglobin at admission, it is expected that by embedding additional risk factors information into GRACE it will lead to a better characterisation of a patient's risk. Making use of data-fusion techniques, the present work proposes a generalisable framework to improve the classification performance of GRACE in predicting the risk of death in the course of six months after an ACS event, while preserving its interpretability and applicability. Considering haemoglobin concentration at admission, as an additional risk factor, it is shown that the discrimination performance of new GRACE Plus score outperformed that of GRACE in a database of cohorts comprising 1506 patients admitted with ACS, showing a F-1 score of 0.6033 for GRACE Plus against 0.5828 for GRACE, which is corroborated by one-tailed t-test in terms of correct stratification of death and survival endpoints, namely, t=−9.1876 and p<0.001. © 2022 Elsevier B.V.","Acute Coronary Syndrome; Correction factor; Data fusion; GRACE risk score; Machine learning"
"Multi-objective programming consensus model based on evolutionary game analysis in group decision making","2023","Information Fusion","10.1016/j.inffus.2022.12.024","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85145175163&doi=10.1016%2fj.inffus.2022.12.024&partnerID=40&md5=338ac64635ebea807caea14da744619c","Consensus-reaching process (CRP) plays an important role in the group decision-making (GDM) process. And CRP is a game between the decision makers (DMs) and the moderator, which involves a series of issues about whether DMs accept the modification suggestions from moderators, how the moderators determine the optimal recommendations and whether compensation is available. To reflect the dynamic interaction between moderators and DMs in CRP, we propose a novel consensus model based on the evolutionary game theory. Specifically, we conduct the strategy stability analysis between DMs and moderators, and prove that there is an evolutionary stable strategy (ESS) with mixed strategies. Then, an ESS-based multi-objective programming consensus model (MOPCM) is developed with the maximum expected utility of DMs and moderators. A non-dominated sorting genetic algorithm is designed to obtain the Pareto solution set containing suggested opinions, adjusted opinions, and the unit adjustment cost. In addition, we provide decision-making guidance for consensus improvement through sensitivity analysis and demonstrate the significance of the evolutionary game between DMs and moderators on CRP. © 2022 Elsevier B.V.","Consensus-reaching process; Evolutionary game; Group decision-making; Multi-objective programming model"
"Fusion of colour contrasted images for early detection of oesophageal squamous cell dysplasia from endoscopic videos in real time","2023","Information Fusion","10.1016/j.inffus.2022.11.023","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85145649406&doi=10.1016%2fj.inffus.2022.11.023&partnerID=40&md5=f0e0b1b4ef4c2ea7c11c962a7b8ee332","Standard white light (WL) endoscopy often misses precancerous oesophageal changes due to their only subtle differences to the surrounding normal mucosa. While deep learning (DL) based decision support systems benefit to a large extent, they face two challenges, which are limited annotated data sets and insufficient generalisation. This paper aims to fuse a DL system with human perception by exploiting computational enhancement of colour contrast. Instead of employing conventional data augmentation techniques by alternating RGB values of an image, this study employs a human colour appearance model, CIECAM, to enhance the colours of an image. When testing on a frame of endoscopic videos, the developed system firstly generates its contrast-enhanced image, then processes both original and enhanced images one after another to create initial segmentation masks. Finally, fusion takes place on the assembled list of masks obtained from both images to determine the finishing bounding boxes, segments and class labels that are rendered on the original video frame, through the application of non-maxima suppression technique (NMS). This deep learning system is built upon real-time instance segmentation network Yolact. In comparison with the same system without fusion, the sensitivity and specificity for detecting early stage of oesophagus cancer, i.e. low-grade dysplasia (LGD) increased from 75% and 88% to 83% and 97%, respectively. The video processing/play back speed is 33.46 frames per second. The main contribution includes alleviation of data source dependency of existing deep learning systems and the fusion of human perception for data augmentation. © 2022 The Author(s)","Colour contrast enhancement; Deep machine learning; Early squamous cell cancer detection; Endoscopic treatment; gastrointestinal endoscopy; Oesophagus cancer; Surveillance"
"AOBERT: All-modalities-in-One BERT for multimodal sentiment analysis","2023","Information Fusion","10.1016/j.inffus.2022.11.022","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143162682&doi=10.1016%2fj.inffus.2022.11.022&partnerID=40&md5=972b116c50f8eb2b677a7a33b2d32ae1","Multimodal sentiment analysis utilizes various modalities such as Text, Vision and Speech to predict sentiment. As these modalities have unique characteristics, methods have been developed for fusing features. However, the overall modality characteristics are not guaranteed, because traditional fusion methods have some loss of intra-modality and inter-modality. To solve this problem, we introduce a single-stream transformer, All-modalities-in-One BERT (AOBERT). The model is pre-trained on two tasks simultaneously: Multimodal Masked Language Modeling (MMLM) and Alignment Prediction (AP). The dependency and relationship between modalities can be determined using two pre-training tasks. AOBERT achieved state-of-the-art results on the CMU-MOSI, CMU-MOSEI, and UR-FUNNY datasets. Furthermore, ablation studies that validated combinations of modalities, effects of MMLM and AP and fusion methods confirmed the effectiveness of the proposed model. © 2022 Elsevier B.V.","Alignment Prediction; Multimodal Masked Language Model; Multimodal Sentiment Analysis; Single-stream Transformer"
"A multi-source information fusion model for outlier detection","2023","Information Fusion","10.1016/j.inffus.2022.12.027","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85145971035&doi=10.1016%2fj.inffus.2022.12.027&partnerID=40&md5=d5e7c2b8c60a974175ae34c2d86f5e63","Multi-source information fusion (MSIF) is a useful strategy for combining complimentary data from numerous information sources to produce an overall precise description, which can help with effective decision-making, prediction, and categorization, etc. In order to find the objects that are different from the expected ones after fusion, i.e., anomalies, or outliers, an MSIF model is put forward for outlier detection. This is a two-stage model that includes fusion of multiple information sources and outlier detection of fused data. The first stage uses information sets to construct uncertainty criteria for information source values and combines multiple information sources into a single information source based on the minimum uncertainty strategy. The second stage uses the Gaussian kernel method for possibility modeling based on the fused data to construct knowledge granules. From the perspective of granular computing, outliers in the fused data can be assigned to each knowledge granule. Then, we can find all outliers just by evaluating these knowledge granules. Inspired by this, the fuzzy knowledge measure (FKM) is proposed to evaluate the knowledge granule. Moreover, several metrics are induced on the basis of FKM to describe outliers in knowledge granules and an FKM-based outlier detection algorithm (FKMOD) is designed. Finally, we conduct the experiments on sixteen open access outlier detection datasets. The experimental results show that the proposed FKMOD method has more accurate detection performance than nine classical methods. © 2023 Elsevier B.V.","Fuzzy knowledge measure; Granular computing; Information set; Knowledge granule; Multi-source information fusion; Outlier detection"
"Multi-GNSS PPP/INS/Vision/LiDAR tightly integrated system for precise navigation in urban environments","2023","Information Fusion","10.1016/j.inffus.2022.09.018","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139043502&doi=10.1016%2fj.inffus.2022.09.018&partnerID=40&md5=661d2f45308b51619e5b93d0e30f9845","Nowadays, high-precision navigation is a fundamental prerequisite for autonomous driving technology. However, it is often difficult for a stand-alone sensor to meet the needs of high-precision navigation in complex scenarios. To address this problem, we propose a tightly coupled precise point positioning (PPP)/inertial navigation system (INS)/Vision/LiDAR integration method to achieve high-precision, continuous and reliable navigation in urban environments. The multi-GNSS carrier phase and pseudorange measurements, low-cost microelectromechanical system (MEMS) inertial measurement units (IMU) records, sparse visual landmarks and extracted LiDAR edge/planar features are directly fused at the observation level through a centralized Extended Kalman Filter (EKF). The vehicle experiments in different GNSS availability conditions were conducted to evaluate the proposed method. Results indicate that our proposed PPP/INS/Vision/LiDAR integration can maintain sub-meter level positioning in both GNSS half-open-sky and difficult environments, with improvements of (50.7%, 58.6%, 54.3%) and (46.2%, 55.0%, 58.8%) relative to PPP/INS/Vision and PPP/INS/LiDAR, respectively. Moreover, both visual and LiDAR information can significantly improve the velocity and attitude estimation performance, especially for the heading. © 2022 Elsevier B.V.","MEMS-IMU; Multi-GNSS PPP; Multi-sensor fusion; Tightly coupled integration; Urban environments"
"Medical image segmentation using deep semantic-based methods: A review of techniques, applications and emerging trends","2023","Information Fusion","10.1016/j.inffus.2022.09.031","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139596076&doi=10.1016%2fj.inffus.2022.09.031&partnerID=40&md5=89c344af4dc6e5633ea110a05972b800","Semantic-based segmentation (Semseg) methods play an essential part in medical imaging analysis to improve the diagnostic process. In Semseg technique, every pixel of an image is classified into an instance, where each class is corresponded by an instance. In particular, the semantic segmentation can be used by many medical experts in the domain of radiology, ophthalmologists, dermatologist, and image-guided radiotherapy. The authors present perspectives on the development of an architectural, and operational mechanism of each machine learning-based semantic segmentation approach with merits and demerits. In this regard, researchers have proposed different Semseg methods and examined their performance in a variety of applications such as medical image analysis (e.g., medical image classification and segmentation). A review of recent advances in Semseg techniques are presented in this paper by applying computational image processing and machine learning methods. This article is further presented a comprehensive investigation on how different architectures are helpful for medical image segmentation. Finally, advantages, open challenges, and possible future directions are elaborated in the discussion part, beneficial to the research community to understand the significance of the available medical imaging segmentation technology based on Semseg and thus deliver robust segmentation solutions. © 2022","Deep learning; Medical imaging; Optimization techniques; Semantic segmentation; Transfer learning"
"AT-GAN: A generative adversarial network with attention and transition for infrared and visible image fusion","2023","Information Fusion","10.1016/j.inffus.2022.12.007","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144302001&doi=10.1016%2fj.inffus.2022.12.007&partnerID=40&md5=473e024417c7933466019ddb53eda2fa","Infrared and visible image fusion methods aim to combine high-intensity instances and detail texture features into fused images. However, the ability to capture compact features under various adverse conditions is limited because the distribution of these multimodal features is generally cluttered. Therefore, targeted designs are necessary to constrain multimodal features to be compact. In addition, many attempts are not robust for low-quality images under various adverse conditions and the high fusion time of most fusion methods leads to less effective subsequent vision tasks. To address these issues, we propose a generative adversarial network with intensity attention modules and semantic transition modules, termed AT-GAN, which are more efficient to extract key information from multimodal images. The intensity attention modules aim to keep infrared instance features clearly and semantic transition modules attempt to filter out noise or other redundant features in visible texture. Moreover, an adaptive fused equilibrium point can be learned by a quality assessment module. Finally, experiments with variety of datasets reveal that the AT-GAN can adaptively learn features fusion and image reconstruction synchronously and further improve the timeliness under premise of fusion superiority of the proposed method over state of the art. © 2022","Adverse conditions; Attention mechanism; Generative adversarial networks; Image fusion; Infrared and visible images"
"Evolving multi-user fuzzy classifier system with advanced explainability and interpretability aspects","2023","Information Fusion","10.1016/j.inffus.2022.10.027","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141814421&doi=10.1016%2fj.inffus.2022.10.027&partnerID=40&md5=a1f36cde45f77aca117d71f02be1a013","Evolving classifiers and especially evolving fuzzy classifiers have been established as a prominent technique for addressing the recent demands in building classifiers in an incremental online manner, based on target labels typically provided by a single user. We present a framework for an interactive evolving multi-user fuzzy classifier system with advanced explainability and interpretability aspects (EFCS-MU-AEI). Multiple users may provide their label feedback based on which own users’ classifiers are incrementally trained with evolving learning concepts. Its classification outputs are amalgamated by a specific ensembling scheme, respecting (i.) uncertainty in the class labels due to labeling ambiguities among the users and (ii.) different experience levels of the users as voting weights. A major focus thereby is concentrated on the explainability of classification outputs for the purpose to increase the quality (consistency and certainty) of the user (labeling) feedbacks. It is established to show reasons why certain decisions have been made and with which certainty levels and rule coverage degrees. The reasons are deduced from the most active rules, which are reduced in their length by a statistically-motivated instance-based feature importance level concept. Another major focus lies on the interpretability of extracted rules in order to represent understandable knowledge contained in the classification problem and especially to realize the labeling behaviors of different users for different parts of the feature space (= different sample groups). A specific incremental feature weighting technique, respecting label uncertainties from multiple users and sample forgetting weights (for handling drifts), as well as a fuzzy set merging process are proposed to aim for a high compactness and transparency of the rules. Our approach was evaluated based on a visual inspection scenario. It could be shown that the explanations of the classifier decisions in fact significantly improved the labeling behavior of three single users in terms of showing higher accumulated accuracy trends. Feature weights integration into the classifier updates could achieve transparent rules with final essential four features to describe the classification problem. Based on this description, it turned out in which ways, i.e. for which sample groups, the users with lower experience levels should be taught to improve their understanding about the process. © 2022 The Author(s)","Drift handling; Evolving fuzzy classifiers; Explainability; Interpretability; On-line interactive multi-user classification system"
"UPanGAN: Unsupervised pansharpening based on the spectral and spatial loss constrained Generative Adversarial Network","2023","Information Fusion","10.1016/j.inffus.2022.10.001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140142315&doi=10.1016%2fj.inffus.2022.10.001&partnerID=40&md5=d0fbc8eb596c9d58af6f89650683a1ed","It is observed that, in most of the CNN-based pansharpening methods, the multispectral (MS) images are taken as the ground truth, and the downsampled panchromatic (Pan) and MS images are taken as the training data. However, the trained models from the downsampled images are not suitable for the pansharpening of the MS images with rich spatial and spectral information at their original spatial resolution. To tackle this problem, a novel iterative network based on spectral and textural loss constrained Generative Adversarial Network (GAN) is proposed for pansharpening. First, instead of directly outputting the fused imagery, the GAN focuses on generating the mean difference image. The input of the GAN is a good initial difference image, which will make the network work better. Second, the coarse-to-fine fusion framework is designed to generate the fused imagery. It uses two optimized discriminators to distinguish the generated images, and performs multi-level fusion processing on PAN and MS images to generate the best pansharpening image in full resolution. Finally, the well-designed loss functions are embedded into both the generator and the discriminators to accurately preserve the fidelity of the fused imagery. We validated our method by the images from QuickBird, GaoFen-2 and WorldView-2 satellites. The experimental results demonstrated that the proposed method obtained a better fusion performance than the state-of-the-art methods in both visual comparison and quantitative evaluation. © 2022 Elsevier B.V.","Convolutional neural network; Generative Adversarial Network; Image fusion; Pansharpening"
"Fusing topology contexts and logical rules in language models for knowledge graph completion","2023","Information Fusion","10.1016/j.inffus.2022.09.020","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139295245&doi=10.1016%2fj.inffus.2022.09.020&partnerID=40&md5=23462bd2365c3dfdcb7520aff0491118","Knowledge graph completion (KGC) aims to infer missing facts based on the observed ones, which is significant for many downstream applications. Given the success of deep learning and pre-trained language models (LMs), some LM-based methods are proposed for the KGC task. However, most of them focus on modeling the text of fact triples and ignore the deeper semantic information (e.g., topology contexts and logical rules) that is significant for KG modeling. For such a reason, we propose a unified framework FTL-LM to Fuse Topology contexts and Logical rules in Language Models for KGC, which mainly contains a novel path-based method for topology contexts learning and a variational expectation–maximization (EM) algorithm for soft logical rule distilling. The former utilizes a heterogeneous random-walk to generate topology paths and further reasoning paths that can represent topology contexts implicitly and can be modeled by a LM explicitly. The strategies of mask language modeling and contrastive path learning are introduced to model these topology contexts. The latter implicitly fuses logical rules by a variational EM algorithm with two LMs. Specifically, in the E-step, the triple LM is updated under the supervision of observed triples and valid hidden triples verified by the fixed rule LM. And in the M-step, we fix the triple LM and fine-tune the rule LM to update logical rules. Experiments on three common KGC datasets demonstrate the superiority of the proposed FTL-LM, e.g., it achieves 2.1% and 3.1% Hits@10 improvement over the state-of-the-art LM-based model LP-BERT in the WN18RR and FB15k-237, respectively. © 2022 Elsevier B.V.","Information fusion; Knowledge graph completion; Language model; Logical rule; Topology context"
"Multimodal sentiment analysis: A systematic review of history, datasets, multimodal fusion methods, applications, challenges and future directions","2023","Information Fusion","10.1016/j.inffus.2022.09.025","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141785465&doi=10.1016%2fj.inffus.2022.09.025&partnerID=40&md5=917b2d253eb816f55cda4cc6579385d9","Sentiment analysis (SA) has gained much traction In the field of artificial intelligence (AI) and natural language processing (NLP). There is growing demand to automate analysis of user sentiment towards products or services. Opinions are increasingly being shared online in the form of videos rather than text alone. This has led to SA using multiple modalities, termed Multimodal Sentiment Analysis (MSA), becoming an important research area. MSA utilises latest advancements in machine learning and deep learning at various stages including for multimodal feature extraction and fusion and sentiment polarity detection, with aims to minimize error rate and improve performance. This survey paper examines primary taxonomy and newly released multimodal fusion architectures. Recent developments in MSA architectures are divided into ten categories, namely early fusion, late fusion, hybrid fusion, model-level fusion, tensor fusion, hierarchical fusion, bi-modal fusion, attention-based fusion, quantum-based fusion and word-level fusion. A comparison of several architectural evolutions in terms of MSA fusion categories and their relative strengths and limitations are presented. Finally, a number of interdisciplinary applications and future research directions are proposed. © 2022","Affective computing; Fusion techniques; Multimodal fusion; Sentiment analysis"
"Hybrid deep learning models for traffic prediction in large-scale road networks","2023","Information Fusion","10.1016/j.inffus.2022.11.019","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143498384&doi=10.1016%2fj.inffus.2022.11.019&partnerID=40&md5=7df9b1c95618826d796a3dca4a43dd13","Traffic prediction is an important component in Intelligent Transportation Systems(ITSs) for enabling advanced transportation management and services to address worsening traffic congestion problems. The methodology for traffic prediction has evolved significantly over the past decades from simple statistical models to recent complex integration of different deep learning models. In this paper, we focus on evaluating recent hybrid deep learning models in the task of traffic prediction. To this end, we first conducted a review and taxonomize the reviewed models based on their feature extraction methods. We analyze their constituent modules and architectural designs. We select ten models representative of different architectural choices from our taxonomy and conducted a performance comparison study. For this, we reconstruct the selected models and performed a series of comparative experiments under identical conditions with three well-known real-world datasets collected from large-scale road networks. We discuss the findings and insights based on our results, highlighting the differences in the achieved prediction accuracy by models with different design decisions. © 2022 Elsevier B.V.","Hybrid deep learning model; Intelligent transportation system; Large-scale road networks; Traffic prediction"
"Evidential classification for defending against adversarial attacks on network traffic","2023","Information Fusion","10.1016/j.inffus.2022.11.024","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143535652&doi=10.1016%2fj.inffus.2022.11.024&partnerID=40&md5=9a0ca2425e9a6a029df1f1dd6d7d4c7b","Research interest in demonstrating vulnerability of Machine Learning (ML) algorithms against sophisticated Adversarial Machine Learning (AML) perturbation attacks has become more prominent in recent years. Adversarial attacks perturb dataset instances by finding the nearest decision boundary and moving the instance values towards the boundary. Thus, a popular challenge in this field is combating such adversarial attacks by increasing model accuracy. Making a model more robust often requires the ML engineer to have preemptive knowledge not only that an adversarial attack will occur, but also which attack will occur. This work is the first to reinforce a Neural Network (NN) model in a network security environment against AML attacks by leveraging an evidential classification approach. Evidential approaches allow for measuring an extra degree of insight of uncertainty between features to enable classification of ambiguous instances as uncertain. Crucially, the proposed approach does not require any training of perturbed datasets or any knowledge that an adversarial attack may take place. Recent advances in making ML models more robust against single-step adversarial attacks have been greatly successful, but researchers have found greater issue in making their models more robust against complex, iterative attacks. The proposed approach is evaluated using a modern network security dataset, and compared against a conventional Bayesian NN. Rather than training a model to increase Accuracy, the proposed approach aims to reduce the misclassification rate of perturbed data. By allowing instances in a dataset to be classified as uncertain, comparing against a conventional NN, the proposed approach produces results that decrease the misclassification rates on the two perturbed malicious classes from 70.53% to 13.09%, and from 99.67% to 1.33%, respectively. © 2022 The Authors","Adversarial machine learning; Dempster-Shafer Theory; Evidence theory; Evidential classification; Network security; Neural Networks"
"A Multitask learning model for multimodal sarcasm, sentiment and emotion recognition in conversations","2023","Information Fusion","10.1016/j.inffus.2023.01.005","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146144725&doi=10.1016%2fj.inffus.2023.01.005&partnerID=40&md5=e0c2e5b7f939d4aa39d68dee419b3d4e","Sarcasm, sentiment and emotion are tightly coupled with each other in that one helps the understanding of another, which makes the joint recognition of sarcasm, sentiment and emotion in conversation a focus in the research in artificial intelligence (AI) and affective computing. Three main challenges exist: Context dependency, multimodal fusion and multitask interaction. However, most of the existing works fail to explicitly leverage and model the relationships among related tasks. In this paper, we aim to generically address the three problems with a multimodal joint framework. We thus propose a multimodal multitask learning model based on the encoder–decoder architecture, termed M2Seq2Seq. At the heart of the encoder module are two attention mechanisms, i.e., intramodal (Ia) attention and intermodal (Ie) attention. Ia attention is designed to capture the contextual dependency between adjacent utterances, while Ie attention is designed to model multimodal interactions. In contrast, we design two kinds of multitask learning (MTL) decoders, i.e., single-level and multilevel decoders, to explore their potential. More specifically, the core of a single-level decoder is a masked outer-modal (Or) self-attention mechanism. The main motivation of Or attention is to explicitly model the interdependence among the tasks of sarcasm, sentiment and emotion recognition. The core of the multilevel decoder contains the shared gating and task-specific gating networks. Comprehensive experiments on four bench datasets, MUStARD, Memotion, CMU-MOSEI and MELD, prove the effectiveness of M2Seq2Seq over state-of-the-art baselines (e.g., CM-GCN, A-MTL) with significant improvements of 1.9%, 2.0%, 5.0%, 0.8%, 4.3%, 3.1%, 2.8%, 1.0%, 1.7% and 2.8% in terms of Micro F1. © 2023 Elsevier B.V.","Affective computing; Emotion recognition; Multimodal sarcasm recognition; Multitask learning; Sentiment analysis"
"Multi-source aggregated classification for stock price movement prediction","2023","Information Fusion","10.1016/j.inffus.2022.10.025","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141923315&doi=10.1016%2fj.inffus.2022.10.025&partnerID=40&md5=857b21217a923657667594eae1c22eef","Predicting stock price movements is a challenging task. Previous studies mostly used numerical features and news sentiments of target stocks to predict stock price movements. However, their semantics-based sentiment analysis is sub-optimal to represent real market sentiments. Moreover, only considering the information of target companies is insufficient because the stock prices of target companies can be affected by their related companies. Thus, we propose a novel Multi-source Aggregated Classification (MAC) method for stock price movement prediction. MAC incorporates the numerical features and market-driven news sentiments of target stocks, as well as the news sentiments of their related stocks. To better represent real market sentiments from the news, we pre-train an embedding feature generator by fitting the news to real stock price movements. Embeddings given by the pre-trained sentiment classifier can represent the sentiment information in vector space. Moreover, MAC introduces a graph convolutional network to capture the news effects of related companies on the target stock. Finally, MAC can predict stock price movements for the next trading day based on the aforementioned features. Extensive experiments prove that MAC outperforms state-of-the-art baselines in stock price movement prediction, Sharpe Ratio, and backtesting trading incomes. © 2022 Elsevier B.V.","Event-driven investing; Multi-source aggregating; Sentiment analysis; Stock prediction"
"VQF: Highly accurate IMU orientation estimation with bias estimation and magnetic disturbance rejection","2023","Information Fusion","10.1016/j.inffus.2022.10.014","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140458893&doi=10.1016%2fj.inffus.2022.10.014&partnerID=40&md5=c56424682c2ab7f0cc173a344d49e808","The miniaturization of MEMS-based inertial measurement units (IMUs) facilitates their widespread use in a growing number of application domains. The fundamental sensor fusion task of orientation estimation is a prerequisite for most further data processing steps in inertial motion tracking, such as position and velocity estimation, joint angle estimation, and 3D visualization. Errors in the estimated orientations severely affect all further processing steps. Recent systematic comparisons of existing algorithms show that out-of-the-box accuracy is often low and that application-specific tuning is required to obtain high accuracy. In the present work, we propose and extensively evaluate a quaternion-based orientation estimation algorithm that is based on a novel approach of filtering the acceleration measurements in an almost-inertial frame and that includes extensions for gyroscope bias estimation and magnetic disturbance rejection, as well as a variant for offline data processing. In contrast to all existing work, we perform an extensive evaluation, using a large collection of publicly available datasets and eight literature methods for comparison. The proposed method consistently outperforms all eight literature methods and achieves an average RMSE of 2.9°, while the errors obtained with literature methods range from 5.3° to 16.7°. This improved accuracy with respect to the state of the art is observed not only in average but also for each of several different motion characteristics, as well as for gyroscope bias estimation. Since the evaluation was performed with one single fixed parametrization across a very diverse dataset collection, we conclude that the proposed method provides unprecedented out-of-the-box performance for a broad range of motions, sensor hardware, and environmental conditions. This gain in orientation estimation accuracy is expected to advance the field of IMU-based motion analysis and provide performance benefits in numerous applications. The provided open-source implementation makes it easy to employ the proposed method. © 2022 Elsevier B.V.","AHRS; Attitude estimation; Gyroscope bias estimation; IMU; Inertial measurement unit; Inertial sensor; Magnetic disturbances; Orientation estimation; Sensor fusion"
"Dynamic interactive multiview memory network for emotion recognition in conversation","2023","Information Fusion","10.1016/j.inffus.2022.10.009","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140325783&doi=10.1016%2fj.inffus.2022.10.009&partnerID=40&md5=9d7a68d85ad425ca2522ed3fa64a5d84","When available, multimodal data is key for enhanced emotion recognition in conversation. Text, audio, and video in dialogues can facilitate and complement each other in analyzing speakers’ emotions. However, it is very challenging to effectively fuse multimodal features to understand the detailed contextual information in conversations. In this work, we focus on dynamic interactions during the information fusion process and propose a Dynamic Interactive Multiview Memory Network (DIMMN) model to integrate interaction information for recognizing emotions. Specifically, the information fusion within DIMMN is through multiple perspectives (combining different modalities). We designed multiview layers in attention networks to enable the model to mine the crossmodal dynamic dependencies between different groups in the process of dynamic modal interaction. In order to learn the long-term dependency information, temporal convolutional networks are introduced to synthesize contextual information of a single person. Then, the gated recurrent units and memory networks are used to model the global session to detect contextual dependencies for multi-round, multi-speaker interactive emotion information. Experimental results on IEMOCAP and MELD demonstrate that DIMMN achieves better and comparable performance to the state-of-the-art methods, with an accuracy of 64.7% and 60.6%, respectively. © 2022 Elsevier B.V.","Dynamic interactive multiview memory network; Emotion recognition in conversation; Multimodal fusion"
"Multimodality information fusion for automated machine translation","2023","Information Fusion","10.1016/j.inffus.2022.10.018","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141280543&doi=10.1016%2fj.inffus.2022.10.018&partnerID=40&md5=56ce10f769e94844419d558a766bfe19","Machine translation is a popular automation approach for translating texts between different languages. Although traditionally it has a strong focus on natural language, images can potentially provide an additional source of information in machine translation. However, there are presently two challenges: (i) the lack of an effective fusion method to handle the triangular-mapping function between image, text, and semantic knowledge; and (ii) the accessibility of large-scale parallel corpus to train a model for generating accurate machine translations. To address these challenges, this work proposes an effective multimodality information fusion method for automated machine translation based on semi-supervised learning. The method fuses multimodality information, texts and images to deliver automated machine translation. Specifically, our objective fuses multimodalities with alignment in a multimodal attention network, which advances the method through the power of mapping text and image features to their semantic information with accuracy. Moreover, a semi-supervised learning method is utilized for its capability in using a small number of parallel corpus for supervised training on the basis of unsupervised training. Conducted on the Multi30k dataset, the experimental results shows the promising performance of our proposed fusion method compared with state-of-the-art approaches. © 2022 Elsevier B.V.","Machine translation; Multimodal alignment; Multimodal fusion; Semi-supervised learning"
"Deep reinforcement learning in agent-based simulations for optimal media planning","2023","Information Fusion","10.1016/j.inffus.2022.10.029","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142320573&doi=10.1016%2fj.inffus.2022.10.029&partnerID=40&md5=ad21a5a9f5294e90d783f5046c9f883a","Agent-based models establish a suitable simulation technique to recreate real complex systems, such as those approached in marketing. Reinforcement learning is about learning a behavior policy in order to maximize a long-term reward signal. In this work, we develop a deep reinforcement learning agent that represents a brand in an agent-based model of a market. The goal of the learning agent is to obtain a marketing investment strategy that improves the awareness of its corresponding brand in the marketing scenario. In opposition to conventional marketing investment strategies, the learned strategy is dynamic, so the agent makes its investment decision on-line based on the current state of the market. We choose the Double Deep Q-Network algorithm to train this agent on diverse instances of the model, each of them with different knowledge levels of the brand. First we adjust a subset of the hyperparameters of Double Deep Q-Network on two of the model instances, and then we use the best configuration found to train the agent on all the available instances. The brand agent learns a dynamic policy that optimizes brand's awareness levels. We perform an expert analysis of the policy obtained, where we observe that the learning brand agent tends to increase investment in media channels with greater awareness impact, but it also invests in other channels according to the situation and the characteristics of the model instance. These results show the benefits of having an on-line dynamic learning environment in a decision support system for media planning in marketing. © 2022 Elsevier B.V.","Agent-based modeling; Deep Q-Network; Deep reinforcement learning; Marketing; Media planning"
"ExtendedSketch+: Super host identification and network host trust evaluation with memory efficiency and high accuracy","2023","Information Fusion","10.1016/j.inffus.2022.12.009","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144045751&doi=10.1016%2fj.inffus.2022.12.009&partnerID=40&md5=01a605ce114c89a70a7de9761129be74","Host cardinality estimation is one crucial task in network traffic measurement. Super host is the host that exhibits anomalies in host cardinality and it is usually related to network abnormal events. Therefore, accurate host cardinality estimation is the premise of super host identification and it can be used to measure the trust degree of a network. Sketches have been widely used in super host identification. However, expanding network scale and increasing link rate bring challenges to the efficiency and accuracy of sketch-based super host identification. The size of the counters in most sketches requires a trade-off between memory resources and accuracy. To meet the need of measuring high cardinalities, large size counters are applied, which leads to memory waste in monitoring low cardinality hosts. On the other hand, most sketches have high computational overhead when tracking superhosts, resulting in inefficiency. In order to address these issues, we propose a novel memory efficient and reversible sketch, named ExtendedSketch+, to provide accurate host cardinality estimation with the purpose of super host identification and network host trust evaluation. ExtendedSketch+ achieves both high memory utilization efficiency and high accuracy, in addition to high super host identification efficiency. It applies extensible counters to record unbalanced host cardinality distribution, by adaptively expanding the counters with the increase of cardinality. It adopts a lossless traffic information transfer strategy during counter extension to ensure the accuracy of cardinality estimation. It can directly tracks the host with the highest cardinality in each bucket, which greatly improves the identification efficiency of super hosts. Based on accurate cardinality estimation of ExtendedSketch+, we can further accurately evaluate host trust degree. We theoretically analyze ExtendedSketch+ with regard to its space and time complexities and estimation accuracy. We conduct performance evaluation based on real network traffic traces. Experimental results show that ExtendedSketch+ performs better than state-of-the-art sketches regarding super host identification and provides accurate host trust evaluation. © 2022 Elsevier B.V.","Memory efficient; Network host trust evaluation; Network traffic measurement; Sketch; Super host identification"
"SGFusion: A saliency guided deep-learning framework for pixel-level image fusion","2023","Information Fusion","10.1016/j.inffus.2022.09.030","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140478119&doi=10.1016%2fj.inffus.2022.09.030&partnerID=40&md5=74524673af4136a1c239cd36a216f9d1","Pixel-level image fusion, which merges different modal images into an informative image, has attracted more and more attention. Despite many methods that have been proposed for pixel-level image fusion, there is a lack of effective image fusion methods that can simultaneously deal with different tasks. To address this problem, we propose a saliency guided deep-learning framework for pixel-level image fusion called SGFusion, which is an end-to-end fusion network and can be applied to a variety of fusion tasks by training one model. In specific, the proposed network uses the dual-guided encoding, image reconstruction decoding, and the saliency detection decoding processes to simultaneously extract the feature maps and saliency maps in different scales from the image. The saliency detection decoding is used as fusion weights to merge the features of image reconstruction decoding for generating the fusion image, which can effectively extract meaningful information from the source images and make the fusion image more in line with visual perception. Experiments indicate that the proposed fusion method achieves state-of-the-art performance in infrared and visible image fusion, multi-exposure image fusion, and medical image fusion on various public datasets. © 2022 Elsevier B.V.","Deep learning; Fusion weight; Pixel-level image fusion; Saliency detection"
"Dual-grained human mobility learning for location-aware trip recommendation with spatial–temporal graph knowledge fusion","2023","Information Fusion","10.1016/j.inffus.2022.11.018","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85145648856&doi=10.1016%2fj.inffus.2022.11.018&partnerID=40&md5=5fd36ebbc2b42a58cf58a3a9f03cf599","Trip recommendation is a popular and significant location-aware service that can help visitors make more accurate travel plans. Its principal purpose is to provide a sequence of points of interest (POIs) for a visitor who has a specific demand, such as the number of attractions, start location, end location, etc. Previous studies either regard the trip recommendation task as a simplistic orienteering problem or endeavor to maximize the users’ visiting preferences and transitional regularities in a multi-round iteration manner. However, significant contexts such as long-term transitional dependencies and spatial–temporal correlations are under-explored. Although the emerging deep recursive models (e.g., recurrent neural networks) enable us to relieve the above limitations, there still exist three major challenges: (1) most conventional offline-homogeneous knowledge distillation approaches for key entities (e.g, POI and visiting time) could lead to the inadequacy of capturing the inherent heterogeneous interactions among the different entities and even result in the deviation of understanding human real individual preferences; (2) data sparsity in transitional regularity learning impedes the ability to comprehend human diverse mobility patterns; and (3) the lack of considering contextual facts such as attractive bias would degrade the generalization ability of the model. To remedy the above issues, this work presents a novel framework based on spatial–temporal graph representation learning, namely GraphTrip. Specifically, we first introduce a location-aware information fusion after building the spatial–temporal graph (ST-Graph). Then, a dual-grained human mobility learning module is proposed to address the sparsity of periodic regularity. In addition, we fuse the explicit information (e.g., POI popularity) behind the trip data as prior knowledge to facilitate the performance of trip inference. In the end, the experimental results conducted on five real-world trip datasets demonstrate our proposed GraphTrip achieves promising gains against several cutting-edge baselines, e.g., up to 5.75% and 4.45% improvements on Toronto regarding F1 and pairs-F1. © 2022 Elsevier B.V.","Contrastive learning; Graph neural network; Knowledge fusion; Mobility learning; Spatial–temporal graph"
"Pixel and region level information fusion in membership regularized fuzzy clustering for image segmentation","2023","Information Fusion","10.1016/j.inffus.2022.12.008","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144614400&doi=10.1016%2fj.inffus.2022.12.008&partnerID=40&md5=4f590f86579499ce07c1c6ffca5252b1","Membership regularized fuzzy clustering methods apply an important prior that neighboring data points should possess similar memberships according to an affinity/similarity matrix. As result, they achieve good performance in many data mining tasks. However, these clustering methods fail to take full advantage of image spatial information in their regularizations. Their performance in image segmentation problem is still not promising. In this paper, we first focus on building a novel affinity matrix to store and present the image spatial information as the prior to help membership regularized fuzzy clustering methods get excellent segmentation results. To this end, the affinity value is calculated by the fusion of pixel and region level information to present the subtle relationship of two points in an image. In addition, to reduce the impact of image noise, we use fixed cluster centers in the iteration of algorithm, thus, the updating of membership values is only guided by the prior of fused information. Experimental results over synthetic and real image datasets demonstrate that the proposed method shows better segmentation results than state-of-the-art clustering methods. © 2022 Elsevier B.V.","Image segmentation; Information fusion; Region level information; Regularized fuzzy clustering"
"A survey on cross-media search based on user intention understanding in social networks","2023","Information Fusion","10.1016/j.inffus.2022.11.017","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142179409&doi=10.1016%2fj.inffus.2022.11.017&partnerID=40&md5=8c4b1d84cf56d5b47e2d3da2bb789f79","With the increasing popularity of online social networks, more and more people are posting information, updating their statuses, and searching for topics there. Massive cross-media big data has been gathered by online social networks, with high dynamics, context-sparsity, and cross-media semantic gaps. In addition, it can be challenging to understand users' search intentions in the setting of social networks. The above problems have brought severe challenges and obstacles to cross-media searches, which also attracted more and more attention on social networks. As a relatively new research topic and interest, the concept, methodology, and overall research idea of cross-media search based on user search intention understanding are not evident in the literature. The research also lacks a unified paradigm and relatively complete research ideas on social networks. To solve these problems, we reviewed more than 100 references based on our preliminary exploration and research experience in this field from the whole process involved. We also detailed methodology, datasets, evaluation indicators, experiment evaluation, and research trends and analyzed the challenges. These works will help beginners quickly establish research ideas and processes in this field, and enable them to focus on algorithm design without paying too much attention to datasets, evaluation metrics, and research frameworks. We believe this review will attract more researchers to focus on social network cross-media search based on user search intention understanding and benefit their work. © 2022 Elsevier B.V.","Cross-media search; Deep learning; Social network; User intention understanding"
"A non-parametric statistical inference framework for Deep Learning in current neuroimaging","2023","Information Fusion","10.1016/j.inffus.2022.11.007","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142173022&doi=10.1016%2fj.inffus.2022.11.007&partnerID=40&md5=df4c7ceaf9adb4f53114ff29002e61d7","Deep Learning (DL) predictions are uncertain; but how uncertain? Statistical inference estimates the probabilities of uncertainty from a sample drawn from a population. Assessing the statistical significance of accuracies reported by DL remains largely unexplored. A framework to do so would usefully support a range of applications, and in particular group classifications from neuroimages where, for operational reasons, sample sizes are necessary limited and thus often do not generalise well. We applied a random-effects inference based on a label permutation test to calculate the statistical significance of K-fold cross-validation (CV) from statistical power and Type-I error rates. Our hypothesis is that in low sample size scenarios, the use of resubstitution with upper bound correction (RUB) as a validation would mitigate the debate on the generalisation ability of DL models. The derived framework enables testing such generalisation ability of DL models as feature extraction methods. A combination of autoencoders and support vector machines as feature extraction and classification models is evaluated in a case-control analysis of Alzheimer's disease with well-established outcomes. We found that RUB slightly outperforms K-fold CV as a validation method, especially estimating statistical power in the most heterogeneous samples. Therefore, we suggest RUB as potent and valid method for DL with neuroimages in terms of bias, variance and computational demand. © 2022 Elsevier B.V.","Alzheimer's disease; Deep Learning; Family wise error; Neuroimaging; Statistical power; Statistical significance"
"Quaternion higher-order singular value decomposition and its applications in color image processing","2023","Information Fusion","10.1016/j.inffus.2022.11.026","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144077683&doi=10.1016%2fj.inffus.2022.11.026&partnerID=40&md5=fb2483650c7669b8df99be65bb6b8637","Higher-order singular value decomposition (HOSVD) is one of the most efficient tensor decomposition techniques. It has the salient ability to represent high-dimensional data and extract features. On the other hand, in more recent years, the quaternion has proven to be a very suitable tool for color pixel representation as it can well preserve cross-channel correlation of color channels. Motivated by the advantages of the HOSVD and the quaternion tool, in this paper, we generalize the HOSVD to the quaternion domain and define quaternion-based HOSVD (QHOSVD). Due to the non-commutability of quaternion multiplication, QHOSVD is not a trivial extension of the HOSVD. They have similar but different calculation procedures. Theoretically, QHOSVD is a proper tensor generalization of the quaternion singular value decomposition (QSVD), and a proper quaternion generalization of the standard HOSVD. From the application point of view, the defined QHOSVD can be widely used in various visual data processing with color pixels. As examples, in this paper, we present two applications of the defined QHOSVD in color image processing—multi-focus color image fusion and color image denoising. The experimental results on the two applications respectively demonstrate the competitive performance of the proposed methods over some existing ones. © 2022 Elsevier B.V.","Color image denoising; Multi-focus color image fusion; Quaternion higher-order singular value decomposition (QHOSVD); Quaternion tensor"
"Spectral-invariant matching network","2023","Information Fusion","10.1016/j.inffus.2022.10.033","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142145270&doi=10.1016%2fj.inffus.2022.10.033&partnerID=40&md5=3d4763e2211044505ac90182d28eb917","As the need for sensor fusion systems has grown, developing methods to find correspondences between images with different spectral ranges has become increasingly important. Since most images do not share low-level information, such as textures and edges, existing matching approaches fail even with convolutional neural networks (CNNs). In this paper, we propose an end-to-end metric learning method, called SPIMNet (SPectral-Invariant Matching Network) for robust cross- and multi-spectral image patch matching. While existing methods based on CNNs learn matching features directly from cross- and multi-spectral image patches, SPIMNet transforms across spectral bands and discriminates for similarity in three steps. First, (1) SPIMNet is adjusted for a feature domain by introducing a domain translation network; then (2) two Siamese networks learn to match the adjusted features with the same spectral domain; and (3) the matching features are fed to fully-connected layers to determine the identity of the patches as a classification task. By effectively incorporating each step, SPIMNet achieved competitive results on a variety of challenging datasets, including both VIS–NIR and VIS–Thermal image pairs. Our code is available at https://github.com/koyeongmin/SPIMNet. © 2022","Domain conversion; Image matching; Sensor fusion; Stereo matching; VIS–NIR"
"GAN review: Models and medical image fusion applications","2023","Information Fusion","10.1016/j.inffus.2022.10.017","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140323593&doi=10.1016%2fj.inffus.2022.10.017&partnerID=40&md5=05999685aaeefe5307ececb7057ae9bf","Generative Adversarial Network (GAN) is a research hotspot in deep generative models, which has been widely used in the field of medical image fusion. This paper summarizes GAN models from the following four aspects: firstly, the basic principles of GAN are expounded from two aspects: basic model and training process; secondly, variant GAN models are summarized into three directions (Probability Distribution Distance, Overall Network Architecture, Neural Network Structure), from the methods based on f-divergence, the methods based on IPM, Single-Generator and Dual-Discriminators GAN, Multi-Generators and Single-Discriminator GAN, Multi-Generators and Multi-Discriminators GAN, Conditional Constraint GAN, Convolutional Neural Network structure GAN and Auto-Encoder Neural Network structure GAN are eight dimensions to summarize the typical models in recent years; thirdly, the advantages and application of GAN models in the field of medical image fusion are explored from three aspects; fourthly, the main challenges faced by GAN and the challenges faced by GAN models in medical image fusion field are discussed and the future prospects are given. This paper systematically summarizes various models of GAN, advantages and challenges of GAN models in medical image fusion field, which is very important for the future research of GAN. © 2022","Generative adversarial network (GAN); Generative models; Medical image fusion; Multi-generators and multi-discriminators GAN; Probability distribution distance"
"Boosting target-level infrared and visible image fusion with regional information coordination","2023","Information Fusion","10.1016/j.inffus.2022.12.005","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85145666045&doi=10.1016%2fj.inffus.2022.12.005&partnerID=40&md5=95bf52a8efb3b7572cbcf29a64994321","The target-level infrared and visible image fusion aims to prominently retain the feature of target areas in the entire scene of fusion results. Nonetheless, most of existing fusion methods tend to evaluate the global information and ignore the retention of specific target information during feature extraction. A few existing target-level fusion methods also have the problem of missing target or scene information under special conditions. In order to address the challenges of image fusion and make further deployment planning in high-level image vision tasks, we propose a target-level infrared and visible image fusion method. In our method, a scene texture attention module is designed to enhance the complementary description of global scene information, and a target extraction module with the target-level loss function is designed to prominently retain the feature of target areas. Furthermore, target information and scene information are equilibrated by the coordination of target-scene information loss function. A large number of comparison experiments with the state-of-the-art methods demonstrate that our fusion method has competitive advantages in highlighting target features and describing global scene. More importantly, in downstream target detection and depth estimation tasks, the excellent performance in accuracy and speed considerably enhances the portability of our method. © 2022 Elsevier B.V.","High-level vision tasks; Image fusion; Scene information; Target-level"
"Combining heterogeneous data sources for spatio-temporal mobility demand forecasting","2023","Information Fusion","10.1016/j.inffus.2022.09.028","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140242428&doi=10.1016%2fj.inffus.2022.09.028&partnerID=40&md5=7902a5f6aa6ada57669d04d4dc053f9f","There is a growing need to optimize mobility in medium to large-size cities. The use of a car for one-person trips is widely established as a common trend, which combined with the age of the vehicle fleet from many countries leads to high levels of pollution. Besides, the time wasted on commuting is more than significant for many people. Under these premises, it is paramount to understand the dynamics of mobility in every city. In this work, the problem of modeling and predicting transport demand in large cities with high spatio-temporal resolution is tackled. The city studied and its metropolitan area are subdivided into a new mobility mesh-grid, and transport demand is binned into short time intervals. The proposed Spatio-Temporal Mobility Demand Forecaster (ST-MDF) model is trained with real mobility demand data (such as taxi and bicycle rental), historical weather data (e.g., temperature, precipitation, and wind speed), and temporal information (e.g., weekday, time, and holiday) to predict mobility demand in every region of the mesh, for several forecast horizons. The experiments show that the ST-MDF model exhibits flexibility and robustness, while at the same time it outperforms the baseline models, such as a Long Short-Term Memory (LSTM) network, or the persistence and naive models. © 2022 The Authors","Deep learning; Mobility demand; Multi-sensor information; Spatio-temporal forecasting"
"TRIMOON: Two-Round Inconsistency-based Multi-modal fusion Network for fake news detection","2023","Information Fusion","10.1016/j.inffus.2022.12.016","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85145968635&doi=10.1016%2fj.inffus.2022.12.016&partnerID=40&md5=afa4c8bd374fe6fa206e7e6996410de1","Compared to ordinary news, fake news is characterized by faster dissemination and lower production cost and therefore causes a great social harm. For these reasons, the challenge to efficiently and accurately detect fake news has attracted a lot of attention in the research community. We propose a Two-Round Inconsistency-based Multi-modal fusion Network (TRIMOON) for fake news detection, which consists of three main components: the multi-modal feature extraction module, the multi-modal feature fusion module and the classification module. To filter the noise generated in the fusion process, we perform a two-fold inconsistency detection, once before and once after the fusion process. Experimental results also prove this to be quite effective. Our proposed TRIMOON is evaluated on both the Chinese and the English datasets, and our model outperforms the state-of-the-art approaches on several classification evaluation metrics. © 2022 Elsevier B.V.","Deep learning; Fake news detection; Feature fusion; Multi-modal fusion"
"Improving aspect-based sentiment analysis with Knowledge-aware Dependency Graph Network","2023","Information Fusion","10.1016/j.inffus.2022.12.004","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144079350&doi=10.1016%2fj.inffus.2022.12.004&partnerID=40&md5=22d73f9035351f538f4f3fe7952c6176","Aspect-based sentiment analysis (ABSA) aims to mine multiple sentiment–target pairs contained in a review sentence. The main challenge of this task is how to extract the sentiment polarity of a specific sentiment item efficiently. Earlier research focused on recurrent neural networks (RNNs), which implicitly associate the sentiment items with sentiment polarities through an attention mechanism. However, due to the complexity of language and the fact that a sentence contains multiple sentiment pairs, these models often fail to capture sentiment pairs accurately. Most recent efforts have applied syntactic information, especially dependency information, to construct structured models (e.g., tree-based models or graph neural networks) for sentiment analysis. Although these structured models achieve better results, they ignore the domain knowledge related to the entities of the comment sentences. This domain knowledge (e.g., brand reputation, influence) significantly impacts the sentiment polarity. Hence, this paper proposes a Knowledge-aware Dependency Graph Network (KDGN) based on the dependency graph incorporating domain knowledge, dependency labels, and syntax path. Experimental results on the benchmarking datasets demonstrate that our KDGN significantly outperforms previous state-of-the-art methods on the ABSA task, further illustrating that the domain knowledge, dependency labels, and syntax path are crucial for the ABSA task. © 2022 Elsevier B.V.","Dependency graph network; Domain knowledge; Sentiment analysis"
"Learning to simultaneously enhance field of view and dynamic range for light field imaging","2023","Information Fusion","10.1016/j.inffus.2022.10.021","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140806256&doi=10.1016%2fj.inffus.2022.10.021&partnerID=40&md5=fddf410420e583a78fa700e9073174ad","Light field (LF) imaging, which simultaneously captures the intensity and direction information of light rays, enabling many vision applications, has received widespread attention. However, limited by the optical structure of the LF camera, the acquired LF images usually suffer from narrow field of view (FOV) and low dynamic range. To address these problems, this paper proposes an unsupervised wide-FOV high dynamic range (HDR) LF imaging method, which can effectively reconstruct a wide-FOV HDR LF image from a set of source LF images captured from different perspectives and simultaneously with different exposures. Specifically, the proposed method first exploits tensor decomposition to obtain a compact representation of high-dimensional LF image, so as to enable a computationally efficient 2D neural network for LF registration. Subsequently, an exposure restoration network is constructed to recover the multi-exposure information of the registered non-overlapping regions, which is then linearly fused with the previous registered results to generate the stitched wide-FOV multi-exposure LF images. Finally, an HDR LF blending network with two ingenious unsupervised losses is designed to blend the stitching results to generate the desired wide-FOV HDR LF image. Experimental results show that the proposed method achieves superior performance compared with the state-of-the-art methods in both qualitative and quantitative evaluation. Moreover, a series of ablation studies effectively validate the performance of each module in the proposed method. © 2022 Elsevier B.V.","High dynamic range; Image fusion; Light field; Unsupervised learning; Wide field of view"
"Deep multi-view multiclass twin support vector machines","2023","Information Fusion","10.1016/j.inffus.2022.10.005","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140322930&doi=10.1016%2fj.inffus.2022.10.005&partnerID=40&md5=74aa248517903a7dfe2a463d8c8798b6","Multi-view learning (MVL) is a rapidly evolving direction in the field of machine learning. Despite the positive results, most algorithms that combine multi-view learning with twin support vector machines (TSVM) focus on the traditional machine learning domain. No method has been accomplished for combining MVL, TSVM, and deep learning. In this paper, we propose two novel multi-view deep models to solve the multiclass classification problem, namely deep multi-view twin support vector machines (DMvTSVM) based on deep neural network (DNN) and auto-encoder (AE) network. They find two non-parallel hyperplanes such that each hyperplane is as close to its own class as possible while being as far away from the other class as possible. Meanwhile, we apply similarity regularization to the output of the Deep TSVM classifier for each view to learn consensus information between views, and use this to refine the joint weights of the deep model and TSVM. Finally, the novel models employ the one−vs−rest strategy to allow the DMvTSVM classifier to solve the multiclass classification problems. In the experiments, the proposed methods are compared with existing state-of-the-art algorithms to prove their effectiveness. © 2022 Elsevier B.V.","Auto-encoder; Deep multi-view learning; Multiclass classification; Twin support vector machines"
"A novel deep learning approach using blurring image techniques for Bluetooth-based indoor localisation","2023","Information Fusion","10.1016/j.inffus.2022.10.011","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140434547&doi=10.1016%2fj.inffus.2022.10.011&partnerID=40&md5=2dfe56c98d3b925f4330881a116d6c46","The growing interest in the use of IoT technologies has generated the development of numerous and diverse applications. Many of the services provided by the applications are based on knowledge of the localisation and profile of the end user. Thus, the present work aims to develop a system for indoor localisation prediction using Bluetooth-based fingerprinting using Convolutional Neural Networks (CNN). For this purpose, a novel technique was developed that simulates the diffusion behaviour of the wireless signal by transforming tidy data into images. For this transformation, we implemented the technique used in painting known as blurring, simulating the diffusion of the signal spectrum. Our proposal also includes the use and a comparative analysis of two dimensional reduction algorithms, PCA and t-SNE. Finally, an evolutionary algorithm was implemented to configure and optimise our solution with the combination of different transmission power levels. The results reported in this work present an accuracy of close to 94%, which clearly shows the great potential of this novel technique in the development of more accurate indoor localisation systems. © 2022 The Author(s)","Convolutional Neural Network; Fingerprinting localisation; Image blurring technique; Image generation; Indoor positioning; Metaheuristic algorithm optimisation"
"Attentive gated graph sequence neural network-based time-series information fusion for financial trading","2023","Information Fusion","10.1016/j.inffus.2022.10.006","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140905775&doi=10.1016%2fj.inffus.2022.10.006&partnerID=40&md5=348fca344088ff14086e56e5f445e688","With the advances in financial technology (FinTech) in recent years, the finance industry has attempted to enhance the efficiency of their services through technology. The financial service most commonly desired by people is a robo-advisor, which is a virtual expert that advises people on how to make good decisions related to financial market trading. Some mathematical models may be difficult to apply to prediction problems involving multiple cross correlation. To overcome this issue, the rules of and implicit correlation between the collected data must be determined through algorithms to forecast the future market situation. By combining financial information from the financial market, we apply an information fusion approach to collect data. Also, a relational model can be developed using a deep neural network, which can be represented using a graph structure, to determine the real market situation. However, the structural information of the graph may be lost if a traditional deep learning module is used. Therefore, in this paper, we present a visual-question-answering-like deep learning fusion model based on the graph structure and attention mechanism. This model was used to study the interaction between the time-series data of various financial variables. The relationships among financial commodities were formulated, and the graph representation was learned through graph neural networks. Moreover, the importance of each commodity was determined through the attention mechanism. The proposed method improved the accuracy of trend and volatility prediction up to 6% on S&P500 and developed a pairs trading application. © 2022 Elsevier B.V.","Graph neural network; Relational network; Robo-advisor"
"Distributed minimum error entropy Kalman filter","2023","Information Fusion","10.1016/j.inffus.2022.11.016","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141918702&doi=10.1016%2fj.inffus.2022.11.016&partnerID=40&md5=c47e55030521f4afb11cd67450544024","Recently, the distributed Kalman filter (DKF) has been considered a major method for the applications of Wireless sensor networks (WSNs), for instance, the Internet of Things, and Swarm Intelligence, in which non-Gaussian noise influence is an urgent issue. In this paper, taking any sensor of WSNs as a fusion node, a dynamic Gain Matrix is constructed for its neighbors’ information fusion. Then, the Minimum Error Entropy (MEE) is furtherly introduced into the information fusion process, a modified DKF algorithm called the Distributed Fusion MEE Kalman Filter (DF-MEE-KF) is proposed for eliminating the non-Gaussian noise influence, which improved the estimation accuracy well. Moreover, considering many bad communication conditions of WSNs, such as Communication Denial Environments, and Underwater Acoustic Communication Environments, it is required that the higher estimation accuracy the better, and the lower communication cost the better. Therefore, the diffusion rule is applied for the nodes’ information fusion by constructed fusion weights, thereby an extended DF-MEE-KF algorithm, the Diffusion MEE Kalman filter (Diff-MEE-KF), is obtained. Finally, the convergence of the proposed DF-MEE-KF and Diff-MEE-KF algorithms is proved. Numerical simulation examples also demonstrate that the DF-MEE-KF algorithm performs good estimation accuracy, and the Diff-MEE-KF algorithm achieves a lower communication cost under the same estimation accuracy, when in non-Gaussian noise-influenced WSNs’ applications. © 2022 Elsevier B.V.","Diffusion strategy; Distributed Kalman filter; Information fusion; Minimum error entropy; Wireless sensor networks"
"Angular contrastive distillation driven self-supervised scanner independent screening and grading of retinopathy","2023","Information Fusion","10.1016/j.inffus.2022.12.006","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85145658549&doi=10.1016%2fj.inffus.2022.12.006&partnerID=40&md5=4eb50127bf0b9285aa885ebce1652d46","Retinopathy is a group of retinal diseases that causes severe retinal damage, resulting in partial visual impairment or complete vision loss. Due to the capability of optical coherence tomography in revealing early retinal abnormalities, many researchers have utilized it to develop autonomous retinal screening systems. However, to the best of our knowledge, the majority of these systems are vulnerable against diversified scanner specifications, hence, requiring extensive training supervision (on large-scale datasets) to accurately learn retinal screening tasks. In this paper, we present a novel self-supervised segmentation-driven classification pipeline that employs a proposed angular contrastive distillation scheme to extract retinal lesions (from the multi-vendor data) in order to give lesion-aware scanner independent screening and grading of retinopathy. The diagnostic capacity of the proposed framework is further enhanced by the integration of a novel co-attention mechanism, which enables the underlying network to focus its attention on retinal abnormalities to effectively grade retinal diseases without incurring supervision from the ground truth labels. The proposed framework is rigorously validated on seven public datasets, acquired with four different scanners, where it outperforms its competitors by achieving 9.22% improvement in terms of mean intersection-over-union for extracting retinal lesions and 10.71% improvement in terms of F1 score for grading retinopathy. © 2022 Elsevier B.V.","Contrastive learning; Few-shot learning; Ophthalmology; Optical coherence tomography; Retina"
"Multi-level multi-type self-generated knowledge fusion for cardiac ultrasound segmentation","2023","Information Fusion","10.1016/j.inffus.2022.11.004","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142714700&doi=10.1016%2fj.inffus.2022.11.004&partnerID=40&md5=9c59709c8a174ba36306304c9fd85880","Most existing works on cardiac echocardiography segmentation require a large number of ground-truth labels to appropriately train a neural network; this, however, is time consuming and laborious for physicians. Self-supervision learning is one of the potential solutions to address this challenge by deeply exploiting the raw data. However, existing works mainly exploit single type/level of pretext task. In this work, we propose fusion of the multi-level and multi-type self-generated knowledge. We obtain multi-level information of sub-anatomical structures in ultrasound images via a superpixel method. Subsequently, we fuse various types of information generated through multi-types of pretext tasks. In the end, we transfer the learned knowledge to our downstream task. In the experimental studies, we have demonstrated the prove the effectiveness of this method through the cardiac ultrasound segmentation task. The results show that the performance of our proposed method for echocardiography segmentation matches the performance of fully supervised methods without requiring a high amount of labeled data. © 2022 Elsevier B.V.","Anatomically constrained neural network (ACNN); Deep Neural Networks (DNNs); Dual Closed-loop Network (DCLNet); Full convolution network (FCN); Multi-level and Multi-type Self-Generated (MM-SG); SLIC (Simple Linear Iterative Clustering) algorithm"
"Excavating multimodal correlation for representation learning","2023","Information Fusion","10.1016/j.inffus.2022.11.003","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141917735&doi=10.1016%2fj.inffus.2022.11.003&partnerID=40&md5=f313c4de57692ab9e21331db76b45176","A majority of previous methods for multimodal representation learning ignore the rich correlation information inherently stored in each sample, leading to a lack of robustness when trained on small datasets. Although a few contrastive learning frameworks leverage that information in a self-supervised manner, they generally encourage the intra-sample unimodal representations to be identical, neglecting the modality-specific information carried by individual modalities. In contrast, we propose a novel algorithm that learns the correlations between modalities to facilitate downstream multimodal tasks by leveraging the prior information across samples, and we explore the feasibility of the proposed method on elaborately designed unsupervised and supervised auxiliary learning tasks. Specifically, we construct the positive and negative sets for correlation learning as unimodal embeddings from the same sample and from different samples, respectively. A weak predictor is employed on the concatenated unimodal embeddings to learn the correspondence relationship for each set. In this way, the model can correlate unimodal features and discover the shared information across modalities. In contrast to contrastive learning methods, the proposed framework is compatible with any number of modalities and can retain modality-specific information, enabling multimodal representation to capture richer information. Moreover, in the supervised version, one of the main novelties is that the sample labels are further utilized to learn more discriminative features, where the assigned correlation scores of negative sets vary according to the label variations between the associated samples. Extensive experiments suggest that the proposed method reaches state-of-the-art performance on the tasks of multimodal sentiment analysis, emotion recognition, and humor detection, and can improve the performance of various fusion approaches. © 2022 Elsevier B.V.","Correlation learning; Multimodal emotion recognition; Multimodal humor detection; Multimodal representation learning; Multimodal sentiment analysis"
"UncertaintyFuseNet: Robust uncertainty-aware hierarchical feature fusion model with Ensemble Monte Carlo Dropout for COVID-19 detection","2023","Information Fusion","10.1016/j.inffus.2022.09.023","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140038259&doi=10.1016%2fj.inffus.2022.09.023&partnerID=40&md5=7815f2948023092a820625fbdda1ae79","The COVID-19 (Coronavirus disease 2019) pandemic has become a major global threat to human health and well-being. Thus, the development of computer-aided detection (CAD) systems that are capable of accurately distinguishing COVID-19 from other diseases using chest computed tomography (CT) and X-ray data is of immediate priority. Such automatic systems are usually based on traditional machine learning or deep learning methods. Differently from most of the existing studies, which used either CT scan or X-ray images in COVID-19-case classification, we present a new, simple but efficient deep learning feature fusion model, called UncertaintyFuseNet, which is able to classify accurately large datasets of both of these types of images. We argue that the uncertainty of the model's predictions should be taken into account in the learning process, even though most of the existing studies have overlooked it. We quantify the prediction uncertainty in our feature fusion model using effective Ensemble Monte Carlo Dropout (EMCD) technique. A comprehensive simulation study has been conducted to compare the results of our new model to the existing approaches, evaluating the performance of competing models in terms of Precision, Recall, F-Measure, Accuracy and ROC curves. The obtained results prove the efficiency of our model which provided the prediction accuracy of 99.08% and 96.35% for the considered CT scan and X-ray datasets, respectively. Moreover, our UncertaintyFuseNet model was generally robust to noise and performed well with previously unseen data. The source code of our implementation is freely available at: https://github.com/moloud1987/UncertaintyFuseNet-for-COVID-19-Classification. © 2022 Elsevier B.V.","COVID-19; Deep learning; Early fusion; Feature fusion; Uncertainty quantification"
"A transfer fusion framework for body sensor networks (BSNs): Dynamic domain adaptation from distribution evaluation to domain evaluation","2023","Information Fusion","10.1016/j.inffus.2022.10.026","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140985601&doi=10.1016%2fj.inffus.2022.10.026&partnerID=40&md5=c29259f70d918a10042d006f9fa38d33","Information fusion is a scenario-driven, long-term, challenging task in body sensor networks (BSNs). Recent strategies, such as supervised or semi-supervised learning, rely heavily on fusion-decision models that are supported by prior knowledge or experience. Such techniques typically need a large amount of labeled physiological data and require the target data to have the same distribution as the prior data, which is challenging to achieve in practice. Domain adaptation (DA) is considered a viable solution for the cross-domain problem in BSNs. However, the correlation between the fusion rules and DA was rarely considered in existing studies. The independence of the domain deviation for each sensing source was ignored. This study aims to provide a universal solution for cross-domain information fusion scenarios in BSNs. Firstly, a transfer fusion framework (TF) was proposed to simultaneously solve the problems of the information fusion and multidomain deviation in BSNs by adjusting the correlation between the DA and fusion. Secondly, a DA algorithm based on dynamic domain evaluation (DDE) was proposed for the DA stage of the TF framework. In addition, we provided a feasible solution for quantitatively evaluating the domain weights. Extensive experiments on emotion recognition, fall detection, daily activity recognition, and hand movement recognition have verified the adaptability and promising performance of TF and DDE for cross-domain information fusion in BSNs. The average classification accuracy of the TF is 8.39% and 6.71% higher than that of the conventional fusion transfer framework and the baseline method, respectively. In all transfer tasks, DDE shows the best performance, which is 4.66% higher than the classification accuracy of the optimal comparison method. This study can provide technical support for BSN applications based on cross-domain information fusion. © 2022 Elsevier B.V.","Body sensor networks; Domain adaptation; Information fusion; Transfer learning; Wearable device"
"Online public opinion prediction based on rolling fractional grey model with new information priority","2023","Information Fusion","10.1016/j.inffus.2022.10.012","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140879769&doi=10.1016%2fj.inffus.2022.10.012&partnerID=40&md5=6de7c60b4a46b6d99b1282da064466b9","The data of online public opinion updates quickly and new information plays a greater role than old information, this paper proposes a novel new information variable weight fractional rolling grey model for predicting online public opinion trends. Firstly, the new information variable weight buffer operator is proposed, and it follows the principle of “New information priority”. The new information is assigned larger weight under the action of the buffer operator. On the basis of the buffer operator, the new information variable weight fractional order accumulating generated operator is proposed, which has the dual functions of accumulation and weighting. In addition, the idea of metabolism is introduced to the model, which adds the latest online public opinion time point data and eliminates the earliest data. Finally, this model is applied to forecast the online public opinion trends with monotonically increasing sequence, monotonically decreasing sequence, and oscillation sequence. Compared with other models, the new information variable-weight fractional rolling grey model has better prediction performance in the online public opinion. © 2022","Buffer operator; Fractional order; New information priority; Online public opinion; Prediction"
"The Krypteia ensemble: Designing classifier ensembles using an ancient Spartan military tradition","2023","Information Fusion","10.1016/j.inffus.2022.09.021","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139302323&doi=10.1016%2fj.inffus.2022.09.021&partnerID=40&md5=cd78c16df6946f59678d7852ffa35860","In this work we propose a new algorithm to train and optimize an ensemble of classifiers. We call this algorithm the Krypteia ensemble, based on an ancient Spartan tradition designed to convert their most promising individuals into future leaders of their society. We show how to adapt this ancient custom to optimize classifiers by generating different variations of the same task, each one offering different hardships according to distinct stochastic variables. This is thus applied to induce diversity in the set of individual weak learners. Then, we use a set of agents designed to select those subjects who excel in their assignments, and whose interaction minimizes excessive redundancies in the resulting population. We also study how different Krypteia ensembles can be stacked together, so that more complex classifiers can be built using the same procedure. Besides, we consider a wide range of different aggregation functions in the decision making phase to find the optimal performance for the different Krypteia ensemble variations tested. Finally, we study how different Krypteia ensembles perform for a wide range of classification datasets and we compare them with other state-of-the-art design techniques of classifier ensembles, obtaining favourable results to our proposal. © 2022 The Author(s)","Classifier ensemble; Human social behaviour; Krypteia; Multi-agent systems; Optimal classifier selection; Social network; Sparta"
"Modality-invariant temporal representation learning for multimodal sentiment classification","2023","Information Fusion","10.1016/j.inffus.2022.10.031","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141893362&doi=10.1016%2fj.inffus.2022.10.031&partnerID=40&md5=5f5bddd567a28748139c01ec1b89f4ef","Multimodal sentiment classification is a notable research field that aims to refine sentimental information and classify the sentiment tendency from sequential multimodal data. Most existing sentimental recognition algorithms explore multimodal fusion schemes that achieve good performance. However, there are two key challenges to overcome. First, it is essential to effectively extract inter- and intra-modality features prior to fusion, while simultaneously reducing ambiguity. The second challenge is how to learn modality-invariant representations that capture the underlying similarities. In this paper, we present a modality-invariant temporal learning technique and a new gated inter-modality attention mechanism to overcome these issues. For the first challenge, our proposed gated inter-modality attention mechanism performs modality interactions and filters inconsistencies from multiple modalities in an adaptive manner. We also use parallel structures to learn more comprehensive sentimental information in pairs (i.e., acoustic and visual). In addition, to address the second problem, we treat each modality as a multivariate Gaussian distribution (considering each timestamp as a single Gaussian distribution) and use the KL divergence to capture the implicit temporal distribution-level similarities. These strategies are helpful in reducing domain shifts between different modalities and extracting effective sequential modality-invariant representations. We have conducted experiments on several public datasets (i.e., YouTube and MOUD) and the results show that our proposed method outperforms the state-of-the-art multimodal sentiment categorization methods. © 2022 Elsevier B.V.","KL divergence; Modality-invariant representation learning; Multimodal learning; Sentiment classification; Transformer"
"Nation-wide touristic flow prediction with Graph Neural Networks and heterogeneous open data","2023","Information Fusion","10.1016/j.inffus.2022.11.005","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142169603&doi=10.1016%2fj.inffus.2022.11.005&partnerID=40&md5=4eedc36eefb096ba107d7d67b3264b44","Tourism has become a very active ecosystem to deploy solutions based on Information and Communication Technologies. Indeed, it is now possible to analyse the mobility behaviour of tourists in great detail. However, current solutions aimed at anticipating tourist flows usually follow a limited approach based on the local (e.g., to predict the next landmark to visit) or regional (e.g., to predict the incoming number of tourists in a city) level. This paper states a novel approach to solve the problem of tourist inflow forecasting on a broader nationwide scale by defining it as an edge prediction task. To do so, we model the tourist mobility of a country as a graph which fuses heterogeneous tourism data obtained from multiple sources related to the country's mobility and infrastructure features. Then, as a major contribution, an ensemble of Graph Neural Networks are fed with the graph models to provide the final prediction. The proposed solution has been tested in Spain showing a F1 score higher than 0.7. © 2022 The Author(s)","Graph Neural Networks; Online Social Networks; Open data; Touristic mobility; Twitter"
"Multi-dimensional shared representation learning with graph fusion network for Session-based Recommendation","2023","Information Fusion","10.1016/j.inffus.2022.11.021","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144046900&doi=10.1016%2fj.inffus.2022.11.021&partnerID=40&md5=97edbe5d062fb0e125fcb82e16f3b133","The Session-based Recommendation (SBR) system aims to forecast anonymous users’ short-term decisions. Many prior research have demonstrated that using Graph Neural Networks (GNN) and Recurrent Neural Networks (RNN) to solve SBR tasks can lead to excellent results. However, the existing SBR models only use single feature extraction method to represent an item in the recommendation process. These models either use the GNN methods which ignore the sequence location features in the training process or use RNN methods which cannot obtain the weight features of every item in the sequence. All of them fail to extract features of different dimensions at the same time, which results in low-quality item representations. To tackle the aforementioned issue, this research introduces a novel method called Multi-dimensional Shared Representation Learning (MSR). (i) To get multi-dimensional features, we use the multi-dimensional feature extraction in a double-flow way based on transformer layers and graph attention network (GAT) layers. (ii) Through the MSR module, we train the joint representation of items in the session by using multiple GNNs, then merge the multi-dimensional features by using an attention mechanism. A variety of experiments have been carried out and the simulation results demonstrate the designed strategy largely surpasses the state-of-the-art proposal in recommendation accuracy. © 2022 Elsevier B.V.","Attention mechanism; Graph neural networks; Session-based Recommendation; Transformer"
"Aggregation models in ensemble learning: A large-scale comparison","2023","Information Fusion","10.1016/j.inffus.2022.09.015","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139349858&doi=10.1016%2fj.inffus.2022.09.015&partnerID=40&md5=2d7528c0c467616615d1f2908cdb4f7d","In this work we present a large-scale comparison of 21 learning and aggregation methods proposed in the ensemble learning, social choice theory (SCT), information fusion and uncertainty management (IF-UM) and collective intelligence (CI) fields, based on a large collection of 40 benchmark datasets. The results of this comparison show that Bagging-based approaches reported performances comparable with XGBoost, and significantly outperformed other Boosting methods. In particular, ExtraTree-based approaches were as accurate as both XGBoost and Decision Tree-based ones while also being more computationally efficient. We also show how standard Bagging-based and IF-UM-inspired approaches outperformed the approaches based on CI and SCT. IF-UM-inspired approaches, in particular, reported the best performance (together with standard ExtraTrees), as well as the strongest resistance to label noise (together with XGBoost). Based on our results, we provide useful indications on the practical effectiveness of different state-of-the-art ensemble and aggregation methods in general settings. © 2022 Elsevier B.V.","Aggregation methods; Collective intelligence; Ensemble learning; Information fusion; Social choice theory; Uncertainty management"
"D-NISQ: A reference model for Distributed Noisy Intermediate-Scale Quantum computers","2023","Information Fusion","10.1016/j.inffus.2022.08.003","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136076598&doi=10.1016%2fj.inffus.2022.08.003&partnerID=40&md5=e10519da2e50a7b2c0ad54206f492fe9","Quantum computing has entered its mature life thanks to the availability of cloud-based Noisy Intermediate-Scale Quantum (NISQ) technologies. These devices allow quantum researchers and practitioners to design, develop and test quantum algorithms on actual hardware, paving the way toward new approaches in solving problems intractable by classical computers. However, in spite of these achievements in quantum technologies, the size of the problems that can be actually solved by quantum algorithms is still limited by the small number of qubits and the considerable noise in computation that still characterizes NISQ devices. As a consequence, there is a strong need of introducing innovative computing architectures able to interconnect a set of NISQ devices to increase the capabilities of current quantum computers of solving hard problems in a reliable way. In this paper, the concept of Distributed Noisy-Intermediate Scale Quantum (D-NISQ) is introduced as a reference computational model by which designing innovative frameworks where quantum devices interact to solve a complex problem by working cooperatively. In detail, the D-NISQ model consists of a hybrid and hierarchical architecture where classical and quantum processors interact to iteratively split up a problem into a collection of sub-problems, solve each one of them by means of a proper quantum algorithm, and fuse output quantum information so as to compute the final solution to the problem posed. As demonstrated by two case studies based on the well-known Grover's algorithm, a multi-threaded implementation of the D-NISQ reference model allows for greater reliability in solving problems by quantum computation. © 2022 Elsevier B.V.","Distributed architectures; Quantum algorithms; Quantum computing"
"FuAlign: Cross-lingual entity alignment via multi-view representation learning of fused knowledge graphs","2023","Information Fusion","10.1016/j.inffus.2022.08.002","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136676713&doi=10.1016%2fj.inffus.2022.08.002&partnerID=40&md5=c224e5e404f8371b61c63be8463dcca7","Cross-lingual entity alignment is essential in knowledge graph completion. Recently, knowledge representation learning (KRL) has gained remarkable achievements in cross-lingual entity alignment. Most existing methods first learn entity representations of different knowledge graphs and transform them into a unified space based on a seed set of pre-aligned entity pairs. However, the transformation is error-prone due to the distribution differences between the seed set and the whole entity set. This paper presents FuAlign, a novel cross-lingual entity alignment framework based on multi-view KRL of a pre-fused knowledge graph. FuAlign first fuses two matching knowledge graphs based on the given seed set. Then, it exploits multi-view representation learning to map the fused knowledge graph into a unified space. FuAlign improves the performance from two aspects. First, it represents entities in a unified embedding space, thus avoiding the error-prone transformation between different embedding spaces. Second, the proposed multi-view representation learning model captures different kinds of information such as semantics, entity context, and long-term entity dependency in knowledge graphs. We conduct extensive experiments to evaluate the performance of the proposed method. Experimental results show that FuAlign outperforms most baseline methods and achieves comparable performance with the Bert-based model. © 2022 Elsevier B.V.","Entity alignment; Entity embedding; Knowledge fusion; Knowledge graph"
"Distracted driving detection based on the fusion of deep learning and causal reasoning","2023","Information Fusion","10.1016/j.inffus.2022.08.009","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136460997&doi=10.1016%2fj.inffus.2022.08.009&partnerID=40&md5=60228e4a36888e9722a5e3e46f3e294f","Distracted driving is one of the key factors that cause drivers to ignore potential road hazards and then lead to accidents. Existing efforts in distracted behavior recognition are mainly based on deep learning (DL) methods, which identifies distracted behaviors by analyzing static characteristics of images. However, the convolutional neural network (CNN) — based DL methods lack the causal reasoning ability for behavior patterns. The uncertainty of driving behaviors, noise of the collected data, and occlusion between body agents, bring additional challenges to existing DL methods to recognize distracted behaviors continuously and accurately. Therefore, in this paper, we propose a distracted behavior recognition method based on the Temporal–Spatial double-line DL network (TSD-DLN) and causal And-or graph (C-AOG). TSD-DLN fuses the attention feature extracted from the dynamic optical flow information and the spatial feature of the single video frame to recognize the distracted driving posture. Furthermore, a causal knowledge fence based on C-AOG is fused with TSD-DLN to improve the recognition robustness. The C-AOG represents the causality of behavior state fluent change and adopts counterfactual reasoning to suppress behavior recognition failures caused by frame features distortion or occlusion between body agents. We compared the performance of the proposed method with other state-of-the-art (SOTA) DL methods on two public datasets and self-collected dataset. Experimental results demonstrate that proposed method significantly outperforms other SOTA methods when acquiring distracted driving behavior by processing consecutive frames. In addition, the proposed method exhibits accurate continuous recognition and robustness under incomplete observation scenarios. © 2022 Elsevier B.V.","Behavior recognition; Causal reasoning; Counterfactual reasoning; Deep learning network; Driving distraction detection"
"Multimodal and multicontrast image fusion via deep generative models","2022","Information Fusion","10.1016/j.inffus.2022.07.017","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135723814&doi=10.1016%2fj.inffus.2022.07.017&partnerID=40&md5=507ba235f31885ad3242ff40dc1dc598","Recently, it has become progressively more evident that classic diagnostic labels are unable to accurately and reliably describe the complexity and variability of several clinical phenotypes. This is particularly true for a broad range of neuropsychiatric illnesses such as depression and anxiety disorders or behavioural phenotypes such as aggression and antisocial personality. Patient heterogeneity can be better described and conceptualized by grouping individuals into novel categories, which are based on empirically-derived sections of intersecting continua that span both across and beyond traditional categorical borders. In this context, neuroimaging data (i.e. the set of images which result from functional/metabolic (e.g. functional magnetic resonance imaging, functional near-infrared spectroscopy, or positron emission tomography) and structural (e.g. computed tomography, T1-, T2- PD- or diffusion weighted magnetic resonance imaging) carry a wealth of spatiotemporally resolved information about each patient's brain. However, they are usually heavily collapsed a priori through procedures which are not learned as part of model training, and consequently not optimized for the downstream prediction task. This is due to the fact that every individual participant usually comes with multiple whole-brain 3D imaging modalities often accompanied by a deep genotypic and phenotypic characterization, hence posing formidable computational challenges. In this paper we design and validate a deep learning architecture based on generative models rooted in a modular approach and separable convolutional blocks (which result in a 20-fold decrease in parameter utilization) in order to a) fuse multiple 3D neuroimaging modalities on a voxel-wise level, b) efficiently convert them into informative latent embeddings through heavy dimensionality reduction, c) maintain good generalizability and minimal information loss. As proof of concept, we test our architecture on the well characterized Human Connectome Project database (n = 974 healthy subjects), demonstrating that our latent embeddings can be clustered into easily separable subject strata which, in turn, map to different phenotypical information (including organic, neuropsychological, personality variables) which was not included in the embedding creation process. The ability to extract meaningful and separable phenotypic information from brain images alone can aid in creating multi-dimensional biomarkers able to chart spatio-temporal trajectories which may correspond to different pathophysiological mechanisms unidentifiable to traditional data analysis approaches. In turn, this may be of aid in predicting disease evolution as well as drug response, hence supporting mechanistic disease understanding and also empowering clinical trials. © 2022 Elsevier B.V.","Deep autoencoder; Latent embeddings; Multimodal neuroimaging; Phenotype stratification; Precision medicine; Separable Convolutions"
"A model-driven network for guided image denoising","2022","Information Fusion","10.1016/j.inffus.2022.03.006","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130855243&doi=10.1016%2fj.inffus.2022.03.006&partnerID=40&md5=40fdbbaf54e36ca61ef934099f3abf88","Guided image denoising recovers clean target images by fusing guidance images and noisy target images. Several deep neural networks have been designed for this task, but they are black-box methods lacking interpretability. To overcome the issue, this paper builds a more interpretable network. To start with, an observation model is proposed to account for modality gap between target and guidance images. Then, this paper formulates a deep prior regularized optimization problem, and solves it by alternating direction method of multipliers (ADMM) algorithm. The update rules are generalized to design the network architecture. Extensive experiments conducted on FAIP and RNS datasets manifest that the novel network outperforms several state-of-the-art and benchmark methods regarding both evaluation metrics and visual inspection. © 2022 Elsevier B.V.","Guided image denoising; Modality gap; Multi-modal image denoising"
"Multi-attentive hierarchical dense fusion net for fusion classification of hyperspectral and LiDAR data","2022","Information Fusion","10.1016/j.inffus.2021.12.008","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122211409&doi=10.1016%2fj.inffus.2021.12.008&partnerID=40&md5=26e649b9314335d081af2240ded2aba8","With recent advance in Earth Observation techniques, the availability of multi-sensor data acquired in the same geographical area has been increasing greatly, which makes it possible to jointly depict the underlying land-cover phenomenon using different sensor data. In this paper, a novel multi-attentive hierarchical fusion net (MAHiDFNet) is proposed to realize the feature-level fusion and classification of hyperspectral image (HSI) with Light Detection and Ranging (LiDAR) data. More specifically, a triple branch HSI-LiDAR Convolutional Neural Network (CNN) backbone is first developed to simultaneously extract the spatial features, spectral features and elevation features of the land-cover objects. On this basis, hierarchical fusion strategy is adopted to fuse the oriented feature embeddings. In the shallow feature fusion stage, we propose a novel modality attention (MA) module to generate the modality integrated features. By fully considering the correlation and heterogeneity between different sensor data, feature interaction and integration is released by the proposed MA module. At the same time, self-attention modules are also adopted to highlight the modality specific features. In the deep feature fusion stage, the obtained modality specific features and modality integrated features are fused to construct the hierarchical feature fusion framework. Experiments on three real HSI-LiDAR datasets demonstrate the effectiveness of the proposed framework. The code will be public on https://github.com/SYFYN0317/-MAHiDFNet. © 2021 Elsevier B.V.","Hierarchical dense fusion strategy; HSI-LiDAR classification; Modality attention; Multi-sensor data fusion; self-attention"
"Deriving the personalized individual semantics of linguistic information from flexible linguistic preference relations","2022","Information Fusion","10.1016/j.inffus.2021.12.002","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121434726&doi=10.1016%2fj.inffus.2021.12.002&partnerID=40&md5=43e3943e02f36881c7578e8708f877e3","In group decision making, flexible linguistic preference relations (FLPRs) are very useful with the pairwise comparisons taking the form of flexible linguistic expressions (FLEs). Due to the fact that different decision makers have different understandings of words, this paper investigates the personalized individual semantics (PISs) of the linguistic information in FLPRs. Two optimization models are constructed to compute a linguistic distribution which is closest to an incomplete FLE. The FLPRs are transformed into fuzzy preference relations by using optimization models which maximize consistency and consensus of the fuzzy preference relations. The PISs of linguistic terms and subsets of the linguistic term set are obtained in this process. A group decision making model based on FLPRs is presented and a green supplier selection problem in automotive industry is solved by using the proposed model. The comparative analysis is presented to show the feasibility of the group decision making model. © 2021 Elsevier B.V.","Flexible linguistic expression; Group decision making; Linguistic distribution; Personalized individual semantics"
"Improving the performance of lung nodule classification by fusing structured and unstructured data","2022","Information Fusion","10.1016/j.inffus.2022.07.019","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135687086&doi=10.1016%2fj.inffus.2022.07.019&partnerID=40&md5=7815b23a6687bca082bf674124fa3c3c","We investigated the issue of improving the classification performance for pulmonary nodules by learning the fusion features of structured and unstructured data. Current strategies for lung nodule classification, such as radiomics methods and deep learning approaches, all share the flaw of only using the unstructured data of patients, which is always a collection of medical images (e.g., computed tomography (CT) scans, X-rays, and pathological sections), while ignoring the structured data (e.g., baseline demographics, clinical characteristics, and laboratory examinations). However, from a clinical perspective, all of this information is required for accurate patient diagnosis. Therefore, to exploit all patient information, we addressed a more difficult problem: jointly modeling the multimodal patient data. Two models are proposed to combine structured and unstructured data. One employs deep learning with a softmax classifier (the structured and unstructured data fusion neural network (SUDFNN)), and the other implements an extreme gradient boosting (XGBoost) classifier (the structured and unstructured data fusion XGBoost (SUDFX)). The annotated structured data in the extensible markup language (XML) file from the Lung Image Database Consortium and Image Database Resource Initiative (LIDC-IDRI) database and the CT scans from the LUng Nodule Analysis 2016 (LUNA16) dataset were used to validate our model. The results show that the performance of the model is significantly improved when introducing the structured data, regardless of the nodule cube size and which classifier is used. The rationale for the improvement with the addition of structured features is provided. The optimal accuracy, sensitivity, specificity, and area under the receiver operating characteristic (ROC) curve (AUC) values reached 0.936, 0.919, 0.956, and 0.971, respectively. Consequently, fusing structured and unstructured data can uncover more patient information and provide better decision support for the clinical diagnosis and treatment process, providing good application value and promotion prospects. © 2022 Elsevier B.V.","Computer-aided diagnosis (CAD); Convolutional neural networks （CNN）; Information fusion; Lung nodule classification; XGBoost"
"Ordinal and joint feedback mechanisms to support group consensus based on interval-valued number with self-confidence","2022","Information Fusion","10.1016/j.inffus.2022.07.021","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135720387&doi=10.1016%2fj.inffus.2022.07.021&partnerID=40&md5=60df74b123e60acd4b3d6db019ca49a7","This article proposes a framework of consensus reaching process based on interval-valued number with self-confidence involving two feedback mechanisms: (1) the ordinal feedback mechanism (OFM), and (2) the joint feedback mechanism (JFM). Firstly, a new concept called the interval-valued number with self-confidence (IVN-SC) is defined, which allows experts to express self-confidence (SC) when providing their evaluations by interval-valued number (IVN). In OFM, three types of discordant behaviours are explored from the perspective of IVN consensus and SC consensus, and then the corresponding personalized mechanisms for discordant behaviours are implemented to guarantee they both reach consensus threshold. While in JFM, the comprehensive consensus degree by combing the IVN and SC is presented to measure the agreement level among experts, and then a joint optimization model with IVN-SC is activated to support the discordant experts to reach the threshold value of group consensus. It explores that the JFM is less strict than the OFM because the former contains the compensatory aggregation operator while the latter does not. Finally, an illustrative example and comparative analysis are devised to testify the effectiveness of the proposed models. © 2022 Elsevier B.V.","Adjustment cost; Consensus; Group decision making; Joint feedback mechanism; Ordinal feedback mechanism; Self-Confidence"
"A novel multimodal fusion network based on a joint coding model for lane line segmentation","2022","Information Fusion","10.1016/j.inffus.2021.10.008","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119699661&doi=10.1016%2fj.inffus.2021.10.008&partnerID=40&md5=c4fdeb2a2aeabbbb2fc9f9628fbdc379","There has recently been growing interest in utilizing multimodal sensors to achieve robust lane line segmentation. In this paper, we introduce a novel multimodal fusion architecture from an information theory perspective, and demonstrate its practical utility using Light Detection and Ranging (LiDAR) camera fusion networks. In particular, we develop, for the first time, a multimodal fusion network as a joint coding model, where each single node, layer, and pipeline is represented as a channel. The forward propagation is thus equal to the information transmission in the channels. Then, we can qualitatively and quantitatively analyze the effect of different fusion approaches. We argue the optimal fusion architecture is related to the essential capacity and its allocation based on the source and channel. To test this multimodal fusion hypothesis, we progressively determine a series of multimodal models based on the proposed fusion methods and evaluate them on the KITTI and the A2D2 datasets. Our optimal fusion network achieves 85%+ lane line accuracy and 98.7%+ overall. The performance gap among the models will inform continuing future research into development of optimal fusion algorithms for the deep multimodal learning community. © 2021 Elsevier B.V.","Information theory; Lane line segmentation; Multimodal fusion; Neural Network; Semantic segmentation"
"Current advances and future perspectives of image fusion: A comprehensive review","2023","Information Fusion","10.1016/j.inffus.2022.09.019","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139032899&doi=10.1016%2fj.inffus.2022.09.019&partnerID=40&md5=af82a7b5b8305dcdc4687823dcc196c9","Multiple imaging modalities can be combined to provide more information about the real world than a single modality alone. Infrared images discriminate targets with respect to their thermal radiation differences, and visible images are promising for texture details. On the other hand, polarized images deliver intensity and polarization information, and multispectral images dispense the spatial, spectral, and temporal information depending upon the environment. Different sensors provide images with different characteristics, such as type of degradation, important features, textural attributes, etc. Several stimulating tasks have been explored in the last decades based on algorithms, performance assessments, processing techniques, and prospective applications. However, most of the reviews and surveys have not properly addressed the issues of additional possibilities of imaging fusion. The primary goal of this paper is to give a thorough overview of image fusion approaches, including associated background and current breakthroughs. We introduce image fusion and categorize the methods based on conventional image processing, deep learning (DL) architectures, and fusion scenarios. Further, we emphasize the recent DL developments in various image fusion scenarios. However, there are still several difficulties to overcome, including developing more advanced algorithms to support more dependable and real-time practical applications, discussed in future perspectives. This study can assist researchers in coping with multiple imaging modalities, recent fusion developments, and future perspectives. © 2022","Deep learning; Image fusion; Multi-modal; Polarization; Transform domain"
"Survey on federated learning threats: Concepts, taxonomy on attacks and defences, experimental study and challenges","2023","Information Fusion","10.1016/j.inffus.2022.09.011","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138467603&doi=10.1016%2fj.inffus.2022.09.011&partnerID=40&md5=273b7443e7c33d4dc20387d54eebc3de","Federated learning is a machine learning paradigm that emerges as a solution to the privacy-preservation demands in artificial intelligence. As machine learning, federated learning is threatened by adversarial attacks against the integrity of the learning model and the privacy of data via a distributed approach to tackle local and global learning. This weak point is exacerbated by the inaccessibility of data in federated learning, which makes the protection against adversarial attacks harder and evidences the need to furtherance the research on defence methods to make federated learning a real solution for safeguarding data privacy. In this paper, we present an extensive review of the threats of federated learning, as well as as their corresponding countermeasures, attacks versus defences. This survey provides a taxonomy of adversarial attacks and a taxonomy of defence methods that depict a general picture of this vulnerability of federated learning and how to overcome it. Likewise, we expound guidelines for selecting the most adequate defence method according to the category of the adversarial attack. Besides, we carry out an extensive experimental study from which we draw further conclusions about the behaviour of attacks and defences and the guidelines for selecting the most adequate defence method according to the category of the adversarial attack. Finally, we present our learned lessons and challenges. © 2022 Elsevier B.V.","Adversarial attacks; Defences; Federated learning; Privacy attacks"
"Multi-band remote sensing image fusion based on collaborative representation","2023","Information Fusion","10.1016/j.inffus.2022.09.004","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138185131&doi=10.1016%2fj.inffus.2022.09.004&partnerID=40&md5=d8e1a31ba00e6b6ce89bde4cd83c75dc","Remote sensing image fusion extracts the spatial information of the panchromatic (PAN) image to sharpen the geometric structure of a multi-spectral (MS) image. Traditional algorithms that solve the fusion image problem by applying various transformations often result in some losses of spatial and spectral details. To improve the quality of the fusion result, we develop a novel fusion method based on collaborative representation for multi-band remote sensing images. In the developed collaborative representation model, a spectral preservation coefficient based on the spectral contribution and spectral-spatial dependency is designed to retain the spectral in the low-resolution MS (LRMS) image. An intensity modulation coefficient based on the spatial difference between the PAN and MS images that is spectral dependent is designed to adaptively recover and modulate the spatial of the MS image. Through the proposed collaborative representation model, the LRMS, low-resolution PAN, and PAN images, and the designed coefficients collaboratively represent the fusion image. The results of the experiment on various satellite datasets show that the method we develop is effective and robust in enhancing pansharpening. © 2022 Elsevier B.V.","Collaborative representation; Multi-band remote sensing image; Pansharpening; Spectral dependency"
"Heterogeneous relational reasoning in knowledge graphs with reinforcement learning","2022","Information Fusion","10.1016/j.inffus.2022.07.001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134891019&doi=10.1016%2fj.inffus.2022.07.001&partnerID=40&md5=78a570ce1fef6ea1b33267459bbd1b0b","Path-based relational reasoning over knowledge graphs has become increasingly popular due to a variety of downstream applications such as question answering in dialogue systems, fact prediction, and recommendation systems. In recent years, reinforcement learning (RL) based solutions for knowledge graphs have been demonstrated to be more interpretable and explainable than other deep learning models. However, the current solutions still struggle with performance issues due to incomplete state representations and large action spaces for the RL agent. We address these problems by developing HRRL (Heterogeneous Relational reasoning with Reinforcement Learning), a type-enhanced RL agent that utilizes the local heterogeneous neighborhood information for efficient path-based reasoning over knowledge graphs. HRRL improves the state representation using a graph neural network (GNN) for encoding the neighborhood information and utilizes entity type information for pruning the action space. Extensive experiments on real-world datasets show that HRRL outperforms state-of-the-art RL methods and discovers more novel paths during the training procedure, demonstrating the explorative power of our method. © 2022 The Authors","Knowledge graphs; Reinforcement learning; Relational reasoning"
"Opinion Evolution Model for Online Reviews from the Perspective of Value Co-creation","2022","Information Fusion","10.1016/j.inffus.2022.07.018","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135513278&doi=10.1016%2fj.inffus.2022.07.018&partnerID=40&md5=e8a2d7ca6d1d63ff94d4e753acb05ce6","Opinions from online reviews reflect consumers’ value perception toward products and services. However, the evolution mechanism of online opinions in the process of value co-creation resulting from an interaction between heterogeneous consumers and merchants remains unclear. In this context, we propose an opinion evolution model based on the advanced Hegselmann–Krause model from the value co-creation perspective to explore the online opinions in a merchant–consumer interaction process. Simulation results show that the heterogeneity of consumers, merchants’ review display methods, and investment behaviors have an impact on online opinions and merchants’ profits. Radical and active consumers are less likely satisfied with merchants’ products or services; whereas balanced, robust, and conservative consumers are more likely satisfied. In addition, the review volume displayed per page has an impact on online opinions and merchants’ profits but becomes invalid when a certain threshold is exceeded. The brand effect can significantly increase online opinions and merchants’ profits only when such an effect exceeds a certain threshold. Furthermore, findings indicate that merchants should not only be concerned about short-term investment in initial products/services quality but also on the long-term investment in the brand effect. They should also avoid the idea of getting once-and-for-all or free-riding. © 2022","Hegselmann–Krause Model; Merchant–Consumer Interaction; Online Opinion Evolution; Online Reviews; Value Co-creation"
"Constraint-Induced Symmetric Nonnegative Matrix Factorization for Accurate Community Detection","2023","Information Fusion","10.1016/j.inffus.2022.08.031","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138073420&doi=10.1016%2fj.inffus.2022.08.031&partnerID=40&md5=bb5de8762340b0959611c3cb30ed281a","As a fundamental characteristic of an undirected network, community reveals its networking organization and functional mechanisms, making community detection be a highly-interesting issue in network representation learning. With great interpretability, a symmetric and nonnegative matrix factorization (SNMF)-based approach is frequently adopted to tackle this issue. However, it only adopts a unique feature matrix for describing the symmetry of an undirected network, which unfortunately results in a reduced feature space that evidently impairs its representation learning ability. Motivated by this discovery, this paper proposes a novel Constraint-induced Symmetric Nonnegative Matrix Factorization (C-SNMF) model that adopts three-fold ideas: a) Representing a target undirected network with multiple latent feature matrices, thus preserving its representation learning capacity; b) Incorporating a symmetry-regularizer into its objective function, which preserves the symmetry of the learnt low-rank approximation to the adjacency matrix, thereby making the resultant detector precisely illustrate the target network's symmetry; and c) Introducing a graph-regularizer that preserves local invariance of the network's intrinsic geometry into its learning objective, thus making the achieved detector well-aware of community structure within the target network. Note that the regularization coefficients are selected according to the modularity of the learnt community structure on the training data only, thereby greatly improving the achieved model's practical significance for real applications. Experimental results on six real-world networks demonstrate that the proposed C-SNMF model significantly outperforms the benchmarks and state-of-the-art models in achieving highly-accurate community detection results. © 2022","Community Detection; Information Fusion; Multiple Constraints; Network Representation Learning; Nonnegative Matrix Factorization; Social Network; Symmetry-regularization; Undirected Network"
"H∞ fusion estimation for uncertain discrete time-delayed Hamiltonian systems with sensor saturations: An event-triggered approach","2022","Information Fusion","10.1016/j.inffus.2022.06.004","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133704963&doi=10.1016%2fj.inffus.2022.06.004&partnerID=40&md5=4aa9c305b4fdfce1665872cafcfb9986","This paper is concerned with the event-triggered H∞ fusion estimation problem for uncertain discrete-time Hamiltonian systems with time-varying delays and sensor saturations. In order to improve the efficiency of resource utilization, a component-based event-triggered mechanism is implemented on the communication path from sensors to the estimator, where each output is sent only when a prescribed event-triggering condition is satisfied. By considering the structural characteristics of discrete-time Hamiltonian systems and utilizing the Lyapunov–Krasovskii stability, sufficient conditions are established to guarantee the augmented system (i.e., the underlying system combined with the estimation error dynamics) is locally exponentially stable. Meanwhile, the estimator gain is acquired by resorting the approach of certain matrix inequality. Finally, two examples are provided to demonstrate the effectiveness of the proposed scheme. © 2022 Elsevier B.V.","Discrete-time Hamiltonian systems; Event-triggered transmission; H<sub>∞</sub> fusion estimation; Sensor saturations; Time-varying delays"
"A Synchronous Holo-Balancing Method for Flexible Rotors Based on the Modified Initial Phase Vector","2023","Information Fusion","10.1016/j.inffus.2022.09.013","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138332055&doi=10.1016%2fj.inffus.2022.09.013&partnerID=40&md5=7e09de64e6892a9118fca97e511fd832","Reducing the vibration responses caused by the unbalance of the rotor is a crucial technology to ensure the safe and efficient operation of high-speed rotating machinery. For the flexible rotor system, the unbalance responses of rotors vary in different radial directions due to the anisotropic stiffness. The holospectrum technique using multi-sensor fusion provides ideas to solve this issue. The standard balancing method based on the holospectrum technique takes the Initial Phase Vector (IPV) as the balancing object, which could not represent the unbalance of flexible rotors correctly. In addition, the operating speed of the flexible rotor is generally higher than the first critical speed (FCS), making it necessary to fulfill the balancing of the first two modal shapes respectively in two steps. The above-mentioned procedure is not only very dangerous but also requires a large number of test runs resulting in corresponding wastages. In order to solve the issues mentioned above, a synchronous holo-balancing method for flexible rotors based on the modified initial phase vector (MIPV) is developed in this paper. Firstly, to tackle the limitation of IPV, the concept of equivalent rotating frequency circle is presented and then the MIPV is proposed as a new balancing object. MIPV could linearly represent the unbalance of the flexible rotor and increase the accuracy of holo-balancing. Secondly, the synchronous holo-balancing method is carried out to achieve the balancing at the speed below the FCS, reducing the complexity and danger of test runs at high operating speeds. And the synchronous balancing procedures based on the MIPV are further summarized in detail. Finally, two experimental results with different operating speeds and probe installations validate the feasibility and effectiveness of the proposed method. Compared with other traditional balancing methods, the proposed method can minimize the residual vibration and achieve state-of-the-art performances. © 2022","Holospectrum; Modified initial phase vector; Multi-sensor information fusion; Rotor system; Synchronous holo-balancing; Vibration"
"MetaPro: A computational metaphor processing model for text pre-processing","2022","Information Fusion","10.1016/j.inffus.2022.06.002","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133306828&doi=10.1016%2fj.inffus.2022.06.002&partnerID=40&md5=693014d673c6256b9d01d8e3bd19d087","Metaphor is a special linguistic phenomenon, challenging diverse natural language processing tasks. Previous works focused on either metaphor identification or domain-specific metaphor interpretation, e.g., interpreting metaphors with a specific part-of-speech, metaphors in a specific application scenario or metaphors with specific concepts. These methods cannot be used directly in everyday texts. In this paper, we propose a metaphor processing model, termed MetaPro, which integrates metaphor identification and interpretation modules for text pre-processing. To the best of our knowledge, this is the first end-to-end metaphor processing approach in the present field. MetaPro can identify metaphors in a sentence on token-level, paraphrasing the identified metaphors into their literal counterparts, and explaining metaphoric multi-word expressions. It achieves state-of-the-art performance in the evaluation of sub-tasks. Besides, the model can be used as a text pre-processing method to support downstream tasks. We examine the utility of MetaPro text pre-processing on a news headline sentiment analysis task. The experimental results show that the performance of sentiment analysis classifiers can be improved with the pre-processed texts. © 2022 Elsevier B.V.","Metaphor identification; Metaphor interpretation"
"ContrXT: Generating contrastive explanations from any text classifier","2022","Information Fusion","10.1016/j.inffus.2021.11.016","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85120957434&doi=10.1016%2fj.inffus.2021.11.016&partnerID=40&md5=a42a5d4531a6fa0aac15324a6eb2bdb9","The need for explanations of ML systems is growing as new models outperform their predecessors while becoming more complex and less comprehensible for their end-users. Though several XAI methods have been proposed in recent years, not enough attention was paid to explaining how models change their behaviour in contrast with previous ones (e.g., due to retraining). In such cases, an XAI system should explain why the model changes its predictions concerning past outcomes. Capturing and understanding such differences is crucial, as the need for trust is key in any application to support human-AI decision-making processes. This is the idea of ContrXT, a novel approach that (i) traces the decision criteria of a black box text classifier by encoding the changes in the decision logic through Binary Decision Diagrams. Then (ii) it provides global, model-agnostic, Time-Contrastive (T-contrast) explanations in natural language, estimating why – and to what extent – the model has modified its behaviour over time. We implemented and evaluated ContrXT over several supervised ML models trained on a benchmark dataset and a real-life application, showing it is effective in catching majorly changed classes and in explaining their variation through a user study. The approach has been implemented, and it is available to the community both as a python package and through REST API, providing contrastive explanations as a service. © 2021 Elsevier B.V.","Contrastive explanation methods for XAI; Post-hoc explainability; XAI interpretability of text classifiers"
"Multi-level information fusion with motion constraints: Key to achieve high-precision gait analysis using low-cost inertial sensors","2023","Information Fusion","10.1016/j.inffus.2022.09.009","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138040871&doi=10.1016%2fj.inffus.2022.09.009&partnerID=40&md5=6b248a7d7f26f27ca9750196397d64f5","Gait can reflect locomotion and physical condition and thus is used to assess people's health. Traditional high-precision gait analysis devices are expensive and are limited to laboratory conditions, so the trend is to use wearable devices to analyze gait. The existing wearable inertial-based gait-analysis methods have stride-length and foot-clearance estimation accuracy of 2.0 cm to 5.0 cm (in root mean square) and have limitations. They have not considered the regularity of the movement between the toe and the heel, the varying dual-feet distance due to foot dynamics, and the diversity of sensors used. Involving these factors, this paper achieves an improved gait-analysis system that provides stride-length and foot-clearance accuracy of 1.5 cm and 1.0 cm, respectively. Such accuracy is state-of-the-art for low-cost inertial systems and is even competitive with those from visual-sensor-based gait-analysis systems. A key to the proposed method is a new multi-level information fusion architecture and the extraction of human-walking constraints. The information-fusion architecture involves data fusion from the sensor, single-foot, and dual-foot levels. Two gait-characteristic-based motion constraints are presented to achieve such fusion, including the toe-heel constant distance constraint and the dual-foot flexible distance constraint. To implement these constraints, a constrained Kalman filter is constructed. The corresponding hardware system has been designed using multiple dollar-level inertial measurement units. © 2022","Data fusion; Gait parameters; Inertial sensors; MEMS sensors; Motion constraint"
"Tabular data: Deep learning is not all you need","2022","Information Fusion","10.1016/j.inffus.2021.11.011","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85120921985&doi=10.1016%2fj.inffus.2021.11.011&partnerID=40&md5=b76b1e41691e4c92e052db3818d02de8","A key element in solving real-life data science problems is selecting the types of models to use. Tree ensemble models (such as XGBoost) are usually recommended for classification and regression problems with tabular data. However, several deep learning models for tabular data have recently been proposed, claiming to outperform XGBoost for some use cases. This paper explores whether these deep models should be a recommended option for tabular data by rigorously comparing the new deep models to XGBoost on various datasets. In addition to systematically comparing their performance, we consider the tuning and computation they require. Our study shows that XGBoost outperforms these deep models across the datasets, including the datasets used in the papers that proposed the deep models. We also demonstrate that XGBoost requires much less tuning. On the positive side, we show that an ensemble of deep models and XGBoost performs better on these datasets than XGBoost alone. © 2021 Elsevier B.V.","Deep neural networks; Hyperparameter optimization; Tabular data; Tree-based models"
"An emotion role mining approach based on multiview ensemble learning in social networks","2022","Information Fusion","10.1016/j.inffus.2022.07.010","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135392517&doi=10.1016%2fj.inffus.2022.07.010&partnerID=40&md5=c2345630741d8a731ba4ae0fbc85dc00","Emotion is a status that combines people's feelings, thoughts, and behaviors, and plays a crucial role in communication among people. Large studies suggest that human emotions can also be conveyed through online interactions. Previous studies have addressed the mechanism of emotional contagion; however, emotional contagion, through users of online social networks, has not yet been thoroughly researched. Therefore, in this study, initially, the definition of emotion roles, which may play an important role in emotional contagion, is introduced. On this basis, an emotion role mining approach based on multiview ensemble learning (ERM-ME) is proposed to detect emotion roles in social networks by fusing the information contained in different features. The ERM-ME approach includes three stages: detection of emotional communities, local fusion, and global fusion. First, ERM-ME divides emotional communities based on user emotional preferences. Then, emotional features are employed to train basic classifiers, which are then combined into meta-classifiers. Finally, an accuracy-based weighted voting scheme is used to integrate the results of meta-classifiers to achieve a more accurate and comprehensive classification. Experiments and evaluations are performed using Flickr and Microblog datasets to verify the practicability and effectiveness of the proposed method. Extensive experimental results show that the proposed approach outperforms alternative methods. The micro F-score is used as an evaluation indicator. Using the ERM-ME approach, the indicator is improved by approximately 1.09%–14.57% on Flickr and 5.19%–8.95% on Microblog, compared with Graph Convolutional Network, random forest, AdaBoost, bagging, and stacking. © 2022 Elsevier B.V.","Emotion contagion; Emotion role; Ensemble learning; Social network"
"Multimodal Co-learning: Challenges, applications with datasets, recent advances and future directions","2022","Information Fusion","10.1016/j.inffus.2021.12.003","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121656512&doi=10.1016%2fj.inffus.2021.12.003&partnerID=40&md5=230a15a10ff7a513bd60fcce9d5aabaa","Multimodal deep learning systems that employ multiple modalities like text, image, audio, video, etc., are showing better performance than individual modalities (i.e., unimodal) systems. Multimodal machine learning involves multiple aspects: representation, translation, alignment, fusion, and co-learning. In the current state of multimodal machine learning, the assumptions are that all modalities are present, aligned, and noiseless during training and testing time. However, in real-world tasks, typically, it is observed that one or more modalities are missing, noisy, lacking annotated data, have unreliable labels, and are scarce in training or testing, and or both. This challenge is addressed by a learning paradigm called multimodal co-learning. The modeling of a (resource-poor) modality is aided by exploiting knowledge from another (resource-rich) modality using the transfer of knowledge between modalities, including their representations and predictive models. Co-learning being an emerging area, there are no dedicated reviews explicitly focusing on all challenges addressed by co-learning. To that end, in this work, we provide a comprehensive survey on the emerging area of multimodal co-learning that has not been explored in its entirety yet. We review implementations that overcome one or more co-learning challenges without explicitly considering them as co-learning challenges. We present the comprehensive taxonomy of multimodal co-learning based on the challenges addressed by co-learning and associated implementations. The various techniques, including the latest ones, are reviewed along with some applications and datasets. Additionally, we review techniques that appear to be similar to multimodal co-learning and are being used primarily in unimodal or multi-view learning. The distinction between them is documented. Our final goal is to discuss challenges and perspectives and the important ideas and directions for future work that we hope will benefit for the entire research community focusing on this exciting domain. © 2021 Elsevier B.V.","Missing modalities; Multimodal co-learning; Multimodal datasets; Multimodal deep learning; Multimodal taxonomy"
"Intentional bounded rationality methodology to assess the quality of decision-making approaches with latent alternative performances","2023","Information Fusion","10.1016/j.inffus.2022.08.019","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137101209&doi=10.1016%2fj.inffus.2022.08.019&partnerID=40&md5=41960161b495bdb673030787eb65c643","Expert's judgments have been crucial in the development of decision theory; however, what criterion to use in the selection of experts remains an issue to address. Decision support techniques proposed to improve the quality of expert judgment decision making consider a demonstrated inconsistency of the judgments expressed by an expert as a criterion of exclusion in the decision-making process of such expert. Although consistency appears to be a desirable condition to qualify as “expert”, little is known about the quality of the decisions made imposing consistency as the expert qualifying condition. This paper proposes a simulation methodology, based on an automaton programmed to make decisions in an intended but bounded rational way, to assess the cost-benefit of different aspects of decision support techniques. Within this methodology, the imposition of the consistency condition in the selection of experts is studied. In particular, the paper shows with a case study example that the Analytical hierarchy process (AHP) decision support technique expected payoff is at most 5% higher when implementing Saaty's consistency criterion of the expert's judgments than when the consistency criterion is not considered. © 2022","Analysis of decision support techniques; Error; Inconsistency; Intentional bounded rationality methodology"
"EPMDroid: Efficient and privacy-preserving malware detection based on SGX through data fusion","2022","Information Fusion","10.1016/j.inffus.2021.12.006","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124306466&doi=10.1016%2fj.inffus.2021.12.006&partnerID=40&md5=0c990c7069856896b2b3c6243c76deb0","Android has stood at a predominant position in mobile operating systems for many years. However, its popularity and openness make it a desirable target of malicious attackers. There is an increasing need for mobile malware detection. Existing analysis methods fall into two categories, i.e., static analysis and dynamic analysis. The dynamic analysis is more effective and timely than the static one, but it incurs a high computational overhead, thus cannot be deployed in resource-constrained mobile devices. Existing studies solve this issue by outsourcing malware detection to the cloud. However, the privacy of mobile app runtime data uploaded to the cloud is not well preserved during both detection model training and malware detection. Numerous efforts have been made to preserve privacy with cryptography, which suffers from high computational overhead and low flexibility. To address these issues, in this paper, we propose an Intel SGX-empowered mobile malware detection scheme called EPMDroid. We also design a probabilistic data structure based on cuckoo filters, named CuckooTable, to effectively fuse features for detection and achieve high space efficiency. We conduct both theoretical analysis and real-world data based tests on EPMDroid performance. Experimental results show that EPMDroid can speed up malware detection by up to 43.8 times and save memory space by up to 3.7 times with the same accuracy, as compared to a baseline method. © 2021","Data fusion; Intel SGX; Malware detection; Privacy preservation; Probabilistic data structures"
"Explaining the impact of source behaviour in evidential reasoning","2022","Information Fusion","10.1016/j.inffus.2021.11.007","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85120878250&doi=10.1016%2fj.inffus.2021.11.007&partnerID=40&md5=c3c5f5aa29f7018053d79f0496ba39ab","Explanation abilities are required for data-driven models, where the high number of parameters may render its internal reasoning opaque to users. Despite the natural transparency brought by the graphical model structure of Bayesian networks, decisions trees or valuation networks, additional explanation abilities are still required due to both the complexity of the problem as well as the consequences of the decision to be taken. Threat assessment is an example of such a complex problem in which several sources with partially unknown behaviour provide information on distinct but related frames of discernment. In this paper, we propose a solution as an evidential network with explanation abilities to detect and investigate threat to maritime infrastructure. We propose a post-hoc explanation approach to an already transparent by design threat assessment model, combining feature relevance and natural language explanations with some visual support. To this end, we extend the sensitivity analysis method of generation of explanations for evidential reasoning to a multi-source model where sources can have several and disparate behaviours. Natural language explanations are generated on the basis of a series of sensitivity measures quantifying the impact of both direct reports and source models. We conclude on challenges to be addressed in future work. © 2021","Belief functions; Explainability; Graphical models; Information fusion; Maritime; Sensitivity; Threat assessment"
"Using artificial intelligence and data fusion for environmental monitoring: A review and future perspectives","2022","Information Fusion","10.1016/j.inffus.2022.06.003","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133352034&doi=10.1016%2fj.inffus.2022.06.003&partnerID=40&md5=6d01935fe28cf2edf2fb201ee512e8ea","Analyzing satellite images and remote sensing (RS) data using artificial intelligence (AI) tools and data fusion strategies has recently opened new perspectives for environmental monitoring and assessment. This is mainly due to the advancement of machine learning (ML) and data mining approaches, which facilitate extracting meaningful information at a large scale from geo-referenced and heterogeneous sources. This paper presents the first review of AI-based methodologies and data fusion strategies used for environmental monitoring, to the best of the authors’ knowledge. The first part of the article discusses the main challenges of geographical image analysis. Thereafter, a well-designed taxonomy is introduced to overview the existing frameworks, which have been focused on: (i) detecting different environmental impacts, e.g. land cover land use (LULC) change, gully erosion susceptibility (GES), waterlogging susceptibility (WLS), and land salinity and infertility (LSI); (ii) analyzing AI models deployed for extracting the pertinent features from RS images in addition to data fusion techniques used for combining images and/or features from heterogeneous sources; (iii) describing existing publicly-shared and open-access datasets; (iv) highlighting most frequent evaluation metrics; and (v) describing the most significant applications of ML and data fusion for RS image analysis. This is followed by an overview of existing works and discussions highlighting some of the challenges, limitations and shortcomings. To provide the reader with insight into real-world applications, two case studies illustrate the use of AI for classifying LULC changes and monitoring the environmental impacts due to dams’ construction, where classification accuracies of 98.57% and 97.05% have been reached, respectively. Lastly, recommendations and future directions are drawn. © 2022 Elsevier B.V.","Artificial intelligence; Data fusion; Environmental monitoring; Evaluation metrics; Land cover and land use; Remote sensing images"
"Distributed detection of sparse signals with censoring sensors in clustered sensor networks","2022","Information Fusion","10.1016/j.inffus.2022.03.002","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127145650&doi=10.1016%2fj.inffus.2022.03.002&partnerID=40&md5=f76d34fff73bf616bee59fdcca640bf1","In this paper, we explore the distributed detection of sparse signals in energy-limited clustered sensor networks (CSNs). For this problem, the centralized detector based on locally most powerful test (LMPT) methodology that uses the analog data transmitted by all the sensor nodes in CSNs can be easily realized according to the prior work. However, for the centralized LMPT detector, the energy consumption caused by data transmission is excessively high, which makes its implementation in CSNs with limited energy supply impractical. To address this issue, we propose a new detector by combining the advantages of censoring and LMPT strategies, in which both the cluster head (CLH) nodes and the ordinary (ORD) nodes only send data deemed to be informative enough and the fusion center (FC) fuses the received data based on LMPT methodology. The detection performance of the proposed detector, characterized by Fisher Information, is analyzed in the asymptotic regime. Also, we analytically derive the relationship between the detection performance of the proposed censoring-based LMPT (cens-LMPT) detector and the communication rates, both of which are controlled by the censoring thresholds. We present an illustrative example by considering the detection problem with 2-CSNs, i.e., CSNs in which each cluster contains two nodes, and provide corresponding theoretical analysis and simulation results. © 2022","Censoring; Clustered sensor networks; Distributed detection; Locally most powerful tests; Sparse signals"
"A novel quantum model of mass function for uncertain information fusion","2023","Information Fusion","10.1016/j.inffus.2022.08.030","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138188591&doi=10.1016%2fj.inffus.2022.08.030&partnerID=40&md5=bbfda90a61b0266f110c4381d01ef3e4","Understanding the uncertainty involved in a mass function is a central issue in Dempster–Shafer evidence theory for uncertain information fusion. Recent advances suggest to interpret the mass function from a view of quantum theory. However, existing studies do not truly implement the quantization of evidence. In order to solve the problem, a usable quantization scheme for mass function is studied in this paper. At first, a novel quantum model of mass function is proposed, which effectively embodies the principle of quantum superposition. Then, a quantum averaging operator is designed to obtain the quantum average of evidence, which not only retains many basic properties, for example idempotency, commutativity, and quasi-associativity, required by a rational approach for uncertain information fusion, but also yields some new characters, namely nonlinearity and globality, caused by the quantization of mass functions. At last, based on the quantum averaging operator, a new rule called quantum average combination rule is developed for the fusion of multiple pieces of evidence, which is compared with other representative average-based combination methods to show its performance. Numerical examples and applications for classification tasks are provided to demonstrate the effectiveness of the proposed quantum model, averaging operator, and combination rule. © 2022 Elsevier B.V.","Dempster–Shafer evidence theory; Information fusion; Mass function; Quantum probability"
"Unified gradient- and intensity-discriminator generative adversarial network for image fusion","2022","Information Fusion","10.1016/j.inffus.2022.07.016","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135955602&doi=10.1016%2fj.inffus.2022.07.016&partnerID=40&md5=22fea08a0a1cee2afc30f0bca3bc0afb","This study proposes a unified gradient- and intensity-discriminator generative adversarial network for various image fusion tasks, including infrared and visible image fusion, medical image fusion, multi-focus image fusion, and multi-exposure image fusion. On the one hand, we unify all fusion tasks into discriminating a fused image's gradient and intensity distributions based on a generative adversarial network. The generator adopts a dual-encoder–single-decoder framework to extract source image features by using different encoder paths. A dual-discriminator is employed to distinguish the gradient and intensity, ensuring that the generated image contains the desired geometric structure and conspicuous information. The dual adversarial game can tackle the generative adversarial network's mode collapse problem. On the other hand, we define a loss function based on the gradient and intensity that can be adapted to various fusion tasks by using varying relevant parameters with the source images. Qualitative and quantitative experiments on publicly available datasets demonstrate our method's superiority over state-of-the-art methods. © 2022 Elsevier B.V.","Generative adversarial network; Gradient; Image fusion; Intensity"
"A novel motion-based online temporal calibration method for multi-rate sensors fusion","2022","Information Fusion","10.1016/j.inffus.2022.07.004","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135533908&doi=10.1016%2fj.inffus.2022.07.004&partnerID=40&md5=0ad680b1feaa389bd9d01e435adc3eee","Accurate and robust calibration is an essential prerequisite for multi-rate sensors fusion. However, most existing calibration methods ignore the temporal calibration and assumed the timestamps of the multi-rate sensors are precisely aligned; more importantly, many approaches are designed for offline calibration. For these reasons, this paper develops a novel online temporal calibration method for multi-rate sensors fusion based on the motion constrains of the sensors. In this new calibration framework, the high update rate inertial measurement unit (IMU) is utilized as the unified calibrating references, while other moderate or low-frequency target sensors can be estimated based on the reference IMU. As a result, the targetless, online, and high-precision temporal self-calibration can be achieved. During the calibration, an improved multi-state constraint Kalman filter (I-MSCKF) algorithm is proposed for both position and temporal states estimation of the multi-rate sensors to establish a multi-constraint filter and correct the temporal offset error in a real-time manner. Furthermore, the motion constraints models in the two-dimensional (2D) planar and three-dimensional (3D) space are developed from per-sensor ego-motion to enhance the robust and reliable abilities of the proposed temporal self-calibration method. Experimental results demonstrate that the proposed method can accurately and online estimate the temporal offset error and transformation parameters, which significantly improves the performance of moving trajectory estimation for robots equipped with the multi-rate sensors. © 2022 Elsevier B.V.","Motion constraints; Multi-rate sensors fusion; Temporal offset; Temporal self-calibration"
"Multi-focus image fusion with deep residual learning and focus property detection","2022","Information Fusion","10.1016/j.inffus.2022.06.001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133280698&doi=10.1016%2fj.inffus.2022.06.001&partnerID=40&md5=f958cabf07851883e57bcfabf0f0a717","Multi-focus image fusion methods can be mainly divided into two categories: transform domain methods and spatial domain methods. Recent emerged deep learning (DL)-based methods actually satisfy this taxonomy as well. In this paper, we propose a novel DL-based multi-focus image fusion method that can combine the complementary advantages of transform domain methods and spatial domain methods. Specifically, a residual architecture that includes a multi-scale feature extraction module and a dual-attention module is designed as the basic unit of a deep convolutional network, which is firstly used to obtain an initial fused image from the source images. Then, the trained network is further employed to extract features from the initial fused image and the source images for a similarity comparison, aiming to detect the focus property of each source pixel. The final fused image is obtained by selecting corresponding pixels from the source images and the initial fused image according to the focus property map. Experimental results show that the proposed method can effectively preserve the original focus information from the source images and prevent visual artifacts around the boundary regions, leading to more competitive qualitative and quantitative performance when compared with the state-of-the-art fusion methods. © 2022 Elsevier B.V.","Convolutional neural networks; Multi-focus image fusion; Residual learning; Spatial domain methods; Transform domain methods"
"A linguistic information granulation model based on best-worst method in decision making problems","2023","Information Fusion","10.1016/j.inffus.2022.08.015","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139250034&doi=10.1016%2fj.inffus.2022.08.015&partnerID=40&md5=69dd102bc0774c2c0394a585be8e6b45","In the elicitation of decision makers’ fuzzy and uncertain assessments, linguistic terms are natural and efficient as the preference modeling tools. Although the linguistic variables are available, they would not be operational without any detailed quantification. Motivated by the flexibility of information granularity, this paper develops information granules to represent linguistic terms in the form of intervals and interval type-2 fuzzy sets (IT2FSs) in best worst method (BWM). The development is aimed at minimizing inconsistency in the decision making (DM) process to ensure the rationality of the assessments provided by decision makers. Furthermore, the input and output based consistencies of BWM are considered. The granulation of entries of pairwise comparison vectors are the foundation of BWM to formulate an optimization problem where particle swarm optimization (PSO) algorithm serves as the optimization framework. Both individual and group decision making (GDM) scenarios are taken into consideration. For the GDM process, a performance index for measuring the group consensus is also proposed. Several examples and validity analysis are covered to illustrate the major ideas of this study. Finally, as a case study, a recommendation of the sequence of visiting tourist attractions in Wuhan and the corresponding comparative analysis are represented. © 2022 Elsevier B.V.","Best worst method; Group consensus; Information granularity; Interval type-2 fuzzy sets; Linguistic elicitation"
"Radar sensor network resource allocation for fused target tracking: A brief review","2022","Information Fusion","10.1016/j.inffus.2022.06.009","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133912298&doi=10.1016%2fj.inffus.2022.06.009&partnerID=40&md5=6cc67fc2159b2336f87b84616b75b8a5","Traditional networked radar fusion technology adopts an open-loop signal processing manner, in which multiple nodes independently detect or track target first, and then send their raw data or processed measurements to the fusion center for target state estimation. In such a working manner, each radar sensor operates within predetermined rules, adopts fixed transmit and receiving mode for changeable target tracking environment, and thus will definitely cause an insufficient use of its limited resource. Resource allocation (RA) has emerged as a promising technology to exploit the limited radar resource in a more efficient way by allocating the available resource parameters w.r.t. multiple nodes collaboratively in view of the fused target tracking performance. The goal of this paper is to provide a brief overview of the RA methods for fused target tracking in radar sensor network. We mainly investigate the existing RA works and divide them into two types, namely tracking quality constrained RA type and performance driven RA type. Solution techniques for both types appeared in the literatures are also summarized. Finally, some potential future research directions in this field are discussed. © 2022 The Author(s)","Fusion; Radar sensor network; Resource allocation; Target tracking"
"Locality guided cross-modal feature aggregation and pixel-level fusion for multispectral pedestrian detection","2022","Information Fusion","10.1016/j.inffus.2022.06.008","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134826461&doi=10.1016%2fj.inffus.2022.06.008&partnerID=40&md5=7e8b6f25665b8315e20bebc53d2a586b","Multispectral pedestrian detection has received much attention in recent years due to its superiority in detecting targets under adverse lighting/weather conditions. In this paper, we aim to generate highly discriminative multi-modal features by aggregating the human-related clues based on all available samples presented in multispectral images. To this end, we present a novel multispectral pedestrian detector performing locality guided cross-modal feature aggregation and pixel-level detection fusion. Given a number of single bounding boxes covering pedestrians in both modalities, we deploy two segmentation sub-branches to predict the existence of pedestrians on visible and thermal channels. By referring to the important locality information in the reference modality, we perform locality guided cross-modal feature aggregation to learn highly discriminative human-related features in the complementary modality by exploring the clues of all available pedestrians. Moreover, we utilize the obtained spatial locality maps to provide prediction confidence scores in visible and thermal channels and conduct pixel-wise adaptive fusion of detection results in complementary modalities. Extensive experiments demonstrate the effectiveness of our proposed method, outperforming the current state-of-the-art detectors on both KAIST and CVC-14 multispectral pedestrian detection datasets. © 2022 Elsevier B.V.","Deep neural networks; Feature aggregation; Multispectral fusion; Pedestrian detection; Pixel-wise guidance"
"PrivStream: A privacy-preserving inference framework on IoT streaming data at the edge","2022","Information Fusion","10.1016/j.inffus.2021.11.013","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85120374700&doi=10.1016%2fj.inffus.2021.11.013&partnerID=40&md5=3c13e1393469449ed9d51f4e07a27636","Edge computing combining with artificial intelligence (AI) has enabled the timely processing and analysis of streaming data produced by IoT intelligent applications. However, it causes privacy risk due to the data exchanges between local devices and untrusted edge servers. The powerful analytical capability of AI further exacerbates the risks because it can even infer private information from insensitive data. In this paper, we propose a privacy-preserving IoT streaming data analytical framework based on edge computing, called PrivStream, to prevent the untrusted edge server from making sensitive inferences from the IoT streaming data. It utilizes a well-designed deep learning model to filter the sensitive information and combines with differential privacy to protect against the untrusted edge server. The noise is also injected into the framework in the training phase to increase the robustness of PrivStream to differential privacy noise. Taking into account the dynamic and real-time characteristics of streaming data, we realize PrivStream with two types of models to process data segment with fixed length and variable length, respectively, and implement it on a distributed streaming platform to achieve real-time streaming data transmission. We theoretically prove that Privstream satisfies ε-differential privacy and experimentally demonstrate that PrivStream has better performance than the state-of-the-art and has acceptable computation and storage overheads. © 2021 Elsevier B.V.","Artificial intelligence; Differential privacy; Edge computing; Feature extraction; IoT streaming data"
"Supervised-unsupervised combined deep convolutional neural networks for high-fidelity pansharpening","2023","Information Fusion","10.1016/j.inffus.2022.08.018","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137153075&doi=10.1016%2fj.inffus.2022.08.018&partnerID=40&md5=d792b58e3806dc9912311fce0d512fc8","Deep learning for pansharpening method has become a hot research topic in recent years due to the impressive performance, and the convolutional neural networks (CNN)-based pansharpening methods on Wald's protocol (i.e., the general adoption of the network learned at a coarser reduced resolution scale to the finer full resolution) have been dominating for a long time in this research area. However, the scale-invariant assumption may not be accurate enough to make full use of the spatial and spectral information of original panchromatic (PAN) and multispectral (MS) images at full resolution. In this paper, a Supervised-Unsupervised combined Fusion Network (SUFNet) for high-fidelity pansharpening is proposed to alleviate this problem. First, by comprehensively considering the robustness of the network with reference label images, a novel supervised network based on Wald's protocol is proposed by integrating the multiscale mechanisms, dilated convolution, and skip connection, termed SMDSNet. Then, an interesting Unsupervised Spatial-Spectral Compensation Network (USSCNet) without real high-spatial-resolution (HR) MS label image is proposed to enhance the spatial and spectral fidelity of the SMDSNet. The qualitative and quantitative results in reduced resolution and full resolution experiments on different satellite datasets demonstrate the competitive performance of the proposed method. Furthermore, the proposed USSCNet can be employed as a universal spatial-spectral compensation framework for other pansharpening methods. © 2022 Elsevier B.V.","Convolutional neural networks (CNN); High fidelity; Image fusion; Pansharpening; Unsupervised learning"
"Learning-aware feature denoising discriminator","2023","Information Fusion","10.1016/j.inffus.2022.08.006","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136469268&doi=10.1016%2fj.inffus.2022.08.006&partnerID=40&md5=12dcff536940befaee1502f9be53ee63","Although generative adversarial networks (GANs) show great prospects for the task of image synthesis, the quality of synthesized images by existing GANs is sometimes inferior to real images because their discriminators cannot effectively learn robust identification features from input images. In addition, the training process of discriminator is prone to be unstable. To this end, inspired by the denoising auto-encoders, we propose a learning-aware feature denoising discriminator. It is designed to pay attention to robust features of input images, so as to improve its robustness in identifying features and recognition ability in training process. First, we use a decoder to generate perturbing noise and add it to real image to get corrupted image. Then, we get the encodings of the corrupted image and real image through an encoder. Finally, we minimize both types of encoding to constitute a denoising penalty and add it to the loss of the discriminator. We also show that our method is compatible with most existing GANs for three image synthesis tasks. Extensive experimental results show that compared with baseline models, our proposed method not only improves the quality of synthesized images, but also stabilizes the training process of discriminator. © 2022 Elsevier B.V.","Feature denoising; GANs; Image synthesis; Robustness"
"Exploration in deep reinforcement learning: A survey","2022","Information Fusion","10.1016/j.inffus.2022.03.003","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128759155&doi=10.1016%2fj.inffus.2022.03.003&partnerID=40&md5=afe02aa6e661379a2416f0cd57669735","This paper reviews exploration techniques in deep reinforcement learning. Exploration techniques are of primary importance when solving sparse reward problems. In sparse reward problems, the reward is rare, which means that the agent will not find the reward often by acting randomly. In such a scenario, it is challenging for reinforcement learning to learn rewards and actions association. Thus more sophisticated exploration methods need to be devised. This review provides a comprehensive overview of existing exploration approaches, which are categorised based on the key contributions as: reward novel states, reward diverse behaviours, goal-based methods, probabilistic methods, imitation-based methods, safe exploration and random-based methods. Then, unsolved challenges are discussed to provide valuable future research directions. Finally, the approaches of different categories are compared in terms of complexity, computational effort and overall performance. © 2022 Elsevier B.V.","Deep reinforcement learning; Exploration; Intrinsic motivation; Sparse reward problems"
"Partial feedback online transfer learning with multi-source domains","2023","Information Fusion","10.1016/j.inffus.2022.07.025","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136145475&doi=10.1016%2fj.inffus.2022.07.025&partnerID=40&md5=dffa349a4755a73ce5d43c687149f8bb","Online machine learning is an effective way for observation-based learning when a static dataset is not available. However, it can be challenging in real-world applications, especially when there are missing labels in multi-class classification tasks. Although partial feedback can be applied to tackle the problem, it can make the learning process slow and limit the classification performance as the correct label information is missing when the instance is misclassified. To cope with the lack of the target domain knowledge in online learning, transfer learning can be applied to convey knowledge from one or multiple source domains to the target domain. To this end, we propose a partial feedback online transfer learning algorithm with multiple source domains (PFMSD) to transfer the knowledge learned from multi-source domains to the target domain and enhance the learning performance by exploring the correct label when there is an erroneous prediction. A mistake bound is derived for the proposed algorithm, and extensive experiments are conducted using several wildly-used benchmark datasets. The obtained results in all experiments show the superiority of the proposed algorithm over the state-of-the-art partial feedback algorithms. © 2022 Elsevier B.V.","Multi-class classification; Multi-source domains information fusion; Online learning; Partial feedback; Transfer learning"
"UIFGAN: An unsupervised continual-learning generative adversarial network for unified image fusion","2022","Information Fusion","10.1016/j.inffus.2022.07.013","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136145351&doi=10.1016%2fj.inffus.2022.07.013&partnerID=40&md5=369cf237f1b51ed57f2e11e3dec942fe","In this paper, we propose a novel unsupervised continual-learning generative adversarial network for unified image fusion, termed as UIFGAN. In our model, for multiple image fusion tasks, a generative adversarial network for training a single model with memory in a continual-learning manner is proposed, rather than training an individual model for each fusion task or jointly training multiple tasks. We use elastic weight consolidation to avoid forgetting what has been learned from previous tasks when training multiple tasks sequentially. In each task, the generation of the fused image comes from the adversarial learning between a generator and a discriminator. Meanwhile, a max-gradient loss function is adopted for forcing the fused image to obtain richer texture details of the corresponding regions in two source images, which applies to most typical image fusion tasks. Extensive experiments on multi-exposure, multi-modal and multi-focus image fusion tasks demonstrate the advantages of our method over the state-of-the-art approaches. © 2022 Elsevier B.V.","Continual-learning; Generative adversarial network; Image fusion; Max-gradient loss; Unified model"
"Nonredundancy regularization based nonnegative matrix factorization with manifold learning for multiview data representation","2022","Information Fusion","10.1016/j.inffus.2021.12.001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122560859&doi=10.1016%2fj.inffus.2021.12.001&partnerID=40&md5=7428866d51891c4011ecb1705a89725b","In the real world, one object is usually described via multiple views or modalities. Many existing multiview clustering methods fuse the information of multiple views by learning a consensus representation. However, the feature learned in this manner is usually redundant and has neglected the distinctions among the different views. Addressing this issue, a method named nonredundancy regularization based nonnegative matrix factorization with manifold learning (NRRNMF-ML) is proposed in the paper. A novel nonredundancy regularizer defined with the Hilbert–Schmidt Independence Criterion (HSIC) is incorporated in the objective function of the proposed method. By minimizing this term, the redundant information among the multiple views can be effectively reduced and the distinct contributions of the different views can be encouraged. To further utilizing manifold structure information of the data, a manifold regularizer is also constructed and included in the objective function of the proposed method. For the proposed method, an iterative optimization strategy was designed to solve the problem; the corresponding proof is presented both theoretically and experimentally in this paper. Experimental results on five multiview data sets compared with several representative multiview clustering methods revealed the effectiveness of the proposed method. © 2022 Elsevier B.V.","HSIC; Manifold regularizer; Multiview clustering; Nonnegative matrix factorization; Nonredundancy"
"Vessel detection via multi-order saliency-based fuzzy fusion of spaceborne and airborne SAR images","2023","Information Fusion","10.1016/j.inffus.2022.08.022","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138098620&doi=10.1016%2fj.inffus.2022.08.022&partnerID=40&md5=1f395b20952cc1ba9f83e5aa9d3d3bc8","This study focuses on vessel target detection by fusing synthetic aperture radar (SAR) remote sensing images collaboratively collected from spaceborne and airborne platforms. Accurate vessel detection is difficult in the presence of inshore interferences and in the case of structured and shaped targets. In this study, we have proposed a new method for the fusion of spaceborne and airborne SAR images based on multi-order superpixel-level saliency and fuzzy logic (MSSFL). We first generated a new global regional contrast map (GRCM) by exploiting the multi-order superpixel-level saliency (MSS). In GRCMs, the vessel targets are well restored, and the background is suppressed. Next, a new fuzzy logic approach based on regional features is presented to fuse the MSS information provided by the GRCMs of the spaceborne and airborne SAR images. This regional feature-based fuzzy fusion can further enhance the vessel target regions and filter out the inshore interference regions. Experimental results using the SAR images of Gaofen-3 satellite and unmanned aerial vehicle show that the proposed MSSFL method yields a higher target-to-clutter ratio of fused images and improved detection performance, compared with the commonly utilized image fusion approaches and the classical detection algorithms solely using spaceborne or airborne SAR images. © 2022 Elsevier B.V.","Fuzzy logic; Saliency; Spaceborne and airborne platforms; Synthetic aperture radar (SAR) image; Vessel target detection"
"OLP++: An online local classifier for high dimensional data","2023","Information Fusion","10.1016/j.inffus.2022.09.010","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138482266&doi=10.1016%2fj.inffus.2022.09.010&partnerID=40&md5=41623d1ac12f532eee7e307d5fe03ca4","Ensemble diversity is an important characteristic of Multiple Classifier Systems (MCS), which aim at improving the overall performance of a classification system by combining the response of several models. While diversity may be introduced through various manipulations at the data level and the model level, some MCSs incorporate local information in order to increase it and/or take advantage of it, based on the idea that the different classifiers in the ensemble may have expertise in distinct areas of the feature space.1 a similar reasoning, we introduced in a previous work an ensemble method which produces in test time a few experts in the local region where each given query sample is located. These local experts, which are generated with slightly differing views of the target area, are then used to label the corresponding unknown instance. While the framework was shown to perform well especially over imbalanced problems, the locality definition in the method is based on the nearest neighbors rule and Euclidian distance, as is the case of various local-based ensembles, which may suffer from the effects of the curse of dimensionality over high dimensional problems. Thus, in this work, we propose a local ensemble method in which we leverage the data partitions given by decision trees for locality definition. More specifically, the partitions defined at different levels of the decision path that a given query instance traverses in the tree(s) are used as the regions over which the local experts are produced. By using different node levels from the path, each classifier in the local pool has a moderately distinct view of the target region without resorting to a dissimilarity metric, which might be susceptible to high dimensional spaces. Experimental results over 39 high dimensional problems showed that the proposed approach was significantly superior to our previous, distance-based framework in balanced accuracy rate. Compared to other six local-based ensemble methods, including dynamic selection and weighting schemes, the proposed method achieved competitive results, outperforming the random forest baseline and two state-of-the-art dynamic ensemble selection techniques. © 2022 Elsevier B.V.","Decision trees; High dimensional data; Local learning; Multiple classifier systems"
"A regret-theory-based three-way decision method with a priori probability tolerance dominance relation in fuzzy incomplete information systems","2023","Information Fusion","10.1016/j.inffus.2022.08.027","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137319407&doi=10.1016%2fj.inffus.2022.08.027&partnerID=40&md5=5855b5ecf338167bd6e4dc2d6f8edc35","In real world, decision-makers’ regret psychology often affects decision outcomes due to uncertain risks. Moreover, decision information may be missing in the process of data acquisitions or data storages. Three-way decision has been widely explored in the risky decision-making area by providing effective strategies to divide objects into three mutually disjoint regions. Existing three-way decision methods in fuzzy incomplete information systems rarely consider the influence of decision-makers’ psychological states on decision outcomes. In the current paper, we primarily study a new decision-making method that combines regret theory with three-way decision in fuzzy incomplete information systems. First, a prior probability tolerance dominance relation in a fuzzy incomplete information system is defined to handle a binary relation among evaluation values, and a method to calculate objective weights is designed as well. When an incomplete information system does not contain a fuzzy decision attribute value, we put forward a new method to calculate the decision attribute value of each object in the incomplete information system. Then, integrated utility perception values are obtained by combining with regret theory. Further, a regret theory-based three-way decision method with a priori probability tolerance dominance relation is proposed for fuzzy incomplete information systems. At last, the stability and validity of the presented method are verified via corresponding experimental and comparative analysis of realistic cases. © 2022 Elsevier B.V.","Fuzzy incomplete information system; Multi-attribute decision-making; Priori probability tolerance dominance relation; Regret theory; Three-way decision"
"Data harmonisation for information fusion in digital healthcare: A state-of-the-art systematic review, meta-analysis and future research directions","2022","Information Fusion","10.1016/j.inffus.2022.01.001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123598870&doi=10.1016%2fj.inffus.2022.01.001&partnerID=40&md5=c69075638eb44d86898e1c006652c702","Removing the bias and variance of multicentre data has always been a challenge in large scale digital healthcare studies, which requires the ability to integrate clinical features extracted from data acquired by different scanners and protocols to improve stability and robustness. Previous studies have described various computational approaches to fuse single modality multicentre datasets. However, these surveys rarely focused on evaluation metrics and lacked a checklist for computational data harmonisation studies. In this systematic review, we summarise the computational data harmonisation approaches for multi-modality data in the digital healthcare field, including harmonisation strategies and evaluation metrics based on different theories. In addition, a comprehensive checklist that summarises common practices for data harmonisation studies is proposed to guide researchers to report their research findings more effectively. Last but not least, flowcharts presenting possible ways for methodology and metric selection are proposed and the limitations of different methods have been surveyed for future research. © 2022 The Author(s)","data harmonisation; data standardisation; domain adaptation; Information fusion; reproducibility"
"A type-2 fuzzy system-based approach for image data fusion to create building information models","2022","Information Fusion","10.1016/j.inffus.2022.07.007","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135398140&doi=10.1016%2fj.inffus.2022.07.007&partnerID=40&md5=3bae255f02a7d2b0c50a4101d81351bc","Building Information Modelling (BIM) is a standard digital process that fuses buildings information from different sources into a 3D model during their lifecycle. For new construction sites using BIM, it is possible to monitor the cost, schedule, and changes throughout the lifecycle; however, existing buildings do not have a BIM model. Manually creating the BIM models for existing buildings is a high-cost task, both in time and money, hence there is a need for extracting information from available paper-based documentation and fuse it into a BIM model. The struggle of facility management and utility companies to fully adopt a BIM process (due to their high volumes of paper-based documentation of existing buildings) has led to the research on creating these 3D BIM models from 2D floor plan images. This paper presents a novel processing pipeline to extract 2D digital information from floorplans, fusing it into a 3D BIM model. The work focuses on fusing the available information to create the structure of the building in BIM format, which is considered the essential step before looking on working with other sources of data. In this process, we introduce a type-2 fuzzy logic based Explainable Artificial Intelligence (XAI) approach for the semantic segmentation step. The approach consists of using the outputs of type-2 fuzzy logic systems to classify a pixel as wall or background, by using information around and from the pixel of interest as the inputs to the system. After the semantic segmentation step, the output of the type-2 fuzzy logic goes through a noise removal process and finally a transformation from 2D to 3D by assigning the corresponding BIM tag to each identified element. The proposed type-2 fuzzy logic semantic segmentation approach produced comparable results (97.3% mean Intersection over Union (IoU) performance metric value) to the opaque box model approach based on Convolutional Neural Network (CNN) (99.3% mean IoU performance metric value). However, the type-2 fuzzy XAI system benefits from being an augmentable and interpretable model, which means that human users can understand the decision process and modify the model using their expert knowledge. © 2022 Elsevier B.V.","BIM; Building Information Modelling; Convolutional neural network (CNN); Semantic segmentation; Type-2 fuzzy logic systems"
"Integrated MPCAM: Multi-PSF learning for large depth-of-field computational imaging","2023","Information Fusion","10.1016/j.inffus.2022.09.005","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137695656&doi=10.1016%2fj.inffus.2022.09.005&partnerID=40&md5=b4a40d9b4bc9a83429733cc0ece18315","Large DOF (depth-of-field) imaging with high SNR (signal-noise-ratio) is useful for applications such as machine vision and medical imaging. In traditional optical systems, DOF extension is always implemented at the cost of SNR. In this paper, we present a MPCAM (Multi-PSF Camera) system highly integrated with AF (auto-focus) function to realize both large DOF and high SNR imaging. MPCAM based on MPGAN (Multi-PSF Generative Adversarial Network) is first proposed to automatically extract multiple PSFs (point spread functions) and realize high fidelity image reconstruction by features fusion. The proposed end-to-end generative image fusion network is flexible and can be designed with different input dimensions for a given AF application, which is vital to circumvent the trade-off between DOF and SNR. We build a dataset containing 5000 raw images tailored to the proposed network by an off-the-shelf camera. Results show that our MPCAM system can produce images with average higher values than raw images over 4.625, and 0.061 in PNSR (peak signal to noise ratio), and SSIM (structure similarity) metrics, respectively. Moreover, compared to the classic and latest image fusion methods, the results also verify that our method has achieved comparable or even better performance. Due to its advance in high SNR and large DOF imaging, this novel, portable and inexpensive system is suitable for computational applications such as microscopic pathological diagnosis, domain-specific computational imaging and smartphone photography. The implementation code of MPGAN and dataset are available from https://www.kaggle.com/datasets/ktd970903/multi-psf-camera. © 2022","Computational imaging; Depth-of-field extension; Generative image fusion network; M"
"A multi-representation re-ranking model for Personalized Product Search","2022","Information Fusion","10.1016/j.inffus.2021.11.010","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121809987&doi=10.1016%2fj.inffus.2021.11.010&partnerID=40&md5=a6a2d423d221f46ef403683856ba390e","In recent years, a multitude of e-commerce websites arose. Product Search is a fundamental part of these websites, which is often managed as a traditional retrieval task. However, Product Search has the ultimate goal of satisfying specific and personal user needs, leading users to find and purchase what they are looking for, based on their preferences. To maximize users’ satisfaction, Product Search should be treated as a personalized task. In this paper, we propose and evaluate a simple yet effective personalized results re-ranking approach based on the fusion of the relevance score computed by a well-known ranking model, namely BM25, with the scores deriving from multiple user/item representations. Our main contributions are: (1) we propose a score fusion-based approach for personalized re-ranking that leverages multiple user/item representations, (2) our approach accounts for both content-based features and collaborative information (i.e. features extracted from the user–item interactions graph), (3) the proposed approach is fast and scalable, can be easily added on top of any search engine and it can be extended to include additional features. The performed comparative evaluations show that our model can significantly increase the retrieval effectiveness of the underlying retrieval model and, in the great majority of cases, outperforms modern Neural Network-based personalized retrieval models for Product Search. © 2021 Elsevier B.V.","Personalization; Product Search; Results re-ranking"
"Intrinsic Cramér–Rao bounds for distributed Bayesian estimator","2022","Information Fusion","10.1016/j.inffus.2021.10.014","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121316521&doi=10.1016%2fj.inffus.2021.10.014&partnerID=40&md5=854187ac3ff002d30a2753106371d37b","This paper addresses the intrinsic Cramér–Rao bounds (CRBs) for a distributed Bayesian estimator whose states and measurements are on Riemannian manifolds. As Euclidean-based CRBs for recursive Bayesian estimator are no longer applicable to general Riemannian manifolds, the bounds need redesigning to accommodate the non-zero Riemannian curvature. To derive the intrinsic CRBs, we append a coordination step to the recursive Bayesian procedure, where the proposed sequential steps are prediction, measurement and coordination updates. In the coordination step, the estimator minimises the Kullback–Liebler divergence to obtain the consensus of multiple probability density functions (PDFs). Employing the PDFs from those steps together with the affine connection on manifolds the Fisher Information Matrix (FIM) and the curvature terms of the corresponding intrinsic bounds are derived. Subsequently, the design of a distributed estimator for Riemannian information manifold with Gaussian distribution – referred to as distributed Riemannian Kalman filter – is also presented to exemplify the application of the proposed intrinsic bounds. Finally, simulations utilising the designed filter for a distributed quaternionic estimation problem verifies that the covariance matrices of the filter are never below the formulated intrinsic CRBs. © 2021 Elsevier B.V.","Bayesian estimation; Distributed estimation; Intrinsic Cramér–Rao bound; Riemannian Kalman filter; Riemannian manifolds"
"QAPP: A quality-aware and privacy-preserving medical image release scheme","2022","Information Fusion","10.1016/j.inffus.2022.07.011","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135965662&doi=10.1016%2fj.inffus.2022.07.011&partnerID=40&md5=70172aeee1d053c0cbdee42b5b2b0396","The direct release of medical image may face the dilemma: the privacy protection of medical images inevitably affects the visual quality of images. To balance medical image quality and privacy, this paper proposes a quality-aware and privacy-preserving medical image release scheme, QAPP, which effectively integrates the discrete cosine transform (DCT) with differential privacy (DP). Specifically, QAPP is composed of three phases. First, DCT is applied to each medical image to obtain its cosine coefficients matrix. Second, the original cosine coefficients matrix is compressed into k*k cosine coefficients matrix, which can retain the main features of each image. Third, the appropriate Laplace noise is injected into the formed k*k matrix to achieve differential privacy, and these noise-added coefficients are used to reconstruct the noise-added medical images through inverse DCT. Especially, considering there two error sources affecting the image quality in our work: the compression error caused by DCT, and the injected noise error caused by DP, Therefore, a selection function is proposed to determine the optimal compression dimension k, which can minimize the influence of these two errors to improve the visualization quality of the medical image. Subjective and objective image quality evaluation, and extensive experiments of image classification and segmentation using the real medical image dataset demonstrate that the proposed method QAPP can better balance medical image quality and privacy than other similar DP-based methods. © 2022 Elsevier B.V.","Differential privacy; Discrete cosine transform; Image quality improvement; Privacy protection"
"Deep Emotional Arousal Network for Multimodal Sentiment Analysis and Emotion Recognition","2022","Information Fusion","10.1016/j.inffus.2022.07.006","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144392369&doi=10.1016%2fj.inffus.2022.07.006&partnerID=40&md5=f40ff656e57b96749a81c87fe06887f3","Multimodal sentiment analysis and emotion recognition has become an increasingly popular research area, where the biggest challenge is to efficiently fuse the input information from different modality. The recent success is largely credited to the attention-based models, e.g., transformer and its variants. However, the attention-based mechanism often neglects the coherency of human emotion due to its parallel structure. Inspired by the emotional arousal model in cognitive science, a Deep Emotional Arousal Network (DEAN) that is capable of simulating the emotional coherence is proposed in this paper, which incorporates the time dependence into the parallel structure of transformer. The proposed DEAN model consists of three components, i.e., a cross-modal transformer is devised to simulate the functions of perception analysis system of humans; a multimodal BiLSTM system is developed to imitate the cognitive comparator, and a multimodal gating block is introduced to mimic the activation mechanism in human emotional arousal model. We perform extensive comparison and ablation studies on three benchmarks for multimodal sentiment analysis and emotion recognition. The empirical results indicate that DEAN achieves state-of-the-art performance, and useful insights are derived from the results. © 2022","Deep Emotional Arousal Network; Multimodal Emotion Recognition; Multimodal Fusion Strategy; Multimodal Sentiment Analysis"
"Diversified branch fusion for self-knowledge distillation","2023","Information Fusion","10.1016/j.inffus.2022.09.007","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138037576&doi=10.1016%2fj.inffus.2022.09.007&partnerID=40&md5=14c80de04fccfe9391bf08b91e4796b3","Knowledge distillation improves the performance of a compact student network by adding supervision from a pre-trained cumbersome teacher network during training. To avoid the resource consumption of acquiring an extra teacher network, the self-knowledge distillation designs a multi-branch network architecture with shared layers for teacher and student models, which are trained collaboratively in a one-stage manner. However, this method ignores the knowledge of shallow branches and rarely provides diverse knowledge for effective collaboration of different branches. To solve these two shortcomings, this paper proposes a novel Diversified Branch Fusion approach for Self-Knowledge Distillation (DBFSKD). Firstly, we design lightweight networks for adding to the middle layers of the backbone. They capture discriminative information by global–local attention. Then we introduce a diversity loss between different branches to explore diverse knowledge. Moreover, the diverse knowledge is further integrated to form two knowledge sources by a Selective Feature Fusion (SFF) and a Dynamic Logits Fusion (DLF). Thus, the significant knowledge of shallow branches is efficiently utilized and all branches learn from each other through the fused knowledge sources. Extensive experiments with various backbone structures on four public datasets (CIFAR100, Tiny-ImageNet200, ImageNet, and RAF-DB) show superior performance of the proposed method over other methods. More importantly, the DBFSKD achieves even better performance with fewer resource consumption than the baseline. © 2022 Elsevier B.V.","Deep learning; Diversity loss; Knowledge fusion; Multiple branches; Self-knowledge distillation"
"CLEVR-XAI: A benchmark dataset for the ground truth evaluation of neural network explanations","2022","Information Fusion","10.1016/j.inffus.2021.11.008","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85120632168&doi=10.1016%2fj.inffus.2021.11.008&partnerID=40&md5=8910eebd973ff586ddb94a12d8940ad6","The rise of deep learning in today's applications entailed an increasing need in explaining the model's decisions beyond prediction performances in order to foster trust and accountability. Recently, the field of explainable AI (XAI) has developed methods that provide such explanations for already trained neural networks. In computer vision tasks such explanations, termed heatmaps, visualize the contributions of individual pixels to the prediction. So far XAI methods along with their heatmaps were mainly validated qualitatively via human-based assessment, or evaluated through auxiliary proxy tasks such as pixel perturbation, weak object localization or randomization tests. Due to the lack of an objective and commonly accepted quality measure for heatmaps, it was debatable which XAI method performs best and whether explanations can be trusted at all. In the present work, we tackle the problem by proposing a ground truth based evaluation framework for XAI methods based on the CLEVR visual question answering task. Our framework provides a (1) selective, (2) controlled and (3) realistic testbed for the evaluation of neural network explanations. We compare ten different explanation methods, resulting in new insights about the quality and properties of XAI methods, sometimes contradicting with conclusions from previous comparative studies. The CLEVR-XAI dataset and the benchmarking code can be found at https://github.com/ahmedmagdiosman/clevr-xai. © 2021 The Authors","Benchmark; Computer vision; Convolutional neural network; Evaluation; Explainable AI; Relation network; Visual question answering"
"Exploring diversity in data complexity and classifier decision spaces for pool generation","2023","Information Fusion","10.1016/j.inffus.2022.09.001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138081808&doi=10.1016%2fj.inffus.2022.09.001&partnerID=40&md5=f9d079f53dd1010ecd439f61d9aee729","This paper introduces a novel method for classifier pool generation in which a two-level strategy explores diversity in both data complexity and classifier decision spaces. The rationale is to induce pool members using data subsets representing subproblems with different difficulties while promoting diversity in classifiers’ decisions. Two possible variants of the proposed method with a focus on maximum dispersion and maximum accuracy are presented. These differ in the property used to define the best pool of classifiers provided by an optimization process. A robust experimental protocol encompassing 28 classification datasets shows that the proposed pool generation provided the best accuracy on 327 over 336 experiments (97.3%) when compared to well-known pool generation methods to provide multiple classifier systems with and without dynamic selection. © 2022 Elsevier B.V.","Classifier pool generation; Data complexity measures; Diversity"
"Enhanced Minimum-Cost Consensus: Focusing on Overadjustment and Flexible Consensus Cost","2023","Information Fusion","10.1016/j.inffus.2022.08.028","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137165961&doi=10.1016%2fj.inffus.2022.08.028&partnerID=40&md5=caacd915e58039e0ad4853a53dd649c4","Minimum-cost consensus (MCC) using the optimization-based consensus rule (OR) has been developed and widely applied to various group decision-making (GDM) contexts because resources for the consensus-reaching process are generally limited. In view of the shortcomings of traditional MCC, including the overadjustment of individual opinions and reliance on single type of consensus constraints, this study proposes several enhanced MCC (EMCC) models. First, we provide a visual analytical solution for opinion adjustment in MCC using explicit adjustment paths, through which the adjustment direction and feedback coefficient of each individual opinion are embodied and quantified. According to the obtained feedback coefficients, the criterion for determining overadjustment is defined. By incorporating explicit adjustment paths into traditional MCC, several EMCC models with different types of consensus constraints are developed, all of which can effectively avoid overadjustment. Then, the connection between the identification-direction consensus rule and OR is established based on EMCC. We propose the concept of coordination elasticity and discuss the performance of EMCC from the perspective of consensus cost and overadjustment in order to analyze the using conditions of EMCC. Flexible EMCC provides a negotiated solution for dealing with overadjustment by following the principle of individual consensus cost priority. Finally, the characteristics and advantages of the proposed EMCC models are revealed through a case study and comparison with traditional MCC. © 2022 Elsevier B.V.","consensus-reaching process (CRP); coordination elasticity; Enhanced minimum-cost consensus (EMCC); explicit adjustment path; flexible consensus cost; individual consensus cost priority"
"Multi-modal knowledge graphs representation learning via multi-headed self-attention","2022","Information Fusion","10.1016/j.inffus.2022.07.008","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135344973&doi=10.1016%2fj.inffus.2022.07.008&partnerID=40&md5=a886ba1a2769ca6c498df557bc0ef756","Traditional knowledge graphs (KG) representation learning focuses on the link information between entities, and the effectiveness of learning is influenced by the complexity of KGs. Considering a multi-modal knowledge graph (MKG), due to the introduction of considerable other modal information(such as images and texts), the complexity of KGs further increases, which degrades the effectiveness of representation learning. To resolve this solve the problem, this study proposed the multi-modal knowledge graphs representation learning via multi-head self-attention (MKGRL-MS) model, which improved the effectiveness of link prediction by adding rich multi-modal information to the entity. We first generated a single-modal feature vector corresponding to each entity. Then, we used multi-headed self-attention to obtain the attention degree of different modal features of entities in the process of semantic synthesis. In this manner, we learned the multi-modal feature representation of entities. New knowledge representation is the sum of traditional knowledge representation and an entity's multi-modal feature representation. Simultaneously, we successfully train our model on two existing models and two different datasets and verified its versatility and effectiveness on the link prediction task. © 2022 Elsevier B.V.","Multi-modal information fusion; Multi-modal knowledge graphs; Representation learning"
"Nonlinear unknown input observability and unknown input reconstruction: The general analytical solution","2022","Information Fusion","10.1016/j.inffus.2022.03.004","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129493129&doi=10.1016%2fj.inffus.2022.03.004&partnerID=40&md5=d7a44a71a7d61c1b2536892b93d131a8","Observability is a fundamental structural property of any dynamic system and describes the possibility of reconstructing the state that characterizes the system from fusing the observations of its inputs and outputs. Despite the effort made to study this property and to introduce analytical criteria capable of verifying whether or not a dynamic system satisfies this property, there is no general analytical criterion to obtain the observability of the state when the dynamics are also driven by unknown inputs. Here, we introduce the general analytical solution of this fundamental open problem, often called the unknown input observability problem. We provide the systematic procedure, based on automatic calculation (differentiation and determination of the matrix rank), which allows us to check the observability of the state even in the presence of unknown inputs. One of the fundamental ingredients to obtain this solution is the characterization of the group of invariance of observability. We have very recently introduced this group, together with a new set of tensor fields with respect to this group of transformations (Martinelli, 2020). The analytical solution of the unknown input observability problem is expressed in terms of these tensor fields. In Martinelli (2020) we provided the solution by restricting our investigation to systems that satisfy a special assumption that is called canonicity with respect to the unknown inputs. Here, after an exhaustive characterization of the concept of canonicity, we also account for the case when this assumption is not satisfied and we provide the general solution. This solution is also provided in the form of a new algorithm. In addition, even in the canonic case dealt with in Martinelli (2020), here we provide a new fundamental result that regards the convergence properties of the solution. Finally, as a consequence of the results obtained here, we also provide the condition to reconstruct the unknown inputs, and, when this condition is not met, what can be reconstructed on the unknown inputs. We illustrate the implementation of the new algorithm by studying the observability properties of a nonlinear system in the framework of visual-inertial sensor fusion, whose dynamics are driven by two unknown inputs and one known input. In particular, for this system, we follow step by step the algorithm introduced by this paper, which solves the unknown input observability problem in the most general case. © 2022 Elsevier B.V.","Nonlinear observability; Observability rank condition; Unknown input observability; Unknown input reconstruction; Visual-inertial sensor fusion"
"Identifying user geolocation with Hierarchical Graph Neural Networks and explainable fusion","2022","Information Fusion","10.1016/j.inffus.2021.11.004","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85120481141&doi=10.1016%2fj.inffus.2021.11.004&partnerID=40&md5=20c10bad7520282c2f0f0c9657e13747","Determining user geolocation from social media data is essential in various location-based applications — from improved transportation/supply management, through providing personalized services and targeted marketing, to better overall user experiences. Previous methods rely on the similarity of user posting content and neighboring nodes for user geolocation, which suffer the problems of: (1) position-agnostic of network representation learning, which impedes the performance of their prediction accuracy; and (2) noisy and unstable user relation fusion due to the flat graph embedding methods employed. This work presents Hierarchical Graph Neural Networks (HGNN) – a novel methodology for location-aware collaborative user-aspect data fusion and location prediction. It incorporates geographical location information of users and clustering effect of regions and can capture topological relations while preserving their relative positions. By encoding the structure and features of regions with hierarchical graph learning, HGNN can primarily alleviate the problem of noisy and unstable signal fusion. We further design a relation mechanism to bridge connections between individual users and clusters, which not only leverages the information of isolated nodes that are useless in previous methods but also captures the relations between unlabeled nodes and labeled subgraphs. Furthermore, we introduce a robust statistics method to interpret the behavior of our model by identifying the importance of data samples when predicting the locations of the users. It provides meaningful explanations on the model behaviors and outputs, overcoming the drawbacks of previous approaches that treat user geolocation as “black-box” modeling and lacking interpretability. Comprehensive evaluations on real-world Twitter datasets verify the proposed model's superior performance and its ability to interpret the user geolocation results. © 2021 Elsevier B.V.","Graph Neural Networks; Influence function; Interpretable fusion; Social information fusion; User geolocation"
"Minimum information-loss transformations to support heterogeneous group decision making in a distributed linguistic context","2023","Information Fusion","10.1016/j.inffus.2022.07.009","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137641222&doi=10.1016%2fj.inffus.2022.07.009&partnerID=40&md5=d3dbffe7655b8d706b97a29a2c78b505","In the problems that linguistic assessments are conducted by adopting multiple sources of information representations, the management of unification of heterogeneous information and information loss are necessary. To support a useful fusion of heterogeneous distributed information in linguistic group decision making, a minimum information-loss transformation framework is proposed in this paper. First, distributed linguistic distance measurements are defined to measure information loss among heterogeneous distributed linguistic preference information, and then several minimum information-loss transformation models (MILTMs) with desirable properties are proposed. Furthermore, the application of the MILTMs in addressing the fusion of heterogeneous distributed linguistic information in a multi-attribute group decision context is discussed, and the flexibility of distributed linguistic information is studied to justify the MILTMs through numerical examples and comparative analyses. © 2022","Distributed linguistic representation; Group decision making; Heterogeneous decision making; Information loss"
"MST-GAT: A multimodal spatial–temporal graph attention network for time series anomaly detection","2023","Information Fusion","10.1016/j.inffus.2022.08.011","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138046640&doi=10.1016%2fj.inffus.2022.08.011&partnerID=40&md5=a7c89083ca37f14002ac8652a23edaab","Multimodal time series (MTS) anomaly detection is crucial for maintaining the safety and stability of working devices (e.g., water treatment system and spacecraft), whose data are characterized by multivariate time series with diverse modalities. Although recent deep learning methods show great potential in anomaly detection, they do not explicitly capture spatial–temporal relationships between univariate time series of different modalities, resulting in more false negatives and false positives. In this paper, we propose a multimodal spatial–temporal graph attention network (MST-GAT) to tackle this problem. MST-GAT first employs a multimodal graph attention network (M-GAT) and a temporal convolution network to capture the spatial–temporal correlation in multimodal time series. Specifically, M-GAT uses a multi-head attention module and two relational attention modules (i.e., intra- and inter-modal attention) to model modal correlations explicitly. Furthermore, MST-GAT optimizes the reconstruction and prediction modules simultaneously. Experimental results on four multimodal benchmarks demonstrate that MST-GAT outperforms the state-of-the-art baselines. Further analysis indicates that MST-GAT strengthens the interpretability of detected anomalies by locating the most anomalous univariate time series. © 2022","Anomaly detection; Graph attention networks; Multimodal time series; Unsupervised learning"
"Multifusion schemes of INS/GNSS/GCPs/V-SLAM applied using data from smartphone sensors for land vehicular navigation applications","2023","Information Fusion","10.1016/j.inffus.2022.08.012","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137062760&doi=10.1016%2fj.inffus.2022.08.012&partnerID=40&md5=d4b04a07801845522f86393c8a2ab5b7","Contemporary smartphones contain embedded inertial measurement unit (IMU), global navigation satellite system (GNSS), camera, and other sensors that are capable of providing user position, velocity, and attitude. However, the actual navigation performance capabilities of smartphones are difficult to use because of the low-cost and disparate sensors employed, differing software technologies adopted by manufacturers, and considerable influence of environmental conditions. In this study, we proposed multifusion schemes that integrated sensor data from smartphone IMU, GNSS chipsets, cameras, and ground control points (GCPs), using an extended Kalman filter to enhance the system navigation performance. Different processes of scale recovery and refreshed-simultaneous localization and mapping (SLAM) based on GNSS and GCPs corresponding to outdoor and indoor environments were proposed to increase the accuracy and robustness of the integrated system. To verify the performance of the integrated system, field test data were collected in an urban area of Tainan City, Taiwan. The experimental results indicated improvements of 87.09% and 36.27% for the refreshed-SLAM and its integration system, respectively, compared with visual-SLAM one-scale recovery and conventional integrated schemes. The proposed integrated system that uses smartphone sensor data increased navigation accuracy in GNSS-challenged environments. © 2022","GNSS-challenged environments; INS/GNSS; Scale recovery; Smartphone sensors; Visual SLAM"
"Multimodal Attentive Fusion Network for audio-visual event recognition","2022","Information Fusion","10.1016/j.inffus.2022.03.001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129464636&doi=10.1016%2fj.inffus.2022.03.001&partnerID=40&md5=a014ca44783bb2fdef44cd79bad12d7b","Event classification is inherently sequential and multimodal. Therefore, deep neural models need to dynamically focus on the most relevant time window and/or modality of a video. In this study, we propose the Multimodal Attentive Fusion Network (MAFnet), an architecture that can dynamically fuse visual and audio information for event recognition. Inspired by prior studies in neuroscience, we couple both modalities at different levels of visual and audio paths. Furthermore, the network dynamically highlights a modality at a given time window relevant to classify events. Experimental results in AVE (Audio-Visual Event), UCF51, and Kinetics-Sounds datasets show that the approach can effectively improve the accuracy in audio-visual event classification. Code is available at: https://github.com/numediart/MAFnet © 2022 Elsevier B.V.","Attention; Audio-visual fusion; Event recognition; Modality conditioning; Multimodal deep learning"
"The Bonferroni mean-type pre-aggregation operators construction and generalization: Application to edge detection","2022","Information Fusion","10.1016/j.inffus.2021.11.002","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121013114&doi=10.1016%2fj.inffus.2021.11.002&partnerID=40&md5=d90383cf8eb88ff19ab35fd1b1e18779","In recent years, immense interest in the exploration of the generalized version of the monotonicity condition has been significantly accomplished by the researchers. The intention behind generalizing the monotonicity condition is to envelop many prime functions which are of huge interest in the domain of mathematical applications such as classification problems, image processing, decision-making systems, etc. In this regard, the framework of the pre-aggregation operators was introduced to generalize the notion of monotonicity in the traditionally defined concept of aggregation operators. Such functions have extended the group of operators utilized for information accumulation by considering directional monotonicity with respect to a specified vector. This study emphasizes the systematized exploration of the theoretical framework of the Bonferroni mean-type (BM-type) pre-aggregation operators. We propose the construction methodology of the BM-type pre-aggregation operators by suitably befitting preferable functions to provide a descriptive arrangement, which is quite adaptable, understandable, and interpretable. First, a construction mechanism is proposed by utilizing a bivariate function M. To enhance the potentiality of the proposed operator, a generalized variation of it has been proposed by suitably using two functions M and M∗, respectively. The primary step for an object recognition problem is edge detection and is considered as an important tool in image processing systems. For the applicatory purpose, an edge detection algorithm based on the proposed BM-type pre-aggregation operator has been presented with more emphasis given to the feature image extraction. A comprehensive comparative study has been made to assess the results obtained through the proposed edge detection algorithm with some other well-known edge detectors extensively utilized in the literature. © 2021 Elsevier B.V.","Aggregation operator; Bonferroni mean-type pre-aggregation operator; Directional monotonicity; Edge detection; Feature image; Image processing; Pre-aggregation operator"
"Fusion of engineering insights and emerging trends: Intelligent urban traffic management system","2022","Information Fusion","10.1016/j.inffus.2022.07.020","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135807269&doi=10.1016%2fj.inffus.2022.07.020&partnerID=40&md5=06164545ab525464df695445f5541446","Traffic congestion is a great concern, especially in urban areas where the vehicles’ number on roads continues to intensify significantly against the slow development of road infrastructure. To resolve this intractable problem, researchers proposed various Traffic Management Systems that rely on the fusion of traffic data sources and emerging technologies to maximize the traffic flow, and thus fluidify the intersections since they are the origin of traffic congestions, and also reroute the vehicles to avoid traffic congestions areas, and thus reduce fuel consumption and air pollution. Although there are many studies on traffic management, there is still a lack of research covering the entire urban road traffic management system. Therefore, this study intends to fill the gap, generating new insight into the state of research related to the entire Traffic Management System. The principal aim of this survey is to provide a complete view of current approaches proposed in the literature to handle the traffic congestion problem. We first supply a review of the body of knowledge in recent years of Traffic Management Systems. Second, we summarize the benefits and drawbacks of the recent literature. Third, we analyze and discuss the three main subsystems of a Traffic Management System and then classify the various contributions according to the subsystem to which they belong. Finally, we present and discuss future research orientations and open issues that need further investigation for a realistic and efficient Traffic Management System. © 2022 Elsevier B.V.","Artificial intelligence; Emerging technologies; Intelligent transportation systems; Smart city; Traffic congestion; Traffic management system"
"Formal definitions of conservative probability distribution functions (PDFs)","2022","Information Fusion","10.1016/j.inffus.2022.07.014","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135943636&doi=10.1016%2fj.inffus.2022.07.014&partnerID=40&md5=195f4ff44e7f0afbc4a86383939d64db","Under ideal conditions, the probability density function (PDF) of a random variable, such as a sensor measurement, would be well known and amenable to computation and communication tasks. However, this is often not the case, so the user looks for some other PDF that approximates the true but intractable PDF. Conservativeness is a commonly sought property of this approximating PDF, especially in distributed or unstructured data systems where the data being fused may contain un-known correlations. Roughly, a conservative approximation is one that overestimates the uncertainty of a system. While prior work has introduced some definitions of conservativeness, these definitions either apply only to normal distributions or violate some of the intuitive appeal of (Gaussian) conservative definitions. This work provides a general and intuitive definition of conservativeness that is applicable to any probability distribution that is a measure over Rm or an infinite subset thereof, including multi-modal and uniform distributions. Unfortunately, we show that this strong definition of conservative does not hold with any of the commonly used data fusion techniques. Therefore, we also describe a weaker definition of conservative and show it is preserved through common data fusion methods, assuming the input distributions can be factored into independent and common PDFs that can be normalized over Rm. By illustrating what is possible and not possible in terms of conservativeness during data fusion, an improved understanding of data fusion methods for general PDFs can be obtained. © 2022","Covariance intersection; Distributed data fusion; Distributed estimation; Sensor fusion"
"Data stream fusion for accurate quantile tracking and analysis","2023","Information Fusion","10.1016/j.inffus.2022.08.005","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136517800&doi=10.1016%2fj.inffus.2022.08.005&partnerID=40&md5=f7accf62b72b7b0211897f0ab30a27a2","UDDSKETCH is a recent algorithm for accurate tracking of quantiles in data streams, derived from the DDSKETCH algorithm. UDDSKETCH provides accuracy guarantees covering the full range of quantiles independently of the input distribution and greatly improves the accuracy with regard to DDSKETCH. In this paper we show how to compress and fuse two or more data streams (or datasets) by leveraging the mergeability of the UDDSKETCH data summaries. In general, two summaries on two data streams are said to be mergeable if there exists an algorithm that allows combining the two summaries into a single one related to the union of the two datasets, simultaneously preserving the error and size guarantees. The property of mergeability of a sketch enables the parallel and distributed processing of big volume data streams that can be compressed and fused by means of such mergeable data structures. Among the applications strictly related to accurate tracking of quantiles, requiring parallel and/or distributed processing we recall here estimating the latency of a web site, database query optimizers and the need of succinctly summarizing the distribution of values occurring over a sensor network. We prove that UDDSKETCH is fully mergeable and introduce PUDDSKETCH, a parallel version of UDDSKETCH suitable for message-passing based architectures. We formally prove its correctness and compare it to a parallel version of DDSKETCH, showing through extensive experimental results that our parallel algorithm almost always outperforms the parallel DDSKETCH algorithm with regard to the overall accuracy in determining the quantiles. Moreover, we also design and implement parallel versions of both the state of the art KLL and REQ sequential algorithms in order to compare and contrast PUDDSKETCH versus the corresponding parallel algorithms. Our experiments clearly show that PUDDSKETCH is faster or on par with regard to parallel running time, whilst providing simultaneously greater accuracy. © 2022 Elsevier B.V.","Message-passing; Quantiles; Sketches"
"Comprehensive Multi-view Representation Learning","2023","Information Fusion","10.1016/j.inffus.2022.08.014","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136718480&doi=10.1016%2fj.inffus.2022.08.014&partnerID=40&md5=b7a52b6e0b78bca644cb0a3e0f6dae95","Recently, Multi-view Representation Learning (MRL) has drawn immense attentions in the analysis of multi-source data and ubiquitously employed across different research fields. This important issue is designed to learn a feature representation with sufficient information from multiple views. In this paper, we propose a novel Comprehensive Multi-view Representation Learning (CMRL), which can fully explore available information contained in both the feature representations and subspace representations of multiple views. The desired feature representation learned in CMRL profits from the consistency and complementarity of multi-view data. Specifically, the complementary information is mined by applying the degeneration mapping model on multiple feature representations, the consensus information is explored by imposing a low-rank tensor constraint on multiple subspace representations. Further, the objective function of CMRL is optimized by an Augmented Lagrangian Multiplier (ALM) based algorithm. Finally, our CMRL is evaluated on seven benchmark multi-view datasets and compared with several state-of-the-art methods, experimental results illustrate the superiority and effectiveness of the proposed method. What is more, we find that the proposed method can also be successfully applied to multi-view subspace clustering and achieves promising clustering results. © 2022 Elsevier B.V.","Complementary information; Consensus information; Multi-view representation learning; Unsupervised multi-view learning"
"EnHAT — Synergy of a tree-based Ensemble with Hoeffding Adaptive Tree for dynamic data streams mining","2023","Information Fusion","10.1016/j.inffus.2022.08.026","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137616372&doi=10.1016%2fj.inffus.2022.08.026&partnerID=40&md5=ee7afe62230f7ff210e68144a388f481","The goal of this paper is to improve the predictive accuracy of data streaming algorithms without increasing the processing time of the incoming data. We propose the EnHAT (Ensemble Combined with Hoeffding Adaptive Tree) algorithm, which combines the state-of-the-art Hoeffding Adaptive Tree (HAT) algorithm with an ensemble of J48 decision trees induced from sequential chunks of the data stream. The slack time of HAT adaptation to a new window of incoming records is utilized in parallel for building a decision-tree ensemble. In our experiments on 4 benchmark streaming datasets and 4 synthetic datasets with different types of concept drift, EnHAT has reached the highest predictive accuracy in 23 out of 26 cases compared to an ensemble of J48 trees, HAT, and a single J48 model induced from the last sliding window. Thus, we can conclude that the ensemble/HAT synergy yields better prediction results than each one of the two approaches on its own. The higher accuracy does not come at the expense of any additional computational effort beyond the model induction times of the combined algorithms. © 2022 Elsevier B.V.","Concept drift; Data streams; Ensemble learning; Hoeffding Adaptive Tree; Online learning"
"A novel model usability evaluation framework (MUsE) for explainable artificial intelligence","2022","Information Fusion","10.1016/j.inffus.2021.11.017","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121292646&doi=10.1016%2fj.inffus.2021.11.017&partnerID=40&md5=6567abd77935b65223d340910c4e53c0","When it comes to complex machine learning models, commonly referred to as black boxes, understanding the underlying decision making process is crucial for domains such as healthcare and financial services, as well as when they are used in connection with safety critical systems such as autonomous vehicles. As a result, interest in explainable artificial intelligence (xAI) tools and techniques has increased in recent years. However, the user experience (UX) effectiveness of existing xAI frameworks, especially concerning algorithms that work with data as opposed to images, is still an open research question. In order to address this gap, we examine the UX effectiveness of the Local Interpretable Model-Agnostic Explanations (LIME) xAI framework, one of the most popular model agnostic frameworks found in the literature, with a specific focus on its performance in terms of making tabular models more interpretable. In particular, we apply several state of the art machine learning algorithms on a tabular dataset, and demonstrate how LIME can be used to supplement conventional performance assessment methods. Based on this experience, we evaluate the understandability of the output produced by LIME both via a usability study, involving participants who are not familiar with LIME, and its overall usability via a custom made assessment framework, called Model Usability Evaluation (MUsE), which is derived from the International Organisation for Standardisation 9241-11:2018 standard. © 2021 Elsevier B.V.","Explainable artificial intelligence; Machine learning; Model agnostic explanations; Usability study; User experience"
"An intelligent fault diagnosis for machine maintenance using weighted soft-voting rule based multi-attention module with multi-scale information fusion","2022","Information Fusion","10.1016/j.inffus.2022.06.005","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133228422&doi=10.1016%2fj.inffus.2022.06.005&partnerID=40&md5=55b148cb21f8a58d4d30ec07f8ee35d5","The ability of engineering systems to process multi-scale information is a crucial requirement in the development of an intelligent fault diagnosis model. This study develops a hybrid multi-scale convolutional neural network model coupled with multi-attention capability (HMS-MACNN) to solve both the inefficient and insufficient extrapolation problems of multi-scale models in fault diagnosis of a system operating in complex environments. The model's capabilities are demonstrated by its ability to capture the rich multi-scale characteristics of a gearbox including time and frequency multi-scale information. The capabilities of the Multi-Attention Module, which consists of an adaptive weighted rule and a novel weighted soft-voting rule, are respectively integrated to efficiently consider the contribution of each characteristic with different scales-to-faults at both feature- and decision-levels. The model is validated against experimental gearbox fault results and offers robustness and generalization capability with F1 value that is 27% higher than other existing multi-scale CNN-based models operating in a similar environment. Furthermore, the proposed model offers higher accuracy than other generic models and can accurately assign attention to features with different scales. This offers an excellent generalization performance due to its superior capability in capturing multi-scale information and in fusing advanced features following different fusion strategies by using Multi-Attention Module and the hybrid MS block compared to conventional CNN-based models. © 2022 Elsevier B.V.","Convolutional neural network; Fault diagnosis; Gearbox maintenance; Intelligent diagnosis; Multi-scale information fusion; Prognosis and health management"
"Knowledge graph-based rich and confidentiality preserving Explainable Artificial Intelligence (XAI)","2022","Information Fusion","10.1016/j.inffus.2021.11.015","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85120902248&doi=10.1016%2fj.inffus.2021.11.015&partnerID=40&md5=f6322ebc397bca40317c74c57cfa3829","The paper proposes a novel architecture for explainable artificial intelligence based on semantic technologies and artificial intelligence. We tailor the architecture for the domain of demand forecasting and validate it on a real-world case study. The explanations provided result from knowledge fusion regarding concepts describing features relevant to a particular forecast, related media events, and metadata regarding external datasets of interest. The Knowledge Graph enhances the quality of explanations by informing concepts at a higher abstraction level rather than specific features. By doing so, explanations avoid exposing sensitive details regarding the demand forecasting models, thus preserving confidentiality. In addition, the Knowledge Graph enables linking domain knowledge, forecasted values, and forecast explanations while also providing insights into actionable aspects on which users can take action. The ontology and dataset we developed for this use case are publicly available for further research. © 2021 The Authors","Confidentiality; Demand forecasting; Explainable Artificial Intelligence; Knowledge Graph; Privacy; Smart manufacturing"
"Dwarfism computer-aided diagnosis algorithm based on multimodal pyradiomics","2022","Information Fusion","10.1016/j.inffus.2021.11.012","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119584639&doi=10.1016%2fj.inffus.2021.11.012&partnerID=40&md5=e0974cee8ed965aae30ff181e876dff7","Dwarfism refers to the phenomenon that children with same gender and age are lower than two standard deviations of normal height in the same living environment. It is of great significance for early diagnosis and early treatment of dwarfism. Dwarfism can be divided into growth hormone deficiency (GHD) and idiopathic short stature (ISS). GHD can be distinguished by growth hormone, while ISS is difficult to distinguish because its hormone features are not obvious. Thus, a computer-aided diagnosis model based on brain image data and clinical features is established for the first time and a dwarfism prediction algorithm is proposed based on multimodal pyradiomics. Firstly, we establish the extraction of pituitary gland based on tensor and binary wavelet model, as the pituitary gland is an important organ that affects the growth hormone. Then, the multi-dimensional fusion model is established to distinguish dwarfism. In the process of distinguishment, the pyradiomics features and clinical features are extracted to distinguish together. Finally, dwarfism computer-aided diagnosis algorithm based on multimodal pyradiomics is realized. © 2021","Brain-computer interface; Children; Computer-aided diagnosis; Dwarfism; Multimodal; Pyradiomics"
"Defocus to focus: Photo-realistic bokeh rendering by fusing defocus and radiance priors","2023","Information Fusion","10.1016/j.inffus.2022.08.023","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137158770&doi=10.1016%2fj.inffus.2022.08.023&partnerID=40&md5=add2e35fddea40da0fb0061392298b9b","We consider the problem of realistic bokeh rendering from a single all-in-focus image. Bokeh rendering mimics aesthetic shallow depth-of-field (DoF) in professional photography, but these visual effects generated by existing methods suffer from simple flat background blur and blurred in-focus regions, giving rise to unrealistic rendered results. In this work, we argue that realistic bokeh rendering should (i) model depth relations and distinguish in-focus regions, (ii) sustain sharp in-focus regions, and (iii) render physically accurate Circle of Confusion (CoC). To this end, we present a Defocus to Focus (D2F) framework to learn realistic bokeh rendering by fusing defocus priors with the all-in-focus image and by implementing radiance priors in layered fusion. Since no depth map is provided, we introduce defocus hallucination to integrate depth by learning to focus. The predicted defocus map implies the blur amount of bokeh and is used to guide weighted layered rendering. In layered rendering, we fuse images blurred by different kernels based on the defocus map. To increase the reality of the bokeh, we adopt radiance virtualization to simulate scene radiance. The scene radiance used in weighted layered rendering reassigns weights in the soft disk kernel to produce the CoC. To ensure the sharpness of in-focus regions, we propose to fuse upsampled bokeh images and original images. We predict the initial fusion mask from our defocus map and refine the mask with a deep network. We evaluate our model on a large-scale bokeh dataset. Extensive experiments show that our approach is capable of rendering visually pleasing bokeh effects in complex scenes. In particular, our solution receives the runner-up award in the AIM 2020 Rendering Realistic Bokeh Challenge. © 2022 Elsevier B.V.","Bokeh rendering; Circle of confusion; Deep blending; Defocus estimation; Image fusion"
"Consistency improvement under a personalized individual semantics context in distributed linguistic group decision making","2022","Information Fusion","10.1016/j.inffus.2022.07.022","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136117233&doi=10.1016%2fj.inffus.2022.07.022&partnerID=40&md5=2954fd6f1d63560b0670a2731166af64","Consistency measurement is a significant issue in linguistic decision making when preferences are expressed via linguistic preference relations. However, the extant literatures on linguistic consistency generally overlook the fact that even the same word can have diverse meanings for different people, which indicates that people usually possess personalized individual semantics (PISs) over words. Furthermore, with the complexity of the practical decision-making problem increases, decision makers become more likely to be uncertain and hesitant to make their preferences due to the lack of knowledge, therefore, their linguistic preferences may be represented through distributed linguistic representations. However, there are few consistency improving studies on distributed linguistic representations. Therefore, in this study we devise a novel consistency improving approach for distribution linguistic preference relations under a PISs context. Furthermore, the usability and effectiveness of the PISs based consistency improvement method are verified through the detail numerical analysis and comparative study. © 2022","Consistency improvement; Distribution linguistic preference relation; Group decision making; Personalized individual semantics"
"Stability-based PAC-Bayes analysis for multi-view learning algorithms","2022","Information Fusion","10.1016/j.inffus.2022.06.006","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133471186&doi=10.1016%2fj.inffus.2022.06.006&partnerID=40&md5=465c67081feb136df168f9367721b594","Multi-view learning exploits structural constraints among multiple views to effectively learn from data. Although it has made great methodological achievements in recent years, the current generalization theory is still insufficient to prove the merit of multi-view learning. This paper blends stability into multi-view PAC-Bayes analysis to explore the generalization performance and effectiveness of multi-view learning algorithms. We propose a novel view-consistency regularization to produce an informative prior that helps to obtain a stability-based multi-view bound. Furthermore, we derive an upper bound on the stability coefficient that is involved in the PAC-Bayes bound of multi-view regularization algorithms for the purpose of computation, taking the multi-view support vector machine as an example. Experiments provide strong evidence on the advantageous generalization bounds of multi-view learning over single-view learning. We also explore strengths and weaknesses of the proposed stability-based bound compared with previous non-stability multi-view bounds experimentally. © 2022 Elsevier B.V.","Generalization; Multi-view learning; PAC-Bayes analysis; Stability"
"RuleCOSI+: Rule extraction for interpreting classification tree ensembles","2023","Information Fusion","10.1016/j.inffus.2022.08.021","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137173959&doi=10.1016%2fj.inffus.2022.08.021&partnerID=40&md5=cc1d5afc69886ba0ecc0c244744db46a","Despite the advent of novel neural network architectures, tree-based ensemble algorithms such as random forests and gradient boosting machines still prevail in many practical machine learning problems in manufacturing, financial, and medical domains. However, tree ensembles have the limitation that the internal decision mechanisms of complex models are difficult to understand. Therefore, we present a post-hoc interpretation approach for classification tree ensembles. The proposed method, RuleCOSI+, extracts simple rules from tree ensembles by greedily combining and simplifying their base trees. Compared with its previous version, RuleCOSI, this new version can be applied to both bagging (e.g., random forest, RF) and boosting ensembles (e.g., gradient boosting machines, GBM) and run much faster for ensembles with hundreds of trees. To assess the performance and applicability of the method, empirical experiments were conducted using two bagging algorithms and four gradient boosting algorithms over 33 datasets. RuleCOSI+ could generate the best classification rulesets in terms of F-measure together with RuleFit for RF and GBM models of the datasets among five ensemble simplification algorithms, but the rulesets of RuleCOSI+ had, on average, less than half the size of those of RuleFit. Moreover, RuleCOSI+ had the best antecedent uniqueness rate (“UNIQ”) among the five algorithms, and had also ranked high in the number of rules (“NRULES”) and the rule reduction rate (“REDU”). In addition, the proposed method could reduce generalization errors in the simplified rulesets to obtain, on average, slightly better classification errors than original models of two bagging and three gradient boosting algorithms except CATBoost. © 2022","Ensemble learning; Ensemble simplification; Explainable artificial intelligence; Interpretable machine learning; Rule extraction; tree ensembles"
"Cross-sensor periocular biometrics in a global pandemic: Comparative benchmark and novel multialgorithmic approach","2022","Information Fusion","10.1016/j.inffus.2022.03.008","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127807945&doi=10.1016%2fj.inffus.2022.03.008&partnerID=40&md5=2f792750ce467f1a3c10c07ef645f0cd","The massive availability of cameras and personal devices results in a wide variability between imaging conditions, producing large intra-class variations and a significant performance drop if images from heterogeneous environments are compared for person recognition purposes. However, as biometric solutions are extensively deployed, it will be common to replace acquisition hardware as it is damaged or newer designs appear or to exchange information between agencies or applications operating in different environments. Furthermore, variations in imaging spectral bands can also occur. For example, face images are typically acquired in the visible (VIS) spectrum, while iris images are usually captured in the near-infrared (NIR) spectrum. However, cross-spectrum comparison may be needed if, for example, a face image obtained from a surveillance camera needs to be compared against a legacy database of iris imagery. Here, we propose a multialgorithmic approach to cope with periocular images captured with different sensors. With face masks in the front line to fight against the COVID-19 pandemic, periocular recognition is regaining popularity since it is the only region of the face that remains visible. As a solution to the mentioned cross-sensor issues, we integrate different biometric comparators using a score fusion scheme based on linear logistic regression This approach is trained to improve the discriminating ability and, at the same time, to encourage that fused scores are represented by log-likelihood ratios. This allows easy interpretation of output scores and the use of Bayes thresholds for optimal decision-making since scores from different comparators are in the same probabilistic range. We evaluate our approach in the context of the 1st Cross-Spectral Iris/Periocular Competition, whose aim was to compare person recognition approaches when periocular data from visible and near-infrared images is matched. The proposed fusion approach achieves reductions in the error rates of up to 30%–40% in cross-spectral NIR–VIS comparisons with respect to the best individual system, leading to an EER of 0.2% and a FRR of just 0.47% at FAR = 0.01%. It also represents the best overall approach of the mentioned competition. Experiments are also reported with a database of VIS images from two different smartphones as well, achieving even bigger relative improvements and similar performance numbers. We also discuss the proposed approach from the point of view of template size and computation times, with the most computationally heavy comparator playing an important role in the results. Lastly, the proposed method is shown to outperform other popular fusion approaches in multibiometrics, such as the average of scores, Support Vector Machines, or Random Forest. © 2022 The Authors","Cross-sensor; Cross-spectral; Linear logistic regression; Multibiometrics fusion; Ocular biometrics; Periocular recognition; Sensor interoperability"
"Towards a data collection methodology for Responsible Artificial Intelligence in health: A prospective and qualitative study in pregnancy","2022","Information Fusion","10.1016/j.inffus.2022.03.011","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127526963&doi=10.1016%2fj.inffus.2022.03.011&partnerID=40&md5=44ab7502a059f6ca5a1e9902ca9871cf","A medical field that is increasingly benefiting from Artificial Intelligence applications is Gyne- cology and Obstetrics. In previous work, we exposed that Artificial Intelligence (AI) technology and obstetric control by physicians can enhance pregnancy health, leading to better pregnancy outcomes and overall better experience, also reducing any possible long-term effects that can be produced by complications. This work presents a data collection methodology for responsible AI in Health and a case study in the pregnancy domain. It is a qualitative descriptive study on the preferences and expectations expressed by pregnant women regarding responsible AI and affective computing. A 41-items structured interview was distributed among 150 pregnant pa- tients attending prenatal care at Hospital Virgen del Rocío and the Clinic Victoria Rey (Seville, Spain) during the months of October and November 2020. A substantial interest in intelligent pregnancy solutions among pregnant women has been revealed in this study. Participants with a lower level of interest reported privacy concerns and lack of trust towards AI solutions. Re- garding affective computing based intelligent solutions specifically, most participants reported positively and no significant difference was found between women having a healthy or a high risk pregnancy on this matter. Our findings also suggest that a high demand of personalized intelligent solutions exists among participants. On the topic of sharing pregnancy data with the healthcare provider in favor of scientific research, pregnant women assisting public health- care services were found to be more likely to share their data when the provider was a public healthcare system rather than a private entity. Pregnant women who are interested in using an AI pregnancy application share a strong idea that it needs to be responsible, trustworthy, useful, and safe. Likewise, we found that pregnant women would change their mind about their concerns and they would feel more confident if the intelligent solution gives explanations about the system decisions and recommendations, as XAI approach promotes. © 2022 The Author(s)","Affective computing; Emotional computing; Explainable Artificial Intelligence (XAI); Human-Centered Design; Pregnancy; Privacy; Responsible Artificial Intelligence (RAI); Security; User-centered design"
"A dynamic hybrid trust network-based dual-path feedback consensus model for multi-attribute group decision-making in intuitionistic fuzzy environment","2022","Information Fusion","10.1016/j.inffus.2021.09.020","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119988371&doi=10.1016%2fj.inffus.2021.09.020&partnerID=40&md5=0cb480efda28f7e521d7da43f7039e6b","This paper proposes a dual-path feedback consensus model based on dynamic hybrid trust relationships to solve multi-attribute group decision-making problems in intuitionistic fuzzy environment. This model comprises two main parts: (a) the construction of a dynamic hybrid trust network among decision makers (DMs) and (b) the formation of a dual-path feedback mechanism to improve the group consensus. In the first part, a hybrid trust network is constructed by combining DMs’ prior knowledge of each other and the preference similarities between them. Then, the hybrid trust network is dynamically updated iteratively to reflect the changes in the trust relationships in the process of joint decision-making. In the second part, DMs with low consensus degrees are identified and provided with either a preference or weight adjustment path to improve the group consensus. The preference adjustment path is activated for DMs who agree to modify their preferences, and a nonlinear programming model is proposed to help DMs improve consensus degrees while minimizing adjustment cost. The weight adjustment path is activated for DMs who stick to their own opinions and refuse to make changes, and their weights is adjusted accordingly. An illustrative example along with the related sensitivity analysis and comparative study are used to verify the effectiveness of the proposed model. © 2021","Dynamic decision-making; Feedback mechanism; Intuitionistic fuzzy sets; Multi-attribute group decision-making; Trust network"
"Image fusion in the loop of high-level vision tasks: A semantic-aware real-time infrared and visible image fusion network","2022","Information Fusion","10.1016/j.inffus.2021.12.004","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123247618&doi=10.1016%2fj.inffus.2021.12.004&partnerID=40&md5=1c59a0a9f79585213c77314dbcac40e3","Infrared and visible image fusion aims to synthesize a single fused image that not only contains salient targets and abundant texture details but also facilitates high-level vision tasks. However, the existing fusion algorithms unilaterally focus on the visual quality and statistical metrics of fused images but ignore the demands of high-level vision tasks. To address these challenges, this paper bridges the gap between image fusion and high-level vision tasks and proposes a semantic-aware real-time image fusion network (SeAFusion). On the one hand, we cascade the image fusion module and semantic segmentation module and leverage the semantic loss to guide high-level semantic information to flow back to the image fusion module, which effectively boosts the performance of high-level vision tasks on fused images. On the other hand, we design a gradient residual dense block (GRDB) to enhance the description ability of the fusion network for fine-grained spatial details. Extensive comparative and generalization experiments demonstrate the superiority of our SeAFusion over state-of-the-art alternatives in terms of maintaining pixel intensity distribution and preserving texture detail. More importantly, the performance comparison of various fusion algorithms in task-driven evaluation reveals the natural advantages of our framework in facilitating high-level vision tasks. In addition, the superior running efficiency allows our algorithm to be effortlessly deployed as a real-time pre-processing module for high-level vision tasks. The source code will be released at https://github.com/Linfeng-Tang/SeAFusion. © 2022 Elsevier B.V.","Gradient residual dense block; High-level vision task; Image fusion; Semantic aware; Task-driven evaluation"
"Distributed Filtering for Multi-sensor Systems with Missing Data","2022","Information Fusion","10.1016/j.inffus.2022.06.007","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133949397&doi=10.1016%2fj.inffus.2022.06.007&partnerID=40&md5=4e68a3d94ac89626ae5eb0f6c62150d4","This paper studies distributed estimation problems for multi-sensor systems with missing data. Missing data may occur during sensor measuring or data exchanging among sensor nodes due to unreliability of communication links or external disturbances. Missing data include random missing measurements of sensor itself and random missing estimates of neighbor nodes. Three distributed Kalman filter (DKF) algorithms with the Kalman-like form are designed for each sensor node. When it is available whether a datum is missing or not at each time, an optimal DKF (ODKF) dependent on the knowledge of missing data is presented, where filter gains and covariance matrices require online computing. To reduce online computational cost, a suboptimal DKF (SDKF) is presented, where filter gains and covariance matrices dependent on missing probabilities can be computed offline. When it is unavailable whether a datum is missing or not, a probability-based DKF (PDKF) dependent on missing probabilities is presented. For each DKF algorithm, an optimal Kalman filter gain for measurements of sensor itself and different optimal consensus filter gains for state estimates of its neighbor nodes are designed in the linear unbiased minimum variance (LUMV) sense, respectively. Mean boundedness of covariance matrix of the proposed ODKF is analyzed. Stability and steady-state properties of the proposed SDKF and PDKF are analyzed. Also, the performance of three DKF algorithms is compared. Simulation examples demonstrate effectiveness of the proposed algorithms. © 2022","Distributed Kalman filter; LUMV; Missing data; Multi-sensor system; Steady-state property"
"Survey of Landmark-based Indoor Positioning Technologies","2023","Information Fusion","10.1016/j.inffus.2022.08.013","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136458455&doi=10.1016%2fj.inffus.2022.08.013&partnerID=40&md5=0cd18ae7cee7b1027d75e9e15c8f94a4","Owing to the increase in the time people spend indoors, coupled with the pervasiveness of high-performance smart devices, the importance of indoor positioning techniques has grown. Researchers have extensively studied indoor positioning techniques using wireless signals or mobile device built-in sensors because satellite signals are absent in indoor environments. However, the built-in sensor readings tend to be distorted by the surrounding indoor environments. Furthermore, wireless signal-based technology incurs substantial cost because of presurvey and maintenance. To address these drawbacks, landmark-based indoor positioning technologies have recently been developed. An indoor landmark is a unique point in a room that is distinguishable from other points based on its features. Because the indoor landmark itself underscores the unique features of a specific region, it acts as a reference point to help users navigate efficiently. In this paper, we review recent landmark-based indoor positioning technologies. We categorize the technologies according to whether they use wireless signals, built-in sensors, images, and multisource-based technologies. We analyze them based on six evaluation criteria, namely, accuracy, core technology, detection difficulty, cost, versatility, and robustness. Finally, we discuss future directions of research and applications on indoor landmark positioning techniques. We believe that this review provides useful viewpoints and necessary information regarding indoor positioning technology using landmarks. © 2022","Indoor positioning; Landmark; Multisource-based technologies; Sensor data; Visual image; Wireless signal"
"An inductive heterogeneous graph attention-based multi-agent deep graph infomax algorithm for adaptive traffic signal control","2022","Information Fusion","10.1016/j.inffus.2022.08.001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135712544&doi=10.1016%2fj.inffus.2022.08.001&partnerID=40&md5=8a06a089a8ca2ee900dfc291b138c11a","Adaptive traffic signal control (ATSC) facilitates alleviating traffic congestion. Multi-agent deep reinforcement learning (MDRL) is a new promising algorithm for ATSC, and Graph Neural Networks (GNNs) further promote its learning ability. However, there are some drawbacks in the state-of-the-art MDRL algorithms. (1) These algorithms cannot effectively fuse diverse heterogeneous information of traffic networks due to adopting homogeneous GNNs; (2) These algorithms cannot be effectively trained due to merely adopting MDRL loss functions. In this paper, we propose an Inductive Heterogeneous graph Attention-based Multi-agent Deep Graph Infomax (IHA-MDGI) algorithm for ATSC. The proposed IHA-MDGI algorithm conducts both feature fusion via a proposed Inductive Heterogeneous graph Attention (IHA) algorithm and training via a proposed Multi-agent Deep Graph Infomax (MDGI) framework. Specifically, (1) Unlike the algorithms which adopt homogeneous GNNs, in the IHA algorithm, heterogeneous GNNs are designed to fuse both heterogeneous structural information and heterogeneous features of traffic networks, which aims to acquire heterogeneous information embeddings of traffic networks. (2) In the MDGI framework, the acquired embeddings are used to calculate the signal-control policies and Q-value for each agent, and then a mutual-information loss function is designed, which combines with the MDRL loss function to jointly train the whole algorithm. The designed mutual-information loss function focuses on maximizing mutual information between input (i.e., heterogeneous information embeddings) and output (i.e., Q-value), which can produce cooperative signal-control policies and maximize Q-value. We conduct the experiments in both real-traffic and synthetic-traffic networks under the time-varying traffic flows, and the results demonstrate that IHA-MDGI algorithm outperforms the state-of-the-art MDRL algorithms about multiple metrics. © 2022 Elsevier B.V.","Adaptive traffic signal control; Attention mechanism; Heterogeneous feature fusion; Multi-agent reinforcement learning; Mutual information"
"A fusion spatial attention approach for few-shot learning","2022","Information Fusion","10.1016/j.inffus.2021.11.019","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121617540&doi=10.1016%2fj.inffus.2021.11.019&partnerID=40&md5=6c61054420218f99c071a5f0b87cd448","Few-shot learning is a challenging problem in computer vision that aims to learn a new visual concept from very limited data. A core issue is that there is a large amount of uncertainty introduced by the small training set. For example, the few images may include cluttered backgrounds or different scales of objects. Existing approaches mostly address this problem from either the original image space or the embedding space by using meta-learning. To the best of our knowledge, none of them tackle this problem from both spaces jointly. To this end, we propose a fusion spatial attention approach that performs spatial attention in both image and embedding spaces. In the image space, we employ a Saliency Object Detection (SOD) module to extract the saliency map of an image and provide it to the network as an additional channel. In the embedding space, we propose an Adaptive Pooling (Ada-P) module tailored to few-shot learning that introduces a meta-learner to adaptively fuse local features of the feature maps for each individual embedding. The fusion process assigns different pooling weights to the features at different spatial locations. Then, weighted pooling can be conducted over an embedding to fuse local information, which can avoid losing useful information by considering the spatial importance of the features. The SOD and Ada-P modules can be used within a plug-and-play module and incorporated into various existing few-shot learning approaches. We empirically demonstrate that designing spatial attention methods for few-shot learning is a nontrivial task and our method has proven effective for it. We evaluate our method using both shallow and deeper networks on three widely used few-shot learning benchmarks, miniImageNet, tieredImageNet and CUB, and demonstrate very competitive performance. © 2021","Adaptive pooling; Feature aggregation; Few-shot learning; Meta-learning; Saliency object detection; Spatial attention"
"Counterfactuals and causability in explainable artificial intelligence: Theory, algorithms, and applications","2022","Information Fusion","10.1016/j.inffus.2021.11.003","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85120935859&doi=10.1016%2fj.inffus.2021.11.003&partnerID=40&md5=a02d66f00840b8163e0d22bbed530af5","Deep learning models have achieved high performance across different domains, such as medical decision-making, autonomous vehicles, decision support systems, among many others. However, despite this success, the inner mechanisms of these models are opaque because their internal representations are too complex for a human to understand. This opacity makes it hard to understand the how or the why of the predictions of deep learning models. There has been a growing interest in model-agnostic methods that make deep learning models more transparent and explainable to humans. Some researchers recently argued that for a machine to achieve human-level explainability, this machine needs to provide human causally understandable explanations, also known as causability. A specific class of algorithms that have the potential to provide causability are counterfactuals. This paper presents an in-depth systematic review of the diverse existing literature on counterfactuals and causability for explainable artificial intelligence (AI). We performed a Latent Dirichlet topic modelling analysis (LDA) under a Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) framework to find the most relevant literature articles. This analysis yielded a novel taxonomy that considers the grounding theories of the surveyed algorithms, together with their underlying properties and applications to real-world data. Our research suggests that current model-agnostic counterfactual algorithms for explainable AI are not grounded on a causal theoretical formalism and, consequently, cannot promote causability to a human decision-maker. Furthermore, our findings suggest that the explanations derived from popular algorithms in the literature provide spurious correlations rather than cause/effects relationships, leading to sub-optimal, erroneous, or even biased explanations. Thus, this paper also advances the literature with new directions and challenges on promoting causability in model-agnostic approaches for explainable AI. © 2021 Elsevier B.V.","Causability; Causality; Counterfactuals; Deep learning; Explainable AI"
"Pedestrian Re-identification Algorithm Based on Visual Attention-positive Sample Generation Network Deep Learning Model","2022","Information Fusion","10.1016/j.inffus.2022.07.002","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134316389&doi=10.1016%2fj.inffus.2022.07.002&partnerID=40&md5=5d27a6ed50485da95499decbf9b90980","In view of the strong generalizability and self-learning capabilities of deep learning models, many scholars have studies how to apply deep learning theory in the pedestrian re-identification field. However, a number of problems persist in practically applying deep learning in this field, including determining how to make full use of the features of the sequence information in the salient region of an image and addressing the data gap between data-driven deep learning models and pedestrian re-identification tasks. In view of these problems, in this paper, a re-identification method is proposed based on a visual common attention mechanism. Initially, the method focuses on the local area of the image at the location specified by the given coordinates. Next, under the constraint of pedestrian image pairing tags, it focuses on the sequence of salient regions of image pairs based on deep learning techniques. Then, the global features and the local attention features are cascaded into joint features for use in pedestrian re-identification. To address the data gap between deep learning models and pedestrian re-identification, a new strategy for generating difficult positive samples is proposed primarily through a positive sample that mainly involves a positive sample generation network, a difficult positive sample conversion network, and a dual-stream twin network. We using this network, a large number of positive samples can be obtained to train the data-driven neural network and solve the re-identification task. The above ideas are combined to propose a pedestrian re-identification algorithm based on a visual attention-positive sample generation network deep learning model. The experimental results show that the method proposed in this paper not only achieves better recognition results than other deep learning methods, but also adapts well to a variety of databases. In addition, the method proposed in this paper is more robust to occluded pedestrian images than other deep learning methods. In addition, the method proposed in this paper is more robust than other deep learning methods for occluding pedestrian images. © 2022","Deep learning; Pedestrian re-identification; Positive sample generation network; Variational self-encoding; Visual attention"
"Double-cohesion learning based multiview and discriminant palmprint recognition","2022","Information Fusion","10.1016/j.inffus.2022.03.005","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127820397&doi=10.1016%2fj.inffus.2022.03.005&partnerID=40&md5=a58f1b9a6f4fc9a6c15b01044510b5ab","Palmprint recognition has been widely used in security authentication. However, most of the existing palmprint representation methods are focused on a special application scenario using the hand-crafted features from a single-view. If the features become weak as the application scenario changes, the recognition performance will be degraded. To address this problem, we propose to comprehensively exploit palmprint features from multiple views to improve the recognition performance in generic scenarios. In this paper, a novel double-cohesion learning based multiview and discriminant palmprint recognition (DC_MDPR) method is proposed, which imposes a double-cohesion strategy to reduce the inter-view margins for each subject and the intra-class margins for each view. In this way, for each subject, the features from different views can be closer to each other in the binary-label space. Meanwhile, for each view, the features sharing the same label information can move towards each other by imposing a neighbor graph regularization. The proposed method can be flexibly applied to any type of palmprint feature fusion. Moreover, it presents the multiview features in a low-dimensionality sub-space, effectively reducing the computational complexity. Experimental results on various palmprint databases have shown that the proposed method can always achieve the best recognition performance compared to other state-of-the-art algorithms. © 2022 Elsevier B.V.","Discriminant projection; Double-cohesion learning; Multiview learning; Palmprint recognition"
"Multimodal audio-visual information fusion using canonical-correlated Graph Neural Network for energy-efficient speech enhancement","2023","Information Fusion","10.1016/j.inffus.2022.09.006","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138109331&doi=10.1016%2fj.inffus.2022.09.006&partnerID=40&md5=13d718f63a7bf6082fce65862b3d26f7","This paper proposes a novel multimodal self-supervised architecture for energy-efficient audio-visual (AV) speech enhancement that integrates Graph Neural Networks with canonical correlation analysis (CCA-GNN). The proposed approach lays its foundations on a state-of-the-art CCA-GNN that learns representative embeddings by maximizing the correlation between pairs of augmented views of the same input while decorrelating disconnected features. The key idea of the conventional CCA-GNN involves discarding augmentation-variant information and preserving augmentation-invariant information while preventing capturing of redundant information. Our proposed AV CCA-GNN model deals with multimodal representation learning context. Specifically, our model improves contextual AV speech processing by maximizing canonical correlation from augmented views of the same channel and canonical correlation from audio and visual embeddings. In addition, it proposes a positional node encoding that considers a prior-frame sequence distance instead of a feature-space representation when computing the node's nearest neighbors, introducing temporal information in the embeddings through the neighborhood's connectivity. Experiments conducted on the benchmark ChiME3 dataset show that our proposed prior frame-based AV CCA-GNN ensures a better feature learning in the temporal context, leading to more energy-efficient speech reconstruction than state-of-the-art CCA-GNN and multilayer perceptron. © 2022","Canonical correlation analysis; Graph Neural Networks; Multimodal learning; Positional encoding; Prior frames neighborhood"
"A One-Class Classification method based on Expanded Non-Convex Hulls","2023","Information Fusion","10.1016/j.inffus.2022.07.023","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135888910&doi=10.1016%2fj.inffus.2022.07.023&partnerID=40&md5=69ed12d42d6608e3ce5b5d1c5e5016ac","This paper presents an intuitive, robust and efficient One-Class Classification algorithm. The method developed is called OCENCH (One-class Classification via Expanded Non-Convex Hulls) and bases its operation on the construction of subdivisible and expandable non-convex hulls to represent the target class. The method begins by reducing the dimensionality of the data to two-dimensional spaces using random projections. After that, an iterative process based on Delaunay triangulations is applied to these spaces to obtain simple polygons that characterizes the non-convex shape of the normal class data. In addition, the method subdivides the non-convex hulls to represent separate regions in space if necessary. The method has been evaluated and compared to several main algorithms of the field using real data sets. In contrast to other methods, OCENCH can deal with non-convex and disjointed shapes. Finally, its execution can be carried out in a parallel way, which is interesting to reduce the execution time. © 2022 The Author(s)","Convex Hull; Delaunay triangulation; Ensemble learning; Machine learning; One-Class Classification; Random projections"
"Neural generators of sparse local linear models for achieving both accuracy and interpretability","2022","Information Fusion","10.1016/j.inffus.2021.11.009","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121130374&doi=10.1016%2fj.inffus.2021.11.009&partnerID=40&md5=adf233f9c9b539d2e89f77c4d122b612","For reliability, it is important for the predictions made by machine learning methods to be interpretable by humans. In general, deep neural networks (DNNs) can provide accurate predictions, although it is difficult to interpret why such predictions are obtained by the DNNs. On the other hand, interpretation of linear models is easy, although their predictive performance is low because real-world data are often intrinsically non-linear. To combine both the benefits of the high predictive performance of DNNs and the high interpretability of linear models into a single model, we propose neural generators of sparse local linear models (NGSLL). Sparse local linear models have high flexibility because they can approximate non-linear functions. NGSLL generates sparse linear weights for each sample using DNNs that take the original representations of each sample (e.g., word sequence) and their simplified representations (e.g., bag-of-words) as input. By extracting features from the original representations, the weights can contain rich information and achieve a high predictive performance. In addition, the prediction is interpretable because it is obtained through the inner product between the simplified representations and the sparse weights, where only a small number of weights are selected by our gate module in NGSLL. In experiments on image, text and tabular datasets, we demonstrate the effectiveness of NGSLL quantitatively and qualitatively by evaluating the prediction performance and visualizing generated weights. © 2021","Explainability; Feature selection; Interpretable machine learning; Local linear models; Neural networks"
"Consistency and consensus reaching process for group decision making based on complete interval distributed preference relations under social network analysis","2022","Information Fusion","10.1016/j.inffus.2022.07.015","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135720833&doi=10.1016%2fj.inffus.2022.07.015&partnerID=40&md5=6b0b4ab5c41c33744fe2257b0b798779","Group decision-making (GDM) problems often consist of many indeterminacy factors in realistic situation. How to cope with consistency and consensus under uncertain circumstance are two critical issues in pairwise comparison based GDM problems. In this paper, we firstly propose the model of complete interval distributed preference relation (CIDPR) based on the concept of linguistic distribution with interval symbolic proportions, distribution linguistic preference relation (DLPR) and IDPR. Secondly, the additive consistency index of CIDPR is defined to measure the consistency level of expert's judgment, and an adjustment algorithm is proposed for converting inconsistent CIDPR to an acceptable consistent level. Thirdly, since trust relation is a critical factor in the generation of experts’ weights and the adjustment of experts’ opinions, consensus reaching process (CRP) is designed to take into account distributed linguistic trust relations under social network analysis (SNA). In the proposed adjustment mechanism, non-consensus individual should modify opinion towards his/her trusted and highly weighted expert. The advantage of the proposed inconsistent CIDPR adjustment model can maximally retain the information in the original distribution, while the CRP has a relatively fast convergent speed and good practicality. An illustrative example of strategic new product selection is conducted to demonstrate the applicability of the proposed method and its potential in supporting realistic GDM problems. © 2022 Elsevier B.V.","Complete interval distributed preference relation; Consensus reaching process; Consistency; Distributed linguistic trust relation; Group decision making; Opinion fusion"
"DFMKE: A dual fusion multi-modal knowledge graph embedding framework for entity alignment","2023","Information Fusion","10.1016/j.inffus.2022.09.012","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138475820&doi=10.1016%2fj.inffus.2022.09.012&partnerID=40&md5=826ddf0a1420a818da736c67474acbfc","Entity alignment is critical for multiple knowledge graphs (KGs) integration. Although researchers have made significant efforts to explore the relational embeddings between different KGs, existing approaches may not describe multi-modal knowledge well in some tasks, e.g., entity alignment. In this paper, we propose DFMKE, a dual fusion multi-modal knowledge graph embedding framework, to address entity alignment. We first devise an early fusion method for fusing features of multi-modal entity representations of a KG. Simultaneously, multiple representations of various types of knowledge are generated independently by various techniques and fused by a low-rank multi-modal late fusion method. Finally, the outputs of early and late fusion methods are combined using a dual fusion scheme. DFMKE provides an ultimate fusion solution by leveraging the advantages of early and late fusion methods. Extensive experiments on two public datasets show that the DFMKE outperforms state-of-the-art methods by a significant margin achieving at least 10% more regard to Hits@n and MRR metrics. © 2022 Elsevier B.V.","Entity alignment; Knowledge graph; Multi-modal knowledge; Neural networks"
"Robust minimum cost consensus models with various individual preference scenarios under unit adjustment cost uncertainty","2023","Information Fusion","10.1016/j.inffus.2022.09.002","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138798925&doi=10.1016%2fj.inffus.2022.09.002&partnerID=40&md5=17160cb1664c65d93e981bf8466056f7","In group decision making (GDM), individual opinions and unit adjustment costs are essential factors in reaching a collective consensus. However, in previous studies, most scholars only considered the uncertainty of individual opinions while ignored the uncertainty of unit adjustment costs or had an inaccurate description of unit adjustment cost uncertainty, which increases the risk for decision makers (DMs). This study constructs four types of uncertainty sets to describe the uncertainty of unit adjustment costs more accurately to solve this problem. Moreover, based on multi-role individual preference scenarios, we adopt a robust optimisation (RO) method to reduce the risk of the model, and we propose robust minimum cost consensus models with various individual preference scenarios under the uncertainty of unit adjustment costs. Furthermore, the proposed robust models were applied to numerical experiments on marine ranching in Weihai, China. The results showed that the proposed robust models were more potent than the original model. Finally, a sensitivity analysis is presented and the characteristics of the proposed models are revealed. © 2022 Elsevier B.V.","Consensus models; Group decision making; Individual preference; Robust optimisation; Uncertainty set"
"Comparing and extending the use of defeasible argumentation with quantitative data in real-world contexts","2023","Information Fusion","10.1016/j.inffus.2022.08.025","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138070328&doi=10.1016%2fj.inffus.2022.08.025&partnerID=40&md5=80489c4ba7cb5111554b7e35e4660762","Dealing with uncertain, contradicting, and ambiguous information is still a central issue in Artificial Intelligence (AI). As a result, many formalisms have been proposed or adapted so as to consider non-monotonicity. A non-monotonic formalism is one that allows the retraction of previous conclusions or claims, from premises, in light of new evidence, offering some desirable flexibility when dealing with uncertainty. Among possible options, knowledge-base, non-monotonic reasoning approaches have seen their use being increased in practice. Nonetheless, only a limited number of works and researchers have performed any sort of comparison among them. This research article focuses on evaluating the inferential capacity of defeasible argumentation, a formalism particularly envisioned for modelling non-monotonic reasoning. In addition to this, fuzzy reasoning and expert systems, extended for handling non-monotonicity of reasoning, are selected and employed as baselines, due to their vast and accepted use within the AI community. Computational trust was selected as the domain of application of such models. Trust is an ill-defined construct, hence, reasoning applied to the inference of trust can be seen as non-monotonic. Inference models were designed to assign trust scalars to editors of the Wikipedia project. Scalars assigned to recognised trustworthy editors provided the basis for the analysis of the models’ inferential capacity according to evaluation metrics from the domain of computational trust. In particular, argument-based models demonstrated more robustness than those built upon the baselines despite the knowledge bases or datasets employed. This study contributes to the body of knowledge through the exploitation of defeasible argumentation and its comparison to similar approaches. It provides publicly implementations for the designed models of inference, which might be a useful aid to scholars interested in performing non-monotonic reasoning activities. It adds to previous works, empirically enhancing the generalisability of defeasible argumentation as a compelling approach to reason with quantitative data and uncertain knowledge. © 2022","Argumentation theory; Computational trust; Defeasible argumentation; Expert systems; Fuzzy logic; Knowledge-based systems; Non-monotonic reasoning"
"PoNet: A universal physical optimization-based spectral super-resolution network for arbitrary multispectral images","2022","Information Fusion","10.1016/j.inffus.2021.10.016","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119626398&doi=10.1016%2fj.inffus.2021.10.016&partnerID=40&md5=04172654486ddf9399f1e48772505e04","Spectral super-resolution is a very important technique to obtain hyperspectral images from only multispectral images, which can effectively solve the high acquisition cost and low spatial resolution of hyperspectral images. However, in practice, multispectral channels or images captured by the same sensor are often with different spatial resolutions, which brings a severe challenge to spectral super-resolution. This paper proposed a universal spectral super-resolution network based on physical optimization unfolding for arbitrary multispectral images, including single-resolution and cross-scale multispectral images. Furthermore, two new strategies are proposed to make full use of the spectral information, namely, cross-dimensional channel attention and cross-depth feature fusion. Experimental results on five data sets show superiority and stability of PoNet addressing any spectral super-resolution situations. © 2021 Elsevier B.V.","Deep learning; Hyperspectral images; Multispectral images; Physical interpretability; Spectral super-resolution"
"PIAFusion: A progressive infrared and visible image fusion network based on illumination aware","2022","Information Fusion","10.1016/j.inffus.2022.03.007","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127469784&doi=10.1016%2fj.inffus.2022.03.007&partnerID=40&md5=75a8df842bde58ab2672afd8785f2944","Infrared and visible image fusion aims to synthesize a single fused image containing salient targets and abundant texture details even under extreme illumination conditions. However, existing image fusion algorithms fail to take the illumination factor into account in the modeling process. In this paper, we propose a progressive image fusion network based on illumination-aware, termed as PIAFusion, which adaptively maintains the intensity distribution of salient targets and preserves texture information in the background. Specifically, we design an illumination-aware sub-network to estimate the illumination distribution and calculate the illumination probability. Moreover, we utilize the illumination probability to construct an illumination-aware loss to guide the training of the fusion network. The cross-modality differential aware fusion module and halfway fusion strategy completely integrate common and complementary information under the constraint of illumination-aware loss. In addition, a new benchmark dataset for infrared and visible image fusion, i.e., Multi-Spectral Road Scenarios (available at https://github.com/Linfeng-Tang/MSRS), is released to support network training and comprehensive evaluation. Extensive experiments demonstrate the superiority of our method over state-of-the-art alternatives in terms of target maintenance and texture preservation. Particularly, our progressive fusion framework could round-the-clock integrate meaningful information from source images according to illumination conditions. Furthermore, the application to semantic segmentation demonstrates the potential of our PIAFusion for high-level vision tasks. Our codes will be available at https://github.com/Linfeng-Tang/PIAFusion. © 2022 Elsevier B.V.","Cross-modality differential aware fusion; Deep learning; Illumination aware; Image fusion"
"A systematic review on affective computing: emotion models, databases, and recent advances","2022","Information Fusion","10.1016/j.inffus.2022.03.009","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127142402&doi=10.1016%2fj.inffus.2022.03.009&partnerID=40&md5=9b5e12b99cc2e0ae6a05298552929cbb","Affective computing conjoins the research topics of emotion recognition and sentiment analysis, and can be realized with unimodal or multimodal data, consisting primarily of physical information (e.g., text, audio, and visual) and physiological signals (e.g., EEG and ECG). Physical-based affect recognition caters to more researchers due to the availability of multiple public databases, but it is challenging to reveal one's inner emotion hidden purposefully from facial expressions, audio tones, body gestures, etc. Physiological signals can generate more precise and reliable emotional results; yet, the difficulty in acquiring these signals hinders their practical application. Besides, by fusing physical information and physiological signals, useful features of emotional states can be obtained to enhance the performance of affective computing models. While existing reviews focus on one specific aspect of affective computing, we provide a systematical survey of important components: emotion models, databases, and recent advances. Firstly, we introduce two typical emotion models followed by five kinds of commonly used databases for affective computing. Next, we survey and taxonomize state-of-the-art unimodal affect recognition and multimodal affective analysis in terms of their detailed architectures and performances. Finally, we discuss some critical aspects of affective computing and its applications and conclude this review by pointing out some of the most promising future directions, such as the establishment of benchmark database and fusion strategies. The overarching goal of this systematic review is to help academic and industrial researchers understand the recent advances as well as new developments in this fast-paced, high-impact domain. © 2022","Affective computing; Deep learning; Feature learning; Machine learning; Multimodal affective analysis; Unimodal affect recognition"
"Two flexibility degrees-driven consensus model in group decision making with intuitionistic fuzzy preference relations","2022","Information Fusion","10.1016/j.inffus.2022.07.012","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135415495&doi=10.1016%2fj.inffus.2022.07.012&partnerID=40&md5=59879ad7076f61d9d84f6edfefb4fa7c","A group of experts are commonly invited to find an optimal solution to a complex decision making problem. When the bipolarity of decision information should be considered in group decision making (GDM), intuitionistic fuzzy values (IFVs) have the capability to model such opinions of decision makers (DMs). This paper develops a consensus model in GDM under intuitionistic fuzzy environments with flexibility. First, it is assumed that the initial opinions of DMs are expressed as intuitionistic fuzzy preference relations (IFPRs). A novel additive consistency index is constructed to measure the deviation degree of IFPRs from fuzzy preference relations (FPRs) with additive consistency, where the non-determinacy degree of IFPRs is incorporated. The thresholds of the proposed index corresponding to IFPRs with acceptable additive consistency are discussed and computed. Second, the consensus level of DMs is defined using the similarity degree between two IFVs. An optimization problem is established by maximizing the fitness function, which is constructed by linearly combining the proposed additive consistency index and consensus level. Two flexibility degrees are offered to each DM such that the initial opinions with the bipolarity can be adjusted correspondingly. Third, individual IFPRs in GDM are optimized using the particle swarm optimization (PSO) algorithm. Numerical examples are carried out to illustrate the proposed consensus model by comparing with the existing ones. The obtained results reveal that the proposed additive consistency index can reflect the inherent property of IFPRs. Different with the previous studies, two original flexibility degrees are proposed to characterize the multi-granularity of decision information in GDM. © 2022 Elsevier B.V.","Additive consistency index; Consensus level; Group decision making (GDM); Intuitionistic fuzzy preference relation (IFPR); Optimization"
"Diagnosis of multiple sclerosis using multifocal ERG data feature fusion","2021","Information Fusion","10.1016/j.inffus.2021.05.006","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107296500&doi=10.1016%2fj.inffus.2021.05.006&partnerID=40&md5=9be215c1a4ed778b504de22bdcc25d45","The purpose of this paper is to implement a computer-aided diagnosis (CAD) system for multiple sclerosis (MS) based on analysing the outer retina as assessed by multifocal electroretinograms (mfERGs). MfERG recordings taken with the RETI-port/scan 21 (Roland Consult) device from 15 eyes of patients diagnosed with incipient relapsing-remitting MS and without prior optic neuritis, and from 6 eyes of control subjects, are selected. The mfERG recordings are grouped (whole macular visual field, five rings, and four quadrants). For each group, the correlation with a normative database of adaptively filtered signals, based on empirical model decomposition (EMD) and three features from the continuous wavelet transform (CWT) domain, are obtained. Of the initial 40 features, the 4 most relevant are selected in two stages: a) using a filter method and b) using a wrapper-feature selection method. The Support Vector Machine (SVM) is used as a classifier. With the optimal CAD configuration, a Matthews correlation coefficient value of 0.89 (accuracy = 0.95, specificity = 1.0 and sensitivity = 0.93) is obtained. This study identified an outer retina dysfunction in patients with recent MS by analysing the outer retina responses in the mfERG and employing an SVM as a classifier. In conclusion, a promising new electrophysiological-biomarker method based on feature fusion for MS diagnosis was identified. © 2021 The Author(s)","Continuous wavelet transform; Empirical Mode Decomposition; Feature fusion; Multifocal electroretinogram; Multiple sclerosis; Support vector machine"
"Self-supervised feature adaption for infrared and visible image fusion","2021","Information Fusion","10.1016/j.inffus.2021.06.002","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107979771&doi=10.1016%2fj.inffus.2021.06.002&partnerID=40&md5=6df79ed573a3adffc72c340e7b23208c","Benefitting from the strong feature extraction capability of deep learning, infrared and visible image fusion has made a great progress. Since infrared and visible images are obtained by different sensors with different imaging mechanisms, there exists domain discrepancy, which becomes stumbling block for effective fusion. In this paper, we propose a novel self-supervised feature adaption framework for infrared and visible image fusion. We implement a self-supervised strategy that facilitates the backbone network to extract features with adaption while retaining the vital information by reconstructing the source images. Specifically, we preliminary adopt an encoder network to extract features with adaption. Then, two decoders with attention mechanism blocks are utilized to reconstruct the source images in a self-supervised way, forcing the adapted features to contain vital information of the source images. Further, considering the case that source images contain low-quality information, we design a novel infrared and visible image fusion and enhancement model, improving the fusion method's robustness. Experiments are constructed to evaluate the proposed method qualitatively and quantitatively, which show that the proposed method achieves the state-of-art performance comparing with existing infrared and visible image fusion methods. Results are available at https://github.com/zhoafan/SFA-Fuse. © 2021","Feature adaption; Infrared and visible image fusion; Low-quality information enhancement; Self-supervision"
"Unbox the black-box for the medical explainable AI via multi-modal and multi-centre data fusion: A mini-review, two showcases and beyond","2022","Information Fusion","10.1016/j.inffus.2021.07.016","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127068702&doi=10.1016%2fj.inffus.2021.07.016&partnerID=40&md5=30808f642dec8ce43d426fc67aa356b6","Explainable Artificial Intelligence (XAI) is an emerging research topic of machine learning aimed at unboxing how AI systems’ black-box choices are made. This research field inspects the measures and models involved in decision-making and seeks solutions to explain them explicitly. Many of the machine learning algorithms cannot manifest how and why a decision has been cast. This is particularly true of the most popular deep neural network approaches currently in use. Consequently, our confidence in AI systems can be hindered by the lack of explainability in these black-box models. The XAI becomes more and more crucial for deep learning powered applications, especially for medical and healthcare studies, although in general these deep neural networks can return an arresting dividend in performance. The insufficient explainability and transparency in most existing AI systems can be one of the major reasons that successful implementation and integration of AI tools into routine clinical practice are uncommon. In this study, we first surveyed the current progress of XAI and in particular its advances in healthcare applications. We then introduced our solutions for XAI leveraging multi-modal and multi-centre data fusion, and subsequently validated in two showcases following real clinical scenarios. Comprehensive quantitative and qualitative analyses can prove the efficacy of our proposed XAI solutions, from which we can envisage successful applications in a broader range of clinical questions. © 2021 The Authors","Explainable AI; Information fusion; Medical image analysis; Multi-domain information fusion; Weakly supervised learning"
"A distributed particle-PHD filter using arithmetic-average fusion of Gaussian mixture parameters","2021","Information Fusion","10.1016/j.inffus.2021.02.020","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102550907&doi=10.1016%2fj.inffus.2021.02.020&partnerID=40&md5=8439fe6de5b2a0c3bf2252b955fa3a28","We propose a particle-based distributed PHD filter for tracking the states of an unknown, time-varying number of targets. To reduce communication, the local PHD filters at neighboring sensors communicate Gaussian mixture (GM) parameters. In contrast to most existing distributed PHD filters, our filter employs an “arithmetic average” fusion. For particles–GM conversion, we use a method that avoids particle clustering and enables a significance-based pruning of the GM components. For GM–particles conversion, we develop an importance sampling based method that enables a parallelization of filtering and dissemination/fusion operations. The resulting distributed PHD filtering framework is able to integrate both particle-based and GM-based local PHD filters. Simulations demonstrate the excellent performance and small communication and computation requirements of our filter. © 2021 The Authors","Arithmetic average fusion; Average consensus; Distributed multitarget tracking; Distributed PHD filter; Flooding; Gaussian mixture; Importance sampling; Probability hypothesis density; Random finite set; Sequential Monte Carlo"
"Efficient closed high-utility pattern fusion model in large-scale databases","2021","Information Fusion","10.1016/j.inffus.2021.05.011","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85108122763&doi=10.1016%2fj.inffus.2021.05.011&partnerID=40&md5=6c58669424ff60e64d935d202ebddfe1","High-Utility Itemset Mining (HUIM) is considered a major issue in recent decades since it reveals profit strategies for use in industry for decision-making. Most existing works have focused on mining high-utility itemsets from databases showing large amount of patterns; however exact decisions are still challenging to make from that large amounts of discovered knowledge. Closed High-utility itemset mining (CHUIM) provides a smart way to present concise high-utility itemsets that can be more effective for making correct decisions. However, none of the existing works have focused on handling large-scale databases to integrate discovered knowledge from several distributed databases. In this paper, we first present a large-scale information fusion architecture to integrate discovered closed high-utility patterns from several distributed databases. The generic composite model is used to cluster transactions regarding their relevant correlation that can ensure correctness and completeness of the fusion model. The well-known MapReduce framework is then deployed in the developed DFM-Miner algorithm to handle big datasets for information fusion and integration. Experiments are then compared to the state-of-the-art CHUI-Miner and CLS-Miner algorithms for mining closed high-utility patterns and the results indicated that the designed model is well designed for handling large-scale databases with less memory usage. Moreover, the designed MapReduce framework can speed up the mining performance of closed high-utility patterns in the developed fusion system. © 2021","Closed high-utility pattern mining; Hadoop; Information fusion; Large-scale"
"Rotation Forest for Big Data","2021","Information Fusion","10.1016/j.inffus.2021.03.007","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103788147&doi=10.1016%2fj.inffus.2021.03.007&partnerID=40&md5=754d5985e7845695ba0bd061069f3cc4","The Rotation Forest classifier is a successful ensemble method for a wide variety of data mining applications. However, the way in which Rotation Forest transforms the feature space through PCA, although powerful, penalizes training and prediction times, making it unfeasible for Big Data. In this paper, a MapReduce Rotation Forest and its implementation under the Spark framework are presented. The proposed MapReduce Rotation Forest behaves in the same way as the standard Rotation Forest, training the base classifiers on a rotated space, but using a functional implementation of the rotation that enables its execution in Big Data frameworks. Experimental results are obtained using different cloud-based cluster configurations. Bayesian tests are used to validate the method against two ensembles for Big Data: Random Forest and PCARDE classifiers. Our proposal incorporates the parallelization of both the PCA calculation and the tree training, providing a scalable solution that retains the performance of the original Rotation Forest and achieves a competitive execution time (in average, at training, more than 3 times faster than other PCA-based alternatives). In addition, extensive experimentation shows that by setting some parameters of the classifier (i.e., bootstrap sample size, number of trees, and number of rotations), the execution time is reduced with no significant loss of performance using a small ensemble. © 2021 Elsevier B.V.","Big Data; Ensemble learning; Machine learning; Random Forest; Rotation Forest; Spark"
"Democratic consensus reaching process for multi-person multi-criteria large scale decision making considering participants’ individual attributes and concerns","2022","Information Fusion","10.1016/j.inffus.2021.07.023","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113280115&doi=10.1016%2fj.inffus.2021.07.023&partnerID=40&md5=8150b6a6c88d1bfa8a724b2f316b0651","Consensus reaching is a key issue in group decision-making, because conflicts of interest among groups are common. Democratic consensus refers to achieve a soft consensus among collective as well as ensure the effective participation and satisfaction of individuals. Multi-person multi-criteria large scale decision making (MpMcLSDM) usually involves a huge number of decision makers (DMs/participants), and different DMs usually have different interests. Thus, how to effectively manage individuals to promote democratic consensus is a current research challenge. To do that, this research develops a democratic consensus reaching process (DCRP) for MpMcLSDM problems. In the proposed approach, a clustering method that considers both the opinion similarity and individual concern similarity of DM is firstly given to decrease the complexity of MpMcLSDM issues. Subsequently, we propose to assign equal initial weight to each cluster to protect the interests of minorities. Meanwhile, a consensus contribution-based dynamic interactive weight updating method is implemented in the DCRPs to promote a high level of democratic consensus. Besides, a compromise degree-based consensus feedback strategy is developed to improve the efficiency of the DCRPs. The proposed feedback mechanism effectively considers the individual concern and adjustment willingness of DMs in the DCRPs. Finally, a case study and some comparisons are given to show the effectiveness and innovation of this research. © 2021 Elsevier B.V.","Democratic consensus reaching processes (DCRPs); Evaluation attributes; Individual concern; Multi-person multi-criteria large scale decision making (MpMcLSDM)"
"LPPTE: A lightweight privacy-preserving trust evaluation scheme for facilitating distributed data fusion in cooperative vehicular safety applications","2021","Information Fusion","10.1016/j.inffus.2021.03.003","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105308468&doi=10.1016%2fj.inffus.2021.03.003&partnerID=40&md5=679bd49187d8947e1980a14b550179da","Vehicular networks have tremendous potential to improve road safety, traffic efficiency, and driving comfort, where cooperative vehicular safety applications are a significant branch. In cooperative vehicular safety applications, through the distributed data fusion for large amounts of data from multiple nearby vehicles, each vehicle can intelligently perceive the surrounding conditions beyond the capability of its own onboard sensors. Trust evaluation and privacy preservation are two primary concerns for facilitating the distributed data fusion in cooperative vehicular safety applications. They have conflicting requirements and a good balance between them is urgently needed. Meanwhile, the computation, communication, and storage overheads will all influence the applicability of a candidate scheme. In this paper, we propose a Lightweight Privacy-Preserving Trust Evaluation (LPPTE) scheme which can primely balance the trust evaluation and privacy preservation with low overheads for facilitating the distributed data fusion in cooperative vehicular safety applications. Furthermore, we provide exhaustive theoretical analysis and simulation evaluation for the LPPTE scheme, and the results demonstrate that the LPPTE scheme can obviously improve the accuracy of fusion results and is significantly superior to the state-of-the-art schemes in multiple aspects. © 2021","Cooperative vehicular safety applications; Distributed data fusion; Overhead; Privacy preservation; Trust evaluation; Vehicular networks"
"Two approaches to partial-nodes-based state estimation for delayed complex networks with intermittent measurement transmissions","2021","Information Fusion","10.1016/j.inffus.2021.06.006","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85109173760&doi=10.1016%2fj.inffus.2021.06.006&partnerID=40&md5=ce74690f526b6dea4e78d8195f06c70a","This paper is concerned with the state estimation problem for delayed complex dynamic networks with non-identical local dynamical systems. The state estimation is conducted based on constrained information of the measurement outputs. Specifically, the network outputs are available only from a portion of network nodes, and such outputs are transmitted from the network nodes to the estimator in an intermittent way. By utilizing the Halanay inequality method as well as the average dwell-time approach, two sets of sufficient conditions are established that ensure the error dynamics of the state estimation to converge to zero exponentially, and explicit expressions of the estimator gains are further characterized. Finally, a numerical example is presented to demonstrate the effectiveness of the proposed approaches. © 2021","Complex networks; Intermittent transmission; Partial-nodes-based measurement; State estimation"
"An edge-cloud-aided incremental tensor-based fuzzy c-means approach with big data fusion for exploring smart data","2021","Information Fusion","10.1016/j.inffus.2021.05.017","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107653805&doi=10.1016%2fj.inffus.2021.05.017&partnerID=40&md5=0fc2f0d1032beae4a640ce206eb33f1c","Recently, smart data has attracted great attention in the smart city community since it can provide valuable information to support intelligent services such as planning, monitoring, and decision making. However, it imposes a big challenge to explore smart data from big data gathered from smart city with various advanced fusion and analysis approaches. This paper proposes an incremental tensor-based fuzzy c-means approach (IT-FCM) for obtaining smart data from continuously generated big data. Specifically, a weighted version of the tensor-based fuzzy c-means approach (T-FCM) is firstly proposed to cluster the dataset that combines the previous cluster centroids and the new generated data. Aiming to improve the clustering efficiency, the old data objects are represented by the centroids to avoid repeat clustering. Furthermore, this paper presents an edge-cloud-aided clustering scheme to fuse big data from different sources and perspectives and further to implement co-clustering on the fused datasets for exploring smart data. Finally, the proposed IT-FCM approach is evaluated by comparing with T-FCM regarding clustering accuracy and efficiency on two different datasets in the experiments. The results state that IT-FCM outperforms T-FCM in clustering streaming big data in terms of accuracy and efficiency for obtaining smart data. © 2021 Elsevier B.V.","Big data fusion; Fuzzy c-means; Smart city; Smart data"
"A data-level fusion model for unsupervised attribute selection in multi-source homogeneous data","2022","Information Fusion","10.1016/j.inffus.2021.10.017","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119424761&doi=10.1016%2fj.inffus.2021.10.017&partnerID=40&md5=cddf7ee1ae2cd7123bce24d578e37894","Information fusion refers to derive an overall precise description of data by using certain fusion technique for utilizing the complementary information from multiple sources of data, which can facilitate effective decision-making, prediction and classification, etc. Multi-source homogeneous data, characterizing the data type of variables in the sample in form of one type (i.e., numerical or categorical) in different information sources, which widely exists in many practical applications. This paper concentrates on efficient fusion of multi-source homogeneous data with a data-level fusion model which involves the consolidation of multiple information sources and unsupervised attribute selection of the fused data. A unified description and modeling method of a multi-source homogeneous information system is introduced. The neighborhood rough sets model is used to construct the neighborhood granular structure, which uses the idea of granular computing to build methods of uncertainty measures. Given the uncertainty of fusing multiple information sources, Sup–Inf fusion functions are developed based on the proposed uncertainty measures, which can fuse the multi-source homogeneous information system into a single-source information system. Finally, an unsupervised attribute selection approach is employed to eliminate redundant attribute of the single-source information system. Theoretical analysis and comprehensive experiments on several datasets demonstrate the feasibility and superiority of our method. © 2021 Elsevier B.V.","Granular computing; Information fusion; Rough sets; Uncertainty measures; Unsupervised attribute selection"
"Multi-exposure image fusion via deep perceptual enhancement","2022","Information Fusion","10.1016/j.inffus.2021.10.006","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118838744&doi=10.1016%2fj.inffus.2021.10.006&partnerID=40&md5=16cd668b70753aef79d5a23c1543dc0d","Due to the huge gap between the high dynamic range of natural scenes and the limited (low) range of consumer-grade cameras, a single-shot image can hardly record all the information of a scene. Multi-exposure image fusion (MEF) has been an effective way to solve this problem by integrating multiple shots with different exposures, which is in nature an enhancement problem. During fusion, two perceptual factors including the informativeness and the visual realism should be concerned simultaneously. To achieve the goal, this paper presents a deep perceptual enhancement network for MEF, termed as DPE-MEF. Specifically, the proposed DPE-MEF contains two modules, one of which responds to gather content details from inputs while the other takes care of color mapping/correction for final results. Both extensive experimental results and ablation studies are conducted to show the efficacy of our design, and demonstrate its superiority over other state-of-the-art alternatives both quantitatively and qualitatively. We also verify the flexibility of the proposed strategy on improving the exposure quality of single images. Moreover, our DPE-MEF can fuse 720p images in more than 60 pairs per second on an Nvidia 2080Ti GPU, making it attractive for practical use. Our code is available at https://github.com/dongdong4fei/DPE-MEF. © 2021 Elsevier B.V.","Color correction; Contrast enhancement; Illumination adjustment; Multi-exposure image fusion; Perceptual enhancement"
"Probabilistic observation model correction using non-Gaussian belief fusion","2021","Information Fusion","10.1016/j.inffus.2021.04.002","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104299194&doi=10.1016%2fj.inffus.2021.04.002&partnerID=40&md5=44c943b1c1c8a6fc7bbaa392337a86c2","This paper presents a framework for state estimation which tolerates uncertainty in observation model parameters by (1) incorporating this uncertainty in state observation, and (2) correcting model parameters to improve future state observations. The first objective is met by an uncertainty propagation approach, while the second is achieved by gradient-descent optimization. The novel framework allows state estimates to be represented by non-Gaussian probability distribution functions. By correcting observation model parameters, estimation performance is enhanced since the accuracy of observations is increased. Monte Carlo simulation experiments validate the efficacy of the proposed approach in comparison with conventional estimation techniques, showing that as model parameters converge to ground-truth over time, state estimation correspondingly improves when compared to a static model estimate. Because observation models cannot be known with perfect accuracy and existing approaches do not address parametric uncertainties in non-Gaussian estimation, this work has both novelty and usefulness in most state estimation contexts. © 2021","Non-Gaussian belief fusion; Recursive Bayesian estimation; Simultaneous Estimation and Modeling; State observation"
"EXplainable Neural-Symbolic Learning (X-NeSyL) methodology to fuse deep learning representations with expert knowledge graphs: The MonuMAI cultural heritage use case","2022","Information Fusion","10.1016/j.inffus.2021.09.022","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85117377421&doi=10.1016%2fj.inffus.2021.09.022&partnerID=40&md5=5a2e55141681d547930d52f2a0ee42bf","The latest Deep Learning (DL) models for detection and classification have achieved an unprecedented performance over classical machine learning algorithms. However, DL models are black-box methods hard to debug, interpret, and certify. DL alone cannot provide explanations that can be validated by a non technical audience such as end-users or domain experts. In contrast, symbolic AI systems that convert concepts into rules or symbols – such as knowledge graphs – are easier to explain. However, they present lower generalization and scaling capabilities. A very important challenge is to fuse DL representations with expert knowledge. One way to address this challenge, as well as the performance-explainability trade-off is by leveraging the best of both streams without obviating domain expert knowledge. In this paper, we tackle such problem by considering the symbolic knowledge is expressed in form of a domain expert knowledge graph. We present the eXplainable Neural-symbolic learning (X-NeSyL) methodology, designed to learn both symbolic and deep representations, together with an explainability metric to assess the level of alignment of machine and human expert explanations. The ultimate objective is to fuse DL representations with expert domain knowledge during the learning process so it serves as a sound basis for explainability. In particular, X-NeSyL methodology involves the concrete use of two notions of explanation, both at inference and training time respectively: (1) EXPLANet: Expert-aligned eXplainable Part-based cLAssifier NETwork Architecture, a compositional convolutional neural network that makes use of symbolic representations, and (2) SHAP-Backprop, an explainable AI-informed training procedure that corrects and guides the DL process to align with such symbolic representations in form of knowledge graphs. We showcase X-NeSyL methodology using MonuMAI dataset for monument facade image classification, and demonstrate that with our approach, it is possible to improve explainability at the same time as performance. © 2021 The Authors","Compositionality; Deep learning; Expert knowledge graphs; Explainable artificial intelligence; Neural-symbolic learning; Part-based object detection and classification"
"Early detection of cardiovascular autonomic neuropathy: A multi-class classification model based on feature selection and deep learning feature fusion","2022","Information Fusion","10.1016/j.inffus.2021.07.010","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111941860&doi=10.1016%2fj.inffus.2021.07.010&partnerID=40&md5=41ae97bc2597431fe5d5c48c582b75dd","The conventional diagnostic process and tools of cardiovascular autonomic neuropathy (CAN) can easily identify the two main categories of the condition: severe/definite CAN and normal/healthy without CAN. Conventional techniques encounter significant challenges when identifying CAN in its early or atypical stages due to the inherent imbalanced and incompleteness condition in the collected clinical multimodal data, including electrocardiogram (ECG) data from ECG sensors, blood chemistry, podiatry, and endocrinology features. Therefore, most detection tools and techniques are limited to binary CAN classification. However, early diagnosis of CAN or diagnosis of the atypical stages of CAN is more important than the diagnosis of severe CAN, which, in fact, is easily identifiable with a few diagnostic reports. In this paper, we propose a novel multi-class classification approach for timely CAN detection. The proposed classification algorithm develops a multistage fusion model by combining feature selection and multimodal feature fusion techniques. The proposed method develops a performance criterion-based feature selection technique to guarantee highly significant features. A multimodal feature fusion technique was developed using deep learning feature fusion and selected original features. The experimental results obtained from testing with a large CAN dataset indicate that the proposed algorithm significantly improved the diagnostic accuracy of CAN compared to conventional Ewing battery features. The algorithm also identified the early or atypical stages of CAN with an AUC score of 0.931 using leave-one-out cross-validation. © 2021 Elsevier B.V.","Cardiovascular autonomic neuropathy (CAN); Deep learning feature fusion; Model fusion; Multi-class AUC-based feature selection"
"Multimodal feature-wise co-attention method for visual question answering","2021","Information Fusion","10.1016/j.inffus.2021.02.022","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101870397&doi=10.1016%2fj.inffus.2021.02.022&partnerID=40&md5=e4c1aaa1230b519264d0a0e0ee763afa","VQA attracts lots of researchers in recent years. It could be potentially applied to the remote consultation of COVID-19. Attention mechanisms provide an effective way of utilizing visual and question information selectively in visual question and answering (VQA). The attention methods of existing VQA models generally focus on spatial dimension. In other words, the attention is modeled as spatial probabilities that re-weights the image region or word token features. However, feature-wise attention cannot be ignored, as image and question representations are organized in both spatial and feature-wise modes. Taking the question “What is the color of the woman's hair” for example, identifying the hair color attribute feature is as important as focusing on the hair region. In this paper, we propose a novel neural network module named “multimodal feature-wise attention module” (MulFA) to model the feature-wise attention. Extensive experiments show that MulFA is capable of filtering representations for feature refinement and leads to improved performance. By introducing MulFA modules, we construct an effective union feature-wise and spatial co-attention network (UFSCAN) model for VQA. Our evaluation on two large-scale VQA datasets, VQA 1.0 and VQA 2.0, shows that UFSCAN achieves performance competitive with state-of-the-art models. © 2021 Elsevier B.V.","Deep learning; Feature-wise attention learning; Multimodal feature fusion; Visual question answering (VQA)"
"Unified framework for learning with label distribution","2021","Information Fusion","10.1016/j.inffus.2021.04.014","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105262656&doi=10.1016%2fj.inffus.2021.04.014&partnerID=40&md5=68ae5bd561ce42cb1f81f620987e3c10","As a recently arisen framework, Label Distribution Learning (LDL) is one of the most appropriate machine learning paradigms to solve the label ambiguity problems. Due to the high cost, it is intractable to directly collect annotated distribution-level data. Therefore, Label Enhancement (LE) is proposed to obtain the label distribution for training LDL model by mining the information hidden in the logical labels. Accordingly, LE is usually taken as the pre-processing of LDL algorithm to learn with logical labels in previous methods. These two-stage learning methods may reduce the performance of LDL. To this end, we propose a unified framework called L2 which simultaneously conducts Label Enhancement and Label Distribution Learning on samples and logical labels to fully exploit the implicit information for learning optimal LDL model. Specifically, the recovery of label distribution benefits from not only the optimization of the conventional LE objective function but also the feedback of LDL loss. What is more, the recovered distribution labels can be directly applied to the supervision of LDL training in an end-to-end way. Extensive experiments illustrate that L2 can correctly recover the distribution-level data from the logical labels, and the trained LDL model can perform favorably against state-of-the-art LDL algorithms with the recovered distribution data.1 © 2021 Elsevier B.V.","Label Distribution Learning; Label Enhancement; Multi-label learning"
"Notions of explainability and evaluation approaches for explainable artificial intelligence","2021","Information Fusion","10.1016/j.inffus.2021.05.009","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107637272&doi=10.1016%2fj.inffus.2021.05.009&partnerID=40&md5=ea43755f8d2ba11dc86623a41862adac","Explainable Artificial Intelligence (XAI) has experienced a significant growth over the last few years. This is due to the widespread application of machine learning, particularly deep learning, that has led to the development of highly accurate models that lack explainability and interpretability. A plethora of methods to tackle this problem have been proposed, developed and tested, coupled with several studies attempting to define the concept of explainability and its evaluation. This systematic review contributes to the body of knowledge by clustering all the scientific studies via a hierarchical system that classifies theories and notions related to the concept of explainability and the evaluation approaches for XAI methods. The structure of this hierarchy builds on top of an exhaustive analysis of existing taxonomies and peer-reviewed scientific material. Findings suggest that scholars have identified numerous notions and requirements that an explanation should meet in order to be easily understandable by end-users and to provide actionable information that can inform decision making. They have also suggested various approaches to assess to what degree machine-generated explanations meet these demands. Overall, these approaches can be clustered into human-centred evaluations and evaluations with more objective metrics. However, despite the vast body of knowledge developed around the concept of explainability, there is not a general consensus among scholars on how an explanation should be defined, and how its validity and reliability assessed. Eventually, this review concludes by critically discussing these gaps and limitations, and it defines future research directions with explainability as the starting component of any artificial intelligent system. © 2021 The Authors","Evaluation methods; Explainable artificial intelligence; Notions of explainability"
"Linguistic stochastic dominance to support consensus reaching in group decision making with linguistic distribution assessments","2021","Information Fusion","10.1016/j.inffus.2021.05.003","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107281481&doi=10.1016%2fj.inffus.2021.05.003&partnerID=40&md5=86b1e7ae082ee3653931351dbdbb0b05","The complexity of linguistic distribution assessments increases the difficulty for the decision makers dealing with them. Recently, stochastic dominance has been varied to be a useful tool to compare two stochastic variables. Inspired by this, in this paper we dedicate to utilizing the stochastic dominance to compare the linguistic distribution assessments and further discuss the consensus reaching issue in GDM with linguistic distribution assessments. First, we introduce three types of individuals’ semantic sensitivity. Based on this, we define the linguistic stochastic dominances respectively under different semantic sensitivity contexts, and then provide several desirable properties. Then, we design a consensus reaching resolution framework based on linguistic stochastic dominance (CRRF-LSD). Finally, a case study is provided to show the application value of the CRRF-LSD, and two comparison analyses are further conducted to show the advantages of the linguistic stochastic dominance and the CRRF-LSD. The comparison results show that the proposed linguistic stochastic dominances method has clear advantages over several classical existing methods in comparing two linguistic distribution assessments. Meanwhile, the comparison results show that only the CRRF-LSD method takes the PIS and semantic sensitivity into account, which is helpful to determine more accurate individual ranking results. © 2021 Elsevier B.V.","Consensus reaching; Group decision making; Linguistic distribution assessment; Linguistic stochastic dominance"
"Dynamic sensor activation and decision-level fusion in wireless acoustic sensor networks for classification of domestic activities","2022","Information Fusion","10.1016/j.inffus.2021.07.022","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112277999&doi=10.1016%2fj.inffus.2021.07.022&partnerID=40&md5=125c3375cb8ab975c4c5be35c386d956","For the past decades there has been a rising interest for wireless sensor networks to obtain information about an environment. One interesting modality is that of audio, as it is highly informative for numerous applications including speech recognition, urban scene classification, city monitoring, machine listening and classifying domestic activities. However, as they operate at prohibitively high energy consumption, commercialisation of battery-powered wireless acoustic sensor networks has been limited. To increase the network's lifetime, this paper explores the joint use of decision-level fusion and dynamic sensor activation. Hereby adopting a topology where processing – including feature extraction and classification – is performed on a dynamic set of sensor nodes that communicate classification outputs which are fused centrally. The main contribution of this paper is the comparison of decision-level fusion with different dynamic sensor activation strategies on the use case of automatically classifying domestic activities. Results indicate that using vector quantisation to encode the classification output, computed at each sensor node, can reduce the communication per classification output to 8 bit without loss of significant performance. As the cost for communication is reduced, local processing tends to dominate the overall energy budget. It is indicated that dynamic sensor activation, using a centralised approach, can reduce the average time a sensor node is active up to 20% by leveraging redundant information in the network. In terms of energy consumption, this resulted in an energy reduction of up to 80% as the cost for computation dominates the overall energy budget. © 2021 Elsevier B.V.","Activities of the Daily Living; Decision-level fusion; Dynamic sensor activation; Edge computing; Sound classification; Wireless acoustic sensor network"
"Aggregating Ordinal Values Using A Measure Based Median","2022","Information Fusion","10.1016/j.inffus.2021.07.020","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115920688&doi=10.1016%2fj.inffus.2021.07.020&partnerID=40&md5=e2601a4b48c0a8ea04b7f8886968c6c5","We introduce the concept of a fuzzy measure μ on a set X. We discuss some of the properties of a fuzzy measure. We provide some notable examples of fuzzy measures. We discuss the important application of using fuzzy measure to provide information about an uncertain variable V. Here the measure of a subset A indicates the anticipation of finding the value of V in A. Our interest here is in finding the best course of action, alternative, in this uncertain environment where each alternative is modeled as a payoff function that associates with an element in X a payoff. Here because of the uncertainty associated with the value of V our concept of best course of action is captured for each alternative by an average like value of its payoff function with respect to the measure μ. Our particular concern here is with the case where the payoffs for each alternative are drawn from a scale, which rather then being numeric, is just ordinal. Here then we become interested in finding an aggregated value of a collection of uncertain ordinal values where the uncertainty is modeled by a measure. © 2021 Elsevier B.V.","Aggregation; Fuzzy Measure; Ordinal Values; Uncertainty; Weighted Median"
"Hyperspectral band selection via region-aware latent features fusion based clustering","2022","Information Fusion","10.1016/j.inffus.2021.09.019","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85117895583&doi=10.1016%2fj.inffus.2021.09.019&partnerID=40&md5=51151278331767a37239229d3170829c","Band selection is one of the most effective methods to reduce the band redundancy of hyperspectral images (HSIs). Most existing band selection methods tend to regard each band as a whole, and then explore the band redundancy with the pixel-wise features directly. However, since the regions of HSIs corresponding to different objects have diverse spectral properties and spatial structure, such above scheme limits the performance of hyperspectral band selection due to the lack of spatial information. To address above issues, a novel band selection method via region-aware latent features fusion based clustering (RLFFC) is proposed. Specifically, we employ the superpixel segmentation to segment HSIs into multiple regions so that the spatial information of HSIs can be fully preserved. In order to capture the priori information, we construct its corresponding Laplacian matrix from which a group of low dimensional latent features are generated to further enhance the separability among different bands. Then, a shared latent feature representation of HSIs is obtained by fusing region-aware latent features to effectively capture the band redundancy of HSIs. Finally, the k-means clustering algorithm is utilized to obtain the index of the selected bands from the shared latent feature representation. As a result, the spectral and spatial properties are well exploited in the proposed method. Extensive experiments on four public hyperspectral datasets show that the proposed method achieves superior performance when compared with other state-of-the-art ones. © 2021 Elsevier B.V.","Clustering; Feature fusion; Hyperspectral band selection; Latent feature learning"
"Managing manipulative and non-cooperative behaviors in large scale group decision making based on a WeChat-like interaction network","2021","Information Fusion","10.1016/j.inffus.2021.04.004","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104347179&doi=10.1016%2fj.inffus.2021.04.004&partnerID=40&md5=8813f854f966bb2abdfc13c34b680723","The main challenges in large scale group decision making (LSGDM) problem are how to tackle with the great number of participants and how to achieve a common solution accepted by most of group members. In LSGDM problems, some decision makers (DMs) will exhibit manipulative and non-cooperative behaviors owing to the different interests they might present. Dealing with such large group implies a need for mechanisms to detect DMs’ manipulative and non-cooperative behaviors, which might affect the overall efficiency of the consensus reaching process. This paper introduces a novel framework based on WeChat-like interaction network to analyze manipulative and non-cooperative behaviors in the LSGDM problems. In the developed framework, we first detect and manage the manipulative behaviors based on the interaction network. Afterwards, for the consensus model based on opinion evolution, we develop an approach to identify and manage non-cooperative behaviors under the WeChat-like interaction network context. As a result, both the DMs’ weights and trust network derived from it are dynamically updated in parallel. Detailed simulation experiments and comparison analysis under different input parameters are presented to demonstrate the efficiency of this novel approach for coping with manipulative and non-cooperative behaviors. © 2021","Consensus reaching process; Large scale group decision making; Manipulative and non-cooperative behaviors; Opinion dynamics; WeChat-like interaction network"
"Minimum cost consensus model for CRP-driven preference optimization analysis in large-scale group decision making using Louvain algorithm","2022","Information Fusion","10.1016/j.inffus.2021.11.001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119415944&doi=10.1016%2fj.inffus.2021.11.001&partnerID=40&md5=711dd299c861f69014f418719118dacb","Large-scale group decision-making problems based on social network analysis and minimum cost consensus models (MCCMs) have recently attracted considerable attention. However, few studies have combined them to form a complete decision-making system. Accordingly, we define the satisfaction index to optimize the classical MCCM by considering the effect of the group on individuals. Similarly, we define the consistency index to optimize the consensus reaching process (CRP). Regarding the evolution of the consensus network, the Louvain algorithm is used to divide the entire group into several subgroups to ensure that each subgroup is independent but has strong cohesion. By constructing the MCCM based on the satisfaction index and the optimized consensus-reaching process, the group opinions in each subgroup are ranked to obtain the final ranking of alternatives. Finally, to verify the validity of CRP and the practical value of the proposed model, we conduct consensus network evolution and decision-making analysis in the case of a negotiation between the government and polluting companies to achieve uniform pollution emissions. Sensitivity analysis is performed to demonstrate the stability of the subgroup weights. Furthermore, a comparative analysis using existing models verifies the effectiveness of the proposed model. © 2021 Elsevier B.V.","Consensus network evolution; Large-scale group decision making; Louvain algorithm; Minimum cost consensus model; Quadratic programming"
"CaSE: Explaining Text Classifications by Fusion of Local Surrogate Explanation Models with Contextual and Semantic Knowledge","2022","Information Fusion","10.1016/j.inffus.2021.07.014","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112361230&doi=10.1016%2fj.inffus.2021.07.014&partnerID=40&md5=fe5b08b88d7c0e712ea1484ad5a15f7f","Generating explanations within a local and model-agnostic explanation scenario for text classification is often accompanied by a local approximation task. In order to create a local neighborhood for a document, whose classification shall be explained, sampling techniques are used that most often treat the according features at least semantically independent from each other. Hence, contextual as well as semantic information is lost and therefore cannot be used to update a human's mental model within the according explanation task. In case of dependent features, such explanation techniques are prone to extrapolation to feature areas with low data density, therefore causing misleading interpretations. Additionally, the ”the whole is greater than the sum of its parts” phenomenon is disregarded when using explanations that treat the according words independently from each other. In this paper, an architecture named CaSE is proposed that either uses Semantic Feature Arrangements or Semantic Interrogations to overcome these drawbacks. Combined with a modified version of Local interpretable model-agnostic explanations (LIME), a state of the art local explanation framework, it is capable of generating meaningful and coherent explanations. The approach utilizes contextual and semantic knowledge from unsupervised topic models in order to enable realistic and semantic sampling and based on that generate understandable explanations for any text classifier. The key concepts of CaSE that are deemed essential for providing humans with high quality explanations are derived from findings of psychology. In a nutshell, CaSE shall enable Semantic Alignment between humans and machines and thus further improve the basis for Interactive Machine Learning. An extensive experimental validation of CaSE is conducted, showing its effectiveness by generating reliable and meaningful explanations whose elements are made of contextually coherent words and therefore are suitable to update human mental models in an appropriate way. In the course of a quantitative analysis, the proposed architecture is evaluated w.r.t. a consistency property and to Local Fidelity of the resulting explanation models. According to that, CaSE generates more realistic explanation models leading to higher Local Fidelity compared to LIME. © 2021 Elsevier B.V.","Contextual and semantic interrogations; Explainable Artificial Intelligence; Explanatory understanding; Human-like explanations; Interpretable Machine Learning; Topic modeling"
"Explain and improve: LRP-inference fine-tuning for image captioning models","2022","Information Fusion","10.1016/j.inffus.2021.07.008","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113322808&doi=10.1016%2fj.inffus.2021.07.008&partnerID=40&md5=f46b407c48d5a1db8520c609b4451f8f","This paper analyzes the predictions of image captioning models with attention mechanisms beyond visualizing the attention itself. We develop variants of Layer-wise Relevance Propagation (LRP) and gradient-based explanation methods, tailored to image captioning models with attention mechanisms. We compare the interpretability of attention heatmaps systematically against the explanations provided by explanation methods such as LRP, Grad-CAM, and Guided Grad-CAM. We show that explanation methods provide simultaneously pixel-wise image explanations (supporting and opposing pixels of the input image) and linguistic explanations (supporting and opposing words of the preceding sequence) for each word in the predicted captions. We demonstrate with extensive experiments that explanation methods (1) can reveal additional evidence used by the model to make decisions compared to attention; (2) correlate to object locations with high precision; (3) are helpful to “debug” the model, e.g. by analyzing the reasons for hallucinated object words. With the observed properties of explanations, we further design an LRP-inference fine-tuning strategy that reduces the issue of object hallucination in image captioning models, and meanwhile, maintains the sentence fluency. We conduct experiments with two widely used attention mechanisms: the adaptive attention mechanism calculated with the additive attention and the multi-head attention mechanism calculated with the scaled dot product. © 2021 The Authors","Attention; Explainable AI; Image captioning; Neural networks"
"A non-threshold consensus model based on the minimum cost and maximum consensus-increasing for multi-attribute large group decision-making","2022","Information Fusion","10.1016/j.inffus.2021.07.006","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112626749&doi=10.1016%2fj.inffus.2021.07.006&partnerID=40&md5=6f7fc3921890c427b74d60e172a50fc9","This study proposes a non-threshold consensus model that combines the minimum cost and maximum consensus-increasing for multi-attribute large group decision-making (MALGDM). First, the large-scale experts is classified into several clusters via the combination of the similarities of evaluation information, unit consensus cost, and adjustment willingness. Then, a more sensitive consensus measure method that combines the mean value and variance of the similarities among clusters is presented. Next, a comprehensive identification rule is put forward to determine the cluster with a low consensus level, low unit consensus cost, and high adjustment willingness for information adjustment. An optimization model that combines the minimization of the cost of the cluster and the maximization of the increase of the global consensus level is then constructed to obtain the adjusted information. Also, the adjustment willingness is considered in the constraints to limit the adjustment range. Moreover, instead of the use of a predefined threshold and a maximum number of iterations, a termination index is developed to terminate the consensus reaching process (CRP) to make the CRP more objective and rational. Finally, an application example is presented, and comparison and simulation analyses are performed to validate the feasibility and effectiveness of the proposed model. © 2021","Consensus measure; Consensus reaching process (CRP); Feedback adjustment; Multi-attribute large group decision-making (MALGDM); Termination index"
"A Linguistic Information Granulation Model and Its Penalty Function-Based Co-Evolutionary PSO Solution Approach for Supporting GDM with Distributed Linguistic Preference Relations","2022","Information Fusion","10.1016/j.inffus.2021.07.017","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85114038036&doi=10.1016%2fj.inffus.2021.07.017&partnerID=40&md5=fb8df0a4bc4bf0c6b50c3fdd08171e94","This study focuses on linguistic information operational realization through information granulation in group decision-making (GDM) scenarios where the preference information offered by decision-makers over alternatives is described using distributed linguistic preference relations (DLPRs). First, an information granulation model is proposed to arrive at the operational realization of linguistic information in the GDM with DLPRs. The information granulation is formulated as a certain optimization problem where a combination of consistency degree of individual DLPRs and consensus degree among individuals is regarded as the underlying performance index. Then, considering that the proposed model is a constrained optimization problem (COP) with an adjustable parameter, which is difficult to be effectively solved using general optimization methods, we develop a novel approach towards achieving the optimal solution, referred to as penalty function-based co-evolutionary particle swarm optimization (PFCPSO). Within the PFCPSO setting, the designed penalty function is used to transform the COPs into unconstrained ones. Besides, the penalty factors and the adjustable parameter, as well as the decision variables of the optimization problems, are simultaneously optimized through the co-evolutionary mechanism of two populations in co-evolutionary particle swarm optimization (CPSO). Finally, a comprehensive evaluation problem about car brands is studied using the proposed model and the newly developed PFCPSO approach, which demonstrates their applicability. Two comparative studies are also conducted to show the effectiveness of the proposals. Overall, this study exhibits two facets of originality: the presentation of the linguistic information granulation model, and the development of the PFCPSO approach for solving the proposed model. © 2021","Constrained optimization problem; Distributed linguistic preference relation; Group decision making; Linguistic information granulation; Particle swarm optimization"
"Proposal-Copula-Based Fusion of Spaceborne and Airborne SAR Images for Ship Target Detection⁎⁎","2022","Information Fusion","10.1016/j.inffus.2021.07.019","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113408516&doi=10.1016%2fj.inffus.2021.07.019&partnerID=40&md5=e5766ceb674dc8122c76536f555c56f9","In this paper, we consider the problem of fusion of synthetic aperture radar (SAR) images from spaceborne and airborne sensors and investigate its applications to inshore ship target detection. Existing SAR image fusion methods mainly focus on image denoising or texture enhancement, but show limited improvement of target-to-clutter ratios (TCRs) in composite images and lead to deteriorated target detection performance. To address this issue, we propose a new method for the fusion of spaceborne and airborne SAR images based on the target proposal and the copula theory (TPCT). In TPCT, target and clutter correspondence between different images are exploited to improve the TCRs of composite images. TPCT consists of three steps. First, target proposals are extracted from spaceborne and airborne SAR images and then fused to enhance the common ship target areas therein. Second, a new method to construct the joint probability density function (PDF) of clutter in spaceborne and airborne SAR images is presented to model the statistical dependence of clutter therein based on the copula theory. This copula-based joint PDF is used to suppress the clutter areas remained in the intersection of target proposals. Third, clues from the intersection of target proposals and the copula-based joint PDF of clutter are fused by the Hadamard product to generate the composite image with enhanced ship targets and the suppressed clutter. Experimental results based on measured spaceborne and airborne SAR data show that the proposed TPCT fusion method leads to higher TCRs of composite images and better performance in the ship detection task than other commonly used image fusion methods. © 2021","airborne SAR; copula theory; information fusion; ship detection; Spaceborne synthetic aperture radar (SAR); target proposals"
"Cardinality-limiting extended pre-aggregation functions","2021","Information Fusion","10.1016/j.inffus.2021.05.004","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107030987&doi=10.1016%2fj.inffus.2021.05.004&partnerID=40&md5=d771a324a7628856f48d2b3a115159ba","Aggregation functions, which are at the heart of a number of information fusion processes, allow summarization of multiple inputs into a single representative value. Extended aggregation functions are defined such that the input data can be of varying cardinality, with the implication that there is some consistency across the methods of calculation. This article formalizes an approach to extended aggregation such that contributions of repeated inputs or regions of high density are limited in their ability to influence the final value. We establish important definitions and properties, in particular around whether such functions will be monotone or directionally monotone. We then propose a powerful construction method for extended pre-aggregation functions. Illustrative examples are provided throughout. © 2021 Elsevier B.V.","Aggregation function; Cardinality-limiting function; Directional monotonicity; Extended aggregation function; Pre-aggregation function"
"Influence identification of opinion leaders in social networks: an agent-based simulation on competing advertisements","2021","Information Fusion","10.1016/j.inffus.2021.06.004","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85109550691&doi=10.1016%2fj.inffus.2021.06.004&partnerID=40&md5=acd42bb62d7c425ebbabec3789ee353a","In social networks, factors that influence the spread of information are essential for companies to comprehend. This study uses the opinion dynamic theory to investigate the influence of multiple advertisement opinion leaders in social networks. We construct an integrated bounded confidence model to simulate the evolution of followers’ opinions under two advertisement opinion leaders. Through experimental simulation, we found that the weight of influence on advertisements has a dual effect on the evolution of followers’ opinions, and the probability that information is transmitted by opinion leaders has a significant impact on the evolution of collective opinions. The results show that, for competitive products, companies should properly understand the propaganda power of product advertisements and improve the probability of information being successfully transmitted by opinion leaders. © 2021","bounded confidence model; opinion dynamics; opinion leaders; social network"
"A bidirectional feedback mechanism for balancing group consensus and individual harmony in group decision making","2021","Information Fusion","10.1016/j.inffus.2021.05.012","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85108062593&doi=10.1016%2fj.inffus.2021.05.012&partnerID=40&md5=841dd27a02ea54fa7c05ba3b58576550","This article proposes a bidirectional feedback mechanism for consensus in group decision making (GDM) driven by the behavior of decision makers (DMs), which is discriminated with a flexible harmony degree as one of three possible states: (1) ‘tolerance behavior’; (2) ‘rationalist behavior’; and (3) ‘conflict behavior’. The first two states are possible to be resolved in the consensus reaching process with one round of feedback recommendations to the discordant DMs. However, in the conflict state, which implies the lack of harmony between the group aim of ‘consensus’ and the individual benefit, it is unreasonable to be resolved with only discordant DMs’ feedback recommendations, and concordant DMs are also expected to make concessions at some degree. To address this not so unusual research problem, a theoretical bidirectional feedback mechanism framework for consensus is developed. Firstly, a maximum consensus driven feedback model is proposed to resolve ‘conflict behavior’ between the concordant and discordant DMs. Secondly, a maximum harmony driven feedback model is activated to support the discordant DMs to reach the threshold values of group consensus. A numerical example is provided to illustrate and verify the proposed mechanism usefulness and how it compares against other existent feedback mechanisms in terms of the extent up to which DMs’ preferences are changed for reaching consensus. © 2021 Elsevier B.V.","Behavior analysis; Bidirectional feedback mechanism; Consensus; Group decisions and negotiations; Harmony degree"
"Information fusion as an integrative cross-cutting enabler to achieve robust, explainable, and trustworthy medical artificial intelligence","2022","Information Fusion","10.1016/j.inffus.2021.10.007","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119285419&doi=10.1016%2fj.inffus.2021.10.007&partnerID=40&md5=6d62a961843ec279ab47d0d8d93efc2d","Medical artificial intelligence (AI) systems have been remarkably successful, even outperforming human performance at certain tasks. There is no doubt that AI is important to improve human health in many ways and will disrupt various medical workflows in the future. Using AI to solve problems in medicine beyond the lab, in routine environments, we need to do more than to just improve the performance of existing AI methods. Robust AI solutions must be able to cope with imprecision, missing and incorrect information, and explain both the result and the process of how it was obtained to a medical expert. Using conceptual knowledge as a guiding model of reality can help to develop more robust, explainable, and less biased machine learning models that can ideally learn from less data. Achieving these goals will require an orchestrated effort that combines three complementary Frontier Research Areas: (1) Complex Networks and their Inference, (2) Graph causal models and counterfactuals, and (3) Verification and Explainability methods. The goal of this paper is to describe these three areas from a unified view and to motivate how information fusion in a comprehensive and integrative manner can not only help bring these three areas together, but also have a transformative role by bridging the gap between research and practical applications in the context of future trustworthy medical AI. This makes it imperative to include ethical and legal aspects as a cross-cutting discipline, because all future solutions must not only be ethically responsible, but also legally compliant. © 2021 The Authors","Artificial intelligence; Explainability; Explainable AI; Graph-based machine learning; Information fusion; Medical AI; Neural-symbolic learning and reasoning; Robustness; Trust"
"RFN-Nest: An end-to-end residual fusion network for infrared and visible images","2021","Information Fusion","10.1016/j.inffus.2021.02.023","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102340995&doi=10.1016%2fj.inffus.2021.02.023&partnerID=40&md5=763fec64f68029b14a31ce48d489d285","In the image fusion field, the design of deep learning-based fusion methods is far from routine. It is invariably fusion-task specific and requires a careful consideration. The most difficult part of the design is to choose an appropriate strategy to generate the fused image for a specific task in hand. Thus, devising learnable fusion strategy is a very challenging problem in the community of image fusion. To address this problem, a novel end-to-end fusion network architecture (RFN-Nest) is developed for infrared and visible image fusion. We propose a residual fusion network (RFN) which is based on a residual architecture to replace the traditional fusion approach. A novel detail-preserving loss function, and a feature enhancing loss function are proposed to train RFN. The fusion model learning is accomplished by a novel two-stage training strategy. In the first stage, we train an auto-encoder based on an innovative nest connection (Nest) concept. Next, the RFN is trained using the proposed loss functions. The experimental results on public domain data sets show that, compared with the existing methods, our end-to-end fusion network delivers a better performance than the state-of-the-art methods in both subjective and objective evaluation. The code of our fusion method is available at https://github.com/hli1221/imagefusion-rfn-nest. © 2021","End-to-end network; Image fusion; Infrared image; Nest connection; Residual network; Visible image"
"A public and large-scale expert information fusion method and its application: Mining public opinion via sentiment analysis and measuring public dynamic reliability","2022","Information Fusion","10.1016/j.inffus.2021.09.015","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115747845&doi=10.1016%2fj.inffus.2021.09.015&partnerID=40&md5=1b617832a9786a390986011eab4cc34f","With the rapid development of social media, reliable information released by the public on social media can provide important decision-making support. Therefore, the consideration of the public as another decision-making body participating in large-scale group decision-making (LSGDM) problems has become an extensively researched topic. However, the participation of the public as a decision-making body with decision-making experts faces several issues, such as the acquisition of public opinion, the reliability of public opinion, the integration of public and expert opinions, etc. Given this, this paper proposes a public and large-scale expert information fusion method that considers public dynamic reliability via sentiment analysis and intuitionistic fuzzy number (IFN) expressions. First, sentiment analysis technology is used to process public social media data and obtain IFNs as the opinions of the public decision-making body. Second, the concept of public dynamic reliability is defined to measure the degree of integration of public opinion. Third, a novel information entropy measure of IFNs is proposed, and a new method is introduced to determine the criteria weights under the two different decision-making bodies. Finally, an optimization model that considers the consensus levels of expert subgroups is proposed to determine the weights of different decision-making bodies. The public and expert opinions are then aggregated to obtain collective decision-making information. A case study is proposed to illustrate the application of the proposed method, and the comparative analysis reveals the features and advantages of this model. © 2021","Dynamic reliability; Information fusion; Large-scale group decision making; Public participation; Sentiment analysis"
"High quality 3D reconstruction based on fusion of polarization imaging and binocular stereo vision","2022","Information Fusion","10.1016/j.inffus.2021.07.002","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111836073&doi=10.1016%2fj.inffus.2021.07.002&partnerID=40&md5=b4e8091a8bbde08d5c05aebfa634cbfd","Polarization imaging can retrieve inaccurate objects’ 3D shapes with fine textures, whereas coarse but accurate depths can be provided by binocular stereo vision. To take full advantage of these two complementary techniques, we investigate a novel 3D reconstruction method based on the fusion of polarization imaging and binocular stereo vision for high quality 3D reconstruction. We first generate the polarization surface by correcting the azimuth angle errors on the basis of registered binocular depth, to solve the azimuthal ambiguity in the polarization imaging. Then we propose a joint 3D reconstruction model for depth fusion, including a data fitting term and a robust low-rank matrix factorization constraint. The former is to transfer textures from the polarization surface to the fused depth by assuming their relationship linear, whereas the latter is to utilize the low-frequency part of binocular depth to improve the accuracy of the fused depth considering the influences of missing-entries and outliers. To solve the optimization problem in the proposed model, we adopt an efficient solution based on the alternating direction method of multipliers. Extensive experiments have been conducted to demonstrate the efficiency of the proposed method in comparison with state-of-the-art methods and to exhibit its wide application prospects in 3D reconstruction. © 2021 Elsevier B.V.","3D reconstruction; Binocular stereo vision; Depth fusion; Polarization imaging"
"A theoretical and practical survey of image fusion methods for multispectral pansharpening","2022","Information Fusion","10.1016/j.inffus.2021.10.001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118732062&doi=10.1016%2fj.inffus.2021.10.001&partnerID=40&md5=434a767bb05d2f89ae9b15155e8fc1e2","Pansharpening fuses the spatial features of a high-resolution panchromatic (PAN) image with the spectral features of a lower-resolution multispectral (MS) image to generate a spatially enriched MS image. Numerous pansharpening strategies have been developed for more than three decades, which forces the analysts who intend to apply pansharpening to choose from various pansharpening techniques. Hence, this study aims to investigate the performances of many conventional and state-of-the-art pansharpening techniques in order to guide the analysts in this regard. To this aim, the spectral and spatial structure fidelity of the pansharpened images produced from a total of 47 pansharpening methods were evaluated qualitatively and quantitatively. The methods examined were from six pansharpening methods categories, including Multiresolution Analysis (MRA)-based, Component Substitution (CS)-based, Colour-Based (CB), Deep Learning (DL)-based, Variational Optimization (VO)-based and hybrid techniques. The methods in the MRA, DL, CB and VO category were found to exhibit the best pansharpening performances; whereas the hybrid and CS-based techniques showed the poorest performances. We believe that the outcomes of this study will guide the analysts who are in the need to apply pansharpening for their applications. © 2021 Elsevier B.V.","deep learning; image fusion; image processing; multiresolution analysis; Pansharpening; sparse representation"
"Supervised contrastive learning over prototype-label embeddings for network intrusion detection","2022","Information Fusion","10.1016/j.inffus.2021.09.014","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118731095&doi=10.1016%2fj.inffus.2021.09.014&partnerID=40&md5=6ac9820c5cef2adb5a8ee95d10670c65","Contrastive learning makes it possible to establish similarities between samples by comparing their distances in an intermediate representation space (embedding space) and using loss functions designed to attract/repel similar/dissimilar samples. The distance comparison is based exclusively on the sample features. We propose a novel contrastive learning scheme by including the labels in the same embedding space as the features and performing the distance comparison between features and labels in this shared embedding space. Following this idea, the sample features should be close to its ground-truth (positive) label and away from the other labels (negative labels). This scheme allows to implement a supervised classification based on contrastive learning. Each embedded label will assume the role of a class prototype in embedding space, with sample features that share the label gathering around it. The aim is to separate the label prototypes while minimizing the distance between each prototype and its same-class samples. A novel set of loss functions is proposed with this objective. Loss minimization will drive the allocation of sample features and labels in embedding space. Loss functions and their associated training and prediction architectures are analyzed in detail, along with different strategies for label separation. The proposed scheme drastically reduces the number of pair-wise comparisons, thus improving model performance. In order to further reduce the number of pair-wise comparisons, this initial scheme is extended by replacing the set of negative labels by its best single representative: either the negative label nearest to the sample features or the centroid of the cluster of negative labels. This idea creates a new subset of models which are analyzed in detail. The outputs of the proposed models are the distances (in embedding space) between each sample and the label prototypes. These distances can be used to perform classification (minimum distance label), features dimensionality reduction (using the distances and the embeddings instead of the original features) and data visualization (with 2 or 3D embeddings). Although the proposed models are generic, their application and performance evaluation is done here for network intrusion detection, characterized by noisy and unbalanced labels and a challenging classification of the various types of attacks. Empirical results of the model applied to intrusion detection are presented in detail for two well-known intrusion detection datasets, and a thorough set of classification and clustering performance evaluation metrics are included. © 2021 The Authors","contrastive learning; Deep learning; Embeddings fusion; Label embedding; Max margin loss; Network intrusion detection"
"Uncertainty-driven ensembles of multi-scale deep architectures for image classification","2022","Information Fusion","10.1016/j.inffus.2022.08.010","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136665514&doi=10.1016%2fj.inffus.2022.08.010&partnerID=40&md5=febc2d8a166ff3d331e9900d582ec115","The use of automatic systems for medical image classification has revolutionized the diagnosis of a high number of diseases. These alternatives, which are usually based on artificial intelligence (AI), provide a helpful tool for clinicians, eliminating the inter and intra-observer variability that the diagnostic process entails. Convolutional Neural Network (CNNs) have proved to be an excellent option for this purpose, demonstrating a large performance in a wide range of contexts. However, it is also extremely important to quantify the reliability of the model's predictions in order to guarantee the confidence in the classification. In this work, we propose a multi-level ensemble classification system based on a Bayesian Deep Learning approach in order to maximize performance while providing the uncertainty of each classification decision. This tool combines the information extracted from different architectures by weighting their results according to the uncertainty of their predictions. Performance is evaluated in a wide range of real scenarios: in the first one, the aim is to differentiate between different pulmonary pathologies: controls vs bacterial pneumonia vs viral pneumonia. A two-level decision tree is employed to divide the 3-class classification into two binary classifications, yielding an accuracy of 98.19%. In the second context, performance is assessed for the diagnosis of Parkinson's disease, leading to an accuracy of 95.31%. The reduced preprocessing needed for obtaining this high performance, in addition to the information provided about the reliability of the predictions evidence the applicability of the system to be used as an aid for clinicians. © 2022","Bayesian Deep Learning; Ensemble classification; Parkinson's; Pneumonia; Uncertainty"
"Protein deep profile and model predictions for identifying the causal genes of male infertility based on deep learning","2021","Information Fusion","10.1016/j.inffus.2021.04.012","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105692089&doi=10.1016%2fj.inffus.2021.04.012&partnerID=40&md5=b3e18061ff4aedb16ba27fe9eebbfc49","A principal task in dissecting the genetics of complex traits is to identify causal genes for disease phenotypes. Millions of genes have been sequenced in data-driven genomics era, but their causal relationships with disease phenotypes remain limited, due to the difficulty of elucidating underlying causal genes by laboratory-based strategies. Here, we proposed an innovative deep learning computational modeling alternative (DPPCG framework) for identifying causal (coding) genes for a specific disease phenotype. In terms of male infertility, we introduced proteins as intermediate cell variables, leveraging integrated deep knowledge representations (Word2vec, ProtVec, Node2vec, and Space2vec) quantitatively represented as ‘protein deep profiles’. We adopted deep convolutional neural network (CNN) classifier to model protein deep profiles relationships with male infertility, creatively training deep CNN models of single-label binary classification and multi-label eight classification. We demonstrate the capabilities of DPPCG framework by integrating and fully harnessing the utility of heterogeneous biomedical big data, including literature, protein sequences, protein–protein interactions, gene expressions, and gene–phenotype relationships, and effective indirect prediction of 794 causal genes of male infertility and associated pathological processes. We present this research in an interactive ‘Smart Protein’ intelligent (demo) system (http://www.smartprotein.cloud/public/home). Researchers can benefit from our intelligent system by (i) accessing a shallow gene/protein-radar service involving research status and a knowledge graph-based vertical search; (ii) querying and downloading protein deep profile matrices; (iii) accessing intelligent recommendations for causal genes of male infertility and associated pathological processes, and references for model architectures, parameter settings, and training outputs; and (iv) carrying out personalized analysis such as online K-Means clustering. © 2021 Elsevier B.V.","Causal gene; Convolutional neural network; Data integration; Deep learning; Disease phenotype; Knowledge representation; Male infertility; Manifold learning"
"Auto-adaptive Grammar-Guided Genetic Programming algorithm to build Ensembles of Multi-Label Classifiers","2022","Information Fusion","10.1016/j.inffus.2021.07.005","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113347043&doi=10.1016%2fj.inffus.2021.07.005&partnerID=40&md5=5c31469887a4752e26d40b6c3d568a3d","Multi-label classification has been used to solve a wide range of problems where each example in the dataset may be related either to one class (as in traditional classification problems) or to several class labels at the same time. Many ensemble-based approaches have been proposed in the literature, aiming to improve the performance of traditional multi-label classification algorithms. However, most of them do not consider the data characteristics to build the ensemble, and those that consider them need to tune many parameters to maximize their performance. In this paper, we propose an Auto-adaptive algorithm based on Grammar-Guided Genetic Programming to generate Ensembles of Multi-Label Classifiers based on projections of k labels (AG3P-kEMLC). It creates a tree-shaped ensemble, where each leaf is a multi-label classifier focused on a subset of k labels. Unlike other methods in the literature, our proposal can deal with different values of k in the same ensemble, instead of fixing one specific value. It also includes an auto-adaptive process to reduce the number of hyper-parameters to tune, prevent overfitting and reduce the runtime required to execute it. Three versions of the algorithm are proposed. The first, fixed, uses the same value of k for all multi-label classifiers in the ensemble. The remaining two deal with different k values in the ensemble: uniform gives the same probability to choose each available value of k, and gaussian favors the selection of smaller values of k. The experimental study carried out considering twenty reference datasets and five evaluation metrics, compared with eleven ensemble methods demonstrates that our proposal performs significantly better than the state-of-the-art methods. © 2021 The Authors","Ensemble learning; Evolutionary algorithm; Grammar-guided genetic programming; Multi-label classification"
"A Self-Training Hierarchical Prototype-based Ensemble Framework for Remote Sensing Scene Classification","2022","Information Fusion","10.1016/j.inffus.2021.11.014","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119582560&doi=10.1016%2fj.inffus.2021.11.014&partnerID=40&md5=af4a135d91c9c2a2ead036df64d9f386","Remote sensing scene classification plays a critical role in a wide range of real-world applications. Technically, however, scene classification is an extremely challenging task due to the huge complexity in remotely sensed scenes, and the difficulty in acquiring labelled data for model training such as supervised deep learning. To tackle these issues, a novel semi-supervised ensemble framework is proposed here using the self-training hierarchical prototype-based classifier as the base learner for chunk-by-chunk prediction. The framework has the ability to build a powerful ensemble model from both labelled and unlabelled images with minimum supervision. Different feature descriptors are employed in the proposed ensemble framework to offer multiple independent views of images. Thus, the diversity of base learners is guaranteed for ensemble classification. To further increase the overall accuracy, a novel cross-checking strategy was introduced to enable the base learners to exchange pseudo-labelling information during the self-training process, and maximize the correctness of pseudo-labels assigned to unlabelled images. Extensive numerical experiments on popular benchmark remote sensing scenes demonstrated the effectiveness of the proposed ensemble framework, especially where the number of labelled images available is limited. For example, the classification accuracy achieved on the OPTIMAL-31, PatternNet and RSI-CB256 datasets was up to 99.91%, 98. 67% and 99.07% with only 40% of the image sets used as labelled training images, surpassing or at least on par with mainstream benchmark approaches trained with double the number of labelled images. © 2021 Elsevier B.V.","prototypes; pseudo-labelling; remote sensing; scene classification; self-training"
"Learning an epipolar shift compensation for light field image super-resolution","2022","Information Fusion","10.1016/j.inffus.2021.10.005","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118785751&doi=10.1016%2fj.inffus.2021.10.005&partnerID=40&md5=f72eed8476f823e79b6d41980adc7133","Light field imaging has drawn broad attention since the advent of practical light field capturing systems that facilitate a wide range of applications in computer vision. However, existing learning-based methods for improving the spatial resolution of light field images neglect the shifts in the sub-pixel domain that are widely used by super-resolution techniques, thus, fail in recovering rich high-frequency information. To fully exploit the shift information, our method attempts to learn an epipolar shift compensation for light field image super-resolution that allows the restored light field image to be angular coherent with the enhancement of spatial resolution. The proposed method first utilizes the rich surrounding views along some typical epipolar directions to explore the inter-view correlations. We then implement feature-level registration to capture accurate sub-pixel shifts of central view, which is constructed by the compensation module equipped with dynamic deformable convolution. Finally, the complementary information from different spatial directions is fused to provide high-frequency details for the target view. By taking each sub-aperture image as a central view, our method could be applied for light field images with any angular resolution. Extensive experiments on both synthetic and real scene datasets demonstrate the superiority of our method over the state-of-the-art qualitatively and quantitatively. Moreover, the proposed method shows good performance in preserving the inherent epipolar structures in light field images. Specifically, our LFESCN method outperforms the state-of-the-art method with about 0.7 dB (PSNR) on average. © 2021 Elsevier B.V.","Dynamic deformable convolution; Light field; Multi-view fusion; Super-resolution"
"Scheduler-based state estimation over multiple channels networks","2022","Information Fusion","10.1016/j.inffus.2021.07.021","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112756236&doi=10.1016%2fj.inffus.2021.07.021&partnerID=40&md5=f7092950e3bf6a517a70bbb853ce0ce3","We investigate the remote state estimation problem for networked systems over parallel noise-free communication channels. Due to limited network capabilities in practical network environments, communication schedulers are implemented at the transmit side of each subchannel to promote resource efficiency. Specifically, the processed signals are transmitted only when it is necessary to provide the real-time measurements to the remote estimator. The recursive approximate minimum mean-square error estimator is established to restore the state vector of a target plant by utilizing the scheduled transmission signals. All the information coming from the individual subchannels, even if no measurement is sent, will contribute to improve the estimation performance in an analytical form. Finally, a numerical example is given to illustrate the effectiveness of the main results. © 2021 Elsevier B.V.","Communication rate; Event-based communication; Multiple communication channels; State estimation"
"On consensus reaching process based on social network analysis in uncertain linguistic group decision making: Exploring limited trust propagation and preference modification attitudes","2022","Information Fusion","10.1016/j.inffus.2021.09.006","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85116564255&doi=10.1016%2fj.inffus.2021.09.006&partnerID=40&md5=a7a0e34e1fa3a7fedd62995c41db1c8b","This paper explores a limited trust propagation-based consensus model considering individual attitude for preference modification in a social networked setting with uncertain preference information. To examine the construction of complete linkages, and the status of decision makers in group decision making, it is assumed that the group size and network density will affect the scale of mediators in the propagation process, then a definition of limited trust propagation is proposed and the propagation efficiency can be introduced. On this basis, we obtain missing trust relationships and individual centrality in network. In the process of consensus reaching, both the decision maker's original preference and recommendation advice are considered for flexibly modeling the preference modification process: the individual attitude toward modification is determined by a newly introduced measure of comprehensive relative out-degree centrality, showing the degree of willingness to adjust assessments. When the willingness is too low to reach the preset consensus level, a multi-objective programming model is designed to improve the consensus as much as possible. Moreover, the proposed feedback mechanism narrows the individual acceptable modification range based on the previous adjustment rule, so as to simulate the personalized and targeted decision behavior. To guarantee obtaining a collective aggregated preference in a logical and precise manner, a two-stage optimization model composing of comprehensive relative in-degree centrality-based information aggregation and best consistency-based uncertainty elimination, is proposed. A numerical example and comparative analyses are performed to show the validity and feasibility of the proposed model. © 2021 Elsevier B.V.","Behavioral characteristic; Consensus reaching process; Consistency; Limited trust propagation; Social network analysis"
"Fusing functional connectivity with network nodal information for sparse network pattern learning of functional brain networks","2021","Information Fusion","10.1016/j.inffus.2021.03.006","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105246671&doi=10.1016%2fj.inffus.2021.03.006&partnerID=40&md5=ae63e0cf55319d50ebbff8673bc9753c","Sparse learning methods have been powerful tools for learning compact representations of functional brain networks consisting of a set of brain network nodes and a connectivity matrix measuring functional coherence between the nodes. However, these tools typically focus on the functional connectivity measures alone, ignoring the brain network nodal information that is complementary to the functional connectivity measures for comprehensively characterizing the functional brain networks. In order to provide a comprehensive delineation of the functional brain networks, we develop a new data fusion method for heterogeneous data, aiming at learning sparse network patterns to characterize both the functional connectivity measures and their complementary network nodal information within a unified framework. Experimental results have demonstrated that our method outperforms the best alternative method under comparison in terms of accuracy on simulated data as well as both reproducibility and prediction performance of brain age on real resting state functional magnetic resonance imaging data. © 2021","Brain network analysis; Functional magnetic resonance imaging; Sparse learning"
"A novel approach of multisensory fusion to collaborative fault diagnosis in maintenance","2021","Information Fusion","10.1016/j.inffus.2021.03.008","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103775860&doi=10.1016%2fj.inffus.2021.03.008&partnerID=40&md5=6a3772c580dfe9461033e16f3d490585","Collaborative fault diagnosis can be facilitated by multisensory fusion technologies, as these can give more reliable results with a more complete data set. Although deep learning approaches have been developed to overcome the problem of relying on subjective experience in conventional fault diagnosis, there are two remaining obstacles to collaborative efficiency: integration of multisensory data and fusion of maintenance strategies. To overcome these obstacles, we propose a novel two-part approach: a stacked wavelet auto-encoder structure with a Morlet wavelet function for multisensory data fusion and a flexible weighted assignment of fusion strategies. Taking a planetary gearbox as an example, we use noisy vibration signals from multisensors to test the diagnosis performance of the proposed approach. The results demonstrate that it can provide more accurate and reliable fault diagnosis results than other approaches. © 2021","Collaborative maintenance; Fault diagnosis; Multi-sensor information fusion; Planetary gearbox; Prognostics and health management; Stacked wavelet auto-encoder"
"UAV swarm based radar signal sorting via multi-source data fusion: A deep transfer learning framework","2022","Information Fusion","10.1016/j.inffus.2021.09.007","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115990999&doi=10.1016%2fj.inffus.2021.09.007&partnerID=40&md5=551c1fb472db44f6a502c0de6f86038c","Traditional clustering algorithms can be applied for the pre-sorting step of radar signal sorting. It can effectively dilute the pulse stream and prevent the dense pulse stream from interfering pulse repetition interval (PRI) extraction. However, the pre-sorting deviation will cause interference and missing pulses during the main sorting process. To solve this problem, we deploy the unmanned aerial vehicle (UAV) swarm to monitor reconnaissance areas and put forward a novel deep transfer learning based signal sorting method. The UAV swarm can collect the pulses from different time and spatial domains, and interference and missing pulses in main sorting processing can be relieved dramatically. In our model, we pre-train our model with the data collected from multiple source areas, which corresponds to different areas detected by different parts of UAV swarms. Then we fine-tune our model with the data of the target area. The experimental results prove that the signal sorting accuracy of methods based on deep transfer learning, i.e., YOLO-MobileNet, F-RCNN and cascade RCNN, are higher than that of the baseline methods. In addition, the signal sorting accuracy of traditional methods based on deep learning can be greatly improved with the help of transfer learning. © 2021","Data fusion; Deep transfer learning; Signal sorting; UAV swarm"
"An interval 2-Tuple linguistic Fine-Kinney model for risk analysis based on extended ORESTE method with cumulative prospect theory","2022","Information Fusion","10.1016/j.inffus.2021.09.008","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115796261&doi=10.1016%2fj.inffus.2021.09.008&partnerID=40&md5=c8ea20fbfe61ddcb54b66ba011b4c2b5","The risk assessment is one of the most significant procedures for identifying, preventing, and controlling Occupational Health and Safety (OHS) risks. One of many kinds of techniques for OHS risk assessment is based on the Fine-Kinney model. Most of the Fine-Kinney-based risk assessment approaches can consider the relative importance degree of risk parameters. Nevertheless, the current Fine-Kinney-based risk assessment approaches do not have abilities to capture the reference dependence effects and detailed relationships among hazards. In addition, these approaches overlook the influence of the deviation of risk evaluation information. To overcome these limitations, in this paper, an improved Fine-Kinney model is proposed for OHS risk assessment by integrating the weighted power average (WPA) operator, ORESTE (Organísation, rangement et Synthèse de données relarionnelles (in French)) method, and cumulative prospect theory. First, the interval 2-Tuple linguistic variables are adopted to transform linguistic risk information into quantitative risk rating information. Then, an extended WPA operator is proposed to fuse the risk evaluation information from decision-makers, in which an optimization model is constructed to determine the weights of decision-makers. Next, an extended ORESTE method based on cumulative prospect theory and interval 2-Tuple linguistic variables is incorporated into the Fine-Kinney model to prioritize OHS risk. After that, the OHS risk assessment of the automobile components manufacturing process is presented to test the applicability and rationality of the improved Fine-Kinney model. After that, a sensitivity analysis is conducted to further illustrate the proposed model. Finally, the comparative analyses between the proposed risk assessment approach and other Fine-Kinney models are led to illustrating its effectiveness and advantages. © 2021 Elsevier B.V.","Cumulative prospect theory; Fine Kinney; Interval 2-tuple linguistic; Occupational health and safety; ORESTE method"
"A novel fusion paradigm for multi-channel image denoising","2022","Information Fusion","10.1016/j.inffus.2021.07.003","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111935521&doi=10.1016%2fj.inffus.2021.07.003&partnerID=40&md5=637580716109e76b6361827c9c6f813a","Multi-channel and single-channel image denoising are on two important development fronts. Integrating multi-channel and single-channel image denoisers for further improvement is a valuable research direction. A natural assumption is that using more useful information is helpful to the output results. In this paper, a novel multi-channel and single-channel fusion paradigm (MSF) is proposed. The proposed MSF works by fusing the estimates of a multi-channel image denoiser and a single-channel image denoiser. The performance of recent multi-channel image denoising methods involved in the proposed MSF can be further improved at low additional time-consuming cost. Specifically, the validity principle of the proposed MSF is that the fused single-channel image denoiser can produce auxiliary estimate for the involved multi-channel image denoiser in a designed underdetermined transform domain. Based on the underdetermined transformation, we create a corresponding orthogonal transformation for fusion and better restore the multi-channel images. The quantitative and visual comparison results demonstrate that the proposed MSF can be effectively applied to several state-of-the-art multi-channel image denoising methods. © 2021","Estimate fusion; Image denoising; Image transformation; Multi-channel image"
"Hyperparameter self-tuning for data streams","2021","Information Fusion","10.1016/j.inffus.2021.04.011","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85106918485&doi=10.1016%2fj.inffus.2021.04.011&partnerID=40&md5=b78b0d9d4184a220b95239e4c459d030","The number of Internet of Things devices generating data streams is expected to grow exponentially with the support of emergent technologies such as 5G networks. Therefore, the online processing of these data streams requires the design and development of suitable machine learning algorithms, able to learn online, as data is generated. Like their batch-learning counterparts, stream-based learning algorithms require careful hyperparameter settings. However, this problem is exacerbated in online learning settings, especially with the occurrence of concept drifts, which frequently require the reconfiguration of hyperparameters. In this article, we present SSPT, an extension of the Self Parameter Tuning (SPT) optimisation algorithm for data streams. We apply the Nelder–Mead algorithm to dynamically-sized samples, converging to optimal settings in a single pass over data while using a relatively small number of hyperparameter configurations. In addition, our proposal automatically readjusts hyperparameters when concept drift occurs. To assess the effectiveness of SSPT, the algorithm is evaluated with three different machine learning problems: recommendation, regression, and classification. Experiments with well-known data sets show that the proposed algorithm can outperform previous hyperparameter tuning efforts by human experts. Results also show that SSPT converges significantly faster and presents at least similar accuracy when compared with the previous double-pass version of the SPT algorithm. © 2021 Elsevier B.V.","Data Streams; Hyperparameters; Optimisation"
"Domain structure-based transfer learning for cross-domain word representation","2021","Information Fusion","10.1016/j.inffus.2021.05.013","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107642156&doi=10.1016%2fj.inffus.2021.05.013&partnerID=40&md5=bdcf016f9314e33664e09187d6c2c97d","Cross-domain word representation aims to learn high-quality semantic representations in an under-resourced domain by leveraging information in a resourceful domain. However, most existing methods mainly transfer the semantics of common words across domains, ignoring the semantic relations among domain-specific words. In this paper, we propose a domain structure-based transfer learning method to learn cross-domain representations by leveraging the relations among domain-specific words. To accomplish this, we first construct a semantic graph to capture the latent domain structure using domain-specific co-occurrence information. Then, in the domain adaptation process, beyond domain alignment, we employ Laplacian Eigenmaps to ensure the domain structure is consistently distributed in the learned embedding space. As such, the learned cross-domain word representations not only capture shared semantics across domains, but also maintain the latent domain structure. We performed extensive experiments on two tasks, namely sentiment analysis and query expansion. The experiment results show the effectiveness of our method for tasks in under-resourced domains. © 2021","Semantic structure; Transfer learning; Word representation"
"Consensus reaching for group decision making with multi-granular unbalanced linguistic information: A bounded confidence and minimum adjustment-based approach","2021","Information Fusion","10.1016/j.inffus.2021.04.006","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104330013&doi=10.1016%2fj.inffus.2021.04.006&partnerID=40&md5=2d33ee1731fe1d4758b6d3265dd75b53","In group decision making problems, there exist the situations that decision makers may use unbalanced linguistic term sets that are not uniformly and symmetrically distributed to provide their linguistic assessments over alternatives. Moreover, due to the difference in knowledge and culture backgrounds, it is also possible that multi-granular linguistic term sets may also be used by decision makers. How to manage multi-granular unbalanced linguistic information in consensus-based group decision making has becoming an important topic in linguistic decision making. In this paper, we first revise Herrera's unbalanced linguistic term sets and propose a simplified linguistic computational model to fuse multi-granular unbalanced linguistic terms. Afterwards, for multi-criteria group decision making problems with multi-granular unbalanced linguistic information, we develop two optimization models to generate adjustment advice for decision makers who have to change his/her opinions in consensus reaching process, which consider both the bounded confidence levels and minimum adjustment of decision makers’ linguistic assessments. Moreover, an algorithm is further proposed to help decision makers reach consensus in group decision making. Eventually, an application example for ERP system supplier selection and some simulation results are presented to illustrate and justify the consensus reaching algorithm. © 2021 Elsevier B.V.","Bounded confidence; Consensus reaching process; Minimum adjustment; Multi-granular unbalanced linguistic information"
"On the aggregation of compositional data","2021","Information Fusion","10.1016/j.inffus.2021.02.021","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102597900&doi=10.1016%2fj.inffus.2021.02.021&partnerID=40&md5=f257b9d35d239a1fc1c45d752911eba7","Compositional data naturally appear in many fields of application. For instance, in chemistry, the relative contributions of different chemical substances to a product are typically described in terms of a compositional data vector. Although the aggregation of compositional data frequently arises in practice, the functions formalizing this process do not fit the standard order-based aggregation framework. This is due to the fact that there is no intuitive order that carries the semantics of the set of compositional data vectors (referred to as the standard simplex). In this paper, we consider the more general betweenness-based aggregation framework that yields a natural definition of an aggregation function for compositional data. The weighted centroid is proved to fit within this definition and discussed to be linked to a very tangible interpretation. Other functions for the aggregation of compositional data are presented and their fit within the proposed definition is discussed. © 2021 Elsevier B.V.","Aggregation; Beset; Centroid; Compositional data"
"DF-Net: Deep fusion network for multi-source vessel segmentation","2022","Information Fusion","10.1016/j.inffus.2021.09.010","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85116860463&doi=10.1016%2fj.inffus.2021.09.010&partnerID=40&md5=c5fb2990407d09056bf79c08f97ed731","Accurate retinal vessel segmentation is very challenging. Recently, the deep learning based method has greatly improved performance. However, the non-vascular structures usually harm the performance and some low contrast small vessels are hard to be detected after several down-sampling operations. To solve these problems, we design a deep fusion network (DF-Net) including multiscale fusion, feature fusion and classifier fusion for multi-source vessel image segmentation. The multiscale fusion module allows the network to detect blood vessels with different scales. The feature fusion module fuses deep features with vessel responses extracted from a Frangi filter to obtain a compact yet domain invariant feature representation. The classifier fusion module provides the network more supervision. DF-Net also predicts the parameter of the Frangi filter to avoid manually picking the best parameters. The learned Frangi filter enhances the feature map of the multiscale network and restores the edge information loss caused by down-sampling operations. The proposed end-to-end network is easy to train and the inference time for one image is 41ms on a GPU. The model outperforms state-of-the-art methods and achieves the accuracy of 96.14%, 97.04%, 98.02% from three publicly available fundus image datasets DRIVE, STARE, CHASEDB1, respectively. The code is available at https://github.com/y406539259/DF-Net. © 2021 Elsevier B.V.","Feature fusion; Image segmentation; Retinal vessel segmentation"
"Fusing CNNs and statistical indicators to improve image classification","2022","Information Fusion","10.1016/j.inffus.2021.09.012","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118099641&doi=10.1016%2fj.inffus.2021.09.012&partnerID=40&md5=7ceae7a3fa6531c2788433dfc6610038","Convolutional Neural Networks have dominated the field of computer vision for the last ten years, exhibiting extremely powerful feature extraction capabilities and outstanding classification performance. The main strategy to prolong this trend in the state-of-the-art literature relies on further upscaling networks in size. However, costs increase rapidly while performance improvements may be marginal. Our main hypothesis is that adding additional sources of information can help to increase performance and that this approach is more cost-effective than building bigger networks, which involve higher training time, larger parametrisation space and higher computational resources requirements. In this paper, an ensemble method for accurate image classification is proposed, fusing automatically detected features through a Convolutional Neural Network and a set of manually defined statistical indicators. Through a combination of the predictions of a CNN and a secondary classifier trained on statistical features, a better classification performance can be achieved cheaply. We test five different CNN architectures and multiple learning algorithms in a diverse number of datasets to validate our proposal. According to the results, the inclusion of additional indicators and an ensemble classification approach help to increase the performance in all datasets. Both code and datasets are publicly available via GitHub at: https://github.com/jahuerta92/cnn-prob-ensemble. © 2021 Elsevier B.V.","Convolutional Neural Networks; Data fusion; Ensemble learning; Feature extraction; Statistical indicators"
"Trust-aware recommendation based on heterogeneous multi-relational graphs fusion","2021","Information Fusion","10.1016/j.inffus.2021.04.001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104062121&doi=10.1016%2fj.inffus.2021.04.001&partnerID=40&md5=9655f9a05b06d63baec6da1a80350884","Users’ trust relations have a significant influence on their choice towards different products. However, few recommendation or prediction algorithms both consider users’ social trust relations and item-related knowledge, which makes them difficult to cope with cold start and the data sparsity problems. In this paper, we propose a novel trust-ware recommendation method based on heterogeneous multi-relational graphs fusion, termed as T-MRGF. In contrast with other traditional methods, it fuses the user-related and item-related graphs with the user–item interaction graph and fully utilizes the high-level connections existing in heterogeneous graphs. Specifically, we first establish the user–user trust relation graph, user–item interaction graph and item–item knowledge graph, and the user feature and item feature, which have been obtained from the user–item graph, are used as the input of the user-related graph and the item-related graph respectively. The fusion is achieved through the cascade of feature vectors before and after feature propagation. In this way, the heterogeneous multi-relational graphs are fused for the feature propagation, which largely refines the user and item representation for model prediction. Simulation results show that the proposed method significantly improve the recommendation performance compared to the state-of-the-art KG-based algorithms both in accuracy and training efficiency. © 2021","Graph neural networks; Heterogeneous data fusion; Knowledge graph; Trust-aware"
"Transitive full covers of incomplete preference relations","2022","Information Fusion","10.1016/j.inffus.2021.10.011","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119397827&doi=10.1016%2fj.inffus.2021.10.011&partnerID=40&md5=2d12480a490fd1fe262159b551d4584f","When a decision maker is asked to compare a set of alternatives, it may happen that the information provided is incomplete because she has no time to compare all the options or is unable to compare some alternatives against others. This contribution departs from an incomplete fuzzy weak preference relation by completing it on a consistent way with the known information. Herein the original notion of fuzzy transitivity, min-transitivity, is considered. If the decision maker is assumed to be coherent, i.e. under the assumption that the known preferences satisfy transitivity, a complete transitive preference relation that preserves the information given by the coherent decision maker is derived. In the case of the given preference values violate transitivity, a degree of transitivity is defined, and an algorithm is presented to provide the most coherent preference relation that preserves the original information according to that degree of transitivity. © 2021 Elsevier B.V.","Coherence; Complete preference relation; Degree of transitivity; Fuzzy preference relation"
"Multi-modal bioelectrical signal fusion analysis based on different acquisition devices and scene settings: Overview, challenges, and novel orientation","2022","Information Fusion","10.1016/j.inffus.2021.10.018","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118900628&doi=10.1016%2fj.inffus.2021.10.018&partnerID=40&md5=9731cba3cc577e78766bfce6b2b99691","Multi-modal fusion combines multiple modal information to overcome the limitation of incomplete information expressed by a single modality, so as to realize the complementarity of modal information and enhance feature representation. Multi-modal medical signal fusion algorithm and extraction equipment play an important role in improving the recognition accuracy of brain diseases. This paper compared the existing data fusion methods and explored the fusion research of multi-modal bioelectrical signals, including: (1) the challenges and shortcomings in the signal acquisition phase are explored from the biological signal acquisition equipment and scene settings; (2) five multi-modal fusion forms are analyzed; (3) the fusion methods and evaluation indexes are briefly reviewed; (4) the research status and challenges of multi-modal fusion in the field of spatial cognitive impairment and biometrics are explored; (5) the advantages and challenges of multi-modal fusion are described. The conclusion of this review is that the research of multimodal medical signal fusion is in the initial stage, and some studies have proved that multi-modal fusion is meaningful for medical research. However, the fusion algorithm and fusion strategy need to be improved. While learning the relatively perfect image fusion algorithm, we need to develop the fusion algorithm and fusion strategy that is suitable for medical signal and strengthen its feasibility in clinical application. © 2021 Elsevier B.V.","Fusion strategy; Information complementarity; Medical signal; Multi-modal fusion"
"2D–3D Geometric Fusion network using Multi-Neighbourhood Graph Convolution for RGB-D indoor scene classification","2021","Information Fusion","10.1016/j.inffus.2021.05.002","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107666919&doi=10.1016%2fj.inffus.2021.05.002&partnerID=40&md5=d1c2723403d24eeb4a6365b3934168e4","Multi-modal fusion has been proved to help enhance the performance of scene classification tasks. This paper presents a 2D–3D Fusion stage that combines 3D Geometric Features with 2D Texture Features obtained by 2D Convolutional Neural Networks. To get a robust 3D Geometric embedding, a network that uses two novel layers is proposed. The first layer, Multi-Neighbourhood Graph Convolution, aims to learn a more robust geometric descriptor of the scene combining two different neighbourhoods: one in the Euclidean space and the other in the Feature space. The second proposed layer, Nearest Voxel Pooling, improves the performance of the well-known Voxel Pooling. Experimental results, using NYU-Depth-V2 and SUN RGB-D datasets, show that the proposed method outperforms the current state-of-the-art in RGB-D indoor scene classification task. © 2021 The Authors","Convolutional Graph Neural Network; Indoor scene classification; Multi-modal fusion; Multi-Neighbourhood Graph Neural Network; RGB-D"
"QuickLook: Movie summarization using scene-based leading characters with psychological cues fusion","2021","Information Fusion","10.1016/j.inffus.2021.04.016","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105853154&doi=10.1016%2fj.inffus.2021.04.016&partnerID=40&md5=c691fe7ba32f7701c1a70ef862d33460","Due to recent advances in the film industry, the production of movies has grown exponentially, which has led to challenges in what is referred to as discoverability: given the overwhelming number of choices, choosing which film to watch has become a tedious task for audiences. Movie summarization (MS) could help, as it presents the central theme of the movie in a compact format and makes browsing more efficient for the audience. In this paper, we present an automatic MS framework coined as ‘QuickLook’, which identifies the leading characters and fuses multiple cues extracted from a movie. Firstly, the movie data is preprocessed for its division into scenes, followed by shot segmentation. Secondly, the leading characters in each segmented scene are determined. Next, four visual cues that capture the film's scenic beauty, memorability, informativeness and emotional resonance are extracted from shots containing the leading characters. These extracted features are then intelligently fused based on the assignment of different weights; shots with a fusion score above a certain threshold are selected for the final summary. The proposed MS framework is assessed by comparison with official trailers from ten Hollywood movies, providing a novel baseline for future fair comparison in the MS literature. The proposed framework is shown to outperform other state-of-the-art MS methods in terms of enjoyability and informativeness. © 2021 Elsevier B.V.","Deep learning; Facial expressions; Information fusion; Movie analysis; Psychological cues extraction; Video summarization"
"An analysis model of diagnosis and treatment for COVID-19 pandemic based on medical information fusion","2021","Information Fusion","10.1016/j.inffus.2021.02.016","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101933346&doi=10.1016%2fj.inffus.2021.02.016&partnerID=40&md5=ed941d8aed4777529cd23f6566ec6f1d","Exploring the complicated relationships underlying the clinical information is essential for the diagnosis and treatment of the Coronavirus Disease 2019 (COVID-19). Currently, few approaches are mature enough to show operational impact. Based on electronic medical records (EMRs) of 570 COVID-19 inpatients, we proposed an analysis model of diagnosis and treatment for COVID-19 based on the machine learning algorithms and complex networks. Introducing the medical information fusion, we constructed the heterogeneous information network to discover the complex relationships among the syndromes, symptoms, and medicines. We generated the numerical symptom (medicine) embeddings and divided them into seven communities (syndromes) using the combination of Skip-Gram model and Spectral Clustering (SC) algorithm. After analyzing the symptoms and medicine networks, we identified the key factors using six evaluation metrics of node centrality. The experimental results indicate that the proposed analysis model is capable of discovering the critical symptoms and symptom distribution for diagnosis; the key medicines and medicine combinations for treatment. Based on the latest COVID-19 clinical guidelines, this model could result in the higher accuracy results than the other representative clustering algorithms. Furthermore, the proposed model is able to provide tremendously valuable guidance and help the physicians to combat the COVID-19. © 2021","Analysis model; Coronavirus Disease 2019 (COVID-19); Diagnosis and treatment; Medical information fusion"
"Data fusion and transfer learning empowered granular trust evaluation for Internet of Things","2022","Information Fusion","10.1016/j.inffus.2021.09.001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85116418337&doi=10.1016%2fj.inffus.2021.09.001&partnerID=40&md5=8bd7879086961235ef3c4b899651b907","In the Internet of Things (IoT), a huge amount of valuable data is generated by various IoT applications. As the IoT technologies become more complex, the attack methods are more diversified and can cause serious damages. Thus, establishing a secure IoT network based on user trust evaluation to defend against security threats and ensure the reliability of data source of collected data have become urgent issues, in this paper, a Data Fusion and transfer learning empowered granular Trust Evaluation mechanism (DFTE) is proposed to address the above challenges. Specifically, to meet the granularity demands of trust evaluation, time–space empowered fine/coarse grained trust evaluation models are built utilizing deep transfer learning algorithms based on data fusion. Moreover, to prevent privacy leakage and task sabotage, a dynamic reward and punishment mechanism is developed to encourage honest users by dynamically adjusting the scale of reward or punishment and accurately evaluating users’ trusts. The extensive experiments show that: (i) the proposed DFTE achieves high accuracy of trust evaluation under different granular demands through efficient data fusion; (ii) DFTE performs excellently in participation rate and data reliability. © 2021","Data fusion; Deep reinforcement learning; Internet of Things; Privacy preservation; Transfer learning; Trust evaluation"
"Multimodal Earth observation data fusion: Graph-based approach in shared latent space","2022","Information Fusion","10.1016/j.inffus.2021.09.004","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115401406&doi=10.1016%2fj.inffus.2021.09.004&partnerID=40&md5=180247e9a56560637a79ea9eed3cfb89","Multiple and heterogenous Earth observation (EO) platforms are broadly used for a wide array of applications, and the integration of these diverse modalities facilitates better extraction of information than using them individually. The detection capability of the multispectral unmanned aerial vehicle (UAV) and satellite imagery can be significantly improved by fusing with ground hyperspectral data. However, variability in spatial and spectral resolution can affect the efficiency of such dataset's fusion. In this study, to address the modality bias, the input data was projected to a shared latent space using cross-modal generative approaches or guided unsupervised transformation. The proposed adversarial networks and variational encoder-based strategies used bi-directional transformations to model the cross-domain correlation without using cross-domain correspondence. It may be noted that an interpolation-based convolution was adopted instead of the normal convolution for learning the features of the point spectral data (ground spectra). The proposed generative adversarial network-based approach employed dynamic time wrapping based layers along with a cyclic consistency constraint to use the minimal number of unlabeled samples, having cross-domain correlation, to compute a cross-modal generative latent space. The proposed variational encoder-based transformation also addressed the cross-modal resolution differences and limited availability of cross-domain samples by using a mixture of expert-based strategy, cross-domain constraints, and adversarial learning. In addition, the latent space was modelled to be composed of modality independent and modality dependent spaces, thereby further reducing the requirement of training samples and addressing the cross-modality biases. An unsupervised covariance guided transformation was also proposed to transform the labelled samples without using cross-domain correlation prior. The proposed latent space transformation approaches resolved the requirement of cross-domain samples which has been a critical issue with the fusion of multi-modal Earth observation data. This study also proposed a latent graph generation and graph convolutional approach to predict the labels resolving the domain discrepancy and cross-modality biases. Based on the experiments over different standard benchmark airborne datasets and real-world UAV datasets, the developed approaches outperformed the prominent hyperspectral panchromatic sharpening, image fusion, and domain adaptation approaches. By using specific constraints and regularizations, the network developed was less sensitive to network parameters, unlike in similar implementations. The proposed approach illustrated improved generalizability in comparison with the prominent existing approaches. In addition to the fusion-based classification of the multispectral and hyperspectral datasets, the proposed approach was extended to the classification of hyperspectral airborne datasets where the latent graph generation and convolution were employed to resolve the domain bias with a small number of training samples. Overall, the developed transformations and architectures will be useful for the semantic interpretation and analysis of multimodal data and are applicable to signal processing, manifold learning, video analysis, data mining, and time series analysis, to name a few. © 2021 Elsevier B.V.","Convolutional neural networks; Fusion; Ground measured spectra; Hyperspectral; Multispectral UAV"
"Clustering ensemble via structured hypergraph learning","2022","Information Fusion","10.1016/j.inffus.2021.09.003","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85116543396&doi=10.1016%2fj.inffus.2021.09.003&partnerID=40&md5=a45635903d39501bd798e0b59299ec77","Clustering ensemble integrates multiple base clustering results to obtain a consensus result and thus improves the stability and robustness of the single clustering method. Since it is natural to use a hypergraph to represent the multiple base clustering results, where instances are represented by nodes and base clusters are represented by hyperedges, some hypergraph based clustering ensemble methods are proposed. Conventional hypergraph based methods obtain the final consensus result by partitioning a pre-defined static hypergraph. However, since base clusters may be imperfect due to the unreliability of base clustering methods, the pre-defined hypergraph constructed from the base clusters is also unreliable. Therefore, directly obtaining the final clustering result by partitioning the unreliable hypergraph is inappropriate. To tackle this problem, in this paper, we propose a clustering ensemble method via structured hypergraph learning, i.e., instead of being constructed directly, the hypergraph is dynamically learned from base results, which will be more reliable. Moreover, when dynamically learning the hypergraph, we enforce it to have a clear clustering structure, which will be more appropriate for clustering tasks, and thus we do not need to perform any uncertain postprocessing, such as hypergraph partitioning. Extensive experiments show that, our method not only performs better than the conventional hypergraph based ensemble methods, but also outperforms the state-of-the-art clustering ensemble methods. © 2021 Elsevier B.V.","Clustering ensemble; Ensemble learning; Hypergraph graph learning"
"Emotion recognition based on convolutional neural networks and heterogeneous bio-signal data sources","2022","Information Fusion","10.1016/j.inffus.2021.07.007","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113235214&doi=10.1016%2fj.inffus.2021.07.007&partnerID=40&md5=42f4df07de8371263323742377f45ff1","Emotion recognition is a crucial application in human–computer interaction. It is usually conducted using facial expressions as the main modality, which might not be reliable. In this study, we proposed a multimodal approach that uses 2-channel electroencephalography (EEG) signals and eye modality in addition to the face modality to enhance the recognition performance. We also studied the use of facial images versus facial depth as the face modality and adapted the common arousal–valence model of emotions and the convolutional neural network, which can model the spatiotemporal information from the modality data for emotion recognition. Extensive experiments were conducted on the modality and emotion data, the results of which showed that our system has high accuracies of 67.8% and 77.0% in valence recognition and arousal recognition, respectively. The proposed method outperformed most state-of-the-art systems that use similar but fewer modalities. Moreover, the use of facial depth has outperformed the use of facial images. The proposed method of emotion recognition has significant potential for integration into various educational applications. © 2021 Elsevier B.V.","3D convolutional neural network; Arousal–valence model of emotions; Electroencephalogram; Emotion recognition"
"Incremental learning for exudate and hemorrhage segmentation on fundus images","2021","Information Fusion","10.1016/j.inffus.2021.02.017","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104065500&doi=10.1016%2fj.inffus.2021.02.017&partnerID=40&md5=2cc09792e693c0bf2ef6b8a4cd0c291e","Deep-learning-based segmentation methods have shown great success across many medical image applications. However, the custom training paradigms suffer from a well-known constraint of the requirement of pixel-wise annotations, which is labor-intensive, especially when they are required to learn new classes incrementally. Contemporary incremental learning focuses on dealing with catastrophic forgetting in image classification and object detection. However, this work aims to promote the performance of the current model to learn new classes with the help of the previous model in the context of incremental learning of instance segmentation. It enormously benefits the current model when the labeled data is limited because of the high labor intensity of manual labeling. In this paper, on the Diabetic Retinopathy (DR) lesion segmentation problem, a novel incremental segmentation paradigm is proposed to distill the knowledge of the previous model to improve the current model. Remarkably, we propose various approaches working on the class-based alignment of the probability maps of the current and the previous model, accounting for the difference between the background classes of the two models. The experimental evaluation of DR lesion segmentation shows the effectiveness of the proposed approaches. © 2021 Elsevier B.V.","Incremental learning; Knowledge distillation; Semantic segmentation"
"Cost-effective ensemble models selection using deep reinforcement learning","2022","Information Fusion","10.1016/j.inffus.2021.07.011","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112373125&doi=10.1016%2fj.inffus.2021.07.011&partnerID=40&md5=63186ff2af3b007074400f05da84e524","Ensemble learning – the application of multiple learning models on the same task – is a common technique in multiple domains. While employing multiple models enables reaching higher classification accuracy, this process can be time consuming, costly, and make scaling more difficult. Given that each model may have different capabilities and costs, assigning the most cost-effective set of learners for each sample is challenging. We propose SPIREL, a novel method for cost-effective classification. Our method enables users to directly associate costs to correct/incorrect label assignment, computing resources and run-time, and then dynamically establishes a classification policy. For each analyzed sample, SPIREL dynamically assigns a different set of learning models, as well as its own classification threshold. Extensive evaluation on two large malware datasets – a domain in which the application of multiple analysis tools is common – demonstrates that SPIREL is highly cost-effective, enabling us to reduce running time by ∼80% while decreasing the accuracy and F1-score by only 0.5%. We also show that our approach is both highly transferable across different datasets and adaptable to changes in individual learning model performance. © 2021 Elsevier B.V.","Android package; Malware detection; Portable executable; Reinforcement learning; Transfer learning"
"F-PENN— Forest path encoding for neural networks","2021","Information Fusion","10.1016/j.inffus.2021.06.005","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85108886008&doi=10.1016%2fj.inffus.2021.06.005&partnerID=40&md5=2f8323309bf825ef7e2657bf0d51310a","Deep neural nets (DNNs) mostly tend to outperform other machine learning (ML) approaches when the training data is abundant, high-dimensional, sparse, or consisting of raw data (e.g., pixels). For datasets with other characteristics – for example, dense tabular numerical data – algorithms such as Gradient Boosting Machines and Random Forest often achieve comparable or better performance at a fraction of the time and resources. These differences suggest that combining these approaches has potential to yield superior performance. Existing attempts to combine DNNs with other ML approaches, which usually consist of feeding the output of the latter into the former, often do not produce positive results. We argue that this lack of improvement stems from the fact that the final classifications fail to provide the DNN with an understanding of the other algorithms’ decision-making process (i.e., its “logic”). In this study we present F-PENN, a novel approach for combining decision forests and DNNs. Instead of providing the final output of the forest (or its trees) to the DNN, we provide the paths traveled by each sample. This information, when fed to the neural net, yields significant improvement in performance. We demonstrate the effectiveness of our approach by conducting extensive evaluation on 56 datasets and comparing F-PENN to four leading baselines: DNNs, Gradient Boosted Decision Trees (GBDT), Random Forest and DeepFM. We show that F-PENN outperforms the baselines in 69%–89% of dataset and achieves an overall average error reduction of 16%–26%. © 2021 Elsevier B.V.","Gradient Boosted Decision trees; Neural Networks; Random Forest; Word2Vec"
"EMFusion: An unsupervised enhanced medical image fusion network","2021","Information Fusion","10.1016/j.inffus.2021.06.001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107820823&doi=10.1016%2fj.inffus.2021.06.001&partnerID=40&md5=2dc25ceeb4f522c78ad0c3b9ce82131d","Existing image fusion methods always use the same representations for different modal medical images. Otherwise, they solve the fusion problem by subjectively defining characteristics to be preserved. However, it leads to the distortion of unique information and restricts the fusion performance. To address the limitations, this paper proposes an unsupervised enhanced medical image fusion network. We perform both surface-level and deep-level constraints for enhanced information preservation. The surface-level constraint is based on the saliency and abundance measurement to preserve the subjectively defined and intuitive characteristics. In the deep-level constraint, the unique information is objectively defined based on the unique channels of a pre-trained encoder. Moreover, in our method, the chrominance information of fusion results is also enhanced. It is because we use the high-quality details in structural images (e.g., MRI) to alleviate the mosaic in functional images (e.g., PET, SPECT). Both qualitative and quantitative experiments demonstrate the superiority of our method over the state-of-the-art fusion methods. © 2021 Elsevier B.V.","Enhanced representation; Medical image fusion; Unsupervised learning"
"A defense method based on attention mechanism against traffic sign adversarial samples","2021","Information Fusion","10.1016/j.inffus.2021.05.005","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107060989&doi=10.1016%2fj.inffus.2021.05.005&partnerID=40&md5=145e549b88ad34e4fda86aca8d89064b","A traditional neural network cannot realize the invariance of image rotation and distortion well, so an attacker can fool the neural network by adding tiny disturbances to an image. If traffic signs are attacked, automatic driving will probably be misguided, leading to disastrous consequences. Inspired by the principle of human vision, this paper proposes a defense method based on an attentional mechanism for traffic sign adversarial samples. In this method, the affine coordinate parameters of the target objects in the images are extracted by a CNN, and then the target objects are redrawn by the coordinate mapping model. In this process, the key areas in the image are extracted by the attention mechanism, and the pixels are filtered by interpolation. Our model simulates the daily behavior of human beings, making it more intelligent in the defense against the adversarial samples. Experiments show that our method has a strong defense ability for traffic sign adversarial samples generated by various attack methods. Compared with other defense methods, our method is more universal and has a strong defense ability against a variety of attacks. Moreover, our model is portable and can be easily implanted into neural networks in the form of defense plug-ins. © 2021 Elsevier B.V.","Adversarial sample; Attention mechanism; Defense model; Traffic sign"
"Benchmarking and comparing multi-exposure image fusion algorithms","2021","Information Fusion","10.1016/j.inffus.2021.02.005","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105295423&doi=10.1016%2fj.inffus.2021.02.005&partnerID=40&md5=bae7b864d393f2e7d2992950269ad5e0","Multi-exposure image fusion (MEF) is an important area in computer vision and has attracted increasing interests in recent years. Apart from conventional algorithms, deep learning techniques have also been applied to MEF. However, although many efforts have been made on developing MEF algorithms, the lack of benchmarking studies makes it difficult to perform fair and comprehensive performance comparison among MEF algorithms, thus hindering the development of this field significantly. In this paper, we fill this gap by proposing a benchmark of multi-exposure image fusion (MEFB), which consists of a test set of 100 image pairs, a code library of 21 algorithms, 20 evaluation metrics, 2100 fused images, and a software toolkit. To the best of our knowledge, this is the first benchmarking study in the field of MEF. This paper also gives a literature review on MEF methods with a focus on deep learning-based algorithms. Extensive experiments have been conducted using MEFB for comprehensive performance evaluation and for identifying effective algorithms. We expect that MEFB will serve as an effective platform for researchers to compare the performance of MEF algorithms. © 2021 Elsevier B.V.","Benchmark; Deep learning; Image fusion; Image processing; Multi-exposure image fusion"
"Multimodal spatio-temporal-spectral fusion for deep learning applications in physiological time series processing: A case study in monitoring the depth of anesthesia","2021","Information Fusion","10.1016/j.inffus.2021.03.001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105349030&doi=10.1016%2fj.inffus.2021.03.001&partnerID=40&md5=0cf26da97c5fc97ca4d37dfec00ad2df","Physiological signals processing brings challenges including dimensionality (due to the number of channels), heterogeneity (due to the different range of values) and multimodality (due to the different sources). In this regard, the current study intended, first, to use time-frequency ridge mapping in exploring the use of fused information from joint EEG-ECG recordings in tracking the transition between different states of anesthesia. Second, it investigated the effectiveness of pre-trained state-of-the-art deep learning architectures for learning discriminative features in the fused data in order to classify the states during anesthesia. Experimental data from healthy-brain patients undergoing operation (N = 20) were used for this study. Data was recorded from the BrainStatus device with single ECG and 10 EEG channels. The obtained results support the hypothesis that not only can ridge fusion capture temporal-spectral progression patterns across all modalities and channels, but also this simplified interpretation of time-frequency representation accelerates the training process and yet improves significantly the efficiency of deep models. Classification outcomes demonstrates that this fusion could yields a better performance, in terms of 94.14% precision and 0.28 s prediction time, compared to commonly used data-level fusing methods. To conclude, the proposed fusion technique provides the possibility of embedding time-frequency information as well as spatial dependencies over modalities and channels in just a 2D array. This integration technique shows significant benefit in obtaining a more unified and global view of different aspects of physiological data at hand, and yet maintaining the desired performance level in decision making. © 2021 Elsevier B.V.","Dimensionality reduction; Multimodality; Ridge; Spatial fusion; Spectral fusion; Temporal fusion"
"Mass customized/personalized manufacturing in Industry 4.0 and blockchain: Research challenges, main problems, and the design of an information architecture","2022","Information Fusion","10.1016/j.inffus.2021.09.021","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118702404&doi=10.1016%2fj.inffus.2021.09.021&partnerID=40&md5=6537527faa423110fedec9f85a02cbef","Mass customized and mass personalized production has become facilitated by the fourth industrial revolution. The resulting industrial environments require the development of information systems able to take the specifications of customers and convey them to the production system in such a way as to contribute to the coordination of all the stakeholders and activities required to fulfill the orders of the customers. This is beyond the capabilities of traditional systems based on MRP and ERP, since the information should be managed in a flexible and decentralized way to exploit the Smart Manufacturing facilities of Industry 4.0. Blockchain, instead, is a technology that provides those features constituting a sound information supporting basis for mass customized/personalized production. Consequently, we explore the potential of blockchain as an information technology able to support industries that base their business models on mass customized/personalized production processes. This survey allows us to identify important challenges for further developments, highlighting three issues in the production setting: (i) to deepen the interoperability of systems, (ii) to generate more implementations, and (iii) to develop efficient consensus protocols. As a response to these insights we provide a conceptual design of how blockchain contributes to managing efficiently mass customized production systems. In our design the information of customer specifications can be fused with data from the production process to generate a plan to fulfill the demand. This design arises as a solution approach to three stated problem, which are faced by mass customized production systems. © 2021 Elsevier B.V.","Blockchain technology; Industry 4.0; Information systems; Manufacturing; Mass customization/personalization; Supply Chain"
"A critic evaluation of methods for COVID-19 automatic detection from X-ray images","2021","Information Fusion","10.1016/j.inffus.2021.04.008","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105877411&doi=10.1016%2fj.inffus.2021.04.008&partnerID=40&md5=161a85a463e0d389af46fca752a9a1f5","In this paper, we compare and evaluate different testing protocols used for automatic COVID-19 diagnosis from X-Ray images in the recent literature. We show that similar results can be obtained using X-Ray images that do not contain most of the lungs. We are able to remove the lungs from the images by turning to black the center of the X-Ray scan and training our classifiers only on the outer part of the images. Hence, we deduce that several testing protocols for the recognition are not fair and that the neural networks are learning patterns in the dataset that are not correlated to the presence of COVID-19. Finally, we show that creating a fair testing protocol is a challenging task, and we provide a method to measure how fair a specific testing protocol is. In the future research we suggest to check the fairness of a testing protocol using our tools and we encourage researchers to look for better techniques than the ones that we propose. © 2021","Convolutional neural networks; Covid-19; Covid-19 diagnosis; X-Ray images"
"An adaptive group decision making framework: Individual and local world opinion based opinion dynamics","2022","Information Fusion","10.1016/j.inffus.2021.09.013","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85116857952&doi=10.1016%2fj.inffus.2021.09.013&partnerID=40&md5=cf4f2550e9c3335a5cde4242fc4cf7a7","Opinion dynamics (OD) models, which simulate individuals’ opinion evolution process on social network to analyze the final state of opinion distribution in a group, usually differ from each other due to the differences in social network evolution rules and opinion evolution rules. However, most existing social network evolution rules and opinion evolution rules usually cannot characterize the comprehensive influence of key factors such as neighbors and opinion differences in social relationships. To fully consider the properties of social network evolution and improve the efficiency of consensus reaching process in group decision making, this paper introduces the concept of local world opinion derived from individuals’ common friends, and then proposes an individual and local world opinion-based OD model. In the proposed model, social network evolution is jointly determined by the distance between individual opinions and network structure similarity. The pair of individuals with the largest consensus improvement space are then suggested to adjust their opinions by using an adaptive individual opinion adjustment mechanism. Finally, detailed simulation results are provided to demonstrate the convergence of the proposed model and analyze different parameters’ effects on the stabilized time steps and the number of stable state opinion clusters. © 2021 Elsevier B.V.","Adaptive consensus reaching process; Group decision making; Opinion dynamics; Social network"
"Multi-modal gait: A wearable, algorithm and data fusion approach for clinical and free-living assessment","2022","Information Fusion","10.1016/j.inffus.2021.09.016","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115752340&doi=10.1016%2fj.inffus.2021.09.016&partnerID=40&md5=047820c2c2283cd157038408e55ab823","Gait abnormalities are typically derived from neurological conditions or orthopaedic problems and can cause severe consequences such as limited mobility and falls. Gait analysis plays a crucial role in monitoring gait abnormalities and discovering underlying deficits can help develop rehabilitation programs. Contemporary gait analysis requires a multi-modal gait analysis approach where spatio-temporal, kinematic and muscle activation gait characteristics are investigated. Additionally, protocols for gait analysis are going beyond labs/clinics to provide more habitual insights, uncovering underlying reasons for limited mobility and falls during daily activities. Wearables are the most prominent technology that are reliable and allow multi-modal gait analysis beyond the labs/clinics for extended periods. There are established wearable-based algorithms for extracting informative gait characteristics and interpretation. This paper proposes a multi-layer fusion framework with sensor, data and gait characteristics. The wearable sensors consist of four units (inertial and electromyography, EMG) attached to both legs (shanks and thighs) and surface electrodes placed on four muscle groups. Inertial and EMG data are interpreted by numerous validated algorithms to extract gait characteristics in different environments. This paper also includes a pilot study to test the proposed fusion approach in a small cohort of stroke survivors. Experimental results in various terrains show healthy participants experienced the highest pace and variability along with slightly increased knee flexion angles (≈1°) and decreased overall muscle activation level during outdoor walking compared to indoor, incline walking activities. Stroke survivors experienced slightly increased pace, asymmetry, and knee flexion angles (≈4°) during outdoor walking compared to indoor. A multi-modal approach through a sensor, data and gait characteristic fusion presents a more holistic gait assessment process to identify changes in different testing environments. The utilisation of the fusion approach presented here warrants further investigation in those with neurological conditions, which could significantly contribute to the current understanding of impaired gait. © 2021","Free-living; Gait analysis; Multi-modal fusion; Sensor fusion; Wearable sensors"
"An investigation into the effects of label noise on Dynamic Selection algorithms","2022","Information Fusion","10.1016/j.inffus.2021.10.015","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119455000&doi=10.1016%2fj.inffus.2021.10.015&partnerID=40&md5=fb5c286c6fab736370a2a9bdc30ecc80","In the literature on classification problems, it is widely discussed how the presence of label noise can bring about severe degradation in performance. Several works have applied Prototype Selection techniques, Ensemble Methods, or both, in an attempt to alleviate this issue. Nevertheless, these methods are not always able to sufficiently counteract the effects of noise. In this work, we investigate the effects of noise on a particular class of Ensemble Methods, that of Dynamic Selection algorithms, and we are especially interested in the behavior of the Fire-DES++ algorithm, a state of the art algorithm which applies the Edited Nearest Neighbors (ENN) algorithm to deal with the effects of noise and imbalance. We propose a method which employs multiple Dynamic Selection sets, based on the Bagging-IH algorithm, which we dub Multiple-Set Dynamic Selection (MSDS), in an attempt to supplant the ENN algorithm on the filtering step. We find that almost all methods based on Dynamic Selection are severely affected by the presence of label noise, with the exception of the K-Nearest Oracles-Union algorithm. We also find that our proposed method can alleviate the issues caused by noise in some scenarios. We have made the code for our method available at https://github.com/fnw/baggingds. © 2021 Elsevier B.V.","Bagging; Dynamic Selection; Ensemble Methods; Label noise; Multiple Classifier Systems"
"Attribute filter based infrared and visible image fusion","2021","Information Fusion","10.1016/j.inffus.2021.04.005","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105272600&doi=10.1016%2fj.inffus.2021.04.005&partnerID=40&md5=249e47f972d6fe29fea055603a9cf132","Infrared and visible image fusion is an effective image processing technique to obtain more comprehensive information, which can help people better understand various scenarios. In this paper, a novel infrared and visible image fusion method is proposed which fully considers the attributes of objects in source images. Benefiting from the attribute and the edge-preserving filters, the prominent objects in the infrared source image are effectively extracted. Then, the weight-based Laplacian pyramid fusion strategy is adopted to get more natural fusion results. The experimental results on the public image fusion datasets and a new infrared–visible video fusion dataset show that the proposed method achieves state-of-the-art fusion performance in terms of both visual and objective evaluations. The proposed algorithm is also implemented in an infrared–visible dual sensor system, which demonstrated the practicability of our fusion method. © 2021 Elsevier B.V.","Attribute filtering; Edge-preserving filtering; Image fusion; Image pyramid; Infrared image"
"Hierarchical fusion and divergent activation based weakly supervised learning for object detection from remote sensing images","2022","Information Fusion","10.1016/j.inffus.2021.10.010","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119288798&doi=10.1016%2fj.inffus.2021.10.010&partnerID=40&md5=4b2027ae3ad50e26113e955b32a04136","Object detection and location from remote sensing (RS) images is challenging, computationally expensive, and labor intense. Benefiting from research on convolutional neural networks (CNNs), the performance in this field has improved in the recent years. However, object detection methods based on CNNs require a large number of images with annotation information for training. For object location, these annotations must contain bounding boxes. Furthermore, objects in RS images are usually small and densely co-located, leading to a high cost of manual annotation. We tackle the problem of weakly supervised object detection under such conditions, aiming to learn detectors with only image-level annotations, i.e., without bounding box annotations. Based on the fact that the feature maps of a CNN are localizable, we hierarchically fuse the location information from the shallow feature map with the class activation map to obtain accurate object locations. In order to mitigate the loss of small or densely distributed objects, we introduce a divergent activation module and a similarity module into the network. The divergent activation module is used to improve the response strength of the low-response areas in the shallow feature map. Densely distributed objects in RS images, such as aircraft in an airport, often exhibit a certain similarity. The similarity module is used to improve the feature distribution of the shallow feature map and to suppress background noise. Comprehensive experiments on a public dataset and a self-assembled dataset (which we made publicly available) show the superior performance of our method compared to state-of-the-art object detectors. © 2021 Elsevier B.V.","Class activation map; Divergent activation; Hierarchical fusion; Object detection from remote sensing images; Weakly supervised learning"
"SPICE-IT: Smart COVID-19 pandemic controlled eradication over NDN-IoT","2021","Information Fusion","10.1016/j.inffus.2021.03.005","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103694405&doi=10.1016%2fj.inffus.2021.03.005&partnerID=40&md5=dd73fed02a0dec01ef35ef6b722898bb","Internet of things (IoT) application in e-health can play a vital role in countering rapidly spreading diseases that can effectively manage health emergency scenarios like pandemics. Efficient disease control also requires monitoring of Standard operating procedure (SOP) follow-up of the population in the disease-prone area with a cost-effective reporting and responding mechanism to register any violation. However, the IoT devices have limited resources and the application requires delay-sensitive data transmission. Named Data Networking (NDN) can significantly reduce content retrieval delays but inherits cache overflow and network congestion challenges. Therefore, we are motivated to present a novel smart COVID-19 pandemic-controlled eradication over NDN-IoT (SPICE-IT) mechanism. SPICE-IT introduces autonomous monitoring in indoor environments with efficient pull-based reporting mechanism that records violations at local servers and cloud server. Intelligent face mask detection and temperature monitoring mechanism examines every person. Cloud server controls the response action from the centre with an adaptive decision-making mechanism. Long short-term memory (LSTM) based caching mechanism reduces the cache overflow and overall network congestion problem. © 2021","Content Caching; Health care; Internet of Things (IoT); Named data networking of things"
"SaccadeFork: A lightweight multi-sensor fusion-based target detector","2022","Information Fusion","10.1016/j.inffus.2021.07.004","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112374720&doi=10.1016%2fj.inffus.2021.07.004&partnerID=40&md5=e43676dd23ec62651ce9b13b34835bac","Commercialization of self-driving applications requires precision and reliability of the perception system due to the highly dynamic and complex road environment. Early perception systems either rely on the camera or on LiDAR for moving obstacle detection. With the development of vehicular sensors and deep learning technologies, the multi-view and sensor fusion based convolutional neural network (CNN) model for detection tasks has become a popular research area. In this paper, we present a novel multi-sensor fusion-based CNN model–SaccadeFork–that integrates the image and upsampled LiDAR point clouds as the input. SaccadeFork includes two modules: (1) a lightweight backbone that consists of hourglass convolution feature extraction module and a parallel dilation convolution module for adaptation of the system to different target sizes; (2) an anchor-based detection head. The model also considers deployment of resource-limited edge devices in the vehicle. Two refinement strategies, i.e., Mixup and Swish activation function are also adopted to improve the model. Comparison with a series of latest models on public dataset of KITTI shows that SaccadeFork can achieve the optimal detection accuracy on vehicles and pedestrians under different scenarios. The final model is also deployed and tested on a local dataset collected based on edge devices and low-cost sensor solutions, and the results show that the model can achieve real-time efficiency and high detection accuracy. © 2021 Elsevier B.V.","Camera; Deep learning; LiDAR; Object detection; Self-driving; Sensor fusion"
"Interpretable learning based Dynamic Graph Convolutional Networks for Alzheimer's Disease analysis","2022","Information Fusion","10.1016/j.inffus.2021.07.013","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111766632&doi=10.1016%2fj.inffus.2021.07.013&partnerID=40&md5=69acdfcb752aef0505e0a6e03b81fdc4","Graph Convolutional Networks (GCNs) are widely applied in classification tasks by aggregating the neighborhood information of each sample to output robust node embedding. However, conventional GCN methods do not update the graph during the training process so that their effectiveness is always influenced by the quality of the input graph. Moreover, previous GCN methods lack the interpretability to limit their real applications. In this paper, a novel personalized diagnosis technique is proposed for early Alzheimer's Disease (AD) diagnosis via coupling interpretable feature learning with dynamic graph learning into the GCN architecture. Specifically, the module of interpretable feature learning selects informative features to provide interpretability for disease diagnosis and abandons redundant features to capture inherent correlation of data points. The module of dynamic graph learning adjusts the neighborhood relationship of every data point to output robust node embedding as well as the correlations of all data points to refine the classifier. The GCN module outputs diagnosis results based on the learned inherent graph structure. All three modules are jointly optimized to perform reliable disease diagnosis at an individual level. Experiments demonstrate that our method outputs competitive diagnosis performance as well as provide interpretability for personalized disease diagnosis. © 2021","Alzheimer's disease diagnosis; Dynamic graph learning; Graph convolutional networks; Interpretable learning"
"Multi-objective optimization algorithm based on characteristics fusion of dynamic social networks for community discovery","2022","Information Fusion","10.1016/j.inffus.2021.10.002","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85117909333&doi=10.1016%2fj.inffus.2021.10.002&partnerID=40&md5=c53f31a50a1ec3edc8a402a87c145dd1","The network structure exhibits a variety of changes over time. Fusing this structure and the development of communities in dynamic networks plays an important role in analyzing the evolution and development of the entire network. How to ensure the division of the community structure in social network big data, as well as ensure the continuity of the community between the current time and previous time period, are issues that need to be explored. This problem can be solved by fusing the three characteristics of temporal variability, stability, and continuity in dynamic social network communities, and by adopting the multi-objective optimization method to detect community structures in dynamic networks. The probability fusion method is added to the initial step of the algorithm to generate suitable network partitions and ensure fast convergence and high accuracy. Two neighboring fusion strategies are proposed that are suitable for communities: the neighbor diversity strategy and the neighbor crowd strategy. These two strategies make different changes to the candidate network partitions. A continuity metric for dynamic community evolution is formulated to compare the similarity of the dynamic network communities of two consecutive time steps. Experiments on synthetic datasets and actual datasets prove that the proposed method in this paper provides better performance than existing methods. © 2021 Elsevier B.V.","Community discovery; Data fusion; Dynamic networks"
"Mobile edge-enabled trust evaluation for the Internet of Things","2021","Information Fusion","10.1016/j.inffus.2021.04.007","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104926902&doi=10.1016%2fj.inffus.2021.04.007&partnerID=40&md5=24156997001aae973da29569de5fecd9","The Internet of Things (IoT), including wireless sensors, is one of the highly anticipated contributors to big data; therefore, avoiding misleading or forged data gathering in cases of sensitive and critical data through secure communication is vital. However, due to the relatively long distance between remote cloud and end nodes, cloud computing cannot provide effective and direct management for end nodes, which leads to security vulnerabilities. In this paper, we propose a novel trust evaluation model based on the trust transitivity on a chain assisted by mobile edge nodes, which is used to ensure the reliability of nodes in the Internet of Things and prevent malicious attacks. The mobile edge nodes offer a new solution to solve the above problems with relatively strong computing and storage abilities. Firstly, we design calculation approaches to different trust chains to measure their trust degrees. Secondly, we propose an improved Dijkstra's algorithm for collecting trust information of sensor nodes by mobile edge nodes. Finally, the experimental results show that our trust model based on mobile edge nodes can evaluate sensor nodes more precisely and enhance the security on the Internet of Things. © 2021 Elsevier B.V.","Edge computing; Internet of Things; Mobile edge node; Trust chain"
"Retinal microaneurysms detection using adversarial pre-training with unlabeled multimodal images","2022","Information Fusion","10.1016/j.inffus.2021.10.003","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85117944328&doi=10.1016%2fj.inffus.2021.10.003&partnerID=40&md5=1399e2c7783532b4632d3fb63b4c680a","The detection of retinal microaneurysms is crucial for the early detection of important diseases such as diabetic retinopathy. However, the detection of these lesions in retinography, the most widely available retinal imaging modality, remains a very challenging task. This is mainly due to the tiny size and low contrast of the microaneurysms in the images. Consequently, the automated detection of microaneurysms usually relies on extensive ad-hoc processing. In this regard, although microaneurysms can be more easily detected using fluorescein angiography, this alternative imaging modality is invasive and not adequate for regular preventive screening. In this work, we propose a novel deep learning methodology that takes advantage of unlabeled multimodal image pairs for improving the detection of microaneurysms in retinography. In particular, we propose a novel adversarial multimodal pre-training consisting in the prediction of fluorescein angiography from retinography using generative adversarial networks. This pre-training allows learning about the retina and the microaneurysms without any manually annotated data. Additionally, we also propose to approach the microaneurysms detection as a heatmap regression, which allows an efficient detection and precise localization of multiple microaneurysms. To validate and analyze the proposed methodology, we perform an exhaustive experimentation on different public datasets. Additionally, we provide relevant comparisons against different state-of-the-art approaches. The results show a satisfactory performance of the proposal, achieving an Average Precision of 64.90%, 31.36%, and 33.55% in the E-Ophtha, ROC, and DDR public datasets. Overall, the proposed approach outperforms existing deep learning alternatives while providing a more straightforward detection method that can be effectively applied to raw unprocessed retinal images. © 2021 The Authors","Deep learning; Eye fundus; Generative adversarial networks; Medical imaging; Microaneurysms; Multimodal imaging"
"Pay attention to doctor–patient dialogues: Multi-modal knowledge graph attention image-text embedding for COVID-19 diagnosis","2021","Information Fusion","10.1016/j.inffus.2021.05.015","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85108740403&doi=10.1016%2fj.inffus.2021.05.015&partnerID=40&md5=a331b0ac8c5d37a6188d83c8e10e64f4","The sudden increase in coronavirus disease 2019 (COVID-19) cases puts high pressure on healthcare services worldwide. At this stage, fast, accurate, and early clinical assessment of the disease severity is vital. In general, there are two issues to overcome: (1) Current deep learning-based works suffer from multimodal data adequacy issues; (2) In this scenario, multimodal (e.g., text, image) information should be taken into account together to make accurate inferences. To address these challenges, we propose a multi-modal knowledge graph attention embedding for COVID-19 diagnosis. Our method not only learns the relational embedding from nodes in a constituted knowledge graph but also has access to medical knowledge, aiming at improving the performance of the classifier through the mechanism of medical knowledge attention. The experimental results show that our approach significantly improves classification performance compared to other state-of-the-art techniques and possesses robustness for each modality from multi-modal data. Moreover, we construct a new COVID-19 multi-modal dataset based on text mining, consisting of 1393 doctor–patient dialogues and their 3706 images (347 X-ray + 2598 CT + 761 ultrasound) about COVID-19 patients and 607 non-COVID-19 patient dialogues and their 10754 images (9658 X-ray + 494 CT + 761 ultrasound), and the fine-grained labels of all. We hope this work can provide insights to the researchers working in this area to shift the attention from only medical images to the doctor–patient dialogue and its corresponding medical images. © 2021 Elsevier B.V.","COVID-19 diagnose; Knowledge attention mechanism; Knowledge embedding; Knowledge-based representation learning"
"Artificial intelligence and healthcare: Forecasting of medical bookings through multi-source time-series fusion","2021","Information Fusion","10.1016/j.inffus.2021.03.004","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105264101&doi=10.1016%2fj.inffus.2021.03.004&partnerID=40&md5=d9e6e8dfe2e86514af8868654a0a22ec","Nowadays, Artificial intelligence (AI), combined with the digitalization of healthcare, can lead to substantial improvements in Patient Care, Disease Management, Hospital Administration, and supply chain effectiveness. Among predictive analytics tools, time series forecasting represents a central task to support healthcare management in terms of bookings and medical services predictions. In this context, the development of flexible frameworks to provide robust and reliable predictions became a central point in this healthcare innovation process. This paper presents and discusses a multi-source time series fusion and forecasting framework relying on Deep Learning. By combining weather, air-quality and medical bookings time series through a feature compression stage which preserves temporal patterns, the prediction is provided through a flexible ensemble technique based on machine learning models and a hybrid neural network. The proposed system is able to predict the number of bookings related to a specific medical examination for a 7-days horizon period. To assess the proposed approach's effectiveness, we rely on time series extracted from a real dataset of administrative e-health records provided by the Campania Region health department, in Italy. © 2021 Elsevier B.V.","Artificial intelligence; Deep Learning; Healthcare; Multi-source time-series"
"Position estimation in indoor using networked GNSS sensors and a range-azimuth sensor","2022","Information Fusion","10.1016/j.inffus.2022.08.004","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136475069&doi=10.1016%2fj.inffus.2022.08.004&partnerID=40&md5=5214f5daf98393a035ae5bcfa1dea4e3","The global navigation satellite systems (GNSS) receivers suffer from determining an accurate position estimate in the indoor region due to non-line of sight (Non-LOS) conditions. This paper proposes a novel method of position estimation within the indoor region by using distributed GNSS sensors and a range-azimuth sensor setup. All the GNSS sensors are connected to a central node; the inaccurate position estimates evolved from the Kalman filter (KF) framework are transmitted to a central node as primary data. The deviation between the inaccurate position estimate and the GNSS sensor's actual position is the positional deviation (PD) vector, which needs to be estimated. In the same indoor region, a range-azimuth sensor is also deployed. It estimates the GNSS sensor's physical location in its local coordinates, and these estimates are being transmitted to a central node as secondary data. Further, by using the primary and secondary data, we formulated a PD vector compensation followed by a sequential fusion (SF) framework to derive the precise locations of both GNSS sensors and the range-azimuth sensor by recursively estimating the PD vector. Finally, the Cramer–Rao lower bound (CRLB) for the proposed framework is derived. The simulation results are quantified with the root mean square error (RMSE) and CRLB. © 2022 Elsevier B.V.","GNSS sensor; Indoor localization; Networked GNSS sensors; Range-azimuth sensor; RLS"
"Laplacian pyramid networks: A new approach for multispectral pansharpening","2022","Information Fusion","10.1016/j.inffus.2021.09.002","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85116535775&doi=10.1016%2fj.inffus.2021.09.002&partnerID=40&md5=07f1297d16e061939b6e0e62f195f5c4","Pansharpening is about fusing a high spatial resolution panchromatic image with a simultaneously acquired multispectral image with lower spatial resolution. In this paper, we propose a Laplacian pyramid pansharpening network architecture for accurately fusing a high spatial resolution panchromatic image and a low spatial resolution multispectral image, aiming at getting a higher spatial resolution multispectral image. The proposed architecture considers three aspects. First, we use the Laplacian pyramid method whose blur kernels are designed according to the sensors’ modulation transfer functions to separate the images into multiple scales for fully exploiting the crucial spatial information at different spatial scales. Second, we develop a fusion convolutional neural network (FCNN) for each scale, combining them to form the final multi-scale network architecture. Specifically, we use recursive layers for the FCNN to share parameters across and within pyramid levels, thus significantly reducing the network parameters. Third, a total loss consisting of multiple across-scale loss functions is employed for training, yielding higher accuracy. Extensive experimental results based on quantitative and qualitative assessments exploiting benchmarking datasets demonstrate that the proposed architecture outperforms state-of-the-art pansharpening methods. Code is available at https://github.com/ChengJin-git/LPPN. © 2021 Elsevier B.V.","Convolutional neural network; Image fusion; Laplacian pyramid; Machine learning; Modulation transfer function; Pansharpening; Remote sensing"
"Multi-attribute group decision making with opinion dynamics based on social trust network","2021","Information Fusion","10.1016/j.inffus.2021.04.010","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105077160&doi=10.1016%2fj.inffus.2021.04.010&partnerID=40&md5=de679f17553548b7c7128d19b0f66d17","Social trust network (STN) has facilitated information exchange between experts during interactions. Some feedback mechanisms have been used to provide advices for opinion change to improve their consensus levels. However, they do not consider the experts’ willingness and their self-confidence values. To analyze the influence of the relationship between experts on the decision-making results, this paper proposes a multi-attribute group decision making (MAGDM) with opinion dynamics based on STN. Three stages are included in the proposed approach: trust propagation, consensus reaching process and alternative selection. In the trust propagation stage, the social weight influence matrix and the weights of experts are obtained based on the complete social trust matrix which is constructed by trust aggregation and the given self-confidence values of experts. In the consensus reaching process, the consensus measure is used to determine the consensus between the experts or not, and the feedback mechanism based on opinion dynamics is used to adjust the opinions which do not reach consensus. The appropriate alternative is selected based on the assessable value of the alternative in the selection process. Finally, a numerical experiment about supplier selection is introduced to illustrate the efficiency of the proposed approach and comparison analyses show that the proposed approach can improve efficiency compared with the MAGDM in the social network. © 2021 Elsevier B.V.","consensus reaching process; feedback mechanism; Multi-attribute group decision making; opinion dynamics; social trust network"
"Meta-learning meets the Internet of Things: Graph prototypical models for sensor-based human activity recognition","2022","Information Fusion","10.1016/j.inffus.2021.10.009","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119181735&doi=10.1016%2fj.inffus.2021.10.009&partnerID=40&md5=56340294adf082ca6a48724a81163c91","With the rapid growth of the Internet of Things (IoT), smart systems and applications are equipped with an increasing number of wearable sensors and mobile devices. These sensors are used not only to collect data but, more importantly, to assist in tracking and analyzing the daily human activities. Sensor-based human activity recognition is a hotspot and starts to employ deep learning approaches to supersede traditional shallow learning that rely on hand-crafted features. Although many successful methods have been proposed, there are three challenges to overcome: (1) deep model's performance overly depends on the data size; (2) deep model cannot explicitly capture abundant sample distribution characteristics; (3) deep model cannot jointly consider sample features, sample distribution characteristics, and the relationship between the two. To address these issues, we propose a meta-learning-based graph prototypical model with priority attention mechanism for sensor-based human activity recognition. This approach learns not only sample features and sample distribution characteristics via meta-learning-based graph prototypical model, but also the embeddings derived from priority attention mechanism that mines and utilizes relations between sample features and sample distribution characteristics. What is more, the knowledge learned through our approach can be seen as a priori applicable to improve the performance for other general reasoning tasks. Experimental results on fourteen datasets demonstrate that the proposed approach significantly outperforms other state-of-the-art methods. On the other hand, experiments of applying our model to two other tasks show that our model effectively supports other recognition tasks related to human activity and improves performance on the datasets of these tasks. © 2021 Elsevier B.V.","Attention mechanisms; Graph model; Internet of Things; Meta-learning"
"Multi-criteria assessment of user trust in Social Reviewing Systems with subjective logic fusion","2022","Information Fusion","10.1016/j.inffus.2021.07.012","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111856037&doi=10.1016%2fj.inffus.2021.07.012&partnerID=40&md5=5ba8c9388867791bc879b64f846cbd8e","By now people's opinions and actions are more and more strongly influenced by what is posted and shared on the various social networks. Thus, malicious users can purposely manipulate other users posting fake news/reviews. In order to face this challenge, modern online social networks are beginning to adopt tool for user trustworthiness assessment. Current assessment solutions mainly adopt multi-criteria frameworks for user trustworthiness assessment but fail at properly dealing with uncertainty and vagueness in computed/collected scores and aggregating them in a robust manner. In this paper, we propose a larger set of criteria than existing related works, and the use of subjective logic to represent and combine subjective and objective scores. Specifically, several of assessment criteria are introduced for verifying user trust from different point of views (usefulness and quality of user reviews, users’ influence/importance in terms of activities and centrality within the social network, time dependent crown consensus investigating aspect-based sentiments and opinions of reviews w.r.t. the majority), aiming at improving accuracy and precision in trust estimation. The available fusion operators in the literature of subjective logic have been compared so as to find the best one fitting the needs of trust estimation. The proposed solution has been implemented and evaluated against public Yelp data-sets so as to prove its effectiveness and efficiency w.r.t. existing related works within the literature. © 2021 Elsevier B.V.","Multi-criteria decision making; Opinion aggregation; Reputation; Social networks; Subjective logic; Trust; Trustworthiness assessment"
"Multi-source brain computing with systematic fusion for smart health","2021","Information Fusion","10.1016/j.inffus.2021.03.009","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105594754&doi=10.1016%2fj.inffus.2021.03.009&partnerID=40&md5=974ba544fce61dc79a7242cdb0f2f130","With the progress of artificial intelligence, big data and functional neuroimaging technologies, brain computing has rapidly advanced our understanding of brain intelligence and brain disorders. We argue that existing data analytical methods have become insufficient for brain computing when dealing with multiple brain big data sources, because such methods mainly focus on flattening strategies and fail to work well for systematic understanding of the constituent elements of cognition, emotion and disease, as well as the intra- and inter-relations within and among themselves. To address this problem, we present in this paper a novel multi-source brain computing platform by Data-Brain driven systematic fusion. First, we formalize a series of behaviors surrounding the Brain Informatics-based investigation process, and present a conceptual model to systematically represent content and context of functional neuroimaging data. Then, we propose the systematic brain computing framework with multi-aspect fusion and inference to understand brain specificity and give uncertainty quantification, as well as its inspiration and applications for translational studies on brain health. In particular, a graph matching-based task search algorithm is introduced to help systematic experimental design and data sampling with multiple cognitive tasks. The study increases the interpretability and transparency of brain computing findings by inferring and testing multiple hypotheses taking into consideration the effect of evidence combination. Finally, multiple sources of knowledge (K), information (I) and data (D) are driven by a KID loop as the thinking space to inspire never-ending learning and multi-dimensional interactions in the connected social–cyber–physical spaces. Experimental results have demonstrated the efficacy of the proposed brain computing method with systematic fusion. © 2021 Elsevier B.V.","Brain computing; Brain informatics; Data-Brain; Intelligence system; Smart health; Systematic fusion"
"Risk Prediction of Diabetes: Big data mining with fusion of multifarious physical examination indicators","2021","Information Fusion","10.1016/j.inffus.2021.02.015","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105371511&doi=10.1016%2fj.inffus.2021.02.015&partnerID=40&md5=003d39f21f21a5993186ef9cb0d50d75","Diabetes is a global epidemic. Long-term exposure to hyperglycemia can cause chronic damage to various tissues. Thus, early diagnosis of diabetes is crucial. In this study, we designed a computational system to predict diabetes risk by fusing multifarious types of physical examination data. We collected 1,507,563 physical examination data of healthy people and diabetes patients, as well as 387,076 physical examination data from the follow-up records from 2011 to 2017 of diabetes patients in Luzhou City in China. Three types of physical examination indexes were statistically analyzed: demographics, vital signs, and laboratory values. To distinguish diabetes patients from healthy people, a model based on eXtreme Gradient Boosting (XGBoost) was developed, which could produce an area under the receiver operating characteristic curve (AUC) of 0.8768. Moreover, to improve the convenience and flexibility of the model in clinical and real-life scenarios, a diabetes risk scorecard was established based on logistic regression, which could evaluate human health. Lastly, we statistically analyzed the data from the follow-up records to identify the key factors influencing patient control of their conditions. To improve the diabetes cascade screening and personal lifestyle management, an online diabetes risk assessment system was established, which can be freely accessed at http://lin-group.cn/server/DRSC/index.html. This system is expected to provide guidance for human health management. © 2021",""
"Finding and removing Clever Hans: Using explanation methods to debug and improve deep models","2022","Information Fusion","10.1016/j.inffus.2021.07.015","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113458167&doi=10.1016%2fj.inffus.2021.07.015&partnerID=40&md5=266f4e856422a7b806d5207ac06c06d3","Contemporary learning models for computer vision are typically trained on very large (benchmark) datasets with millions of samples. These may, however, contain biases, artifacts, or errors that have gone unnoticed and are exploitable by the model. In the worst case, the trained model does not learn a valid and generalizable strategy to solve the problem it was trained for, and becomes a “Clever Hans” predictor that bases its decisions on spurious correlations in the training data, potentially yielding an unrepresentative or unfair, and possibly even hazardous predictor. In this paper, we contribute by providing a comprehensive analysis framework based on a scalable statistical analysis of attributions from explanation methods for large data corpora. Based on a recent technique — Spectral Relevance Analysis — we propose the following technical contributions and resulting findings: (a) a scalable quantification of artifactual and poisoned classes where the machine learning models under study exhibit Clever Hans behavior, (b) several approaches we collectively denote as Class Artifact Compensation, which are able to effectively and significantly reduce a model's Clever Hans behavior, i.e., we are able to un-Hans models trained on (poisoned) datasets, such as the popular ImageNet data corpus. We demonstrate that Class Artifact Compensation, defined in a simple theoretical framework, may be implemented as part of a neural network's training or fine-tuning process, or in a post-hoc manner by injecting additional layers, preventing any further propagation of undesired Clever Hans features, into the network architecture. Using our proposed methods, we provide qualitative and quantitative analyses of the biases and artifacts in, e.g., the ImageNet dataset, the Adience benchmark dataset of unfiltered faces, and the ISIC 2019 skin lesion analysis dataset. We demonstrate that these insights can give rise to improved, more representative, and fairer models operating on implicitly cleaned data corpora. © 2021 The Authors","Class Artifact Compensation; Clever Hans predictors; Deep Neural Networks; Explainable Artificial Intelligence; Feature unlearning; Spectral Relevance Analysis"
"Learning disentangled user representation with multi-view information fusion on social networks","2021","Information Fusion","10.1016/j.inffus.2021.03.011","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103785070&doi=10.1016%2fj.inffus.2021.03.011&partnerID=40&md5=6b1f2e5739e02c35b395de5e0fdf6051","User representation learning is one prominent and critical task of user analysis on social networks, which derives conceptual user representations to improve the inference of user intentions and behaviors. Previous efforts have shown its substantial value in multifarious real-world applications, including product recommendation, textual content modeling, link prediction, and many more. However, existing studies either underutilize multi-view information, or neglect the stringent entanglement among underlying factors that govern user intentions, thus deriving deteriorated representations. To overcome these shortages, this paper proposes an adversarial fusion framework to fully exploit substantial multi-view information for user representation, consisting of a generator and a discriminator. The generator learns representations with a variational autoencoder, and is forced by the adversarial fusion framework to pay specific attention to substantial informative signs, thus integrating multi-view information. Furthermore, the variational autoencoder used in the generator is novelly designed to capture and disentangle the latent factors behind user intentions. By fully utilizing multi-view information and achieving disentanglement, our model learns robust and interpretable user representations. Extensive experiments on both synthetic and real-world datasets demonstrate the superiority of our proposed model. © 2021","Disentangled learning; Information fusion; Social networks; User representation"
"PESA-Net: Permutation-Equivariant Split Attention Network for correspondence learning","2022","Information Fusion","10.1016/j.inffus.2021.07.018","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111843083&doi=10.1016%2fj.inffus.2021.07.018&partnerID=40&md5=27ff4c10c18975b2024eb699006ed4fb","Establishing reliable correspondences by a deep neural network is an important task in computer vision, and it generally requires permutation-equivariant architecture and rich contextual information. In this paper, we design a Permutation-Equivariant Split Attention Network (called PESA-Net), to gather rich contextual information for the feature matching task. Specifically, we propose a novel “Split–Squeeze–Excitation–Union” (SSEU) module. The SSEU module not only generates multiple paths to exploit the geometrical context of putative correspondences from different aspects, but also adaptively captures channel-wise global information by explicitly modeling the interdependencies between the channels of features. In addition, we further construct a block by fusing the SSEU module, Multi-Layer Perceptron and some normalizations. The proposed PESA-Net is able to effectively infer the probabilities of correspondences being inliers or outliers and simultaneously recover the relative pose by essential matrix. Experimental results demonstrate that the proposed PESA-Net relative surpasses state-of-the-art approaches for pose estimation and outlier rejection on both outdoor scenes and indoor scenes (i.e., YFCC100M and SUN3D). Source codes: https://github.com/x-gb/PESA-Net. © 2021","Deep learning; Feature matching; Wide-baseline stereo"
"Multi-source unsupervised domain adaptation for object detection","2022","Information Fusion","10.1016/j.inffus.2021.09.011","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85116388865&doi=10.1016%2fj.inffus.2021.09.011&partnerID=40&md5=97ec9535cd619f70a4aa6c4007b361e1","Domain adaptation for object detection has been extensively studied in recent years. Most existing approaches focus on single-source unsupervised domain adaptive object detection. However, a more practical scenario is that the labeled source data is collected from multiple domains with different feature distributions. The conventional approaches do not work very well since multiple domain gaps exist. We propose a Multi-source domain Knowledge Transfer (MKT) method to handle this situation. First, the low-level features from multiple domains are aligned by learning a shallow feature extraction network. Then, the high-level features from each pair of source and target domains are aligned by the followed multi-branch network. After that, we perform two parts of information fusion: (1) We train a detection network shared by all branches based on the transferability of each source sample feature. The transferability of a source sample feature means the indistinguishable degree to the target domain sample features. (2) For using our model, the target sample features output by the multi-branch network are fused based on the average transferability of each domain. Moreover, we leverage both image-level and instance-level attention to promote positive cross-domain transfer and suppress negative transfer. Our main contributions are the two-stage feature alignments and information fusion. Extensive experimental results on various transfer scenarios show that our method achieves the state-of-the-art performance. © 2021 Elsevier B.V.","Feature fusion; Multi-source object detection; Transferability; Unsupervised domain adaptation"
"A smartphone-based multimodal indoor tracking system","2021","Information Fusion","10.1016/j.inffus.2021.05.001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107633888&doi=10.1016%2fj.inffus.2021.05.001&partnerID=40&md5=da0ae0f4a9585e91c19d6160772d66d3","The great popularity of smartphones, together with the increasingly important aim of providing context-aware services, has spurred interest in developing indoor tracking systems. Accurate tracking and localization systems are seen as key services for most context-aware applications. Research projects making use of radio signals detected by radio interfaces and the data captured by sensors commonly integrated in most smartphones have already shown promising and better results than location solutions based on a single data source. In this paper, we present a multi-sensor tracking system built by incrementally integrating state-of-the-art models of the Wi-Fi interface and the accelerometer, gyroscope and magnetometer sensors of a smartphone. Our proposal consists of a simple calibration phase of the tracking system, which involves enabling simultaneous data gathering from all three sensors and the Wi-Fi interface. Taking the Wi-Fi signal model as baseline, four different configurations are evaluated by incrementally adding and integrating the models of the other three sensors. The experimental results reveal a mean error accuracy of 60 cm in the case when the tracking system makes use of all four data sources. Our results also include a spatial characterization of the accuracy and processing power requirements of the proposed solution. Our main findings demonstrate the feasibility of developing accurate localization indoor tracking systems using current smartphones without the need for additional hardware. © 2021 The Authors","IMU-based; Indoor localization; Magnetic field; RSSI-based; Sensor fusion; Smartphone tracking"
"Sentiment Analysis based Multi-Person Multi-criteria Decision Making methodology using natural language processing and deep learning for smarter decision aid. Case study of restaurant choice using TripAdvisor reviews","2021","Information Fusion","10.1016/j.inffus.2020.10.019","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85095781765&doi=10.1016%2fj.inffus.2020.10.019&partnerID=40&md5=d18d961eb4273782803105b0ffcc5ff1","Decision making models are constrained by taking the expert evaluations with pre-defined numerical or linguistic terms. We claim that the use of sentiment analysis will allow decision making models to consider expert evaluations in natural language. Accordingly, we propose the Sentiment Analysis based Multi-person Multi-criteria Decision Making (SA-MpMcDM) methodology for smarter decision aid, which builds the expert evaluations from their natural language reviews, and even from their numerical ratings if they are available. The SA-MpMcDM methodology incorporates an end-to-end multi-task deep learning model for aspect based sentiment analysis, named DOC-ABSADeepL model, able to identify the aspect categories mentioned in an expert review, and to distill their opinions and criteria. The individual evaluations are aggregated via the procedure named criteria weighting through the attention of the experts. We evaluate the methodology in a case study of restaurant choice using TripAdvisor reviews, hence we build, manually annotate, and release the TripR-2020 dataset of restaurant reviews. We analyze the SA-MpMcDM methodology in different scenarios using and not using natural language and numerical evaluations. The analysis shows that the combination of both sources of information results in a higher quality preference vector. © 2020 Elsevier B.V.","Aspect-based sentiment analysis; Multi-person multi-criteria decision making; Multi-task deep learning; Smarter decision aid; Social media"
"DMRFNet: Deep Multimodal Reasoning and Fusion for Visual Question Answering and explanation generation","2021","Information Fusion","10.1016/j.inffus.2021.02.006","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100874719&doi=10.1016%2fj.inffus.2021.02.006&partnerID=40&md5=5ab11c22ad8979276cee2bf20a33795c","Visual Question Answering (VQA), which aims to answer questions in natural language according to the content of image, has attracted extensive attention from artificial intelligence community. Multimodal reasoning and fusion is a central component in recent VQA models. However, most existing VQA models are still insufficient to reason and fuse clues from multiple modalities. Furthermore, they are lack of interpretability since they disregard the explanations. We argue that reasoning and fusing multiple relations implied in multimodalities contributes to more accurate answers and explanations. In this paper, we design an effective multimodal reasoning and fusion model to achieve fine-grained multimodal reasoning and fusion. Specifically, we propose Multi-Graph Reasoning and Fusion (MGRF) layer, which adopts pre-trained semantic relation embeddings, to reason complex spatial and semantic relations between visual objects and fuse these two kinds of relations adaptively. The MGRF layers can be further stacked in depth to form Deep Multimodal Reasoning and Fusion Network (DMRFNet) to sufficiently reason and fuse multimodal relations. Furthermore, an explanation generation module is designed to justify the predicted answer. This justification reveals the motive of the model's decision and enhances the model's interpretability. Quantitative and qualitative experimental results on VQA 2.0, and VQA-E datasets show DMRFNet's effectiveness. © 2021 Elsevier B.V.","Explainable artificial intelligence; Multimodal reasoning and fusion; Visual Question Answering"
"Multi-view Incremental Discriminant Analysis","2021","Information Fusion","10.1016/j.inffus.2020.10.021","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096481713&doi=10.1016%2fj.inffus.2020.10.021&partnerID=40&md5=053db9bd4d72077837426695e734946a","In recent years, the use of multi-view data has attracted much attention resulting in many multi-view batch learning algorithms. However, these algorithms prove expensive in terms of training time and memory when used on the incremental data. In this paper, we propose Multi-view Incremental Discriminant Analysis (MvIDA), which updates the trained model to incorporate new data samples. MvIDA requires only the old model and newly added data to update the model. Depending on the nature of the increments, MvIDA is presented as two cases, sequential MvIDA and chunk MvIDA. We have compared the proposed method against the batch Multi-view Discriminant Analysis (MvDA) for its discriminability, order independence, the effect of the number of views, training time, and memory requirements. We have also compared our method with single-view Incremental Linear Discriminant Analysis (ILDA) for accuracy and training time. The experiments are conducted on four datasets with a wide range of dimensions per view. The results show that through order independence and faster construction of the optimal discriminant subspace, MvIDA addresses the issues faced by the batch multi-view algorithms in the incremental setting. © 2020 Elsevier B.V.","Classification; Discriminant analysis; Incremental learning; Multi-view learning"
"Relaxed multi-view clustering in latent embedding space","2021","Information Fusion","10.1016/j.inffus.2020.10.013","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096166262&doi=10.1016%2fj.inffus.2020.10.013&partnerID=40&md5=59fec22708655f25704d4ba20c193545","Although many multi-view clustering approaches have been developed recently, one common shortcoming of most of them is that they generally rely on the original feature space or consider the two components of the similarity-based clustering separately (i.e., similarity matrix construction and cluster indicator matrix calculation), which may negatively affect the clustering performance. To tackle this shortcoming, in this paper, we propose a new method termed Multi-view Clustering in Latent Embedding Space (MCLES), which jointly recovers a comprehensive latent embedding space, a robust global similarity matrix and an accurate cluster indicator matrix in a unified optimization framework. In this framework, each variable boosts each other in an interplay manner to achieve the optimal solution. To avoid the optimization problem of quadratic programming, we further propose to relax the constraint of the global similarity matrix, based on which an improved version termed Relaxed Multi-view Clustering in Latent Embedding Space (R-MCLES) is proposed. Compared with MCLES, R-MCLES achieves lower computational complexity with more correlations between pairs of data points. Extensive experiments conducted on both image and document datasets have demonstrated the superiority of the proposed methods when compared with the state-of-the-art. © 2020 Elsevier B.V.","Cluster indicator matrix; Latent embedding representation; Multi-view clustering; Similarity matrix"
"Image retrieval from remote sensing big data: A survey","2021","Information Fusion","10.1016/j.inffus.2020.10.008","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85093917112&doi=10.1016%2fj.inffus.2020.10.008&partnerID=40&md5=da60124684a672129b3e955e0da0e8f5","The blooming proliferation of aeronautics and astronautics platforms, together with the ever-increasing remote sensing imaging sensors on these platforms, has led to the formation of rapidly-growing earth observation data with the characteristics of large volume, large variety, large velocity, large veracity and large value, which raises awareness about the importance of large-scale image processing, fusion and mining. Unconsciously, we have entered an era of big earth data, also called remote sensing (RS) big data. Although RS big data provides great opportunities for a broad range of applications such as disaster rescue, global security, and so forth, it inevitably poses many additional processing challenges. As one of the most fundamental and important tasks in RS big data mining, image retrieval (i.e., image information mining) from RS big data has attracted continuous research interests in the last several decades. This paper mainly works for systematically reviewing the emerging achievements for image retrieval from RS big data. And then this paper further discusses the RS image retrieval based applications including fusion-oriented RS image processing, geo-localization and disaster rescue. To facilitate the quantitative evaluation of the RS image retrieval technique, this paper gives a list of publicly open datasets and evaluation metrics, and briefly recalls the mainstream methods on two representative benchmarks of RS image retrieval. Considering the latest advances from multiple domains including computer vision, machine learning and knowledge engineering, this paper points out some promising research directions towards RS big data mining. From this survey, engineers from industry may find skills to improve their RS image retrieval systems and researchers from academia may find ideas to conduct some innovative work. © 2020 Elsevier B.V.","Evaluation datasets and performance discussion; Future research directions; Remote sensing (rs) big data; Rs image retrieval applications; Rs image retrieval methods"
"Network traffic classification for data fusion: A survey","2021","Information Fusion","10.1016/j.inffus.2021.02.009","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101336057&doi=10.1016%2fj.inffus.2021.02.009&partnerID=40&md5=9949ec6bd1f6d64f19db42507d2285f5","Traffic classification groups similar or related traffic data, which is one main stream technique of data fusion in the field of network management and security. With the rapid growth of network users and the emergence of new networking services, network traffic classification has attracted increasing attention. Many new traffic classification techniques have been developed and widely applied. However, the existing literature lacks a thorough survey to summarize, compare and analyze the recent advances of network traffic classification in order to deliver a holistic perspective. This paper carefully reviews existing network traffic classification methods from a new and comprehensive perspective by classifying them into five categories based on representative classification features, i.e., statistics-based classification, correlation-based classification, behavior-based classification, payload-based classification, and port-based classification. A series of criteria are proposed for the purpose of evaluating the performance of existing traffic classification methods. For each specified category, we analyze and discuss the details, advantages and disadvantages of its existing methods, and also present the traffic features commonly used. Summaries of investigation are offered for providing a holistic and specialized view on the state-of-art. For convenience, we also cover a discussion on the mostly used datasets and the traffic features adopted for traffic classification in the review. At the end, we identify a list of open issues and future directions in this research field. © 2021 The Authors","Data fusion; Machine learning; Security management; Traffic classification"
"Advances in multimodal data fusion in neuroimaging: Overview, challenges, and novel orientation","2020","Information Fusion","10.1016/j.inffus.2020.07.006","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088387712&doi=10.1016%2fj.inffus.2020.07.006&partnerID=40&md5=b864e150bd3158d174907797d29cb100","Multimodal fusion in neuroimaging combines data from multiple imaging modalities to overcome the fundamental limitations of individual modalities. Neuroimaging fusion can achieve higher temporal and spatial resolution, enhance contrast, correct imaging distortions, and bridge physiological and cognitive information. In this study, we analyzed over 450 references from PubMed, Google Scholar, IEEE, ScienceDirect, Web of Science, and various sources published from 1978 to 2020. We provide a review that encompasses (1) an overview of current challenges in multimodal fusion (2) the current medical applications of fusion for specific neurological diseases, (3) strengths and limitations of available imaging modalities, (4) fundamental fusion rules, (5) fusion quality assessment methods, and (6) the applications of fusion for atlas-based segmentation and quantification. Overall, multimodal fusion shows significant benefits in clinical diagnosis and neuroscience research. Widespread education and further research amongst engineers, researchers and clinicians will benefit the field of multimodal neuroimaging. © 2020 Elsevier B.V.","Applications; Assessment; Fusion rules; Magnetic resonance imaging; Multimodal data fusion; Neuroimaging; Partial volume effect; PET; SPECT"
"Efficient and accurate structural fusion of Bayesian networks","2021","Information Fusion","10.1016/j.inffus.2020.09.003","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091025373&doi=10.1016%2fj.inffus.2020.09.003&partnerID=40&md5=476d3d0d9d9a5fbe6099edd4805bdb1e","Bayesian Network (BN) fusion provides a precise theoretical framework for aggregating the graphical structure of a set of BNs into a consensus network. The fusion process depends on a total ordering of the variables, but both the problem of searching for an optimal consensus structure (according to the standard problem definition) as well as the one of looking for the optimal ordering are NP-hard. In this paper we start with this theoretical framework and extend it from a practical point of view. The two main methodological contributions we make are: (1) an adaptation of the well-known BN learning algorithm GES (Greedy Equivalence Search) to the case of having a set of BNs as input instead of data (we prove the correctness of the adapted algorithm, i.e., under certain standard assumptions the optimal solution for the BN fusion process is obtained); and (2) a heuristic method for identifying a suitable order of the variables, which allows us to obtain consensus BNs having (far) fewer edges than those obtained by using random orderings. Finally, we design several computational experiments to test our proposals. From the results, we can conclude that the consensus network can be efficiently obtained by using the proposed heuristic to compute the total order of the variables, with this DAG being very close to the optimal one. © 2020","Aggregation; Bayesian networks; Consensus; Fusion; Heuristic orders"
"Multilevel projections with adaptive neighbor graph for unsupervised multi-view feature selection","2021","Information Fusion","10.1016/j.inffus.2020.12.007","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099791380&doi=10.1016%2fj.inffus.2020.12.007&partnerID=40&md5=7f953f9cc05e4025be5c6081aef29143","Multi-view feature selection aims at obtaining a subset of informative features from heterogeneous feature domains. Recent graph based approaches mostly learn view-specific feature selection matrices by virtue of prepared single-view graphs, and weight the view-wise objectives to discriminate them. However, the majority of them encounter that (i) the dimensions of vectors for evaluating features in different views are inconsistent and (ii) the similarities attained by using features in the original high-dimensional space are inferior. As a result, the joint evaluation of heterogeneous features using view-specific selection matrices are inaccurate and immensely depend on ill-defined similarity relations. To overcome them, we propose the Multilevel projections with Adaptive neighbor graph model for unsupervised Multi-view Feature Selection (MAMFS). Our formulation learns the collaborative graph adapting to the adaptive k-nearest neighbors in subspaces, wherein the multilevel projections are involved including the weighted view-specific projections that discriminate different views and the joint projection that collaborates different views. Benefited from this, both of view-within information and the view-across information are jointly explored and made use of. Extensive simulations are conducted to validate the superiority of the proposed method compared to the state-of-the-art competitors. © 2020","Adaptive neighbor graph; Joint heterogeneous evaluation; Multilevel projections; Unsupervised multi-view feature selection"
"A practical tutorial on bagging and boosting based ensembles for machine learning: Algorithms, software tools, performance study, practical perspectives and opportunities","2020","Information Fusion","10.1016/j.inffus.2020.07.007","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089214531&doi=10.1016%2fj.inffus.2020.07.007&partnerID=40&md5=cdd28de7fbcae92a8fe92f224df8926d","Ensembles, especially ensembles of decision trees, are one of the most popular and successful techniques in machine learning. Recently, the number of ensemble-based proposals has grown steadily. Therefore, it is necessary to identify which are the appropriate algorithms for a certain problem. In this paper, we aim to help practitioners to choose the best ensemble technique according to their problem characteristics and their workflow. To do so, we revise the most renowned bagging and boosting algorithms and their software tools. These ensembles are described in detail within their variants and improvements available in the literature. Their online-available software tools are reviewed attending to the implemented versions and features. They are categorized according to their supported programming languages and computing paradigms. The performance of 14 different bagging and boosting based ensembles, including XGBoost, LightGBM and Random Forest, is empirically analyzed in terms of predictive capability and efficiency. This comparison is done under the same software environment with 76 different classification tasks. Their predictive capabilities are evaluated with a wide variety of scenarios, such as standard multi-class problems, scenarios with categorical features and big size data. The efficiency of these methods is analyzed with considerably large data-sets. Several practical perspectives and opportunities are also exposed for ensemble learning. © 2020 Elsevier B.V.","Classification; Decision trees; Ensemble learning; Machine learning; Software"
"Heterogeneous data fusion for predicting mild cognitive impairment conversion","2021","Information Fusion","10.1016/j.inffus.2020.08.023","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090351234&doi=10.1016%2fj.inffus.2020.08.023&partnerID=40&md5=06fae5acd302f2e6a55203c598b70d9c","In the clinical study of Alzheimer's Disease (AD) with neuroimaging data, it is challenging to identify the progressive Mild Cognitive Impairment (pMCI) subjects from the stableMCI (sMCI) subjects (i.e., the pMCI/sMCI classification) in an individual level because of small inter-group differences between two groups (i.e., pMCIs and sMCIs) as well as high intra-group variations within each group. Moreover, there are a very limited number of subjects available, which cannot guarantee to find informative and discriminative patterns for achieving high diagnostic accuracy. In this paper, we propose a novel sparse regression method to fuse the auxiliary data into the predictor data for the pMCI/sMCI classification, where the predictor data is structural Magnetic Resonance Imaging (MRI) information of both pMCI and sMCI subjects and the auxiliary data includes the ages of the subjects, the Positron Emission Tomography (PET) information of the predictor data, and the structural MRI information of AD and Normal Controls (NC). Specifically, we incorporate the auxiliary data and the predictor data into a unified framework to jointly achieve the following objectives: i) jointly selecting informative features from both the auxiliary data and the predictor data; ii) robust to outliers from both the auxiliary data and the predictor data; and iii) reducing the aging effect due to the possible cause of brain atrophy induced by both the normal aging and the disease progression. As a result, our proposed method jointly selects the useful features from the auxiliary data and the predictor data by taking into account the influence of outliers and the age of the two kinds of data, i.e., the pMCI and sMCI subjects as well as the AD and NC subjects. We further employ the linear Support Vector Machine (SVM) with the selected features of the predictor data to conduct the pMCI/sMCI classification. Experimental results on the public data of Alzheimer's Disease Neuroimaging Initiative (ADNI) show the proposed method achieved the best classification performance, compared to the best comparison method, in terms of four evaluation metrics. © 2020 Elsevier B.V.","Alzheimer's disease; Feature selection; Mild cognitive impairment; Sparse learning; Transfer learning"
"Foundations of Multimodal Co-learning: Multimodal Co-learning","2020","Information Fusion","10.1016/j.inffus.2020.06.001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088917657&doi=10.1016%2fj.inffus.2020.06.001&partnerID=40&md5=5c80ad10c779570881ceda8f795be97d","In the current state of the field of machine learning, often, real-world phenomena are learned through studies of isolated modalities; such as modeling language exclusively from verbal modality, which is a common theme in natural language processing. This is widely adopted since downstream tasksin different disciplines of machine learning are also often similarly isolated and unimodal. In sharp contrast to this, human learning from real-world experiences is rarely unimodal, and often exhibits a multisensory nature, regardless of any assumptions about downstream tasks. The cognitive constructs in human brain are consistently developed through multisensory reinforcement, and the same constructs generalize to unimodal scenarios. The difference between the trend of unimodal learning and human cognitive development raises the following question: “Even if downstream tasks are unimodal during test time, is it better to learn from the isolated modality or from multimodal information?”. In this paper we focus on an in-depth study of this research question. We study the differences between unimodal learning and Multimodal Co-learning (MCl), both from empirical and theoretical standpoints. Through the lens of information entropy and characteristics of deep neural networks, we demonstrate strong theoretical justifications in favor of MCl. © 2020","Co-learning; Multimodal learning; Multimodal machine learning"
"Memory based fusion for multi-modal deep learning","2021","Information Fusion","10.1016/j.inffus.2020.10.005","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85094167170&doi=10.1016%2fj.inffus.2020.10.005&partnerID=40&md5=9ecee9df7af3642727a459e2fe640395","The use of multi-modal data for deep machine learning has shown promise when compared to uni-modal approaches with fusion of multi-modal features resulting in improved performance in several applications. However, most state-of-the-art methods use naive fusion which processes feature streams independently, ignoring possible long-term dependencies within the data during fusion. In this paper, we present a novel Memory based Attentive Fusion layer, which fuses modes by incorporating both the current features and long-term dependencies in the data, thus allowing the model to understand the relative importance of modes over time. We introduce an explicit memory block within the fusion layer which stores features containing long-term dependencies of the fused data. The feature inputs from uni-modal encoders are fused through attentive composition and transformation followed by naive fusion of the resultant memory derived features with layer inputs. Following state-of-the-art methods, we have evaluated the performance and the generalizability of the proposed fusion approach on two different datasets with different modalities. In our experiments, we replace the naive fusion layer in benchmark networks with our proposed layer to enable a fair comparison. Experimental results indicate that the MBAF layer can generalize across different modalities and networks to enhance fusion and improve performance. © 2020 Elsevier B.V.","Attention; Generalized multi-modal fusion; Memory networks"
"Fairness concern: An equilibrium mechanism for consensus-reaching game in group decision-making","2021","Information Fusion","10.1016/j.inffus.2021.02.024","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102297896&doi=10.1016%2fj.inffus.2021.02.024&partnerID=40&md5=9797827e9f75d5b7393280f089ae4111","For many group decision-making (GDM) issues, such as water-resource allocation, urban resettlement, and traffic-route planning, the benefits of the decision makers (DMs) are closely related to the collective decision-making result. In fact, the consensus-reaching process is a game between the decision makers and the moderator. The fairness concern in GDM impacts DMs’ preference modification and influences consensus achievement, but it has long been ignored because most studies have focused on the consensus mechanism or cost. We introduced the fairness concern into the consensus-reaching process in GDM and established an equilibrium mechanism for GDM. Specifically, we proposed a general consensus game that considers the decision fairness concern. Then, we proved the existence of the Nash Equilibrium between the decision makers and the moderator and established a consensus model with a minimum compensation cost. A simulated annealing algorithm was designed to solve for an equilibrium solution. Through numerical examples used in previous studies and an application example of green supply chain management, we analyzed the relationship between fairness concern, the degree of coordination, and effectiveness in GDM and demonstrated the impact of the fairness concern on consensus achievement. © 2021 Elsevier B.V.","Consensus-reaching game; Degree of coordination; Equilibrium mechanism; Fairness concern; Group decision-making and negotiation"
"Multiple graph kernel learning based on GMDH-type neural network","2021","Information Fusion","10.1016/j.inffus.2020.08.025","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090860302&doi=10.1016%2fj.inffus.2020.08.025&partnerID=40&md5=b4b249b209d49fd8c0ce57e2e58327a0","Multiple kernel learning (MKL), as a principled classification method, selects and combines base kernels to increase the categorization accuracy of Support Vector Machines (SVMs). The group method of data handling neural network (GMDH-NN) has been applied in many fields of optimization, data mining, and pattern recognition. It can automatically seek interrelatedness in data, select an optimal structure for the model or network, and enhance the accuracy of existing algorithms. We can utilize the advantages of the GMDH-NN to build a multiple graph kernel learning (MGKL) method and enhance the categorization performance of graph kernel SVMs. In this paper, we first define a unitized symmetric regularity criterion (USRC) to improve the symmetric regularity criterion of GMDH-NN. Second, a novel structure for the initial model of the GMDH-NN is defined, which uses the posterior probability output of graph kernel SVMs. We then use a hybrid graph kernel in the H1-space for MGKL in combination with the GMDH-NN. This way, we can obtain a pool of optimal graph kernels with different kernel parameters. Our experiments on standard graph datasets show that this new MGKL method is highly effective. © 2020","Ensemble selection; Group method of data handling; Probabilistic output; Regularity criterion; Support vector machine"
"Sample greedy gossip distributed Kalman filter","2020","Information Fusion","10.1016/j.inffus.2020.08.001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089413690&doi=10.1016%2fj.inffus.2020.08.001&partnerID=40&md5=904708acf56c029f677d139e5b67f119","This paper investigates the problem of distributed state estimation over a low-cost sensor network and proposes a new sample greedy gossip distributed Kalman filter. The proposed algorithm leverages the information weighted fusion concept and the sample greedy gossip averaging protocol. By introducing a stochastic sampling strategy in the greedy sensor node selection process, the proposed algorithm finds a suboptimal communication path for each local sensor node during the process of information exchange. Theoretical analysis on global convergence and uniform boundedness is also performed to investigate the characteristics of the proposed distributed Kalman filter. The main advantage of the proposed algorithm is that it provides well trade-off between communication burden and estimation performance. Extensive empirical numerical simulations are carried out to demonstrate the effectiveness of the proposed algorithm. © 2020 The Authors","Distributed estimation; Gossip process; Information weighted fusion; Kalman filter; Sample greedy"
"Distance metric learning for augmenting the method of nearest neighbors for ordinal classification with absolute and relative information","2021","Information Fusion","10.1016/j.inffus.2020.08.004","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089663687&doi=10.1016%2fj.inffus.2020.08.004&partnerID=40&md5=c270744ebb023de8ed8e33795f660470","The performance of a classifier is often limited by the amount of labeled data (absolute information) available. In order to overcome this limitation, the incorporation of side information into the classification process has become a popular research topic in the field of machine learning. In this work, we propose a new method for ordinal classification that combines absolute information and a specific type of side information: relative information. In particular, this method exploits both types of information to learn an appropriate distance metric and subsequently incorporates the learned distance metric into the classical method of k nearest neighbors. The experimental results show that the proposed method attains a good performance in terms of some of the most popular (ordinal) classification performance measures. © 2020 Elsevier B.V.","Absolute information; Distance metric learning; k nearest neighbors; Ordinal classification; Relative information"
"KM4: Visual reasoning via Knowledge Embedding Memory Model with Mutual Modulation","2021","Information Fusion","10.1016/j.inffus.2020.10.007","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092745169&doi=10.1016%2fj.inffus.2020.10.007&partnerID=40&md5=fa4153a6694d6e1c2a6e9a44a75ed731","Visual reasoning is a special kind of visual question answering, which is essentially multi-step and compositional, and also requires intensive text-visual interaction. The most important and challenging problem of visual reasoning is to design an effective and robust visual reasoning model. To this end, there are two challenges to overcome. The first is that textual and visual information must be jointly considered to make accurate inferences about reasoning. The second is that existing deep learning-based works are often too specific to a particular task. To address these issues, we propose a knowledge memory embedding model with mutual modulation for visual reasoning. This approach learns not only knowledge-based embeddings derived from key–value memory network to make the full and joint of textual and visual information, but also exploits the prior knowledge to improve the performance with knowledge-based representation learning for applying other general reasoning tasks. Experimental results on four benchmarks show that the proposed approach significantly improves performance compared with other state-of-the-art methods, guarantees the robustness with our model. Most importantly, we apply our model to four reasoning tasks, and experimentally show that our model effectively supports relational reasoning and improves performance in several tasks and datasets. © 2020 Elsevier B.V.","Knowledge embedding; Knowledge-based representation learning; Memory network; Visual reasoning"
"Distributed combination of belief functions","2021","Information Fusion","10.1016/j.inffus.2020.09.001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091226248&doi=10.1016%2fj.inffus.2020.09.001&partnerID=40&md5=ee4c5f428ebd474cbf1c7fcd5ad9d813","We consider the problem of combining belief functions in a situation where pieces of evidence are held by agents at the node of a communication network, and each agent can only exchange information with its neighbors. Using the concept of weight of evidence, we propose distributed implementations of Dempster's rule and the cautious rule based, respectively, on average and maximum consensus algorithms. We also describe distributed procedures whereby the agents can agree on a frame of discernment and a list of supported hypotheses, thus reducing the amount of data to be exchanged in the network. Finally, we show the feasibility of a robust combination procedure based on a distributed implementation of the random sample consensus (RANSAC) algorithm. © 2020 Elsevier B.V.","Consensus; Dempster–Shafer theory; Evidence theory; Information fusion; Uncertain reasoning"
"Minimum cost consensus modelling under various linear uncertain-constrained scenarios","2021","Information Fusion","10.1016/j.inffus.2020.08.015","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089689852&doi=10.1016%2fj.inffus.2020.08.015&partnerID=40&md5=177c16347f51c819ed84e008eeea8f06","Group decision-making combined with uncertainty theory is verified as a more conclusive theory, by building a bridge between deterministic and indeterministic group decision-making in this paper. Due to the absence of sufficient historical data, reliability of decisions are mainly determined by experts rather than some prior probability distributions, easily leading to the problem of subjectivity. Thus, belief degree and uncertainty distribution are used in this paper to fit individual preferences, and five scenarios of uncertain chance-constrained minimum cost consensus models are further discussed from the perspectives of the moderator, individual decision-makers and non-cooperators. Through deduction, reaching conditions for consensus and analytic formulas of the minimum total cost are both theoretically given. Finally, with the application in carbon quota negotiation, the proposed models are demonstrated as a further extension of the crisp number or interval preference-based minimum cost consensus models. In other words, the basic conclusions of the traditional models are some special cases of the uncertain minimum cost consensus models under different belief degrees. © 2020 Elsevier B.V.","Belief degree; Group decision-making; Linear uncertainty distribution; Minimum cost consensus model (MCCM); Uncertainty theory"
"On learning effective ensembles of deep neural networks for intrusion detection","2021","Information Fusion","10.1016/j.inffus.2021.02.007","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101425216&doi=10.1016%2fj.inffus.2021.02.007&partnerID=40&md5=d5aa1b96cff318d1800b41ddd4787da9","Classification-oriented Machine Learning methods are a precious tool, in modern Intrusion Detection Systems (IDSs), for discriminating between suspected intrusion attacks and normal behaviors. Many recent proposals in this field leveraged Deep Neural Network (DNN) methods, capable of learning effective hierarchical data representations automatically. However, many of these solutions were validated on data featuring stationary distributions and/or large amounts of training examples. By contrast, in real IDS applications different kinds of attack tend to occur over time, and only a small fraction of the data instances is labeled (usually with far fewer examples of attacks than of normal behavior). A novel ensemble-based Deep Learning framework is proposed here that tries to face the challenging issues above. Basically, the non-stationary nature of IDS log data is faced by maintaining an ensemble consisting of a number of specialized base DNN classifiers, trained on disjoint chunks of the data instances’ stream, plus a combiner model (reasoning on both the base classifiers predictions and original instance features). In order to learn deep base classifiers effectively from small training samples, an ad-hoc shared DNN architecture is adopted, featuring a combination of dropout capabilities, skip-connections, along with a cost-sensitive loss (for dealing with unbalanced data). Tests results, conducted on two benchmark IDS datasets and involving several competitors, confirmed the effectiveness of our proposal (in terms of both classification accuracy and robustness to data scarcity), and allowed us to evaluate different ensemble combination schemes. © 2021 Elsevier B.V.","Deep learning; Ensemble learning; Intrusion Detection Systems"
"COVID-19 classification by CCSHNet with deep fusion using transfer learning and discriminant correlation analysis","2021","Information Fusion","10.1016/j.inffus.2020.11.005","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096646182&doi=10.1016%2fj.inffus.2020.11.005&partnerID=40&md5=96557b7796a2032fbd598f6af73efe25","Aim:: COVID-19 is a disease caused by a new strain of coronavirus. Up to 18th October 2020, worldwide there have been 39.6 million confirmed cases resulting in more than 1.1 million deaths. To improve diagnosis, we aimed to design and develop a novel advanced AI system for COVID-19 classification based on chest CT (CCT) images. Methods:: Our dataset from local hospitals consisted of 284 COVID-19 images, 281 community-acquired pneumonia images, 293 secondary pulmonary tuberculosis images; and 306 healthy control images. We first used pretrained models (PTMs) to learn features, and proposed a novel (L, 2) transfer feature learning algorithm to extract features, with a hyperparameter of number of layers to be removed (NLR, symbolized as L). Second, we proposed a selection algorithm of pretrained network for fusion to determine the best two models characterized by PTM and NLR. Third, deep CCT fusion by discriminant correlation analysis was proposed to help fuse the two features from the two models. Micro-averaged (MA) F1 score was used as the measuring indicator. The final determined model was named CCSHNet. Results:: On the test set, CCSHNet achieved sensitivities of four classes of 95.61%, 96.25%, 98.30%, and 97.86%, respectively. The precision values of four classes were 97.32%, 96.42%, 96.99%, and 97.38%, respectively. The F1 scores of four classes were 96.46%, 96.33%, 97.64%, and 97.62%, respectively. The MA F1 score was 97.04%. In addition, CCSHNet outperformed 12 state-of-the-art COVID-19 detection methods. Conclusions:: CCSHNet is effective in detecting COVID-19 and other lung infectious diseases using first-line clinical imaging and can therefore assist radiologists in making accurate diagnoses based on CCTs. © 2020 Elsevier Ltd","Chest CT; COVID-19; Deep fusion; Discriminant correlation analysis; Micro-averaged F1; pretrained model; transfer learning"
"Optimizing consensus reaching in the hybrid opinion dynamics in a social network•","2021","Information Fusion","10.1016/j.inffus.2021.02.018","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101878316&doi=10.1016%2fj.inffus.2021.02.018&partnerID=40&md5=1a93f0cc6770724dbcdc5763434cba35","Hybrid opinion dynamics which involves two types of individuals (i.e., leaders and followers) communicate in real time and share opinions and knowledge have been widely used in diverse applications. In real applications of hybrid opinion dynamics, one of the main demands is how to manage a consensus among individuals. This paper aims at proposing a novel consensus reaching strategy for the hybrid opinion dynamics in a social network. Firstly, we give the network partition algorithm to divide the social network into sub-network, and introduce Floyd algorithm to calculate the shortest path between any two individuals, which can provide the assistance for determining the weights among individuals. On this basis, we present the hybrid opinion dynamics model. Next, we develop the consensus reaching model with minimum adjustments (i.e. CRMD model) in hybrid opinion dynamics, and discuss some the properties of the CRMD model. Furthermore, the detailed numerical and simulation analysis are conducted to illustrate the effectiveness of this CRMD model. The simulation results show the CRMD model has the distinct advantages over other consensus strategies. Thus, the CRMD model is helpful to manage and control the public opinions for the government and enterprise. © 2021","Consensus reaching; Hybrid opinion dynamics; Minimum adjustment; Social network"
"Multi-body sensor data fusion to evaluate the hippotherapy for motor ability improvement in children with cerebral palsy","2021","Information Fusion","10.1016/j.inffus.2021.01.002","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099510004&doi=10.1016%2fj.inffus.2021.01.002&partnerID=40&md5=0023c9bdd225e07809ff65723cd210bf","Hippotherapy is a new rehabilitation therapy for children with cerebral palsy (CP). Although it has been proved to be effective in clinical research, a quantitative evaluation of such results is still lacking in previous studies. In this research, one method for evaluating the effectiveness of hippotherapy based on body sensor network (BSN) is proposed. The method adopts distributed magnetic, angular rate, and gravity (MARG) sensors to evaluate the gross motor function of CP children by multi-sensor data fusion algorithm, the comparison results with the golden standard optical capture system demonstrate the robustness of sensor fusion algorithm. Moreover, via tracking one-year's hippotherapy projects, a pilot study was conducted for measuring and evaluating the motor coordination function and gait parameters of CP children. Finally, the rehabilitation of gross motor function for the chosen subjects under different treatment periods was evaluated through kinematic analysis. The results of our method show that some children's symptoms, such as limb stiffness, poor joint range of motion, scissors gait, knee flexion gait, have been relieved. Thus, it provides an empirical basis for hippotherapy in the rehabilitation of motor function corresponding to CP children. © 2021 Elsevier B.V.","Body sensor network; Cerebral palsy; Hippotherapy; Rehabilitation medicine; Sensor fusion"
"Quantum-inspired multimodal fusion for video sentiment analysis","2021","Information Fusion","10.1016/j.inffus.2020.08.006","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089582013&doi=10.1016%2fj.inffus.2020.08.006&partnerID=40&md5=91ffc73756de2632e6069039c6b239d7","We tackle the crucial challenge of fusing different modalities of features for multimodal sentiment analysis. Mainly based on neural networks, existing approaches largely model multimodal interactions in an implicit and hard-to-understand manner. We address this limitation with inspirations from quantum theory, which contains principled methods for modeling complicated interactions and correlations. In our quantum-inspired framework, the word interaction within a single modality and the interaction across modalities are formulated with superposition and entanglement respectively at different stages. The complex-valued neural network implementation of the framework achieves comparable results to state-of-the-art systems on two benchmarking video sentiment analysis datasets. In the meantime, we produce the unimodal and bimodal sentiment directly from the model to interpret the entangled decision. © 2020 Elsevier B.V.","Machine learning; Multimodal sentiment analysis; Quantum theory"
"Survey and challenges of story generation models - A multimodal perspective with five steps: Data embedding, topic modeling, storyline generation, draft story generation, and story evaluation","2021","Information Fusion","10.1016/j.inffus.2020.10.009","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092893809&doi=10.1016%2fj.inffus.2020.10.009&partnerID=40&md5=9d42580e78c148b6dcd29524502f534f","The story is the description of events in chronological order that have occurred between people. By delivering facts to the people reading the story, it enables them to feel emotions. Such a story is composed using the following method: each event is analyzed and a storyline is composed, which becomes a skeleton text by linking relationships between major events. As the content of users becomes more diverse, multimodal story composition has become more essential than unimodal text-based story composition. This paper discusses modality integration based on multimodal data types and type conversion for multimodal story composition. We propose a story-graph model to create a story based on the integrated analysis of various modal data. In terms of architecture, the proposed multimodal storytelling model consists of modal data and a topic modeling module that performs clustering based on cross-modal similarities and extracts a topic of clustered modalities. From the perspective of utilization, to visualize a story-graph, the proposed model summarizes nodes with a representative image. Furthermore, the latest techniques are discussed with respect to five main modules and twelve sub-modules for story composition. Lastly, problems that can become issues when composing multimodal story modules are explained. © 2020 Elsevier B.V.","Multimodal content; Multimodal story; Multimodal storytelling; Story generation"
"DEAR-MULSEMEDIA: Dataset for emotion analysis and recognition in response to multiple sensorial media","2021","Information Fusion","10.1016/j.inffus.2020.08.007","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089413048&doi=10.1016%2fj.inffus.2020.08.007&partnerID=40&md5=f99375ec6ae91fc44aaf6110b2af247a","Traditionally, emotion recognition is performed in response to stimuli that engage either one (vision: image or hearing: audio) or two (vision and hearing: video) human senses. An immersive environment can be generated by engaging more than two human senses while interacting with multimedia content and is known as MULtiple SEnsorial media (mulsemedia). This study aims to create a new dataset of multimodal physiological signals to recognize emotions in response to such content. To this end, four multimedia clips are selected and synchronized with fan, heater, olfaction dispenser, and haptic vest to augment cold air, hot air, olfaction, and haptic effects respectively. Furthermore, physiological responses including electroencephalography (EEG), galvanic skin response (GSR), and photoplethysmography (PPG) are observed to analyze human emotional responses while experiencing mulsemedia content. A t-test applied using arousal and valence scores show that engaging more than two human senses evokes significantly different emotions. Statistical tests on EEG, GSR, and PPG responses also show a significant difference between multimedia and mulsemedia content. Classification accuracy of 85.18% and 76.54% is achieved for valence and arousal, respectively, using K-nearest neighbor classifier and feature-level fusion strategy. © 2020 Elsevier B.V.","Classification; Emotion recognition; Modality Level Fusion; Multiple sensorial media; Physiological signals"
"COVID-19 and Non-COVID-19 Classification using Multi-layers Fusion From Lung Ultrasound Images","2021","Information Fusion","10.1016/j.inffus.2021.02.013","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101603399&doi=10.1016%2fj.inffus.2021.02.013&partnerID=40&md5=1a5d0d69a066e7952dc8ba79667a71c3","COVID-19 or related viral pandemics should be detected and managed without hesitation, since the virus spreads very rapidly. Often with insufficient human and electronic resources, patients need to be checked from stable patients using vital signs, radiographic photographs, or ultrasound images. Vital signs do not often offer the right outcome, and radiographic photos have a variety of other problems. Lung ultrasound (LUS) images can provide good screening without a lot of complications. This paper suggests a model of a convolutionary neural network (CNN) that has fewer learning parameters but can achieve strong accuracy. The model has five main blocks or layers of convolution connectors. A multi-layer fusion functionality of each block is proposed to improve the efficiency of the COVID-19 screening method utilizing the proposed model. Experiments are conducted using freely accessible LUS photographs and video datasets. The proposed fusion method has 92.5% precision, 91.8% accuracy, and 93.2% retrieval using the data collection. These efficiency metric levels are considerably higher than those used in any of the state-of-the-art CNN versions. © 2021 Elsevier B.V.",""
"Variational multimodal machine translation with underlying semantic alignment","2021","Information Fusion","10.1016/j.inffus.2020.11.011","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097574584&doi=10.1016%2fj.inffus.2020.11.011&partnerID=40&md5=825597d5a0b1ed20cb2c9111e82198ee","Capturing the underlying semantic relationships of sentences is helpful for machine translation. Variational neural machine translation approaches provide an effective way to model the uncertain underlying semantics in languages by introducing latent variables. Multitask learning is applied in multimodal machine translation to integrate multimodal data. However, these approaches usually lack a strong interpretation in utilizing out-of-text information in machine translation tasks. In this paper, we propose a novel architecture-free multimodal translation model, called variational multimodal machine translation (VMMT), under the variational framework which can model the uncertainty in languages caused by ambiguity through utilizing visual and textual information. In addition, the proposed model can eliminate the discrepancy between training and prediction in the existing variational translation models by constructing encoders only relying on source data. More importantly, the proposed multimodal translation model is designed as multitask learning in which the shared semantic representation for different modes is learned and the gap among semantic representation from various modes is reduced by incorporating additional constraints. Moreover, the information bottleneck theory is adopted in our variational encoder–decoder model, which helps the encoder to filter redundancy and the decoder to concentrate on useful information. Experiments on multimodal machine translation demonstrate that the proposed model is competitive. © 2020 Elsevier B.V.","Machine translation; Multimodal learning; Variational neural machine translation"
"Enhancing the security of blockchain-based software defined networking through trust-based traffic fusion and filtration","2021","Information Fusion","10.1016/j.inffus.2020.12.006","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099030634&doi=10.1016%2fj.inffus.2020.12.006&partnerID=40&md5=abf408f6ff572099892422514b0beaac","With the rapid development of Internet-of-Things (IoT), more smart devices can be connected to the Internet, resulting in a dramatic increase of data transmission and communication. Software-Defined Networking (SDN), which separates the control planes and data planes, is considered as a promising solution to provide the scale and versatility necessary for IoT. However, SDN still suffers from several challenges, i.e., the centralized control plane would be a single point of failure. With the wide adoption of blockchain applications, such technologies can have a positive impact on SDN's performance, i.e., blockchains allow non-confident individuals to interact with each other without the need for a central authority. However, attackers can still inject traffic to influence blockchain nodes from normal operations. Motivated by the recent development of blockchains and SDN, in this work, we focus on blockchain-based SDN and develop BSDNFilter, an IDS-based security mechanism that builds a trust-based filtration by using traffic fusion and aggregation to handle and reduce malicious traffic. Through collaborating with an IT organization, our evaluation in a real blockchain-based SDN environment demonstrates that our BSDNFilter is able to achieve better filtration performance against flooding attacks than similar approaches. © 2020 Elsevier B.V.","Blockchain technology; Intrusion detection; Software-Defined Networking; Traffic filtration; Traffic fusion; Trust computation"
"Deepfakes and beyond: A Survey of face manipulation and fake detection","2020","Information Fusion","10.1016/j.inffus.2020.06.014","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088147708&doi=10.1016%2fj.inffus.2020.06.014&partnerID=40&md5=270b72c43bff3924e5ab268f63d087b5","The free access to large-scale public databases, together with the fast progress of deep learning techniques, in particular Generative Adversarial Networks, have led to the generation of very realistic fake content with its corresponding implications towards society in this era of fake news. This survey provides a thorough review of techniques for manipulating face images including DeepFake methods, and methods to detect such manipulations. In particular, four types of facial manipulation are reviewed: i) entire face synthesis, ii) identity swap (DeepFakes), iii) attribute manipulation, and iv) expression swap. For each manipulation group, we provide details regarding manipulation techniques, existing public databases, and key benchmarks for technology evaluation of fake detection methods, including a summary of results from those evaluations. Among all the aspects discussed in the survey, we pay special attention to the latest generation of DeepFakes, highlighting its improvements and challenges for fake detection. In addition to the survey information, we also discuss open issues and future trends that should be considered to advance in the field. © 2020 Elsevier B.V.","Benchmark; Databases; Deepfakes; Face manipulation; Face recognition; Fake news; Media forensics"
"Covid-19 classification by FGCNet with deep feature fusion from graph convolutional network and convolutional neural network","2021","Information Fusion","10.1016/j.inffus.2020.10.004","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85094901078&doi=10.1016%2fj.inffus.2020.10.004&partnerID=40&md5=cea54d3aa79215fcae1f7c6371ef3f07","(Aim) COVID-19 is an infectious disease spreading to the world this year. In this study, we plan to develop an artificial intelligence based tool to diagnose on chest CT images. (Method) On one hand, we extract features from a self-created convolutional neural network (CNN) to learn individual image-level representations. The proposed CNN employed several new techniques such as rank-based average pooling and multiple-way data augmentation. On the other hand, relation-aware representations were learnt from graph convolutional network (GCN). Deep feature fusion (DFF) was developed in this work to fuse individual image-level features and relation-aware features from both GCN and CNN, respectively. The best model was named as FGCNet. (Results) The experiment first chose the best model from eight proposed network models, and then compared it with 15 state-of-the-art approaches. (Conclusion) The proposed FGCNet model is effective and gives better performance than all 15 state-of-the-art methods. Thus, our proposed FGCNet model can assist radiologists to rapidly detect COVID-19 from chest CT images. © 2020 Elsevier B.V.","Batch normalization; Convolutional neural network; Deep feature fusion; Dropout; Graph convolutional network; Multiple-way data augmentation; Rank-based average pooling"
"Adaptive ensemble of classifiers with regularization for imbalanced data classification","2021","Information Fusion","10.1016/j.inffus.2020.10.017","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097716877&doi=10.1016%2fj.inffus.2020.10.017&partnerID=40&md5=8368f664e50fcc72d68a906712b3a925","The dynamic ensemble selection of classifiers is an effective approach for processing label-imbalanced data classifications. However, such a technique is prone to overfitting, owing to the lack of regularization methods and the dependence on local geometry of data. In this study, focusing on binary imbalanced data classification, a novel dynamic ensemble method, namely adaptive ensemble of classifiers with regularization (AER), is proposed, to overcome the stated limitations. The method solves the overfitting problem through a new perspective of implicit regularization. Specifically, it leverages the properties of stochastic gradient descent to obtain the solution with the minimum norm, thereby achieving regularization; furthermore, it interpolates the ensemble weights by exploiting the global geometry of data to further prevent overfitting. According to our theoretical proofs, the seemingly complicated AER paradigm, in addition to its regularization capabilities, can actually reduce the asymptotic time and memory complexities of several other algorithms. We evaluate the proposed AER method on seven benchmark imbalanced datasets from the UCI machine learning repository and one artificially generated GMM-based dataset with five variations. The results show that the proposed algorithm outperforms the major existing algorithms based on multiple metrics in most cases, and two hypothesis tests (McNemar's and Wilcoxon tests) verify the statistical significance further. In addition, the proposed method has other preferred properties such as special advantages in dealing with highly imbalanced data, and it pioneers the researches on regularization for dynamic ensemble methods. © 2020","Adaptive ensemble; Gradient boosting machines; Imbalanced data classification; Regularization"
"Unscented kalman filter with process noise covariance estimation for vehicular ins/gps integration system","2020","Information Fusion","10.1016/j.inffus.2020.08.005","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089236990&doi=10.1016%2fj.inffus.2020.08.005&partnerID=40&md5=d9a7388324ed98cac526044bd71122ba","The unscented Kalman filter (UKF) has proved to be a promising methodology to integrate INS and GPS for vehicular navigation. Nevertheless, the disturbance suppression of system noise uncertainty on the UKF performance is still an open issue. In this paper, based on the maximum likelihood (ML) principle, a new adaptive UKF with process noise covariance estimation is proposed to enhance the UKF robustness against process noise uncertainty for vehicular INS/GPS integration. The proposed method extends the concept of ML estimation from the linear Kalman filter to the nonlinear UKF to estimate the process noise covariance. Meanwhile, an estimation window for fixed-length memory is introduced to emphasize the use of the new observations and gradually discard the old ones. Since it has the capability to estimate and update the process noise covariance online, the proposed method improves the standard UKF by restraining the disturbance of process noise uncertainty on the filtering solution. The effectiveness and superiority of the proposed method have been verified through Monte Carlo simulations and practical experiment in vehicular INS/GPS integration system. © 2020 Elsevier B.V.","And maximum likelihood estimation; Ins/gps integration; Process noise covariance; Unscented kalman filter; Vehicular navigation"
"Preprocessed dynamic classifier ensemble selection for highly imbalanced drifted data streams","2021","Information Fusion","10.1016/j.inffus.2020.09.004","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090968725&doi=10.1016%2fj.inffus.2020.09.004&partnerID=40&md5=141c6896b7ebe77a80c1c86c6368710e","This work aims to connect two rarely combined research directions, i.e., non-stationary data stream classification and data analysis with skewed class distributions. We propose a novel framework employing stratified bagging for training base classifiers to integrate data preprocessing and dynamic ensemble selection methods for imbalanced data stream classification. The proposed approach has been evaluated based on computer experiments carried out on 135 artificially generated data streams with various imbalance ratios, label noise levels, and types of concept drift as well as on two selected real streams. Four preprocessing techniques and two dynamic selection methods, used on both bagging classifiers and base estimators levels, were considered. Experimentation results showed that, for highly imbalanced data streams, dynamic ensemble selection coupled with data preprocessing could outperform online and chunk-based state-of-art methods. © 2020 Elsevier B.V.","Concept drift; Data preprocessing; Data stream; Dynamic ensemble selection; Imbalanced data"
"Deep ensemble neural-like P systems for segmentation of central serous chorioretinopathy lesion","2021","Information Fusion","10.1016/j.inffus.2020.08.016","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089835781&doi=10.1016%2fj.inffus.2020.08.016&partnerID=40&md5=5c4118fde0b7020b1c80f97f2ab90989","Automatic segmentation of the central serous chorioretinopathy (CSC) lesion and its related ellipsoid zone from the Bruch membrane (EZ-BM) areas is important in the early diagnosis and treatment of retinopathy to prevent vision loss. However, the large variations in the locations and shapes of the CSC lesion, as well as the low contrast of EZ-BM areas with their surroundings make the segmentation task challenging. To address these challenges, in this paper, we propose a new parallel neural-like P system named the deep ensemble neural-like (DEN) P system, which combines the strengths of spiking neural P systems (SN P systems) and deep convolutional neural networks (CNNs) for more accurate and efficient segmentation of CSC lesion and the related EZ-BM areas. The DEN P system establishes three modules with new rules and neuron architectures, which is implemented end-to-end in neurons. Specifically, we propose an ensemble fully convolutional network (FCN) module to train several FCNs with different initializations to obtain effective features, which leverage the strength of ensemble learning in a DEN P system. Benefiting from the parallelism of DEN P systems, FCNs are conducted in different neurons simultaneously. To achieve efficient classification, we propose a multiloss module with three different loss functions to alleviate DEN P system falling into a single-loss function. Different losses are also conducted in different neurons parallelly. To further enhance the performance, we introduce a coarse-fine compensation module to correct detection errors. Being a parallel computational paradigm, DEN P systems are less time consuming, completing CSC lesion and EZ-BM areas on 1,280 images in 0.04 s with an average dice ratio of 0.93±0.04 and 0.95±0.02, respectively. Moreover, the ablation study shows that the proposed modules are critical for effective learning. The extension and generalization of the DEN P systems are also investigated. © 2020 Elsevier B.V.","Coarse-fine compensation module; Convolutional neural networks; Ensemble learning; Neural-like P system; OCT images"
"Two-stage stochastic minimum cost consensus models with asymmetric adjustment costs","2021","Information Fusion","10.1016/j.inffus.2021.02.004","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101371648&doi=10.1016%2fj.inffus.2021.02.004&partnerID=40&md5=e8632fb6194c3435c07c0f257ed30fd4","When dealing with consensus cost problems with asymmetric adjustment costs, the uncertain scenarios with certain probabilities which are becoming a serious problem decision-makers have to face. However, existing optimization-based consensus models have failed to consider uncertain factors that could influence the final consensus and total consensus cost. In order to better deal with these issues, it is necessary to develop practical consensus optimal models. Thus, we establish three two-stage stochastic minimum cost consensus models with asymmetric adjustment costs that may eventually lead the way to better consensus outcomes. The impact of uncertain parameters (such as individual opinions, unit asymmetric adjustment costs, compromise limits, cost-free thresholds) are investigated by modeling three kinds of uncertain consensus models. We solve the proposed two-stage stochastic consensus problem iteratively using the L-shaped algorithm and show the convergence of the algorithm. Furthermore, a case of pollution control negotiations verifies the practicability of the proposed models. Moreover, the comparison of results with the L-shaped algorithm and CPLEX shows that the L-shaped algorithm is more effective in solving time. Some discussions and comparisons on local and global sensitivity analysis of the uncertain parameters are presented to reveal the features of the proposed models. Finally, the relationships between the minimum cost consensus model and minimum cost consensus models with asymmetric adjustment costs and the proposed models are also provided. © 2021 Elsevier B.V.","Directional constraints; L-shaped algorithm; Minimum cost consensus model; Sensitivity analysis; Two-stage stochastic programming"
"A trusted consensus fusion scheme for decentralized collaborated learning in massive IoT domain","2021","Information Fusion","10.1016/j.inffus.2021.02.011","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101851822&doi=10.1016%2fj.inffus.2021.02.011&partnerID=40&md5=5b5980c3bdae690952ff727d7e17e9a5","In a massive IoT systems, large amount of data are collected and stored in clouds, edge devices, and terminals, but the data are mostly isolated. For many new demands of various intelligent applications, self-organized collaborated learning on those data to achieve group decisions has been a new trend. However, in order to reach the goal of group decisions, trust problems on data fusion and model fusion should be solved since the participants may not be trusted. We propose a consistent and trust fusion method with the consortium chain to reach a consensus, and complete the self-organized trusted decentralized collaborated learning. In each consensus process, consensus candidates check others’ trust levels to ensure that they tends to fuse consensus with users with high trust, where the trust levels are evaluated by scores according to their historical behaviors in the past consensus process and stored in the public ledger of blockchain. A trust rewards and punishments method is designed to realize trust incentive consensus, the candidates with higher trust levels have more rights and reputation in the consensus. Simulation results and security analysis show that the method can effectively defend malicious users and data, improve the trust perception performance of the whole federated learning network, and make the federated learning more trusted and stable. © 2021 Elsevier B.V.","Blockchain; Collaborated learning; Consensus fusion; Consortium chain; Trust evaluation"
"DiCyc: GAN-based deformation invariant cross-domain information fusion for medical image synthesis","2021","Information Fusion","10.1016/j.inffus.2020.10.015","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85094323019&doi=10.1016%2fj.inffus.2020.10.015&partnerID=40&md5=64903166b7e31a9f3babe1e43f7c8ce2","Cycle-consistent generative adversarial network (CycleGAN) has been widely used for cross-domain medical image synthesis tasks particularly due to its ability to deal with unpaired data. However, most CycleGAN-based synthesis methods cannot achieve good alignment between the synthesized images and data from the source domain, even with additional image alignment losses. This is because the CycleGAN generator network can encode the relative deformations and noises associated to different domains. This can be detrimental for the downstream applications that rely on the synthesized images, such as generating pseudo-CT for PET-MR attenuation correction. In this paper, we present a deformation invariant cycle-consistency model that can filter out these domain-specific deformation. The deformation is globally parameterized by thin-plate-spline (TPS), and locally learned by modified deformable convolutional layers. Robustness to domain-specific deformations has been evaluated through experiments on multi-sequence brain MR data and multi-modality abdominal CT and MR data. Experiment results demonstrated that our method can achieve better alignment between the source and target data while maintaining superior image quality of signal compared to several state-of-the-art CycleGAN-based methods. © 2020 The Authors","GAN; Image synthesis; Information fusion"
"What makes the difference? An empirical comparison of fusion strategies for multimodal language analysis","2021","Information Fusion","10.1016/j.inffus.2020.09.005","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091217348&doi=10.1016%2fj.inffus.2020.09.005&partnerID=40&md5=a4278b7d336a1706e5f9e12273b24f41","Multimodal video sentiment analysis is a rapidly growing area. It combines verbal (i.e., linguistic) and non-verbal modalities (i.e., visual, acoustic) to predict the sentiment of utterances. A recent trend has been geared towards different modality fusion models utilizing various attention, memory and recurrent components. However, there lacks a systematic investigation on how these different components contribute to solving the problem as well as their limitations. This paper aims to fill the gap, marking the following key innovations. We present the first large-scale and comprehensive empirical comparison of eleven state-of-the-art (SOTA) modality fusion approaches in two video sentiment analysis tasks, with three SOTA benchmark corpora. An in-depth analysis of the results shows that the attention mechanisms are the most effective for modelling crossmodal interactions, yet they are computationally expensive. Second, additional levels of crossmodal interaction decrease performance. Third, positive sentiment utterances are the most challenging cases for all approaches. Finally, integrating context and utilizing the linguistic modality as a pivot for non-verbal modalities improve performance. We expect that the findings would provide helpful insights and guidance to the development of more effective modality fusion models. © 2020 Elsevier B.V.","Emotion recognition; Multimodal human language understanding; Reproducibility in multimodal machine learning; Video sentiment analysis"
"SeDID: An SGX-enabled decentralized intrusion detection framework for network trust evaluation","2021","Information Fusion","10.1016/j.inffus.2021.01.003","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099504024&doi=10.1016%2fj.inffus.2021.01.003&partnerID=40&md5=8df794e3934d2753202094d93c83b374","In order to evaluate network trust, different intrusion detection methods have been proposed. However, it is difficult for a single detection node to collect massive data and perform detection and evaluation in a large-scale network. In addition, disclosure of security-related data and detection pattern might weaken data provision incentives due to privacy concern, which could result in deliberately forging data to evade detection. Current literature still lacks a general framework to conduct decentralized intrusion detection towards network trust evaluation with privacy preservation. In this paper, we propose SeDID, a Software Guard Extension (SGX)-enabled decentralized intrusion detection framework for network trust evaluation based on blockchain. We design a novel consensus mechanism to avoid forking and guarantee high efficiency and real decentralization, where block creation is uniquely consented by miners and block creation difficulty is determined by the number of blocks previously created by a relative miner within a time window. The smaller the number, the easier the miner creates a new block. SeDID also offers incentives according to node contributions for motivating security-related data collection, intrusion detection and network trust evaluation. Additional employment of Intel SGX makes SeDID preserve both data and pattern privacy. We analyze SeDID's efficacy in terms of incentive, privacy preservation and security. Its performance is further evaluated through simulations. In specific settings, its block creation time, task completion time and throughput are 19.61s, 44.55s and 224.47 transactions/s, respectively. Compared with state-of-the-art systems, SeDID offers better performance, which implies its potential to be applied in practice. © 2021","Blockchain; Intel SGX; Intrusion detection; Network trust evaluation; Privacy preservation"
"Remote sensing image classification using subspace sensor fusion","2020","Information Fusion","10.1016/j.inffus.2020.07.002","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85087987714&doi=10.1016%2fj.inffus.2020.07.002&partnerID=40&md5=bf10ddd3c6cec354e0a315eb9d6a76fd","The amount of remote sensing and ancillary datasets captured by diverse airborne and spaceborne sensors has been tremendously increased, which opens up the possibility of utilizing multimodal datasets to improve the performance of processing approaches with respect to the application at hand. However, developing a generic framework with high generalization capability that can effectively fuse diverse datasets is a challenging task since the current approaches are usually only applicable to two specific sensors for data fusion. In this paper, we propose an accurate fusion-based technique called SubFus with capability to integrate diverse remote sensing data for land cover classification. Here, we assume that a high dimensional multisensor dataset can be represented fused features that live in a lower-dimensional space. The proposed classification methodology includes three main stages. First, spatial information is extracted by using spatial filters (i.e., morphology filters). Then, a novel low-rank minimization problem is proposed to represent the multisensor datasets in subspaces using fused features. The fused features in the lower-dimensional subspace are estimated using a novel iterative algorithm based on the alternative direction method of multipliers. Third, the final classification map is produced by applying a supervised spectral classifier (i.e., random forest) on the fused features. In the experiments, the proposed method is applied to a three-sensor (RGB, multispectral LiDAR, and hyperspectral images) dataset captured over the area of the University of Houston, the USA, and a two-sensor (hyperspectral and LiDAR) dataset captured over the city of Trento, Italy. The land-cover maps generated using SubFus are evaluated based on classification accuracies. Experimental results obtained by SubFus confirm considerable improvements in terms of classification accuracies compared with the other methods used in the experiments. The proposed fusion approach obtains 85.32% and 99.25% in terms of overall classification accuracy on the Houston (the training portion of the dataset distributed for the data fusion contest of 2018) and trento datasets, respectively. © 2020 Elsevier B.V.","Classification; Dimensionality reduction; Feature extraction; Multisensor data fusion; Remote sensing; Subspace fusion"
"Towards multi-modal causability with Graph Neural Networks enabling information fusion for explainable AI","2021","Information Fusion","10.1016/j.inffus.2021.01.008","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100313219&doi=10.1016%2fj.inffus.2021.01.008&partnerID=40&md5=9baf537d67d159fcb289eb0d14a5b0b1","AI is remarkably successful and outperforms human experts in certain tasks, even in complex domains such as medicine. Humans on the other hand are experts at multi-modal thinking and can embed new inputs almost instantly into a conceptual knowledge space shaped by experience. In many fields the aim is to build systems capable of explaining themselves, engaging in interactive what-if questions. Such questions, called counterfactuals, are becoming important in the rising field of explainable AI (xAI). Our central hypothesis is that using conceptual knowledge as a guiding model of reality will help to train more explainable, more robust and less biased machine learning models, ideally able to learn from fewer data. One important aspect in the medical domain is that various modalities contribute to one single result. Our main question is “How can we construct a multi-modal feature representation space (spanning images, text, genomics data) using knowledge bases as an initial connector for the development of novel explanation interface techniques?”. In this paper we argue for using Graph Neural Networks as a method-of-choice, enabling information fusion for multi-modal causability (causability – not to confuse with causality – is the measurable extent to which an explanation to a human expert achieves a specified level of causal understanding). The aim of this paper is to motivate the international xAI community to further work into the fields of multi-modal embeddings and interactive explainability, to lay the foundations for effective future human–AI interfaces. We emphasize that Graph Neural Networks play a major role for multi-modal causability, since causal links between features can be defined directly using graph structures. © 2021 The Authors","Counterfactuals; Explainable AI; Graph Neural Networks; Information fusion; Knowledge graphs; Multi-modal causability; xAI"
"Online-review analysis based large-scale group decision-making for determining passenger demands and evaluating passenger satisfaction: Case study of high-speed rail system in China","2021","Information Fusion","10.1016/j.inffus.2020.11.010","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097332165&doi=10.1016%2fj.inffus.2020.11.010&partnerID=40&md5=f4ed98bc553c9dc9e25f132c9c31e290","High-speed rail (HSR) has become an essential mode of public transportation in China and is likely to remain so for the foreseeable future. To promote the development of the HSR industry, a high level of passenger satisfaction must be ensured, which means that passenger satisfaction must be assured. Focusing on HSR in-cabin factors that affect the travel experience of HSR passengers, this study aims to determine passenger demands (PDs) and to evaluate passenger satisfaction by using a combination of online review analysis and large-scale group decision-making (LSGDM). By using web crawler technology, online reviews related to HSR were harvested from a microblogging platform to extract PD data and information. The six PDs that reflect the most frequent concerns of passengers were identified by analyzing the online reviews. The level of satisfaction of passengers with respect to these PDs was analyzed based on the online responses from 100 HSR passengers and by adopting the interval-valued two-tuple linguistic representation model. The final degrees of satisfaction and rankings of the PDs were then determined by using the LSGDM approach with the k-means clustering method and a consensus-reaching process. This research thus constructs an index system of HSR passenger satisfaction evaluation based on online-review analysis and evaluates the process by using LSGDM approaches. The conclusions provide insights into the improvements desired by HSR passengers for in-cabin services and to improve passenger satisfaction. © 2020 Elsevier B.V.","High-speed rail; Large-scale group decision-making; Online-review analysis; Passenger demand; Passenger satisfaction"
"A multimodal-Siamese Neural Network (mSNN) for person verification using signatures and EEG","2021","Information Fusion","10.1016/j.inffus.2021.01.004","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099502800&doi=10.1016%2fj.inffus.2021.01.004&partnerID=40&md5=90aa143dfc6e2bfe17d3e0735ae144f0","Signatures have long been considered to be one of the most accepted and practical means of user verification, despite being vulnerable to skilled forgers. In contrast, EEG signals have more recently been shown to be more difficult to replicate, and to provide better biometric information in response to known a stimulus. In this paper, we propose combining these two biometric traits using a multimodal Siamese Neural Network (mSNN) for improved user verification. The proposed mSNN network learns discriminative temporal and spatial features from the EEG signals using an EEG encoder and from the offline signatures using an image encoder. Features of the two encoders are fused into a common feature space for further processing. A Siamese network then employs a distance metric based on the similarity and dissimilarity of the input features to produce the verification results. The proposed model is evaluated on a dataset of 70 users, comprised of 1400 unique samples. The novel mSNN model achieves a 98.57% classification accuracy with a 99.29% True Positive Rate (TPR) and False Acceptance Rate (FAR) of 2.14%, outperforming the current state-of-the-art by 12.86% (in absolute terms). This proposed network architecture may also be applicable to the fusion of other neurological data sources to build robust biometric verification or diagnostic systems with limited data size. © 2021","CNN; EEG; LSTM; Multimodal; Siamese Neural Network; User verification"
"An integrated framework of learning and evidential reasoning for user profiling using short texts","2021","Information Fusion","10.1016/j.inffus.2020.12.004","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098474596&doi=10.1016%2fj.inffus.2020.12.004&partnerID=40&md5=4eab6b35c78bb84b263ec44b326de74f","Inferring user profiles based on texts created by users on social networks has a variety of applications in recommender systems such as job offering, item recommendation, and targeted advertisement. The problem becomes more challenging when working with short texts like tweets on Twitter, or posts on Facebook. This work aims at proposing an integrated framework based on Dempster–Shafer theory of evidence, word embedding, and k-means clustering for user profiling problem, which is capable of not only working well with short texts but also dealing with uncertainty inherently in user texts. The proposed framework is essentially composed of three phases: (1) Learning abstract concepts at multiple levels of abstraction from user corpora; (2) Evidential inference and combination for user modeling; and (3) User profile extraction. Particularly, in the first phase, a word embedding technique is used to convert preprocessed texts into vectors which capture semantics of words in user corpus, and then k-means clustering is utilized for learning abstract concepts at multiple levels of abstraction, each of which reflects appropriate semantics of user profiles. In the second phase, by considering each document in user corpus as an evidential source that carries some partial information for inferring user profiles, we first infer a mass function associated with each user document by maximum a posterior estimation, and then apply Dempster's rule of combination for fusing all documents’ mass functions into an overall one for the user corpus. Finally, in the third phase, we apply the so-called pignistic probability principle to extract top-n keywords from user's overall mass function to define the user profile. Thanks to the ability of combining pieces of information from many documents, the proposed framework is flexible enough to be scaled when input data coming from not only multiple modes but different sources on web environments. Besides, the resulting profiles are interpretable, visualizable, and compatible in practical applications. The effectiveness of the proposed framework is validated by experimental studies conducted on datasets crawled from Twitter and Facebook. © 2020 The Authors","Dempster–Shafer theory; Information fusion; Mass functions; Short texts; User profiling"
"Multi-granular linguistic distribution evidential reasoning method for renewable energy project risk assessment","2021","Information Fusion","10.1016/j.inffus.2020.08.010","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090183086&doi=10.1016%2fj.inffus.2020.08.010&partnerID=40&md5=b88ec616c1442d9f738f1d34ef9785b1","Nowadays, renewable energy projects have constantly been emphasized and the assessment of potential risks has been considered as an indispensable activity prior to implementation of projects. To carry out a reasonable assessment, multi-granular linguistic distribution assessments (LDAs), an effective and uncertainty representation tool, are adopted to express and quantify opinions based on personalized individual linguistic term sets. Specifically, this study develops a novel uncertain multiple criteria decision making approach, named multi-granular linguistic evidential reasoning method, which can handle incomplete and personalized preferences. A novel comparison method for LDAs is first put forward based on numerical characteristics, namely an expectation value and central moment. To fuse the multi-granular LDAs, a lossless transformation technique is further introduced and some of itsessential properties are discussed. Finally, a case study on renewable energy project risk assessment is discussed to verify the feasibility of the proposed method. Besides, sensitivity analysis is conducted to investigate the sequencing stability and comparative analysis is included to highlight the superiority of the proposed method. © 2020 Elsevier B.V.","Evidential reasoning; Linguistic distribution; Multi-granular linguistic information; Multiple criteria group decision making; Renewable energy project risk assessment"
"Managing transitivity and consistency of preferences in AHP group decision making based on minimum modifications","2021","Information Fusion","10.1016/j.inffus.2020.10.012","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85093973559&doi=10.1016%2fj.inffus.2020.10.012&partnerID=40&md5=b94a20e3572ab8c88c36efa8eec41ce5","Preference transitivity characterized by ordinal consistency is a fundamental principle for decision making models based on pairwise comparison matrices (PCMs). However, little previous research has addressed ordinal consistency in an optimal way. Further, because ordinal consistency is not considered in the consensus reaching process, non-transitive preferences may still exist in the revised PCMs. In this paper, optimization models are proposed to obtain transitive preferences for solving individual consistency and group consensus problems. First, the conditions satisfying the ordinal consistency of PCMs are analysed and a system of constraints is derived to allow for the ordinal consistency to be explicitly controlled in the optimization model. A mixed integer linear optimization model is then proposed to assist decision makers satisfy both the ordinal and cardinal consistencies. A second mixed integer linear optimization model is then designed to ensure that the consensus level in group decision making problems can be achieved when both the group as a whole and all individuals have acceptably cardinal and ordinal consistencies. Optimization models considering ordinal consistency and classical cardinal consistency indices are open problems needing to be managed in future. Compared with existing methods, the proposed models provide an optimal way to minimize modifications in deriving transitive preferences. Finally, the feasibility and validity of the models are verified through comparisons with classic models. © 2020 Elsevier B.V.","Analytic hierarchy process; Cardinal consistency; Consensus; Group decision making; Ordinal consistency; Pairwise comparison matrix"
"Linear uncertain extensions of the minimum cost consensus model based on uncertain distance and consensus utility","2021","Information Fusion","10.1016/j.inffus.2020.12.002","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098541793&doi=10.1016%2fj.inffus.2020.12.002&partnerID=40&md5=c642fa3e5cc2b0d5f035e97248722e05","Uncertainty theory adopts the belief degree and uncertainty distribution to ensure good alignment with a decision-maker's uncertain preferences, making the final decisions obtained from the consensus-reaching process closer to the actual decision-making scenarios. Under the constraints of the uncertain distance measure and consensus utility, this article explores the minimum-cost consensus model under various linear uncertainty distribution-based preferences. First, the uncertain distance is used to measure the deviation between individual opinions and the consensus through uncertainty distributions. A nonlinear analytical formula is derived to avoid the computational complexity of integral and piecewise function operations, thus reducing the calculation cost of the uncertain distance measure. The consensus utility function defined in this article characterizes the adjustment value and degree of aggregation of individual opinions. Three new consensus models are constructed based on the consensus utility and linear uncertainty distribution. The results show that, in complex group decision-making contexts, the uncertain consensus models are more flexible than traditional minimum-cost consensus models: compared with the high volatility of the adjusted opinions in traditional deterministic consensus models with crisp number-based preferences, the variation trends of both individual adjusted opinions and the collective opinion with a linear uncertainty distribution are much smoother and the fitting range is closer to reality. The introduction of the consensus utility not only reflects the relative changes of individual opinions, but also accounts for individual psychological changes during the opinion-adjustment process. Most importantly, it reduces the cost per unit of consensus utility, facilitates the determination of the optimal threshold for the consensus utility, and improves the efficiency of resource allocation. © 2020 Elsevier B.V.","Consensus utility; Group decision-making; Linear uncertain consensus; Minimum-cost consensus; Uncertainty theory"
"SDMP: A secure detector for epidemic disease file based on DNN","2021","Information Fusion","10.1016/j.inffus.2020.10.023","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85095775406&doi=10.1016%2fj.inffus.2020.10.023&partnerID=40&md5=c950984c281e36ace7e79010b938af5d","In the era of intelligent office, reading and processing PDF files by mobile devices have become important parts of various businesses. However, due to the universality of mobile device and PDF file, they are also often used by attackers to disguise malicious codes, which makes users in danger. Especially in medical field, once computer virus invades medical experts’ devices, a large number of data with high medical research value will face huge damage and irreparable loss. Therefore, how to ensure the security when users make use of PDF files is a challenging and meaningful task. In this paper, we design an secure detector of malicious PDF file for epidemic disease file based on Deep Neural Network to solve the problem of privacy and security in handling epidemic disease file. Experiment shows that the detection accuracy of our detector can achieve up to 99.3%. Moreover, the time cost on raining and forecasting of the proposed DNN model is extremely low, less than 1s per epoch. © 2020","Deep Neural Network; Malicious PDF detection; Security"
"Asymmetric Gaussian Process multi-view learning for visual classification","2021","Information Fusion","10.1016/j.inffus.2020.08.020","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089915634&doi=10.1016%2fj.inffus.2020.08.020&partnerID=40&md5=306c91b56473aa8a57f253e50c79d5da","Methods of multi-view learning attain outstanding performance in different fields compared with the single-view based strategies. In this paper, the Gaussian Process Latent Variable Model (GPVLM), which is a generative and non-parametric model, is exploited to represent multiple views in a common subspace. Specifically, there exists a shared latent variable across various views that is assumed to be transformed to observations by using distinctive Gaussian Process projections. However, this assumption is only a generative strategy, being intractable to simply estimate the fused variable at the testing step. In order to tackle this problem, another projection from observed data to the shared variable is simultaneously learned by enjoying the view-shared and view-specific kernel parameters under the Gaussian Process structure. Furthermore, to achieve the classification task, label information is also introduced to be the generation from the latent variable through a Gaussian Process transformation. Extensive experimental results on multi-view datasets demonstrate the superiority and effectiveness of our model in comparison to state-of-the-art algorithms. © 2020","Classification; Gaussian Process; Multi-view; View-shared; View-specific"
"Data fusion strategies for energy efficiency in buildings: Overview, challenges and novel orientations","2020","Information Fusion","10.1016/j.inffus.2020.07.003","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85087624082&doi=10.1016%2fj.inffus.2020.07.003&partnerID=40&md5=1d709f40f6aaa1d9a655b80e54e5b2f9","Recently, tremendous interest has been devoted to develop data fusion strategies for energy efficiency in buildings, where various kinds of information can be processed. However, applying the appropriate data fusion strategy to design an efficient energy efficiency system is not straightforward; it requires a priori knowledge of existing fusion strategies, their applications and their properties. To this regard, seeking to provide the energy research community with a better understanding of data fusion strategies in building energy saving systems, their principles, advantages, and potential applications, this paper proposes an extensive survey of existing data fusion mechanisms deployed to reduce excessive consumption and promote sustainability. We investigate their conceptualizations, advantages, challenges and drawbacks, as well as performing a taxonomy of existing data fusion strategies and other contributing factors. Following, a comprehensive comparison of the state-of-the-art data fusion based energy efficiency frameworks is conducted using various parameters, including data fusion level, data fusion techniques, behavioral change influencer, behavioral change incentive, recorded data, platform architecture, IoT technology and application scenario. Moreover, a novel method for electrical appliance identification is proposed based on the fusion of 2D local texture descriptors, where 1D power signals are transformed into 2D space and treated as images. The empirical evaluation, conducted on three real datasets, shows promising performance, in which up to 99.68% accuracy and 99.52% F1 score have been attained. In addition, various open research challenges and future orientations to improve data fusion based energy efficiency ecosystems are explored. © 2020 Elsevier B.V.","Appliance identification; Data fusion; Energy efficiency; Fusion of 2D descriptors; Machine learning; Sensors"
"A fusion method for multi-valued data","2021","Information Fusion","10.1016/j.inffus.2021.01.001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099613111&doi=10.1016%2fj.inffus.2021.01.001&partnerID=40&md5=c35a68403ee7949c1f22f3fd8237b2dc","In this paper we propose an extension of the notion of deviation-based aggregation function tailored to aggregate multidimensional data. Our objective is both to improve the results obtained by other methods that try to select the best aggregation function for a particular set of data, such as penalty functions, and to reduce the temporal complexity required by such approaches. We discuss how this notion can be defined and present three illustrative examples of the applicability of our new proposal in areas where temporal constraints can be strict, such as image processing, deep learning and decision making, obtaining favourable results in the process. © 2021","Aggregation fusion; Moderate deviation function; Multi-valued data fusion"
"Statistical Agnostic Mapping: A framework in neuroimaging based on concentration inequalities","2021","Information Fusion","10.1016/j.inffus.2020.09.008","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091802392&doi=10.1016%2fj.inffus.2020.09.008&partnerID=40&md5=776667fb2536861e6bedd93118b36ab7","In the 1970s a novel branch of statistics emerged focusing its effort on the selection of a function for the pattern recognition problem that would fulfill a relationship between the quality of the approximation and its complexity. This theory is mainly devoted to problems of estimating dependencies in the case of limited sample sizes, and comprise all the empirical out-of sample generalization approaches; e.g. cross validation (CV). In this paper a data-driven approach based on concentration inequalities is designed for testing competing hypothesis or comparing different models. In this sense we derive a Statistical Agnostic (non-parametric) Mapping (SAM) for neuroimages at voxel or regional levels which is able to: (i) relieve the problem of instability with limited sample sizes when estimating the actual risk via CV; and (ii) provide an alternative way of Family-wise-error (FWE) corrected p-value maps in inferential statistics for hypothesis testing. Using several neuroimaging datasets (containing large and small effects) and random task group analyses to compute empirical familywise error rates, this novel framework resulted in a model validation method for small samples over dimension ratios, and a less-conservative procedure than FWE p-value correction to determine the significance maps from the inferences made using small upper bounds of the actual risk. © 2020 The Authors","Actual and empirical risks; Cross-validation; Finite class lemma; Hypothesis testing; Rademacher averages; Upper bounds"
"Tensor-based restricted kernel machines for multi-view classification","2021","Information Fusion","10.1016/j.inffus.2020.10.022","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096142217&doi=10.1016%2fj.inffus.2020.10.022&partnerID=40&md5=0011c5ec97986dac3850a876c2a0c40a","Multi-view learning deals with data that is described through multiple representations, or views. While various real-world data can be represented by three or more views, several existing multi-view classification methods can only handle two views. Previously proposed methods usually solve this issue by optimizing pairwise combinations of views. Although this can numerically deal with the issue of multiple views, it ignores the higher order correlations which can only be examined by exploring all views simultaneously. In this work new multi-view classification approaches are introduced which aim to include higher order statistics when three or more views are available. The proposed model is an extension to the recently proposed Restricted Kernel Machine classifier model and assumes shared hidden features for all views, as well as a newly introduced model tensor. Experimental results show an improvement with respect to state-of-the art pairwise multi-view learning methods, both in terms of classification accuracy and runtime. © 2020 Elsevier B.V.","Kernel-based learning; Multi-view learning; Tensor"
"Bridging deep and multiple kernel learning: A review","2021","Information Fusion","10.1016/j.inffus.2020.10.002","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092446869&doi=10.1016%2fj.inffus.2020.10.002&partnerID=40&md5=41af4d552a3bcf1f21104ac42ba245ef","Kernel methods and deep learning are two of the most currently remarkable machine learning techniques that have achieved great success in many applications. Kernel methods are powerful tools to capture nonlinear patterns behind data. They implicitly learn high (even infinite) dimensional nonlinear features in the reproducing kernel Hilbert space (RKHS) while making the computation tractable by leveraging the kernel trick. It is commonly agreed that the success of kernel methods is very much dependent on the choice of kernel. Multiple kernel learning (MKL) is one possible scheme that performs kernel combination and selection for a variety of learning tasks, such as classification, clustering, and dimensionality reduction. Deep learning models project input data through several layers of nonlinearity and learn different levels of abstraction. The composition of multiple layers of nonlinear functions can approximate a rich set of naturally occurring input-output dependencies. To bridge kernel methods and deep learning, deep kernel learning has been proven to be an effective method to learn complex feature representations by combining the nonparametric flexibility of kernel methods with the structural properties of deep learning. This article presents a comprehensive overview of the state-of-the-art approaches that bridge the MKL and deep learning techniques. Specifically, we systematically review the typical hybrid models, training techniques, and their theoretical and practical benefits, followed by remaining challenges and future directions. We hope that our perspectives and discussions serve as valuable references for new practitioners and theoreticians seeking to innovate in the applications of the approaches incorporating the advantages of both paradigms and exploring new synergies. © 2020 Elsevier B.V.","Deep learning; Kernel method; Machine learning; Multiple kernel learning; Neural network"
"Revisiting crowd behaviour analysis through deep learning: Taxonomy, anomaly detection, crowd emotions, datasets, opportunities and prospects","2020","Information Fusion","10.1016/j.inffus.2020.07.008","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089438308&doi=10.1016%2fj.inffus.2020.07.008&partnerID=40&md5=b460525c85405c8edcefb43a5e8226b1","Crowd behaviour analysis is an emerging research area. Due to its novelty, a proper taxonomy to organise its different sub-tasks is still missing. This paper proposes a taxonomic organisation of existing works following a pipeline, where sub-problems in last stages benefit from the results in previous ones. Models that employ Deep Learning to solve crowd anomaly detection, one of the proposed stages, are reviewed in depth, and the few works that address emotional aspects of crowds are outlined. The importance of bringing emotional aspects into the study of crowd behaviour is remarked, together with the necessity of producing real-world, challenging datasets in order to improve the current solutions. Opportunities for fusing these models into already functioning video analytics systems are proposed. © 2020","Crowd anomaly detection; Crowd behaviour analysis; Crowd emotions; Deep learning; Models fusion; Review"
"Alzheimer's disease multiclass diagnosis via multimodal neuroimaging embedding feature selection and fusion","2021","Information Fusion","10.1016/j.inffus.2020.09.002","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091343952&doi=10.1016%2fj.inffus.2020.09.002&partnerID=40&md5=1f8a6465118d74c8c7509064617567d6","Alzheimer's disease (AD) will become a global burden in the coming decades according to the latest statistical survey. How to effectively detect AD or MCI (mild cognitive impairment) using reliable biomarkers and robust machine learning methods has become a challenging problem. In this study, we propose a novel AD multiclass classification framework with embedding feature selection and fusion based on multimodal neuroimaging. The framework has three novel aspects: (1) An l2,1-norm regularization term combined with the multiclass hinge loss is used to naturally select features across all the classes in each modality. (2) To fuse the complementary information contained in each modality, an lp-norm (1<p<∞) regularization term is introduced to combine different kernels to perform multiple kernel learning to avoid a sparse kernel coefficient distribution, thereby effectively exploiting complementary modalities. (3) A theorem that transforms the multiclass hinge loss minimization problem using the l2,1-norm and lp-norm regularizations to a previous solvable optimization problem and its proof are given. Additionally, it is theoretically proved that the optimization process converges to the global optimum. Extensive comparison experiments and analysis support the promising performance of the proposed method. © 2020","Alzheimer's disease; Feature selection; Multiclass classification; Multimodal fusion; Multimodal neuroimaging; Multiple kernel learning; Neuroimaging biomarker"
"A spatial-channel progressive fusion ResNet for remote sensing classification","2021","Information Fusion","10.1016/j.inffus.2020.12.008","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099225358&doi=10.1016%2fj.inffus.2020.12.008&partnerID=40&md5=4b7ed6be04744366f895f993b98cfade","In recent years, the panchromatic (PAN) and the multispectral (MS) remote sensing images classification has become a research hotspot. In this paper, we propose a spatial-channel progressive fusion residual network (SCPF-ResNet) for multi-resolution remote sensing classification. Firstly, for the inputs of the proposed network, the interactive data fusion strategy (IDFS) combines generalized-intensity-hue-saturation (GIHS), and discrete wavelet transform (DWT) to interfuse patch pairs of the PAN and the MS images, so as to increase the similarity between them, thus reduce the difference in information between them. Secondly, for the branches of feature extraction, we design an adaptive spatial attention module (ASA-Module) and an adaptive channel attention module (ACA-Module) to strengthen spatial features from both larger-sized with smaller-sized targets and spectral features among channels. Finally, we insert the ASA-Module and ACA-Module into the residual modules to form a triple-branch network and use the common spatial-channel features extracted by the Fusion_Branch to gradually enhance the pure independent features extracted by the PAN_Branch and the MS_Branch, respectively. The experimental results indicate that SCPF-ResNet can achieve competitive performance. © 2020 Elsevier B.V.","Channel attention; Interactive fusion; Multiresolution image classification; Progressive fusion; Spatial attention"
"Behavioral biometrics & continuous user authentication on mobile devices: A survey","2021","Information Fusion","10.1016/j.inffus.2020.08.021","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090859901&doi=10.1016%2fj.inffus.2020.08.021&partnerID=40&md5=761246a49481013665557058fa98881a","This paper offers an up-to-date, comprehensive, extensive and targeted survey on Behavioral Biometrics and Continuous Authentication technologies for mobile devices. Our aim is to help interested researchers to effectively grasp the background in this field and to avoid pitfalls in their work. In our survey, we first present a classification of behavioral biometrics technologies and continuous authentication for mobile devices and an analysis for behavioral biometrics collection methodologies and feature extraction techniques. Then, we provide a state-of-the-art literature review focusing on the machine learning models performance in seven types of behavioral biometrics for continuous authentication. Further, we conduct another review that showed the vulnerability of machine learning models against well-designed adversarial attack vectors and we highlight relevant countermeasures. Finally, our discussions extend to lessons learned, current challenges and future trends. © 2020","Attacks; Behavioral Biometrics; Continuous Authentication; Defense; Machine Learning; Mobile Devices; Survey"
"Integrated fusion framework based on semicoupled sparse tensor factorization for spatio-temporal–spectral fusion of remote sensing images","2021","Information Fusion","10.1016/j.inffus.2020.08.013","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089432061&doi=10.1016%2fj.inffus.2020.08.013&partnerID=40&md5=6d9dc51387052da2ae623df5052f37ef","Remote sensing image fusion is considered a cost effective method for handling the tradeoff between the spatial, temporal and spectral resolutions of current satellite systems. However, most current fusion methods concentrate on fusing images in two domains among the spatial, temporal and spectral domains, and a few efforts have been made to comprehensively explore the relationships of spatio-temporal–spectral features. In this study, we propose a novel integrated spatio-temporal–spectral fusion framework based on semicoupled sparse tensor factorization to generate synthesized frequent high-spectral and high-spatial resolution images by blending multisource observations. Specifically, the proposed method regards the desired high spatio-temporal–spectral resolution images as a four-dimensional tensor and formulates the integrated fusion problem as the estimation of the core tensor and the dictionary along each mode. The high-spectral correlation across the spectral domain and the high self-similarity (redundancy) features in the spatial and temporal domains are jointly exploited using the low dimensional and sparse core tensors. In addition, assuming that the sparse coefficients in the core tensors across the observed and desired image spaces are not strictly the same, we formulate the estimation of the core tensor and the dictionaries as a semicoupled sparse tensor factorization of available heterogeneous spatial, spectral and temporal remote sensing observations. Finally, the proposed method can exploit the multicomplementary spatial, temporal and spectral information of any combination of remote sensing data based on this single unified model. Experiments on multiple data types, including spatio-spectral, spatio-temporal, and spatio-temporal–spectral data fusion, demonstrate the effectiveness and efficiency of the proposed method. © 2020 Elsevier B.V.","Image fusion; Remote sensing; Semicoupled sparse; Spatio-temporal–spectral; Tensor"
"An active opinion dynamics model: the gap between the voting result and group opinion","2021","Information Fusion","10.1016/j.inffus.2020.08.009","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090924767&doi=10.1016%2fj.inffus.2020.08.009&partnerID=40&md5=91b61228cd0c0e7dd4ced69c63e0bb01","Originally developed to simulate the evolution of public opinion, opinion dynamics models have also been successfully applied to market pricing and advertising. However, passive interactions initiated by locational or social relationships in these models are insufficient to characterize purposeful behaviours such as canvassing or trading, where people are driven by their specific intrinsic motivations. Here, we propose an active model in which people tend to communicate with someone who is more likely to be an ally and game theoretically decide whether to interact. Model simulations highlight the macroscopic development of opinion evolution, showing the ubiquitous gap between people's voting result and their collective opinion, and how it narrows with the stabilization of opinion evolution. Our results help explain why group opinion rarely reverses its initial stance and the significance of a level of inclusiveness that is neither too high nor too low. Additionally, we find and attest to the probability distribution of group opinion change, which contributes to predicting how much the collective opinion of a group will change after full discussion. © 2020 Elsevier B.V.","Group opinion; Multi-agent simulation; Opinion dynamics model; Opinion evolution; Voting"
"Relationship between tau, neuroinflammation and atrophy in Alzheimer's disease: The NIMROD study","2021","Information Fusion","10.1016/j.inffus.2020.10.006","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85093972165&doi=10.1016%2fj.inffus.2020.10.006&partnerID=40&md5=e1185778ba8eadd6f27b9ddd93df2996","In addition to beta-amyloid accumulation, misfolded tau and activated microglia are also present in Alzheimer's disease (AD). It is important to study the relationship amongst these pathologies in vivo and their effects on the cognitive deficits for developing effective trails and future therapeutic or preventive strategies for AD. To investigate the relationships amongst different pathologies in AD, in particular how they interact resulting in cognitive impairments, we conducted a study of sixty-six subjects (15 AD, 24 Mild Cognitive Impairment (MCI) and 27 similarly aged healthy controls), who underwent standardised clinical and neuropsychological assessments followed by dynamic PET using [18F]AV1451 (tau) and [11C]PK11195 (activated microglia) and multimodal 3T MRI. MCI patients also underwent [11C]PIB (beta-amyloid) PET. We compared regional PET binding and grey matter atrophy amongst AD, amyloid positive MCI and controls, as well as their spatial distribution across different brain areas. We also applied a mediation analysis to infer the direct and indirect effects of tau, neuroinflammation and grey matter atrophy on cognitive functioning. We found increased [18F]AV1451 and [11C]PK11195 binding as well as grey matter atrophy in AD, with a strong spatial overlap amongst these AD related biomarkers suggesting them interacting with each other. We demonstrated that both tau ([18F]AV1451) and neuroinflammation ([11C]PK11195) have significant effects on cognition however their effects were fully mediated by grey matter atrophy. No mediation effect between tau and neuroinflammation were found with respect to cognition. In conclusion, grey matter atrophy not only spatially overlapped with tau and microglia activity in AD, but also mediate them in affecting cognitive impairments. The mediation analysis enabled data fusion across multiple imaging modalities (PET and MRI) and multiple PET tracers. Our results have significant implications for trials targeting tau and inflammation, and future therapeutic or preventive strategies for AD. © 2020 Elsevier B.V.","AD; Data fusion; MCI; Mediation analysis; MRI; Neuroinflammation; PET; Tau"
"Joint auto-weighted graph fusion and scalable semi-supervised learning","2021","Information Fusion","10.1016/j.inffus.2020.09.007","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091794150&doi=10.1016%2fj.inffus.2020.09.007&partnerID=40&md5=86bff8be3a147175f1202460353076fa","Graph carries out a key role in graph-based semi-supervised label propagation, as it clarifies the structure of the data manifold. The performance of label propagation methods depends on the adopted graph and can be enhanced by merging different graphs that are obtained from multiple sources of information. While there exist algorithms that perform graph fusion they have several weaknesses. Most of these algorithms define graph fusion and label propagation as two separate tasks. Moreover, when the number of data expands, these strategies are not well-suited due to the use of transductive learning in the label propagation phase which makes the label prediction for unseen samples difficult. Furthermore, very few algorithms extract the information contained in the label space. Additionally, most of the graph fusion techniques adopt equal or static weights for different views, which is not the best choice as distinctive features (hence different graphs) contain various information. To overcome these shortcomings, we propose an Auto-weighted Multi-view Semi-Supervised Learning method (AMSSL), which is based on an inductive learning algorithm (i.e., Flexible Manifold Embedding) and profited a projection matrix for predicting the labels of out-of-sample data. The proposed AMSSL method represents a unified framework that dynamically fuses various information obtained from different features and also from the label space and adaptively designates appropriate weights according to the usefulness of each view. Our experimental results on seven small and large image datasets demonstrate the superiority of the proposed method compared to the use of one single feature and other state-of-the-art graph fusion methods. © 2020 Elsevier B.V.","Flexible manifold embedding; Graph fusion; Inductive learning; Label propagation; Manifold learning; Multi-view"
"A survey on deep learning in medicine: Why, how and when?","2021","Information Fusion","10.1016/j.inffus.2020.09.006","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090980993&doi=10.1016%2fj.inffus.2020.09.006&partnerID=40&md5=06759c5e5e98a7caf366ac0d7b467dfa","New technologies are transforming medicine, and this revolution starts with data. Health data, clinical images, genome sequences, data on prescribed therapies and results obtained, data that each of us has helped to create. Although the first uses of artificial intelligence (AI) in medicine date back to the 1980s, it is only with the beginning of the new millennium that there has been an explosion of interest in this sector worldwide. We are therefore witnessing the exponential growth of health-related information with the result that traditional analysis techniques are not suitable for satisfactorily management of this vast amount of data. AI applications (especially Deep Learning), on the other hand, are naturally predisposed to cope with this explosion of data, as they always work better as the amount of training data increases, a phase necessary to build the optimal neural network for a given clinical problem. This paper proposes a comprehensive and in-depth study of Deep Learning methodologies and applications in medicine. An in-depth analysis of the literature is presented; how, where and why Deep Learning models are applied in medicine are discussed and reviewed. Finally, current challenges and future research directions are outlined and analysed. © 2020 Elsevier B.V.","Artificial intelligence; Data science; Deep learning; Medicine; Neural networks"
"ANFIS fusion algorithm for eye movement recognition via soft multi-functional electronic skin","2021","Information Fusion","10.1016/j.inffus.2021.02.003","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101314985&doi=10.1016%2fj.inffus.2021.02.003&partnerID=40&md5=c788b649535f0fa526d3011e19ab9d8c","Eye movement detection has attracted increasing attention in the fields of safety driving, eye motion tracking, psychological assessment and telemedicine. Soft multi-functional electronic skin (SMFES) is designed to collect electrooculogram (EOG), skin temperature and sweat signals simultaneously for eye movement detection. Serpentine structure is adopted to ensure the stretchability of SMFES for satisfying large deformation (>30%) of the soft skin surface. The paper demonstrates that EOG, skin temperature and sweat signals are successfully collected under different eye movements. The feature data from EOG, skin temperature and sweat signals are extracted with different eye movements, and the principal component analysis (PCA) method is adopted to reduce the dimensionality of the feature space. The paper also proposes an intelligent data fusion algorithm for eye movement classification whose input vector is represented by the first three principal components. Adaptive neuro fuzzy inference system (ANFIS) is built to classify and recognize the eye movements (Up, Down, Left, and Right). Furthermore, experiments have demonstrated that ANFIS algorithm achieves 90% recognition accuracy of such eye movements. This work demonstrates that SMFES integrated with data fusion algorithm can successfully solve the eye movement tracking problem, with significant impact in safety driving and wearable electronics. © 2021 Elsevier B.V.","ANFIS; Eye movement recognition; Information fusion; Multi-sensor fusion; Soft electronic skin"
"Multi-source information fusion and deep-learning-based characteristics measurement for exploring the effects of peer engagement on stock price synchronicity","2021","Information Fusion","10.1016/j.inffus.2020.11.006","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097350898&doi=10.1016%2fj.inffus.2020.11.006&partnerID=40&md5=a1fd6cc0a9cb873f35505886c7fa0ddf","By combining financial information from the financial market with social textual information from social media, we apply a two-level information fusion approach to examine the effects of peer engagement on social media on stock price synchronicity and compare the effects between epidemic and non-epidemic contexts. On the first level, single pieces of information are fused at the firm-year level and deep learning models are used to measure the characteristics of peer engagement – informativeness, diversity, information diffusion degree, and expert proportion – which are constructed grounded in the theory of the wisdom of crowds (WoC). On the second level, all measurements at the firm-year level are fused into a full sample to conduct regression analysis. The experimental results show that peer engagement reduces stock price synchronicity. This suggests that high synchronicity could be mitigated through effective guidance from peer engagement activities. We also find that during epidemics, synchronicity is much higher, and group diversity and experts have stronger effects in lowering synchronicity, while the effects of informativeness and information diffusion are hampered. This has implications for combatting the adverse effects of epidemic outbreaks on financial markets. © 2020 Elsevier B.V.","Characteristics measurement; Deep learning; Infectious epidemic; Multi-source information fusion; Stock price synchronicity; Wisdom of crowds"
"MFF-GAN: An unsupervised generative adversarial network with adaptive and gradient joint constraints for multi-focus image fusion","2021","Information Fusion","10.1016/j.inffus.2020.08.022","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090322939&doi=10.1016%2fj.inffus.2020.08.022&partnerID=40&md5=155bfcaaabed59f424dc7a0f8df94057","Multi-focus image fusion is an enhancement method to generate full-clear images, which can address the depth-of-field limitation in imaging of optical lenses. Most existing methods generate the decision map to realize multi-focus image fusion, which usually lead to detail loss due to misclassification, especially near the boundary line of the focused and defocused regions. To overcome this challenge, this paper presents a new generative adversarial network with adaptive and gradient joint constraints to fuse multi-focus images. In our model, an adaptive decision block is introduced to determine whether source pixels are focused or not based on the difference of repeated blur. Under its guidance, a specifically designed content loss can dynamically guide the optimization trend, that is, force the generator to produce a fused result of the same distribution as the focused source images. To further enhance the texture details, we establish an adversarial game so that the gradient map of the fused result approximates the joint gradient map constructed based on the source images. Our model is unsupervised without requiring ground-truth fused images for training. In addition, we release a new dataset containing 120 high-quality multi-focus image pairs for benchmark evaluation. Experimental results demonstrate the superiority of our method over the state-of-the-art in terms of both subjective visual effect and quantitative metrics. Moreover, our method is about one order of magnitude faster compared with the state-of-the-art. © 2020","Generative adversarial network; Image fusion; Multi-focus; Unsupervised learning"
"Recent advances and new guidelines on hyperspectral and multispectral image fusion","2021","Information Fusion","10.1016/j.inffus.2020.11.001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097344421&doi=10.1016%2fj.inffus.2020.11.001&partnerID=40&md5=61ad181ae1c2afe25daaff03da0a18b8","Hyperspectral image (HSI) with high spectral resolution often suffers from low spatial resolution owing to the limitations of imaging sensors. Image fusion is an effective and economical way to enhance the spatial resolution of HSI, which combines HSI with higher spatial resolution multispectral image (MSI) of the same scenario. In the past years, many HSI and MSI fusion algorithms are introduced to obtain high-resolution HSI. However, it lacks a full-scale review for the newly proposed HSI and MSI fusion approaches. To tackle this problem, this work gives a comprehensive review and new guidelines for HSI–MSI fusion. According to the characteristics of HSI–MSI fusion methods, they are categorized as four categories, including pan-sharpening based approaches, matrix factorization based approaches, tensor representation based approaches, and deep convolution neural network based approaches. We make a detailed introduction, discussions, and comparison for the fusion methods in each category. Additionally, the existing challenges and possible future directions for the HSI–MSI fusion are presented. © 2020","Hyperspectral and multispectral image fusion; Hyperspectral image super-resolution; Hyperspectral imaging"
"Multi-focus image fusion: A Survey of the state of the art","2020","Information Fusion","10.1016/j.inffus.2020.06.013","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85087340320&doi=10.1016%2fj.inffus.2020.06.013&partnerID=40&md5=59ecb373a309cb6b2d6ad6b71e34ab9c","Multi-focus image fusion is an effective technique to extend the depth-of-field of optical lenses by creating an all-in-focus image from a set of partially focused images of the same scene. In the last few years, great progress has been achieved in this field along with the rapid development of image representation theories and approaches such as multi-scale geometric analysis, sparse representation, deep learning, etc. This survey paper first presents a comprehensive overview of existing multi-focus image fusion methods. To keep up with the latest development in this field, a new taxonomy is introduced to classify existing methods into four main categories: transform domain methods, spatial domain methods, methods combining transform domain and spatial domain, and deep learning methods. For each category, representative fusion methods are introduced and summarized. Then, a comparative study for 18 representative fusion methods is conducted based on 30 pairs of commonly-used multi-focus images and 8 popular objective fusion metrics. All the relevant resources including source images, objective metrics and fusion results are released online, aiming to provide a benchmark for the future study of multi-focus image fusion. Finally, several major challenges remained in the current research of this field are discussed and some future prospects are put forward. © 2020","Activity level measurement; Deep learning; Fusion rule; Image transform; Multi-focus image fusion"
"Deep learning for pedestrian collective behavior analysis in smart cities: A model of group trajectory outlier detection","2021","Information Fusion","10.1016/j.inffus.2020.08.003","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089426749&doi=10.1016%2fj.inffus.2020.08.003&partnerID=40&md5=a3bc5c8bc57cc219d7661c30366e7c8b","This paper introduces a new model to identify collective abnormal human behaviors from large pedestrian data in smart cities. To accurately solve the problem, several algorithms have been proposed in this paper. These can be split into two categories. First, algorithms based on data mining and knowledge discovery, which study the different correlation among human behavioral data, and identify the collective abnormal human behavior from knowledge extracted. Secondly, algorithms exploring convolution deep neural networks, which learn different features of historical data to determine the collective abnormal human behaviors. Experiments on an actual human behaviors database have been carried out to demonstrate the usefulness of the proposed algorithms. The results show that the deep learning solution outperforms both data mining as well as the state-of-the-art solutions in terms of runtime and accuracy performance. In particular, for large datasets, the accuracy of the deep learning solution reaches 88%, however other solutions do not exceed 81%. Additionally, the runtime of the deep learning solution is below 50 seconds, whereas other solutions need more than 80 seconds for analyzing the same database. © 2020 The Authors","Analysis; Data mining; Deep learning; Human behaviors; Smart cities"
"Image fusion based on generative adversarial network consistent with perception","2021","Information Fusion","10.1016/j.inffus.2021.02.019","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101935759&doi=10.1016%2fj.inffus.2021.02.019&partnerID=40&md5=3a7aa53c269ae7b65bcdda4117ebc2d6","Deep learning is a rapidly developing approach in the field of infrared and visible image fusion. In this context, the use of dense blocks in deep networks significantly improves the utilization of shallow information, and the combination of the Generative Adversarial Network (GAN) also improves the fusion performance of two source images. We propose a new method based on dense blocks and GANs, and we directly insert the input image-visible light image in each layer of the entire network. We use structural similarity and gradient loss functions that are more consistent with perception instead of mean square error loss. After the adversarial training between the generator and the discriminator, we show that a trained end-to-end fusion network – the generator network – is finally obtained. Our experiments show that the fused images obtained by our approach achieve good score based on multiple evaluation indicators. Further, our fused images have better visual effects in multiple sets of contrasts, which are more satisfying to human visual perception. © 2021 Elsevier B.V.","Dense block; Generative adversarial networks; Image fusion; Infrared image; Visible image"
"Multi-scale spatial context-based semantic edge detection","2020","Information Fusion","10.1016/j.inffus.2020.08.014","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089346724&doi=10.1016%2fj.inffus.2020.08.014&partnerID=40&md5=1dee8e7367884a5eeb799a460d2d232b","The good fusion of multi-scale features obtained by Convolutional neural networks (CNNs) is key to semantic edge detection; however, obtaining fusion is challenging. This paper presents a Multi-scale Spatial Context-based deep network for Semantic Edge Detection (MSC-SED). Different from state-of-the-art methods, MSC-SED gradually fuses multi-scale low-to-high level CNN features in an end-to-end architecture. This fusion structure obtains rich multi-scale features while enhancing the details of higher-level features. Beside the overall structure, we present the following two functional modules: the Context Aggregation Module (CAM) and Location-Aware fusion Module (LAM). The CAM helps to enrich context in features at each stage, before and after fusion. The LAM helps to selectively integrate lower-level features. The proposed method outperforms state-of-the-art approaches in terms of both the edge quality and the accuracy of edge categorization on both the SBD and Cityscapes datasets. © 2020 Elsevier B.V.","Convolutional neural network; Gradual fusion; Location-aware information fusion; Multi-scale feature fusion; Semantic edge detection"
"End-to-end multimodal affect recognition in real-world environments","2021","Information Fusion","10.1016/j.inffus.2020.10.011","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85095916539&doi=10.1016%2fj.inffus.2020.10.011&partnerID=40&md5=08429859f53fb84e2cd7d59b62296d89","Automatic affect recognition in real-world environments is an important task towards a natural interaction between humans and machines. The recent years, several advancements have been accomplished in determining the emotional states with the use of Deep Neural Networks (DNNs). In this paper, we propose an emotion recognition system that utilizes the raw text, audio and visual information in an end-to-end manner. To capture the emotional states of a person, robust features need to be extracted from the various modalities. To this end, we utilize Convolutional Neural Networks (CNNs) and propose a novel transformer-based architecture for the text modality that can robustly capture the semantics of sentences. We develop an audio model to process the audio channel, and adopt a variation of a high resolution network (HRNet) to process the visual modality. To fuse the modality-specific features, we propose novel attention-based methods. To capture the temporal dynamics in the signal, we utilize Long Short-Term Memory (LSTM) networks. Our model is trained on the SEWA dataset of the AVEC 2017 research sub-challenge on emotion recognition, and produces state-of-the-art results in the text, visual and multimodal domains, and comparable performance in the audio case when compared with the winning papers of the challenge that use several hand-crafted and DNN features. Code is available at: https://github.com/glam-imperial/multimodal-affect-recognition. © 2020 Elsevier B.V.","Deep learning; Emotion recognition; Multimodal machine learning; Sentiment analysis"
"Phonetic-enriched text representation for Chinese sentiment analysis with reinforcement learning","2021","Information Fusion","10.1016/j.inffus.2021.01.005","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099510729&doi=10.1016%2fj.inffus.2021.01.005&partnerID=40&md5=638a0e81e52824b693934891eeace938","The Chinese pronunciation system offers two characteristics that distinguish it from other languages: deep phonemic orthography and intonation variations. In this paper, we hypothesize that these two important properties can play a major role in Chinese sentiment analysis. In particular, we propose two effective features to encode phonetic information and, hence, fuse it with textual information. With this hypothesis, we propose Disambiguate Intonation for Sentiment Analysis (DISA), a network that we develop based on the principles of reinforcement learning. DISA disambiguates intonations for each Chinese character (pinyin) and, hence, learns precise phonetic representations. We also fuse phonetic features with textual and visual features to further improve performance. Experimental results on five different Chinese sentiment analysis datasets show that the inclusion of phonetic features significantly and consistently improves the performance of textual and visual representations and surpasses the state-of-the-art Chinese character-level representations. © 2021","Chinese phonetics; Deep phonemic orthography; Multilingual sentiment analysis; Sentiment analysis"
"Robust fusion algorithms for unsupervised change detection between multi-band optical images — A comprehensive case study","2020","Information Fusion","10.1016/j.inffus.2020.08.008","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089432500&doi=10.1016%2fj.inffus.2020.08.008&partnerID=40&md5=f62989b0386d91d5263d3091c8a4b792","Unsupervised change detection techniques are generally constrained to two multi-band optical images acquired at different times through sensors sharing the same spatial and spectral resolution. In the case of the optical modality, largely studied in the remote sensing community, a straight comparison of homologous pixels such as pixel-wise differencing is suitable. However, in some specific cases such as emergency situations, punctual missions, defense and security, the only available images may be those acquired through different kinds of sensors with different resolutions. Recently some change detection techniques, dealing with images with different spatial and spectral resolutions, have been proposed. Nevertheless, they are focused on a specific scenario where one image has a high spatial and low spectral resolution while the other has a low spatial and high spectral resolution. This paper addresses the problem of detecting changes between any two multi-band optical images disregarding their spatial and spectral resolution disparities. To overcome resolution disparity, state-of-the art methods apply conventional change detection methods after preprocessing steps applied independently on the two images, e.g. resampling operations intended to reach the same spatial and spectral resolutions. Nevertheless, these preprocessing steps may waste relevant information since they do not take into account the strong interplay existing between the two images. Conversely, in this paper, we propose a method that more effectively uses the available information by modeling the two observed images as spatially and spectrally degraded versions of two (unobserved) latent images characterized by the same high spatial and high spectral resolutions. Covering the same scene, the latent images are expected to be globally similar except for possible changes in spatially sparse locations. Thus, the change detection task is envisioned through a robust fusion task which enforces the differences between the estimated latent images to be spatially sparse. We show that this robust fusion can be formulated as an inverse problem which is iteratively solved using an alternating minimization strategy. The proposed framework is implemented for an exhaustive list of applicative scenarios and applied to real multi-band optical images. A comparison with state-of-the-art change detection methods evidences the accuracy and the versatility of the proposed robust fusion-based strategy. © 2020","Change detection; Different resolutions; Hyperspectral imagery; Image fusion; Multispectral imagery"
"A novel approach to stance detection in social media tweets by fusing ranked lists and sentiments","2021","Information Fusion","10.1016/j.inffus.2020.10.003","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092703716&doi=10.1016%2fj.inffus.2020.10.003&partnerID=40&md5=d5441cb62eb7ee5f8db1002466166ace","Stance detection is a relatively new concept in data mining that aims to assign a stance label (favor, against, or none) to a social media post towards a specific pre-determined target. These targets may not be referred to in the post, and may not be the target of opinion in the post. In this paper, we propose a novel enhanced method for identifying the writer's stance of a given tweet. This comprises a three-phase process for stance detection: (a) tweets preprocessing; here we clean and normalize tweets (e.g., remove stop-words) to generate words and stems lists, (b) features generation; in this step, we create and fuse two dictionaries for generating features vector, and lastly (c) classification; all the instances of the features are classified based on the list of targets. Our innovative feature selection proposes fusion of two ranked lists (top-k) of term frequency-inverse document frequency (tf-idf) scores and the sentiment information. We evaluate our method using six different classifiers: K nearest neighbor (K-NN), discernibility-based K-NN, weighted K-NN, class-based K-NN, exemplar-based K-NN, and Support Vector Machines. Furthermore, we investigate the use of Principal Component Analysis and study its effect on performance. The model is evaluated on the benchmark dataset (SemEval-2016 task 6), and the results significance is determined using t-test. We achieve our best performance of macro F-score (averaged across all topics) of 76.45% using the weighted K-NN classifier. This tops the current state-of-the-art score of 74.44% on the same dataset. © 2020","K-NN variants; Sentiment analysis; Stance detection; Support vector machines; Top-k; Twitter"
"Federated Learning and Differential Privacy: Software tools analysis, the Sherpa.ai FL framework and methodological guidelines for preserving data privacy","2020","Information Fusion","10.1016/j.inffus.2020.07.009","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089410378&doi=10.1016%2fj.inffus.2020.07.009&partnerID=40&md5=57cbc99fac8977a63f2cf0ad769ffa75","The high demand of artificial intelligence services at the edges that also preserve data privacy has pushed the research on novel machine learning paradigms that fit these requirements. Federated learning has the ambition to protect data privacy through distributed learning methods that keep the data in its storage silos. Likewise, differential privacy attains to improve the protection of data privacy by measuring the privacy loss in the communication among the elements of federated learning. The prospective matching of federated learning and differential privacy to the challenges of data privacy protection has caused the release of several software tools that support their functionalities, but they lack a unified vision of these techniques, and a methodological workflow that supports their usage. Hence, we present the Sherpa.ai Federated Learning framework that is built upon a holistic view of federated learning and differential privacy. It results from both the study of how to adapt the machine learning paradigm to federated learning, and the definition of methodological guidelines for developing artificial intelligence services based on federated learning and differential privacy. We show how to follow the methodological guidelines with the Sherpa.ai Federated Learning framework by means of a classification and a regression use cases. © 2020 Elsevier B.V.","Differential privacy; Federated learning; Sherpa.ai Federated Learning framework; Software framework"
"Deep unsupervised learning based on color un-referenced loss functions for multi-exposure image fusion","2021","Information Fusion","10.1016/j.inffus.2020.08.012","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090052917&doi=10.1016%2fj.inffus.2020.08.012&partnerID=40&md5=36eb7411fd577be1590acda3479e00cd","In this paper, an unsupervised learning-based approach is presented for fusing bracketed exposures into high-quality images that avoids the need for interim conversion to intermediate high dynamic range (HDR) images. As an objective quality measure – the colored multi-exposure fusion structural similarity index measure (MEF-SSIMc) – is optimized to update the network parameters, the unsupervised learning can be realized without using any ground truth (GT) images. Furthermore, an unreferenced gradient fidelity term is added in the loss function to recover and supplement the image information for the fused image. As shown in the experiments, the proposed algorithm performs well in terms of structure, texture, and color. In particular, it maintains the order of variations in the original image brightness and suppresses edge blurring and halo effects, and it also produces good visual effects that have good quantitative evaluation indicators. Our code will be publicly available at https://github.com/cathying-cq/UMEF. © 2020 Elsevier B.V.","Multi-exposure image fusion; Structural similarity measurement; Unsupervised deep learning"
"Lights and shadows in Evolutionary Deep Learning: Taxonomy, critical methodological analysis, cases of study, learned lessons, recommendations and challenges","2021","Information Fusion","10.1016/j.inffus.2020.10.014","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85094325767&doi=10.1016%2fj.inffus.2020.10.014&partnerID=40&md5=93fd17972954b6b663e0b9fed9938947","Much has been said about the fusion of bio-inspired optimization algorithms and Deep Learning models for several purposes: from the discovery of network topologies and hyperparametric configurations with improved performance for a given task, to the optimization of the model's parameters as a replacement for gradient-based solvers. Indeed, the literature is rich in proposals showcasing the application of assorted nature-inspired approaches for these tasks. In this work we comprehensively review and critically examine contributions made so far based on three axes, each addressing a fundamental question in this research avenue: (a) optimization and taxonomy (Why?), including a historical perspective, definitions of optimization problems in Deep Learning, and a taxonomy associated with an in-depth analysis of the literature, (b) critical methodological analysis (How?), which together with two case studies, allows us to address learned lessons and recommendations for good practices following the analysis of the literature, and (c) challenges and new directions of research (What can be done, and what for?). In summary, three axes – optimization and taxonomy, critical analysis, and challenges – which outline a complete vision of a merger of two technologies drawing up an exciting future for this area of fusion research. © 2020 Elsevier B.V.","Deep Learning; Evolutionary Computation; Neuroevolution; Swarm Intelligence"
"Point-cloud based 3D object detection and classification methods for self-driving applications: A survey and taxonomy","2021","Information Fusion","10.1016/j.inffus.2020.11.002","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097174674&doi=10.1016%2fj.inffus.2020.11.002&partnerID=40&md5=2edc0aee0430be2aefa746c09cdd7ade","Autonomous vehicles are becoming central for the future of mobility, supported by advances in deep learning techniques. The performance of aself-driving system is highly dependent on the quality of the perception task. Developments in sensor technologies have led to an increased availability of 3D scanners such as LiDAR, allowing for a more accurate representation of the vehicle's surroundings, leading to safer systems. The rapid development and consequent rise of research studies around self-driving systems since early 2010, resulted in a tremendous increase in the number and novelty of object detection methods. After the first wave of works that essentially tried to expand known techniques from object detection in images, more recently there has been a notable development in newer and more adapted to LiDAR data works. This paper addresses the existing literature on object detection using LiDAR data within the scope of self-driving and brings a systematic way for analysing it. Unlike general object detection surveys, we will focus on point-cloud data, which presents specific challenges, notably its high-dimensional and sparse nature. This work introduces a common object detection pipeline and taxonomy to facilitate a thorough comparison between different techniques and, departing from it, this work will critically examine the representation of data (critical for complexity reduction), feature extraction and finally the object detection models. A comparison between performance results of the different models is included, alongside with some future research challenges. © 2020 Elsevier B.V.","3D object detection models; Autonomous vehicles; Computer vision; Deep learning; LiDAR; Perception"
"The introduction of population migration to SEIAR for COVID-19 epidemic modeling with an efficient intervention strategy","2020","Information Fusion","10.1016/j.inffus.2020.08.002","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089420138&doi=10.1016%2fj.inffus.2020.08.002&partnerID=40&md5=ed63f34bbfca610b393aea57d3ce758d","In this paper, we present a mathematical model of an infectious disease according to the characteristics of the COVID-19 pandemic. The proposed enhanced model, which will be referred to as the SEIR (Susceptible–Exposed–Infectious–Recovered) model with population migration, is inspired by the role that asymptomatic infected individuals, as well as population movements can play a crucial role in spreading the virus. In the model, the infected and the basic reproduction numbers are compared under the influence of intervention policies. The experimental simulation results show the impact of social distancing and migration-in rates on reducing the total number of infections and the basic reproductions. And then, the importance of controlling the number of migration-in people and the policy of restricting residents’ movements in preventing the spread of COVID-19 pandemic are verified. © 2020","Basic reproduction number; Contact rate; COVID-19; Migration-in rate; SEIAR"
"RED-Nets: Redistribution Networks for Multi-View Classification","2021","Information Fusion","10.1016/j.inffus.2020.08.017","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090948273&doi=10.1016%2fj.inffus.2020.08.017&partnerID=40&md5=0f1ccbbeefd2e4df032d719ef6b67f95","Multi-View Learning (MVL) focuses on effectively utilizing information from different views to promote analysis performance. To explore the correlation among multiple views, most existing multi-view algorithms usually maximize the correlation between different views for consistency. However, there are two main limitations for this strategy. First, the information from different views cannot be fully integrated only using some specific constraints on pair of views. Second, beyond consistency, the diversity can basically explore the underlying complementary information among multiple views. Therefore, we propose a novel multi-view classification model termed Redistribution Networks for Multi-View Classification (RED-Nets), which is able to jointly explore consistency and diversity in a flexible manner. Specifically, in our model, different (original) views are integrated first and then redistributed into multiple pseudo views to simultaneously capture the consistency and complementarity. The redistributed way is endowed with the ability of searching for the optimal combination for consistent classification and high complementarity from the original views, breaking the barriers among these views. Experimental results on multiple benchmark datasets validate that the proposed RED-Nets is more effective than the state-of-the-art methods. © 2020 Elsevier B.V.","Complementarity; Consistency; Ensemble; Redistribution"
"40 years of sensor fusion for orientation tracking via magnetic and inertial measurement units: Methods, lessons learned, and future challenges","2021","Information Fusion","10.1016/j.inffus.2020.10.018","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096144721&doi=10.1016%2fj.inffus.2020.10.018&partnerID=40&md5=d99be7bd0e2ca9db599a98ca53c39e88","Technological developments over the past two decades have resulted in the development of more accurate and lightweight low-cost magnetic and inertial measurement units (MIMUs). These developments have allowed the extensive application of MIMUs in various fields, specifically tracking the 3D orientation of a rigid body. Despite recent technological improvements, measurements from a tri-axial gyroscope, accelerometer, and/or magnetometer inside the MIMU are characterized by uncertainties. Numerous studies have been conducted to address these uncertainties and develop sensor fusion algorithms (SFAs) to estimate the 3D orientation accurately and robustly. This paper contributes to these efforts by providing a survey of the state-of-the-art SFAs for orientation estimation. We surveyed +250 publications, categorized the SFAs with various structures, identified the modifications proposed to improve their performance, and discussed the strengths and weaknesses of these approaches. We found that, while early SFAs were mostly a vector observation algorithm or an extended Kalman filter, to improve the computational efficiency, more recent works have developed SFAs with a complementary filter or complementary Kalman filter structure. At the same time, to improve the performance of the SFAs, several research teams have proposed various modifications to the basic structure of these filters, such as adaptive gain tuning or imperfect measurement rejection. We also provided an outlook on the lessons learned as well as the main challenges related to SFAs and discussed the practical steps toward developing an effective SFA. We have identified the need for benchmarking studies as the main challenge at the moment. This paper is among the first surveys which provide such breadth of coverage across different SFAs for tracking orientation with MIMUs. © 2020 Elsevier B.V.","Adaptive gain tuning; Attitude and heading reference system; Complementary Filter; Linear/extended Kalman filter; Magnetic and inertial measurement unit; Sensor fusion algorithm"
"Multi-task learning with Multi-view Weighted Fusion Attention for artery-specific calcification analysis","2021","Information Fusion","10.1016/j.inffus.2021.01.009","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100463819&doi=10.1016%2fj.inffus.2021.01.009&partnerID=40&md5=5f2d630b0101c91cfdc9d364fee5a9c2","In general, artery-specific calcification analysis comprises the simultaneous calcification segmentation and quantification tasks. It can help provide a thorough assessment for calcification of different coronary arteries, and further allow for an efficient and rapid diagnosis of cardiovascular diseases (CVD). However, as a high-dimensional multi-type estimation problem, artery-specific calcification analysis has not been profoundly investigated due to the intractability of obtaining discriminative feature representations. In this work, we propose a Multi-task learning network with Multi-view Weighted Fusion Attention (MMWFAnet) to solve this challenging problem. The MMWFAnet first employs a Multi-view Weighted Fusion Attention (MWFA) module to extract discriminative feature representations by enhancing the collaboration of multiple views. Specifically, MWFA weights these views to improve multi-view learning for calcification features. Based on the fusion of these multiple views, the proposed approach takes advantage of multi-task learning to obtain accurate segmentation and quantification of artery-specific calcification simultaneously. We perform experimental studies on 676 non-contrast Computed Tomography scans, achieving state-of-the-art performance in terms of multiple evaluation metrics. These compelling results evince that the proposed MMWFAnet is capable of improving the effectivity and efficiency of clinical CVD diagnosis. © 2021 Elsevier B.V.","Artery-specific calcification analysis; Multi-task learning; Multi-view learning; Multi-view Weighted Fusion Attention"
"RXDNFuse: A aggregated residual dense network for infrared and visible image fusion","2021","Information Fusion","10.1016/j.inffus.2020.11.009","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099175581&doi=10.1016%2fj.inffus.2020.11.009&partnerID=40&md5=d2c84aa940ab9042b17d0d70cae9bb32","This study proposes a novel unsupervised network for IR/VIS fusion task, termed as RXDNFuse, which is based on the aggregated residual dense network. In contrast to conventional fusion networks, RXDNFuse is designed as an end-to-end model that combines the structural advantages of ResNeXt and DenseNet. Hence, it overcomes the limitations of the manual and complicated design of activity-level measurement and fusion rules. Our method establishes the image fusion problem into the structure and intensity proportional maintenance problem of the IR/VIS images. Using comprehensive feature extraction and combination, RXDNFuse automatically estimates the information preservation degrees of corresponding source images, and extracts hierarchical features to achieve effective fusion. Moreover, we design two loss function strategies to optimize the similarity constraint and the network parameter training, thus further improving the quality of detailed information. We also generalize RXDNFuse to fuse images with different resolutions and RGB scale images. Extensive qualitative and quantitative evaluations reveal that our results can effectively preserve the abundant textural details and the highlighted thermal radiation information. In particular, our results form a comprehensive representation of scene information, which is more in line with the human visual perception system. © 2020 Elsevier B.V.","Convolutional neural network; Deep learning; Image fusion; Infrared image; Loss function strategy; Visible image"
"Managing noncooperative behaviors in large-scale group decision-making with linguistic preference orderings: The application in Internet Venture Capital","2021","Information Fusion","10.1016/j.inffus.2020.12.003","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098103574&doi=10.1016%2fj.inffus.2020.12.003&partnerID=40&md5=d396d2565d7846a7a9762f7bd2535756","In Internet venture capital (VC), it is very important to fully analyze and evaluate the influential factors. Because this activity usually involves amounts of experts, it makes sense to incorporate it into large-scale group decision-making (LSGDM). In this process, how to deal with the noncooperative behaviors and express the preference information are two important issues that need to be addressed. Given this, this paper is committed to evaluating the influential factors of Internet VC by managing noncooperative behaviors in LSGDM. Firstly, the preference information can be expressed by linguistic preference orderings (LPOs) which can be used to express unbalanced relationship between any two adjacent alternatives. Then, three kinds of noncooperative behaviors are taken into consideration, and we can identify the group who belongs to one of the three noncooperative behaviors, and then develop methods to manage them respectively. Furthermore, a consensus reaching model is established to manage these noncooperative behaviors. Moreover, we apply the proposed model to solve a practical LSGDM problem involving the evaluations of the influential factors in Internet VC. Finally, comparative analyses between the proposed model and some existing methods are made to show the validity and applicability of the proposed consensus reaching model. © 2020","Consensus; Large-scale group decision-making; Linguistic preference orderings; Noncooperative behaviors; Venture capital"
"Deep learning-based compressed image artifacts reduction based on multi-scale image fusion","2021","Information Fusion","10.1016/j.inffus.2020.10.016","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85094316018&doi=10.1016%2fj.inffus.2020.10.016&partnerID=40&md5=67f4cbc6dcfdd2f430c13deb781f7b01","One of the visually noticeable compression artifacts in block-based image/video compression platforms is called blocking artifact. Several post-processing methods were presented to reduce such kind of artifacts. However, most methods in the literature often induce visibly blurring artifacts. The paper presents a deep network to eliminate image compression artifacts (usually denoted by image deblocking) based on image fusion in multi-scale manner. Recent deep learning-based related methods usually learn deep models using a loss function in per-pixel manner based on explicit image priors in order to directly produce clean images. In place of existing deep learning-guided approaches, the problem is reformulated in this paper to the learning of the residuals (or artifacts) between the received images and their corresponding clean images (ground truths). In the presented deep framework, an input image is first down-sampled while naturally reducing the blocking artifacts. Then, our multi-scale image fusion model is used for fusing the different down-scaled versions (of less artifacts) with the input image (with severer artifacts) to estimate the blocking artifacts. Then, by deducting the estimated artifacts from the input image, the blocking artifacts can be significantly eliminated and most original image details are preserved simultaneously. The presented method is well applicable to any vision-based computer systems with digital visual codec embedded. © 2020 Elsevier B.V.","Blocking artifacts; Convolutional neural networks; Deep learning; Image fusion; Multi-scale; Residual learning"
"Smart anomaly detection in sensor systems: A multi-perspective review","2021","Information Fusion","10.1016/j.inffus.2020.10.001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85093684355&doi=10.1016%2fj.inffus.2020.10.001&partnerID=40&md5=c0c20d3b2d1b292ab0a50b93a60db2fb","Anomaly detection is concerned with identifying data patterns that deviate remarkably from the expected behavior. This is an important research problem, due to its broad set of application domains, from data analysis to e-health, cybersecurity, predictive maintenance, fault prevention, and industrial automation. Herein, we review state-of-the-art methods that may be employed to detect anomalies in the specific area of sensor systems, which poses hard challenges in terms of information fusion, data volumes, data speed, and network/energy efficiency, to mention but the most pressing ones. In this context, anomaly detection is a particularly hard problem, given the need to find computing-energy-accuracy trade-offs in a constrained environment. We taxonomize methods ranging from conventional techniques (statistical methods, time-series analysis, signal processing, etc.) to data-driven techniques (supervised learning, reinforcement learning, deep learning, etc.). We also look at the impact that different architectural environments (Cloud, Fog, Edge) can have on the sensors ecosystem. The review points to the most promising intelligent-sensing methods, and pinpoints a set of interesting open issues and challenges. © 2020 Elsevier B.V.","Anomaly detection; Intelligent sensing; Internet of Things; Machine learning; Sensor systems"
"A new method for anomaly detection based on non-convex boundaries with random two-dimensional projections","2021","Information Fusion","10.1016/j.inffus.2020.08.011","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089548628&doi=10.1016%2fj.inffus.2020.08.011&partnerID=40&md5=8734879c2a74289122ca5131fdd0c4d6","The implementation of anomaly detection systems represents a key problem that has been focusing the efforts of scientific community. In this context, the use one-class techniques to model a training set of non-anomalous objects can play a significant role. One common approach to face the one-class problem is based on determining the geometric boundaries of the target set. More specifically, the use of convex hull combined with random projections offers good results but presents low performance when it is applied to non-convex sets. Then, this work proposes a new method that face this issue by implementing non-convex boundaries over each projection. The proposal was assessed and compared with the most common one-class techniques, over different sets, obtaining successful results. © 2020 Elsevier B.V.","Anomaly detection; Boundary; Convex hull; Limits; One-class; Projection methods"
"Fusion in stock market prediction: A decade survey on the necessity, recent developments, and potential future directions","2021","Information Fusion","10.1016/j.inffus.2020.08.019","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089916634&doi=10.1016%2fj.inffus.2020.08.019&partnerID=40&md5=906ca53bbb1cde998ce04fdb6968df2f","Investment in a financial market is aimed at getting higher benefits; this complex market is influenced by a large number of events wherein the prediction of future market dynamics is challenging. The investors’ etiquettes towards stock market may demand the need of studying various associated factors and extract the useful information for reliable forecasting. Fusion can be considered as an approach to integrate data or characteristics, in general, and enhance the prediction based on the combinational approach that can aid each other. We conduct a systematic approach to present a survey for the years 2011–2020 by considering articles that have used fusion techniques for various stock market applications and broadly categorize them into information fusion, feature fusion, and model fusion. The major applications of stock market include stock price and trend prediction, risk analysis and return forecasting, index prediction, as well as portfolio management. We also provide an infographic overview of fusion in stock market prediction and extend our survey for other finely addressed financial prediction problems. Based on our surveyed articles, we provide potential future directions and concluding remarks on the significance of applying fusion in stock market. © 2020 Elsevier B.V.","Deep learning; Feature fusion; Information fusion; Machine learning; Model fusion; Stock market prediction"
"An infrared and visible image fusion method based on multi-scale transformation and norm optimization","2021","Information Fusion","10.1016/j.inffus.2021.02.008","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102149182&doi=10.1016%2fj.inffus.2021.02.008&partnerID=40&md5=6a4e4a572e2d2297f5d590a49feb7293","In this paper, we propose a new infrared and visible image fusion method based on multi-scale transformation and norm optimization. In this method, a new loss function is designed with contrast fidelity (L2 norm) and sparse constraint (L1 norm), and the split Bregman method is used to optimize the loss function to obtain pre-fusion images. The final fused base layer is obtained by using a multi-level decomposition latent low-rank representation (MDLatLRR) method to decompose the pre-fusion images. Then, using the pre-fusion image as the reference, image structure similarity (SSIM) is introduced to evaluate the validity of detail information from the visible image, and the SSIM is then transformed into a weight map which is applied to the optimization method based on L2 norm to generate the final detail fusion layer. Our proposed method is evaluated and compared with 18 state-of-the-art image fusion methods, both qualitatively and quantitatively on four public datasets (i.e., CVC14 driving dataset, TNO dataset with natural scenarios, RoadScene dataset, and whole brain atlas dataset). The results show that our proposed method is generally better than the compared methods in terms of highlighting targets and retaining effective detail information. © 2021","Image fusion; Infrared image; Intelligent systems; Pre-fusion image; Visible image"
"Consistency and consensus improvement models driven by a personalized normalization method with probabilistic linguistic preference relations","2021","Information Fusion","10.1016/j.inffus.2020.12.005","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098932235&doi=10.1016%2fj.inffus.2020.12.005&partnerID=40&md5=7f299f2193865461d2864468150a6528","Probabilistic linguistic preference relation (PLPR) provides an effective and flexible tool with which preference degrees of decision-makers can be captured when they vacillatingly express linguistic preference values among several linguistic terms. Individual consistency and group consensus are two important research topics of PLPRs in group decision making (GDM). Considering the problems associated with these two topics, this study proposes a novel GDM framework with consistency-driven and consensus-driven optimization models based on a personalized normalization method for managing complete and incomplete PLPRs. First, existing limitations of the traditional normalization method for probabilistic linguistic term sets (PLTSs) managing ignorance information are specifically discussed. Given the potential valuable information hidden in PLTSs, a personalized normalization method is newly proposed through a two-stage decision-making process with a comprehensive fusion mechanism. Then, based on the proposed normalization method for PLTSs, consistency-driven optimization models that aim to minimize the overall adjustment amount of a PLPR are constructed to improve consistency. Moreover, the developed models are extended to improve consistency and estimate the missing values of an incomplete PLPR. Subsequently, a consensus-driven optimization model that aims to maximize group consensus by adjusting experts’ weights is constructed to support the consensus-reaching process. Finally, an illustrative example, followed by some comparative analyses is presented to demonstrate the application and advantages of the proposed approach. © 2020","Group decision making; Incomplete probabilistic linguistic preference relation; Probabilistic linguistic term set; Programming model"
"Conversational transfer learning for emotion recognition","2021","Information Fusion","10.1016/j.inffus.2020.06.005","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089463919&doi=10.1016%2fj.inffus.2020.06.005&partnerID=40&md5=85fe7ec09c82488fd32ecc649ec49abd","Recognizing emotions in conversations is a challenging task due to the presence of contextual dependencies governed by self- and inter-personal influences. Recent approaches have focused on modeling these dependencies primarily via supervised learning. However, purely supervised strategies demand large amounts of annotated data, which is lacking in most of the available corpora in this task. To tackle this challenge, we look at transfer learning approaches as a viable alternative. Given the large amount of available conversational data, we investigate whether generative conversational models can be leveraged to transfer affective knowledge for detecting emotions in context. We propose an approach, TL-ERC, where we pre-train a hierarchical dialogue model on multi-turn conversations (source) and then transfer its parameters to a conversational emotion classifier (target). In addition to the popular practice of using pre-trained sentence encoders, our approach also incorporates recurrent parameters that model inter-sentential context across the whole conversation. Based on this idea, we perform several experiments across multiple datasets and find improvement in performance and robustness against limited training data. TL-ERC also achieves better validation performances in significantly fewer epochs. Overall, we infer that knowledge acquired from dialogue generators can indeed help recognize emotions in conversations. © 2020 Elsevier B.V.","Conversation modeling; Emotion Recognition in Conversations; Generative pre-training; Transfer learning"
"A selection framework of sensor combination feature subset for human motion phase segmentation","2021","Information Fusion","10.1016/j.inffus.2020.12.009","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098621583&doi=10.1016%2fj.inffus.2020.12.009&partnerID=40&md5=7df3592d73e019c813ae9279afaa21ba","Motion phase plays an important role in the spatial–temporal parameters of human motion analysis. Multi-sensor fusion technology based on inertial sensors frees the monitoring of the human body phase from space constraints and improves the flexibility of the system. However, human phase segmentation methods usually rely on the determination of the positioning of the sensor and the number of sensors, it is difficult to artificially select the number and position of the sensors, especially when human motion phases are diverse. This paper proposes a selection framework for the sensor combination feature subset for motion phase segmentation, which combines feature selection algorithms with the subsequent classifiers, and determine the optimum combination of the sensor and the feature subset according to the performance of the trained model. Through the constraint and the sensor combination feature subset (SCFS), the filter method can select any number of sensors and control the size of the feature subset; the embedded method can select any number of sensors, but the size of the feature subset is determined by the classifier model. Experimental results show that the proposed framework can effectively select a specified number of sensors without human intervention, and the number of sensors has an impact on the recognition rate of the classifier within 1.5%. In addition, the filter method has good adaptability to a variety of classifiers, and the classifier prediction time can be controlled by setting the subset size of the feature; the embedded method can achieve a better phase segmentation effect than the filter method. For the application of motion phase segmentation, the proposed framework can reliably and quickly identify redundant sensors that provide effective support for reducing the complexity of the wearable sensor system and improving user comfort. © 2020 Elsevier B.V.","Feature selection; Gait detection; Motion capture; Sensor fusion; Supervised learning; Swimming"
"DeepOption: A novel option pricing framework based on deep learning with fused distilled data from multiple parametric methods","2021","Information Fusion","10.1016/j.inffus.2020.12.010","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098712448&doi=10.1016%2fj.inffus.2020.12.010&partnerID=40&md5=3c31a2aa824d0571691ed1d95b9a20d8","The remarkable performance of deep learning is based on its ability to learn high-level features by processing large amounts of data. This exceptionally superior performance has attracted the attention of researchers studying option pricing. However, option data are more expensive and less accessible than other types of data and are imbalanced because of the liquidity of options. This motivated us to propose a new option pricing and delta-hedging framework called DeepOption. This framework, which is based on deep learning, can improve the performance even when applying imbalanced real option data. In particular, the framework fuses simulated big data, known as distilled data, obtained using various traditional parametric methods. The proposed model employs the following three-stage training approach: Our model is pre-trained using big distilled data after it is fine-tuned using real option data through transfer learning. Finally, a delta branch is added to the model and trained. We experimentally evaluated the proposed method using three sets of real option data, namely S&P 500 European call options, EuroStoxx50 call options, and Hang Seng Index put options. Our experimental results on option pricing demonstrate that our proposed model outperforms parametric methods and other machine learning methods. Specifically, our model, which uses pre-training with distilled data, reduces the overall mean absolute percentage error (MAPE) by more than 50%, compared with that of a deep learning model using only real option data without pre-training. © 2020 Elsevier B.V.","Data distillation; Data fusion; Deep learning; Delta hedging; Option pricing"
"Multimodal deep generative adversarial models for scalable doubly semi-supervised learning","2021","Information Fusion","10.1016/j.inffus.2020.11.003","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096656322&doi=10.1016%2fj.inffus.2020.11.003&partnerID=40&md5=a09b1714cb27e59fe18b50026d3c38a4","The comprehensive utilization of incomplete multi-modality data is a difficult problem with strong practical value. Most of the previous multimodal learning algorithms require massive training data with complete modalities and annotated labels, which greatly limits their practicality. Although some existing algorithms can be used to complete the data imputation task, they still have two disadvantages: (1) they cannot control the semantics of the imputed modalities accurately; and (2) they need to establish multiple independent converters between any two modalities when extended to multimodal cases. To overcome these limitations, we propose a novel doubly semi-supervised multimodal learning (DSML) framework. Specifically, DSML uses a modality-shared latent space and multiple modality-specific generators to associate multiple modalities together. Here we divided the shared latent space into two independent parts, the semantic labels and the semantic-free styles, which allows us to easily control the semantics of generated samples. In addition, each modality has its own separate encoder and classifier to infer the corresponding semantic and semantic-free latent variables. The above DSML framework can be adversarially trained by using our specially designed softmax-based discriminators. Large amounts of experimental results show that the DSML obtains better performance than the baselines on three tasks, including semi-supervised classification, missing modality imputation and cross-modality retrieval. © 2020 Elsevier B.V.","Deep generative models; Generative adversarial networks; Multimodal fusion; Multiview learning; Semi-supervised learning"
"Sugeno integral generalization applied to improve adaptive image binarization","2021","Information Fusion","10.1016/j.inffus.2020.10.020","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096195788&doi=10.1016%2fj.inffus.2020.10.020&partnerID=40&md5=ba030f7d8904bd8fc6e406a2803beec9","Classic adaptive binarization methodologies threshold pixels intensity with respect to adjacent pixels exploiting integral images. In turn, integral images are generally computed optimally by using the summed-area-table algorithm (SAT). This document presents a new adaptive binarization technique based on fuzzy integral images. Which, in turn, this technique is supported by an efficient design of a modified SAT for generalized Sugeno fuzzy integrals. We define this methodology as FLAT (Fuzzy Local Adaptive Thresholding). Experimental results show that the proposed methodology produced a better image quality thresholding than well-known global and local thresholding algorithms. We proposed new generalizations of different fuzzy integrals to improve existing results and reaching an accuracy ≈0.94 on a wide dataset. Moreover, due to high performances, these new generalized Sugeno fuzzy integrals created ad hoc for adaptive binarization, can be used as tools for grayscale processing and more complex real-time thresholding applications. © 2020 Elsevier B.V.","Adaptive binarization; Aggregation functions; Fuzzy integrals; Image processing; Image thresholding"
"Decomposition-Fusion for Label Distribution Learning","2021","Information Fusion","10.1016/j.inffus.2020.08.024","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090599676&doi=10.1016%2fj.inffus.2020.08.024&partnerID=40&md5=2fe1d0cb35355e9c7852ad8327b3355f","Label Distribution Learning (LDL) is a general learning framework that assigns an instance to a distribution over a set of labels rather than to a single label or multiple labels. Current LDL methods have proven their effectiveness in many real-life machine learning applications. However, LDL is a generalization of the classification task and as such it is exposed to the same problems as standard classification algorithms, including class-imbalanced, noise, overlapping or irregularities. The purpose of this paper is to mitigate these effects by using decomposition strategies. The technique devised, called Decomposition-Fusion for LDL (DF-LDL), is based on one of the most renowned strategy in decomposition: the One-vs-One scheme, which we adapt to be able to deal with LDL datasets. In addition, we propose a competent fusion method that allows us to discard non-competent classifiers when their output is probably not of interest. The effectiveness of the proposed DF-LDL method is verified on several real-world LDL datasets on which we have carried out two types of experiments. First, comparing our proposal with the base learners and, second, comparing our proposal with the state-of-the-art LDL algorithms. DF-LDL shows significant improvements in both experiments. © 2020 Elsevier B.V.","Decomposition strategies; Label Distribution Learning; Machine learning; One vs. One"
"A maximum self-esteem degree based feedback mechanism for group consensus reaching with the distributed linguistic trust propagation in social network","2021","Information Fusion","10.1016/j.inffus.2020.10.010","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85093925127&doi=10.1016%2fj.inffus.2020.10.010&partnerID=40&md5=acf9f3aab6842563d2ced98b8857899d","This paper focuses on consensus reaching process (CRP) under social network in which the trust relationship expressed by linguistic information. A new feedback mechanism in social network group decision making (SN-GDM) is proposed, which mainly consists of the following two aspects: (1) The propagation of distributed linguistic trust is investigated to study trust relation among experts; (2) A maximum self-esteem degree based feedback mechanism is developed to produce personalized advice for reaching higher group consensus. To do so, a novel linguistic trust propagation method is proposed to obtain the complete trust relationship among group. The self-esteem degree is used to define the extent that an individual makes concessions. Then, a maximum self-esteem degree based optimal feedback mechanism is built to produce personalized advice to help inconsistent experts make change of their opinion. Its novelty lies in the establishment of an optimization model with the nonlinear group self-esteem degree function as the objective function while group consensus threshold as the restrictions. Therefore, the inconsistent experts will reach a group consensus with the minimum loss of self-esteem degree, and then, it achieves the optimal balance between individual self-esteem and group consensus. Finally, a ranking process is applied to derive the appropriate consensus solution. © 2020 Elsevier B.V.","Consensus; Distributed linguistic trust; Feedback mechanism; Group decision making; Self-esteem degree; Trust propagation"
"Processes and methods of information fusion for ranking products based on online reviews: An overview","2020","Information Fusion","10.1016/j.inffus.2020.02.007","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081241508&doi=10.1016%2fj.inffus.2020.02.007&partnerID=40&md5=adec7c5f548a6e34ad73316b23b9f573","Over the past few years, more and more consumers have come to read online reviews when they shop online. To support consumers' purchase decisions, many scholars focus on ranking products based on online reviews and propose various methods and techniques. Generally, the process of information fusion for ranking products based on online reviews consists of three stages: product feature extraction, sentiment analysis, and ranking products. In this paper, we review the existing studies on processes and methods of information fusion for each stage. Furthermore, we briefly review the existing research on information fusion based on online reviews in other fields. Finally, we summarize the main conclusions of this paper and point out the future research direction. © 2020 Elsevier B.V.","Feature extraction; Information fusion; Online reviews; Product ranking; Sentiment analysis"
"CCE: An ensemble architecture based on coupled ANN for solving multiclass problems","2020","Information Fusion","10.1016/j.inffus.2019.12.015","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077698895&doi=10.1016%2fj.inffus.2019.12.015&partnerID=40&md5=f2d4e3d8a2ab6af5918b34757e22771a","The resolution of multiclass classification problems has been usually addressed by using a “divide and conquer” strategy that splits the original problem into several binary subproblems. This approach is mandatory when the learning algorithm has been designed to solve binary problems and a multiclass version cannot be devised. Artificial Neural Networks, ANN, are binary learning models whose extension to multiclass problems is rather straightforward by using the standard 1-out-of N codification of the classes. However, the use of a single ANN can be inefficient in terms of accuracy and computational complexity when the data set is large, or the number of classes is high. In this work, we exhaustively describe CCE, a new classifier ensemble based on ANN. Each member of this new ensemble is a couple of multiclass ANN's. Each ANN is trained using different subsets of the dataset ensuring these subsets to be disjoint. This new approach allows to combine the benefits of the divide and conquer methodology, with the use of multiclass ANNs and with the combination of individual classification modules that give a complete answer to the addressed problem. The combination of these elements results in a classifier ensemble in which the diversity of the base classifiers provides high accuracy values. Moreover, the use of couples of ANN proves to be tolerant to labeling noise and computationally efficient. The performance of CCE has been tested on various datasets and the results show the higher performance of this approach with respect to other used classification systems. © 2019","Artificial Neural Networks; Diversity; Ensemble of classifiers; Multiclass-classification tasks"
"Theoretical analysis of Tsallis entropy-based quality measure for weighted averaging image fusion","2020","Information Fusion","10.1016/j.inffus.2019.12.010","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077517251&doi=10.1016%2fj.inffus.2019.12.010&partnerID=40&md5=83f83b138de227645f5fcbb3471cef7d","Entropy-based metrics are often employed for objective image fusion quality assessment due to single layer implementation of entropy and a small parameter set. In this paper, we present the theoretical analysis of image fusion quality measure based on Tsallis entropy. The purpose of this study is to theoretically assess if the considered quality measure is able to fulfill the desired behaviors that are expected from an ideal information-based image fusion quality metric. To assess the Tsallis quality measure, the paper employs an image formation model to obtain a closed-form expression for quality while weighted averaging is used as a fusion algorithm. The paper demonstrates that the Tsallis-based quality measure violates the desired behaviors regarding the response to variation of signal-to-noise ratio and effect of entropy order on the measured quality sign. Investigations on real images are also performed and the results agree with the theoretical analysis. © 2019 Elsevier B.V.","Image fusion; Mutual information; Quality assessment; Theoretical analysis; Tsallis entropy"
"Granger causality-based information fusion applied to electrical measurements from power transformers","2020","Information Fusion","10.1016/j.inffus.2019.12.005","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076609027&doi=10.1016%2fj.inffus.2019.12.005&partnerID=40&md5=0b7fb392b31b43c338ca92ff571f7d84","In the immediate future, with the increasing presence of electrical vehicles and the large increase in the use of renewable energies, it will be crucial that distribution power networks are managed, supervised and exploited in a similar way as the transmission power systems were in previous decades. To achieve this, the underlying infrastructure requires automated monitoring and digitization, including smart-meters, wide-band communication systems, electronic device based-local controllers, and the Internet of Things. All of these technologies demand a huge amount of data to be curated, processed, interpreted and fused with the aim of real-time predictive control and supervision of medium/low voltage transformer substations. Wiener–Granger causality, a statistical notion of causal inference based on Information Fusion could help in the prediction of electrical behaviour arising from common causal dependencies. Originally developed in econometrics, it has successfully been applied to several fields of research such as the neurosciences and is applicable to time series data whereby cause precedes effect. In this paper, we demonstrate the potential of this methodology in the context of power measures for providing theoretical models of low/medium power transformers. Up to our knowledge, the proposed method in this context is the first attempt to build a data-driven power system model based on G-causality. In particular, we analysed directed functional connectivity of electrical measures providing a statistical description of observed responses, and identified the causal structure within data in an exploratory analysis. Pair-wise conditional G-causality of power transformers, their independent evolution in time, and the joint evolution in time and frequency are discussed and analysed in the experimental section. © 2019","Functional connectivity; Granger causality; Power transformers; SCADA measurements; Time series analysis"
"Distributed multiple model joint probabilistic data association with Gibbs sampling-aided implementation","2020","Information Fusion","10.1016/j.inffus.2020.04.007","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086829605&doi=10.1016%2fj.inffus.2020.04.007&partnerID=40&md5=3800d94d19a5e34bc4fbf71e8ec02a33","This paper proposes a new distributed multiple model multiple manoeuvring target tracking algorithm. The proposed tracker is derived by combining joint probabilistic data association (JPDA) with consensus-based distributed filtering. Exact implementation of the JPDA involves enumerating all possible joint association events and thus often becomes computationally intractable in practice. We propose a computationally tractable approximation of calculating the marginal association probabilities for measurement-target mappings based on stochastic Gibbs sampling. In order to achieve scalability for a large number of sensors and high tolerance to sensor failure, a simple average consensus algorithm-based information JPDA filter is proposed for distributed tracking of multiple manoeuvring targets. In the proposed framework, the state of each target is updated using consensus-based information fusion while the manoeuvre mode probability of each target is corrected with measurement probability fusion. Simulations clearly demonstrate the effectiveness and characteristics of the proposed algorithm. The results reveal that the proposed formulation is scalable and much more efficient than classical JPDA without sacrificing tracking accuracy. © 2020","Average consensus; Distributed information fusion; Gibbs sampling; Joint probabilistic data association; Multiple target tracking"
"General multi-view semi-supervised least squares support vector machines with multi-manifold regularization","2020","Information Fusion","10.1016/j.inffus.2020.04.005","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084916112&doi=10.1016%2fj.inffus.2020.04.005&partnerID=40&md5=d98c09edea8a6aad9c45dbffbf110450","Multi-view semi-supervised learning achieves great success in recent years which leverages information among labeled and unlabeled multi-view data to improve the generalization performance. So far two classical two-view semi-supervised learning methods are multi-view Laplacian support vector machines (MvLapSVM) and multi-view Laplacian twin support vector machines (MvLapTSVM). But they can only deal with two-view classification problems and cannot deal with general multi-view classification problems. They both solve the quadratic programming problems (QPPs) so that their time complexity is quite high. In this paper, we formulate general multi-view Laplacian least squares support vector machines (GMvLapSVM) and general multi-view Laplacian least squares twin support vector machines (GMvLapTSVM) which solve linear equations as compared to QPPs in MvLapSVM and MvLapTSVM. They can handle the general multi-view classification problems by combining multiple different views in a non-pairwise way. The disagreement among different views is considered as a regularization term in the objective function to explore the consensus information. Multi-manifold regularization is adopted for multi-view semi-supervised learning. Combination weights for all view in the norm regularization terms are adopted to exploit complementarity information among distinct views. Finally, an efficient alternating algorithm is proposed for optimization. Experiments are performed on various real world datasets, which give state-of-the-art generalization performance. © 2020 Elsevier B.V.","Multi-view semi-supervised learning; Quadratic programming; Support vector machine; Twin support vector machine"
"Deep feature fusion through adaptive discriminative metric learning for scene recognition","2020","Information Fusion","10.1016/j.inffus.2020.05.005","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084937339&doi=10.1016%2fj.inffus.2020.05.005&partnerID=40&md5=bc0c0d3109dbbf1e8b607548aa97264d","With the development of deep learning techniques, fusion of deep features has demonstrated the powerful capability to improve recognition performance. However, most researchers directly fuse different deep feature vectors without considering the complementary and consistent information among them. In this paper, from the viewpoint of metric learning, we propose a novel deep feature fusion method, called deep feature fusion through adaptive discriminative metric learning (DFF-ADML), to explore the complementary and consistent information for scene recognition. Concretely, we formulate an adaptive discriminative metric learning problem, which not only fully exploits discriminative information from each deep feature vector, but also adaptively fuses complementary information from different deep feature vectors. Besides, we map different deep feature vectors of the same image into a common space by different linear transformations, such that the consistent information can be preserved as much as possible. Moreover, DFF-ADML is extended to a kernelized version. Extensive experiments on both natural scene and remote sensing scene datasets demonstrate the superiority and robustness of the proposed deep feature fusion method. © 2020","Adaptive discriminative metric learning; Deep feature fusion; Scene recognition"
"A Dual–Branch Attention fusion deep network for multiresolution remote–Sensing image classification","2020","Information Fusion","10.1016/j.inffus.2019.12.013","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077514265&doi=10.1016%2fj.inffus.2019.12.013&partnerID=40&md5=6360966d7c725c91e3bcbd5668f8273e","In recent years, with the diversification of acquisition methods of very high resolution panchromatic (PAN) and multispectral (MS) remote sensing images, multiresolution remote sensing classification has become a research hotspot. In this paper, from the perspective of data–driven deep learning, we design a dual–branch attention fusion deep network (DBAF–Net) for the multiresolution classification. It aims to integrate the feature–level fusion and classification into an end–to–end network model. In the process of establishing a training sample library, unlike the traditional pixel–centric sampling strategy with fixed patch size, we propose an adaptive center–offset sampling strategy (ACO–SS), which allows each patch to adaptively determine the neighborhood range by finding the texture structure of the pixel to be classified. And the neighborhood range is not symmetrical with this pixel, we expect to capture the neighborhood information that is more conducive to its classification. In network structure, based on the captured patches by ACO–SS, we design a spatial attention module (SA–module) for PAN data and a channel attention module (CA–module) for MS data, thus highlighting the spatial resolution advantages of PAN data and the multi–channel advantages of MS data, respectively. Then these two features are interfused to improve and strengthen the fusion features in both spatial and channel. The quantitative and qualitative experimental results verify the robustness and effectiveness of the proposed method. © 2020 Elsevier B.V.","Attention mechanism; Deep learning; Feature fusion; Multiresolution image classification; Panchromatic (PAN) and multispectral (MS) images"
"An overview of data fusion techniques for Internet of Things enabled physical activity recognition and measure","2020","Information Fusion","10.1016/j.inffus.2019.09.002","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072276495&doi=10.1016%2fj.inffus.2019.09.002&partnerID=40&md5=feae0af63104c6cf2d1cd193ba5b0350","Due to importantly beneficial effects on physical and mental health and strong association with many rehabilitation programs, Physical Activity Recognition and Measure (PARM) has been widely recognised as a key paradigm for a variety of smart healthcare applications. Traditional methods for PARM relies on designing and utilising Data fusion or machine learning techniques in processing ambient and wearable sensing data for classifying types of physical activity and removing their uncertainties. Yet they mostly focus on controlled environments with the aim of increasing types of identifiable activity subjects, improved recognition accuracy and measure robustness. The emergence of the Internet of Things (IoT) enabling technology is transferring PARM studies to an open and dynamic uncontrolled ecosystem by connecting heterogeneous cost-effective wearable devices and mobile apps and various groups of users [35]. Little is currently known about whether traditional Data fusion techniques can tackle new challenges of IoT environments and how to effectively harness and improve these technologies. In an effort to understand potential use and opportunities of Data fusion techniques in IoT enabled PARM applications, this paper will give a systematic review, critically examining PARM studies from a perspective of a novel 3D dynamic IoT based physical activity collection and validation model. It summarized traditional state-of-the-art data fusion techniques from three plane domains in the 3D dynamic IoT model: devices, persons and timeline. The paper goes on to identify some new research trends and challenges of data fusion techniques in the IoT enabled PARM studies, and discusses some key enabling techniques for tackling them. © 2019","Activity monitoring; Activity recognition; Information fusion; Lifelogging; Physical activity; Review"
"A survey on empathetic dialogue systems","2020","Information Fusion","10.1016/j.inffus.2020.06.011","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086995406&doi=10.1016%2fj.inffus.2020.06.011&partnerID=40&md5=660453ec5aa92f1e1073d95f3fca9152","Dialogue systems have achieved growing success in many areas thanks to the rapid advances of machine learning techniques. In the quest for generating more human-like conversations, one of the major challenges is to learn to generate responses in a more empathetic manner. In this review article, we focus on the literature of empathetic dialogue systems, whose goal is to enhance the perception and expression of emotional states, personal preference, and knowledge. Accordingly, we identify three key features that underpin such systems: emotion-awareness, personality-awareness, and knowledge-accessibility. The main goal of this review is to serve as a comprehensive guide to research and development on empathetic dialogue systems and to suggest future directions in this domain. © 2020 Elsevier B.V.","Affective computing; Artificial intelligence; Dialogue systems"
"Deep learning based emotion analysis of microblog texts","2020","Information Fusion","10.1016/j.inffus.2020.06.002","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086725184&doi=10.1016%2fj.inffus.2020.06.002&partnerID=40&md5=e0a23b5f2e530d5b7ad522cec2e27a7f","Traditional text emotion analysis methods are primarily devoted to studying extended texts, such as news reports and full-length documents. Microblogs are considered short texts that are often characterized by large noises, new words, and abbreviations. Previous emotion classification methods usually fail to extract significant features and achieve poor classification effect when applied to processing of short texts or micro-texts. This study proposes a microblog emotion classification model, namely, CNN_Text_Word2vec, on the basis of convolutional neural network (CNN) to solve the above-mentioned problems. CNN_Text_Word2vec introduces a word2vec neural network model to train distributed word embeddings on every single word. The trained word vectors are used as input features for the model to learn microblog text features through parallel convolution layers with multiple convolution kernels of different sizes. Experiment results show that the overall accuracy rate of CNN_Text_Word2vec is 7.0% higher than that achieved by current mainstream methods, such as SVM, LSTM and RNN. Moreover, this study explores the impact of different semantic units on the accuracy of CNN_Text_Word2vec, specifically in processing of Chinese texts. The experimental results show that comparing to using feature vectors obtained from training words, feature vector obtained from training Chinese characters yields a better performance. © 2020 Elsevier B.V.","Convolutional neural network; Emotional analysis; Microblog short text; Word2vec"
"FuCiTNet: Improving the generalization of deep learning networks by the fusion of learned class-inherent transformations","2020","Information Fusion","10.1016/j.inffus.2020.06.015","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85087339158&doi=10.1016%2fj.inffus.2020.06.015&partnerID=40&md5=6578ba210f873abb0e2b758793de3f59","It is widely known that very small datasets produce overfitting in Deep Neural Networks (DNNs), i.e., the network becomes highly biased to the data it has been trained on. This issue is often alleviated using transfer learning, regularization techniques and/or data augmentation. This work presents a new approach, independent but complementary to the previous mentioned techniques, for improving the generalization of DNNs on very small datasets in which the involved classes share many visual features. The proposed model, called FuCiTNet (Fusion Class inherent Transformations Network), inspired by GANs, creates as many generators as classes in the problem. Each generator, k, learns the transformations that bring the input image into the k-class domain. We introduce a classification loss in the generators to drive the leaning of specific k-class transformations. Our experiments demonstrate that the proposed transformations improve the generalization of the classification model in three diverse datasets. © 2020","Classification; Deep neural networks; GANs (Generative Adversarial Networks); Generalization; Pre-processing; Small dataset; Transformation"
"A Quantum-Like multimodal network framework for modeling interaction dynamics in multiparty conversational sentiment analysis","2020","Information Fusion","10.1016/j.inffus.2020.04.003","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083718014&doi=10.1016%2fj.inffus.2020.04.003&partnerID=40&md5=1aa92cb48fac69502d8fa9700cdfd209","Sentiment analysis in conversations is an emerging yet challenging artificial intelligence (AI) task. It aims to discover the affective states and emotional changes of speakers involved in a conversation on the basis of their opinions, which are carried by different modalities of information (e.g., a video associated with a transcript). There exists a wealth of intra- and inter-utterance interaction information that affects the emotions of speakers in a complex and dynamic way. How to accurately and comprehensively model complicated interactions is the key problem of the field. To fill this gap, in this paper, we propose a novel and comprehensive framework for multimodal sentiment analysis in conversations, called a quantum-like multimodal network (QMN), which leverages the mathematical formalism of quantum theory (QT) and a long short-term memory (LSTM) network. Specifically, the QMN framework consists of a multimodal decision fusion approach inspired by quantum interference theory to capture the interactions within each utterance (i.e., the correlations between different modalities) and a strong-weak influence model inspired by quantum measurement theory to model the interactions between adjacent utterances (i.e., how one speaker influences another). Extensive experiments are conducted on two widely used conversational sentiment datasets: the MELD and IEMOCAP datasets. The experimental results show that our approach significantly outperforms a wide range of baselines and state-of-the-art models. © 2020 Elsevier B.V.","Human conversation; Interactive dynamics; Long short-term memory (LSTM) network; Multimodal sentiment analysis; Quantum theory"
"Moving horizon estimation meets multi-sensor information fusion: Development, opportunities and challenges","2020","Information Fusion","10.1016/j.inffus.2020.01.009","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85080053238&doi=10.1016%2fj.inffus.2020.01.009&partnerID=40&md5=1f2c55bae52248c6ac79c8a690b3446e","Since the proposal of moving horizon (MH) estimation in 1960s, the MH estimation approach has drawn ever-increasing research interests due mainly to its inherent capability of handling complex nonlinear systems and constrained systems. Recent years have witnessed considerable progress on the theoretical and practical research of MH estimation. In this work, a bibliographical review is provided on the moving horizon estimation problem and its applications. The basic idea of MH estimation is first introduced in detail. Then recent advances of MH estimation according to the underlying systems are summarized. Furthermore, some applications of MH estimation are presented. Finally, some research challenges of MH estimation problem are outlined for the further research. © 2020 Elsevier B.V.","Dynamical systems; Filtering; Moving horizon estimation; Multi-sensor information fusion; Performance analysis; State estimation"
"Real evaluation for designing sensor fusion in UAV platforms","2020","Information Fusion","10.1016/j.inffus.2020.06.003","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086745898&doi=10.1016%2fj.inffus.2020.06.003&partnerID=40&md5=bc09d732847fa872958dded5d5dfbdcf","Evaluation of UAV systems is mostly based on simulation tools that are manually configured to define the trajectory (ground truth trajectory) for comparing with the system output. In this work, the authors present an original method to evaluate the performance of UAV platform in real situations without considering simulations. The proposed evaluation methodology allows calculating the system accuracy and robustness with a considerable number of samples, accumulating the performance of different missions in the same conditions. The main innovation is an alternative evaluation for designing sensor fusion parameters using real performance indicators of navigation accuracy in UAVs based on a commercially available flight controller and peripherals. This methodology and selected performance indicators allow to select the best parameters for the fusion system of a determined configuration of sensors and a predefined real mission not requiring ground truth. The selected platform is described highlighting the available sensors and data processing software, and the experimental methodology is proposed to characterize the sensor data fusion output. The results show in detail the presented performance metrics for a set of trajectories in order to determine the best choice of parameters using quality measurements of navigation output. © 2020","EKF; Real data analysis; System design; UAVS sensor fusion"
"Ordinal scale based uncertainty models for AI","2020","Information Fusion","10.1016/j.inffus.2020.06.010","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85087284695&doi=10.1016%2fj.inffus.2020.06.010&partnerID=40&md5=07b07345bd2766fc7b69daf001911b53","In human processed AI, HP-AI, we build our AI systems based on knowledge learned by human experts rather then that learned by artificial neural networks such as in the case of deep learning. The information provided by these human experts is typically linguistically expressed. In support of HP-AI we look at the properties of an ordinal scale, S, needed to model linguistically expressed quantitative information. Since fuzzy measures provide a very general structure for modeling uncertainty we look at ordinal fuzzy measures. We look at the Sugeno integral based on this ordinal S scale. We discuss the modeling of information about an uncertain variable using an ordinal scale. We look at the problem of multi-source in this ordinal environment. © 2020 Elsevier B.V.","Fuzzy measure; Linguistically expressed; Multi-source fusion; Ordinal information"
"Object fusion tracking based on visible and infrared images: A comprehensive review","2020","Information Fusion","10.1016/j.inffus.2020.05.002","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85087333292&doi=10.1016%2fj.inffus.2020.05.002&partnerID=40&md5=1364fb5905f54f6c41ec41cb1f750290","Visual object tracking has attracted widespread interests recently. Due to the complementary features provided by visible and infrared images, fusion tracking based on visible and infrared images can boost the tracking performance under adverse challenging conditions. RGB-infrared fusion tracking has become an active research topic and various algorithms have been proposed in recent years. In this paper, we present a review on RGB-infrared fusion tracking. We summarize all major RGB-infrared trackers in the literature and categorize them into several major groups for better understanding. We also discuss the development of RGB-infrared datasets, and analyze the main results on public datasets. We observe that deep learning-based methodsachieve the state-of-the-art performances. Besides, the graph-based and correlation filter-based methods give a bit worse but still competitive performances. In conclusion, we give some suggestions on future research directions of fusion tracking based on our observations. This review can serve as a reference for researchers in RGB-infrared fusion tracking, image fusion, and related fields. © 2020","Correlation filter; Deep learning; Fusion tracking; Object tracking; RGBT"
"Heterogeneous sensor data fusion for multiple object association using belief functions","2020","Information Fusion","10.1016/j.inffus.2019.11.002","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075458826&doi=10.1016%2fj.inffus.2019.11.002&partnerID=40&md5=9be420f8fcf9dfb9f726a0e9ccaab6e6","In this study, the object association issue is tackled in order to ensure a correct affiliation of perceived objects with known ones. The proposed approach is based on the evidence theory and includes multiple object features in order to manage pairing issues in a complex environment. Two heterogeneous information sources are built based on kinematic features related to the objects: their position and size on one hand and their direction of motion on the other hand. A study on the estimation of the belief expressed by these independent sources is performed. The multiple features are managed through a hierarchical fusion which includes two levels of combination. The first level is a pairwise combination, fusing position and orientation data of each pair of objects and the second one processes sequentially the previously combined information over all possible associations. This paper also investigates the effectiveness of the association according to different combination operators at both levels. The performance of the proposed approach is demonstrated in the Intelligent Transportation Systems context for which environmental perception is crucial. The validation exploits a large amount of real data issued from a camera and a 3D LiDAR from the KITTI database. © 2019 Elsevier B.V.","Autonomous vehicles; Evidence theory; Hierarchical fusion; Multi-attribute modeling/fusion; Multiple object association"
"Multi-classifier information fusion in risk analysis","2020","Information Fusion","10.1016/j.inffus.2020.02.003","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081156314&doi=10.1016%2fj.inffus.2020.02.003&partnerID=40&md5=0f05307cf8a05f2efc44ef0038fded6f","This paper develops a novel multi-classifier information fusion approach that integrates the probabilistic support vector machine (SVM) and the improved Dempster-Shafer (D-S) evidence theory to support risk analysis under uncertainty. Safety levels for various risk factors can be classified separately using the probabilistic SVM. Then, these multiple classification results will be fused at the decision level to achieve an overall risk evaluation by an improved D-S evidence theory with the integration of the Dempster’ rule and the weighted average rule. The Monte Carlo simulation approach is employed to model the randomness and uncertainty underlying limited observations. A global sensitivity analysis is performed to identify the most significant factors contributing to the risk event. A realistic operational tunnel case in China is used to demonstrate the feasibility and effectiveness of the developed approach, aiming to assess the magnitude of the structural health risk. Results indicate the developed SVM-DS approach is capable of (1) Fusing multi-classifier information effectively from different SVM models with a high classification accuracy of 97.14%; (2) Performing a strong robustness to bias, which can achieve acceptable classification accuracy even under a 20% bias; and (3) Exhibiting a more outstanding classification performance (87.99% accuracy) than the single SVM model (63.84% accuracy) under a high bias (20%). Since the proposed reliable risk analysis method can efficiently fuse multi-sensory information with ubiquitous uncertainties, conflicts, and bias, it provides in-depth analysis for structural health status together with the most critical risk factors, and then proper remedial actions can be taken at an early stage. © 2020","D–s evidence theory; Global sensitivity analysis; Risk analysis; Structural health monitoring; Support vector machine"
"Machine learning information fusion in Earth observation: A comprehensive review of methods, applications and data sources","2020","Information Fusion","10.1016/j.inffus.2020.07.004","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088030361&doi=10.1016%2fj.inffus.2020.07.004&partnerID=40&md5=4956874feeb475a8b6f0512b120700a9","This paper reviews the most important information fusion data-driven algorithms based on Machine Learning (ML) techniques for problems in Earth observation. Nowadays we observe and model the Earth with a wealth of observations, from a plethora of different sensors, measuring states, fluxes, processes and variables, at unprecedented spatial and temporal resolutions. Earth observation is well equipped with remote sensing systems, mounted on satellites and airborne platforms, but it also involves in-situ observations, numerical models and social media data streams, among other data sources. Data-driven approaches, and ML techniques in particular, are the natural choice to extract significant information from this data deluge. This paper produces a thorough review of the latest work on information fusion for Earth observation, with a practical intention, not only focusing on describing the most relevant previous works in the field, but also the most important Earth observation applications where ML information fusion has obtained significant results. We also review some of the most currently used data sets, models and sources for Earth observation problems, describing their importance and how to obtain the data when needed. Finally, we illustrate the application of ML data fusion with a representative set of case studies, as well as we discuss and outlook the near future of the field. © 2020 Elsevier B.V.","Cloud computing; Data blending; Data fusion; Earth observation; Earth science; Gap filling; Information fusion; Machine learning; Multisensor fusion; Remote sensing; Social networks"
"Large-Scale decision-making: Characterization, taxonomy, challenges and future directions from an Artificial Intelligence and applications perspective","2020","Information Fusion","10.1016/j.inffus.2020.01.006","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85079010266&doi=10.1016%2fj.inffus.2020.01.006&partnerID=40&md5=2378c7c305b6f58837d44ba28a4fde26","The last decade witnessed tremendous developments in social media and e-democracy technologies. A fundamental aspect in these paradigms is that the number of decision makers allowed to partake in a decision making event drastically increases. As a result Large Scale Decision Making (LSDM) has established itself as an emerging and rapidly developing research field, attracting comprehensive studies in the last decade. LSDM events are a complex class of decision making problems, in which multiple and highly diverse stakeholders are involved and the provided alternatives are assessed considering multiple criteria/attributes. Since some of the extant LSDM research was extended from group decision making scenarios, there is no established definition for a LSDM problem as of yet. We firstly propose a clear definition and characterization of LSDM events as a basis for characterizing this emerging family of decision frameworks. Secondly, a classification of LSDM literature is provided. Effectively solving an LSDM problem is usually a complex and challenging process, in which reaching a high consensus or accounting for the agreement or conflict relationships between participants becomes critical. Accordingly, we present a taxonomy and an overview of LSDM models, predicated on their key elements, i.e. the procedures and specific steps followed by the existing models: consensus measurement, subgroup clustering, behavior management, and consensus building mechanisms. Finally, we provide a discussion in which we identify research challenges and propose future research directions under a triple perspective: key LSDM methodologies, AI and data fusion for LSDM, and innovative applications. The potential rise of AI-based LSDM is particularly highlighted in the discussion provided. © 2020 Elsevier B.V.","Artificial Intelligence; Behaviour management; Consensus reaching processes; Group decision making; Large-scale decision making; Preference modelling; Subgroup clustering"
"Autosomal dominantly inherited alzheimer disease: Analysis of genetic subgroups by machine learning","2020","Information Fusion","10.1016/j.inffus.2020.01.001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077807763&doi=10.1016%2fj.inffus.2020.01.001&partnerID=40&md5=70f5611828ced821f91bc1139be1ab7d","Despite subjects with Dominantly-Inherited Alzheimer's Disease (DIAD) represent less than 1% of all Alzheimer's Disease (AD) cases, the Dominantly Inherited Alzheimer Network (DIAN) initiative constitutes a strong impact in the understanding of AD disease course with special emphasis on the presyptomatic disease phase. Until now, the 3 genes involved in DIAD pathogenesis (PSEN1, PSEN2 and APP) have been commonly merged into one group (Mutation Carriers, MC) and studied using conventional statistical analysis. Comparisons between groups using null-hypothesis testing or longitudinal regression procedures, such as the linear-mixed-effects models, have been assessed in the extant literature. Within this context, the work presented here performs a comparison between different groups of subjects by considering the 3 genes, either jointly or separately, and using tools based on Machine Learning (ML). This involves a feature selection step which makes use of ANOVA followed by Principal Component Analysis (PCA) to determine which features would be realiable for further comparison purposes. Then, the selected predictors are classified using a Support-Vector-Machine (SVM) in a nested k-Fold cross-validation resulting in maximum classification rates of 72–74% using PiB PET features, specially when comparing asymptomatic Non-Carriers (NC) subjects with asymptomatic PSEN1 Mutation-Carriers (PSEN1-MC). Results obtained from these experiments led to the idea that PSEN1-MC might be considered as a mixture of two different subgroups including: a first group whose patterns were very close to NC subjects, and a second group much more different in terms of imaging patterns. Thus, using a k-Means clustering algorithm it was determined both subgroups and a new classification scenario was conducted to validate this process. The comparison between each subgroup vs. NC subjects resulted in classification rates around 80% underscoring the importance of considering DIAN as an heterogeneous entity. © 2020 Elsevier B.V.","Alzheimer's disease (AD); DIAN; Dominantly-inherited Alzheimer's disease (DIAD); Machine learning; Neuroimaging"
"Feasibility study of a multi-criteria decision-making based hierarchical model for multi-modality feature and multi-classifier fusion: Applications in medical prognosis prediction","2020","Information Fusion","10.1016/j.inffus.2019.09.001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072231135&doi=10.1016%2fj.inffus.2019.09.001&partnerID=40&md5=17333d399a4478327bd2720ac012dd9b","Radiomics has great prospects in terms of tumour grading, diagnosis and prediction of prognosis by analysing multifaceted data from sources such as clinical treatments, medical images, and pathology. However, exploring an effective way to manage miscellaneous clinical information, as well as to select an appropriate classifier for prediction modelling, is still demanding in a practical clinical context. In this study, we propose a multi-criterion decision-making (MCDM) based classifier fusion (MCF) strategy to combine different classifiers within an MCDM framework. A hierarchical predictive scheme (H-MCF) based on the proposed MCF is also investigated to reliably link the multi-modality features and multi-classifiers. Ten public UCI datasets and two clinical datasets were used to validate the proposed MCF and H-MCF. The experimental results showed that H-MCF has superior predictive performance when compared with the traditional fusion strategies and other fusion architectures, thus demonstrating the feasibility of the proposed H-MCF in integrating information from features of diversified modalities and different classifiers. © 2019 Elsevier B.V.","Classifier fusion; Multi-classifier; Multi-modality; Multiple criteria decision making; Radiomics"
"Feature distillation network for aspect-based sentiment analysis","2020","Information Fusion","10.1016/j.inffus.2020.03.003","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082007693&doi=10.1016%2fj.inffus.2020.03.003&partnerID=40&md5=07f74289b4e3802034462d3520cbacf7","A proliferation of user-generated content on the web is fueling research into sentiment analysis for improved extraction of human emotional information. Aspect-based sentiment analysis (ABSA) is currently at the focus, which seeks to predict the sentiment of certain aspects in text. The primary challenge is to recognize the relevant contexts for different aspects. Most prior approaches combining recurrent neural networks and attention mechanisms inevitably introduce extraneous noise and diminish prediction accuracy. Furthermore, the sentiment of some context words varies with different aspects and cannot be inferred from themselves alone, which is another challenge that prevents attention mechanisms from performing properly. In this study, we propose a feature distillation network (FDN) for reducing noise and distilling aspect-relevant sentiment features. A novel double-gate mechanism is designed to implement the interactions between aspects and their corresponding contexts at a fine granularity. We introduce a contextual nonlinear projection layer before the double-gate mechanism to generate aspect-specific word representations, which enables the double-gate mechanism to accurately distinguish between sentiment features of the same context word that corresponds to the different aspects. Experiments show that the FDN achieves state-of-the-art performance and improves accuracy from 1.0 percent to 2.0 percent on all benchmarks for ABSA task. © 2020","Aspect-Based sentiment analysis; Bidirectional long short-Term memory; Gating mechanism; Neural network"
"Reaching a minimum adjustment consensus in social network group decision-making","2020","Information Fusion","10.1016/j.inffus.2020.01.004","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078143421&doi=10.1016%2fj.inffus.2020.01.004&partnerID=40&md5=69e2af6f6d9d6025e638c58b2eef4112","In this paper, we propose a minimum adjustment consensus framework for the social network group decision-making (SN-GDM) with incomplete linguistic preference relations (ILPRs). The extant studies ignore the influence of network structure on the decision-makers’ (DMs’) weights, and set a fixed parameter to adjust DM's preferences that may lead to the inefficiency of reaching a consensus. To solve these issues, we first propose a weight allocation method with the structural hole theory by analyzing the tie strength and topology structure of DM's social networks. After obtaining DMs’ weights, the consistency/consensus indexes at three levels are constructed and used to identify the inconsistent DMs. Then, a novel minimum adjustment consensus model (MACM) for ILPRs is proposed to obtain the optimal adjustment parameters, which are used to recommend customized adjustments in the feedback mechanism. The existence of optimal solutions and the convergence of the proposed consensus models under certain conditions are also proved. Finally, the validity of the proposed method is verified by an application example. Different from the extant MACMs, we optimized the adjustment parameters just for inconsistent DMs instead of all DMs’ adjusted preference values. With less number of consensus rounds and lower costs, we also improved the classical feedback mechanism and established its connection with the current MACMs. © 2020","Consensus reaching process; Incomplete linguistic preference relations; Minimum adjustment; Optimal feedback mechanism; Social network group decision-making; Weight allocation"
"Emotional editing constraint conversation content generation based on reinforcement learning","2020","Information Fusion","10.1016/j.inffus.2019.10.007","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85073566230&doi=10.1016%2fj.inffus.2019.10.007&partnerID=40&md5=d24b953b8a4eff433331ad9a0d4c4971","In recent years, the generation of conversation content based on deep neural networks has attracted many researchers. However, traditional neural language models tend to generate general replies, lacking logical and emotional factors. This paper proposes a conversation content generation model that combines reinforcement learning with emotional editing constraints to generate more meaningful and customizable emotional replies. The model divides the replies into three clauses based on pre-generated keywords and uses the emotional editor to further optimize the final reply. The model combines multi-task learning with multiple indicator rewards to comprehensively optimize the quality of replies. Experiments shows that our model can not only improve the fluency of the replies, but also significantly enhance the logical relevance and emotional relevance of the replies. © 2019 Elsevier B.V.","Affective computing; Emotional conversation generation; Emotional editing; Multitask learning; Reinforcement learning"
"CochleaNet: A robust language-independent audio-visual model for real-time speech enhancement","2020","Information Fusion","10.1016/j.inffus.2020.04.001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088642963&doi=10.1016%2fj.inffus.2020.04.001&partnerID=40&md5=615a4a23f4527806598f09e80c47ac79","Noisy situations cause huge problems for the hearing-impaired, as hearing aids often make speech more audible but do not always restore intelligibility. In noisy settings, humans routinely exploit the audio-visual (AV) nature of speech to selectively suppress background noise and focus on the target speaker. In this paper, we present a novel language-, noise- and speaker-independent AV deep neural network (DNN) architecture, termed CochleaNet, for causal or real-time speech enhancement (SE). The model jointly exploits noisy acoustic cues and noise robust visual cues to focus on the desired speaker and improve speech intelligibility. The proposed SE framework is evaluated using a first of its kind AV binaural speech corpus, ASPIRE, recorded in real noisy environments, including cafeteria and restaurant settings. We demonstrate superior performance of our approach in terms of both objective measures and subjective listening tests, over state-of-the-art SE approaches, including recent DNN based SE models. In addition, our work challenges a popular belief that scarcity of a multi-lingual, large vocabulary AV corpus and a wide variety of noises is a major bottleneck to build robust language, speaker and noise-independent SE systems. We show that a model trained on a synthetic mixture of the benchmark GRID corpus (with 33 speakers and a small English vocabulary) and CHiME 3 noises (comprising bus, pedestrian, cafeteria, and street noises) can generalise well, not only on large vocabulary corpora with a wide variety of speakers and noises, but also on completely unrelated languages such as Mandarin. © 2020 Elsevier B.V.","Audio-Visual; Deep learning; Hearing aids; Language-independent; Multi-modal; Noise-independent; Real noisy audio-visual corpus; Speaker independent; Speech enhancement; Speech separation"
"Random forest explainability using counterfactual sets","2020","Information Fusion","10.1016/j.inffus.2020.07.001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85087720092&doi=10.1016%2fj.inffus.2020.07.001&partnerID=40&md5=9cd813087edb044872044bc4d6de6af3","Nowadays, Machine Learning (ML) models are becoming ubiquitous in today's society, supporting people with their day-to-day decisions. In this context, Explainable ML is a field of Artificial Intelligence (AI) that focuses on making predictive models and their decisions interpretable by humans, enabling people to trust predictive models and to understand the underlying processes. A counterfactual is an effective type of Explainable ML technique that explains predictions by describing the changes needed in a sample to flip the outcome of the prediction. In this paper, we introduce counterfactual sets, an explanation approach that uses a set of counterfactuals to explain a prediction rather than a single counterfactual, by defining a sub-region of the feature space where the counterfactual holds. A method to extract counterfactual sets from a Random Forest (RF), the RandomForestOptimalCounterfactualSetExtractor(RF−OCSE), is presented. The method is based on a partial fusion of tree predictors from a RF into a single Decision Tree (DT) using a modification of the CART algorithm, and it obtains a counterfactual set that contains the optimal counterfactual. The proposal is validated through several experiments against existing alternatives on ten well-known datasets by comparing the percentage of valid counterfactuals, distance to the factual sample, and counterfactual sets quality. © 2020","Counterfactual; Counterfactual sets; Decision tree; Explainable machine learning; Information fusion; Random forest"
"Learning to fuse local geometric features for 3D rigid data matching","2020","Information Fusion","10.1016/j.inffus.2020.03.008","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082872086&doi=10.1016%2fj.inffus.2020.03.008&partnerID=40&md5=25b3f3fb313e0fd191e91ea82df28068","This paper presents a simple yet very effective data-driven approach to fuse both low-level and high-level local geometric features for 3D rigid data matching. It is a common practice to generate distinctive geometric descriptors by fusing low-level features from various viewpoints or subspaces, or enhance geometric feature matching by leveraging multiple high-level features. In prior works, they are typically performed via linear operations such as concatenation and min pooling. We show that more compact and distinctive representations can be achieved by optimizing a neural network (NN) model under the triplet framework that non-linearly fuses local geometric features in Euclidean spaces. The NN model is trained by an improved triplet loss function that fully leverages all pairwise relationships within the triplet. Moreover, the fused descriptor by our approach is also competitive to deep learned descriptors from raw data while being more lightweight and rotational invariant. Experimental results on four standard datasets with various data modalities and application contexts confirm the advantages of our approach in terms of both feature matching and geometric registration. © 2020 Elsevier B.V.","Deep learning; Feature fusion; Feature matching; Local geometric feature; Point cloud registration"
"Managing classification-based consensus in social network group decision making: An optimization-based approach with minimum information loss","2020","Information Fusion","10.1016/j.inffus.2020.05.008","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086504617&doi=10.1016%2fj.inffus.2020.05.008&partnerID=40&md5=bfb1ef64ae0038e685a22329acde21e1","This study proposes a classification-based consensus framework in social network group decision making, which aims to classify alternatives into several ordinal classes from best to worst. In the classification-based consensus framework, a maximum consensus-based optimization model is devised to determine the weight of decision makers by linearly combining three reliable sources: in-degree centrality, consistency and similarity indexes. This is done by maximizing the consensus level among decision makers regarding the collective classification of alternatives. Following this, a minimum information loss-based optimization model is constructed to generate the consensual collective classification of alternatives. It seeks to minimize the information loss between the additive preference relations provided by decision makers and their preference vectors. Particularly, the proposed optimization models are converted into 0–1 mixed linear programming models to easily find their optimal solutions. Finally, a numerical example and a detailed comparison analysis are provided to show the effectiveness of the proposed approach. © 2020 Elsevier B.V.","Alternative classification; Consensus; Group decision making; Minimum information loss; Optimization model; Social network"
"Entropy-driven data aggregation method for energy-efficient wireless sensor networks","2020","Information Fusion","10.1016/j.inffus.2019.10.008","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85073756689&doi=10.1016%2fj.inffus.2019.10.008&partnerID=40&md5=b6f90158f750265a609d38a17295a573","Data aggregation is one of the essential and fundamental processes in Wireless Sensor Networks (WSNs). When and how to gather data from the sensors to the sink has a direct impact on the lifetime of the WSNs because the energy consumption is proportion to the frequency of data transmission. In general, sensors in a WSN are randomly distributed for creating a massive coverage WSN environment within a short period. Because the sensors nearby the sink are responsible for more data forwarding tasks, they normally have much shorter lifetime than those located away from the sink. Once all sensors nearby the sink run out of energy, the data collected from the terminal sensors can not reach the sink because all established connections to the sink are broken, which is called the termination of a WSN lifetime. This paper proposes a strategy with multiple algorithms for deploying sensors aiming at maximizing a WSN lifetime. The proposed Entropy-driven Data Aggregation with Gradient Distribution (EDAGD) deployment strategy contains three algorithms: (1) multihop tree-based data aggregation, (2) entropy-driven aggregation tree-based routing algorithm and (3) gradient deployment algorithm. The numerical and experimental results indicating that the proposed EDAGD method outperforms the conventional algorithm with the random deployment strategy. © 2019 Elsevier B.V.","Data aggregation; Entropy-driven; Gradient; WSN"
"Emotion recognition using multi-modal data and machine learning techniques: A tutorial and review","2020","Information Fusion","10.1016/j.inffus.2020.01.011","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85079047781&doi=10.1016%2fj.inffus.2020.01.011&partnerID=40&md5=29ab8c30b26dc7bc5c5968463baf9a63","In recent years, the rapid advances in machine learning (ML) and information fusion has made it possible to endow machines/computers with the ability of emotion understanding, recognition, and analysis. Emotion recognition has attracted increasingly intense interest from researchers from diverse fields. Human emotions can be recognized from facial expressions, speech, behavior (gesture/posture) or physiological signals. However, the first three methods can be ineffective since humans may involuntarily or deliberately conceal their real emotions (so-called social masking). The use of physiological signals can lead to more objective and reliable emotion recognition. Compared with peripheral neurophysiological signals, electroencephalogram (EEG) signals respond to fluctuations of affective states more sensitively and in real time and thus can provide useful features of emotional states. Therefore, various EEG-based emotion recognition techniques have been developed recently. In this paper, the emotion recognition methods based on multi-channel EEG signals as well as multi-modal physiological signals are reviewed. According to the standard pipeline for emotion recognition, we review different feature extraction (e.g., wavelet transform and nonlinear dynamics), feature reduction, and ML classifier design methods (e.g., k-nearest neighbor (KNN), naive Bayesian (NB), support vector machine (SVM) and random forest (RF)). Furthermore, the EEG rhythms that are highly correlated with emotions are analyzed and the correlation between different brain areas and emotions is discussed. Finally, we compare different ML and deep learning algorithms for emotion recognition and suggest several open problems and future research directions in this exciting and fast-growing area of AI. © 2020","Affective computing; Data fusion; Deep learning; Emotion recognition; Feature dimensionality reduction; Machine learning; Physiological signals"
"Renewable energy harvesting schemes in wireless sensor networks: A Survey","2020","Information Fusion","10.1016/j.inffus.2020.07.005","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85087626678&doi=10.1016%2fj.inffus.2020.07.005&partnerID=40&md5=d2562c2dd6d5f327ce535ad6b4881371","Wireless Sensor Networks (WSNs) are emerging as they demands for various applications, for example, military surveillance, home automation, vehicle tracking, environmental monitoring, wildlife tracking, health monitoring, and scientific exploration. Usually, sensor nodes operate with limited battery capacity. Using conventional batteries, it is not always efficient to design long-lasting sensor networks. Moreover, the replacement of the batteries is too challenging to operate in harsh environmental conditions. Therefore, to overcome, one such technique is to recharge the battery of sensor nodes using an energy harvesting system. On the other hand, some of the existing energy harvesting WSNs still lacking the intelligent strategy for judiciously utilizing both the energy management and harvesting system. The review work we present is categorized into energy management and renewable energy harvesting techniques. In energy management techniques, we discuss various methods to save energy consumption of the energy harvesting sensor networks. Notably, we study their protocol design strategies for energy-saving and essential strategies such as prediction for maximizing the energy harvesting of the sensor nodes. We also summarize their shortcomings and ability to deal with the energy harvesting system. In renewable energy harvesting schemes, we present various energy harvesting mechanisms such as solar, wind and others. We also discuss the different energy harvesting mechanisms, especially their protocol design strategies for maximizing energy harvesting, and summarize their merits and demerits. The work also discusses various challenging issues for energy harvesting WSNs followed by future research directions, and some recent applications. © 2020","Energy harvesting awareness; Energy management; Renewable energy harvesting; Solar energy harvesting; Wind energy harvesting; Wireless sensor networks"
"The four dimensions of social network analysis: An overview of research methods, applications, and software tools","2020","Information Fusion","10.1016/j.inffus.2020.05.009","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086564650&doi=10.1016%2fj.inffus.2020.05.009&partnerID=40&md5=01e8636316ba0784969fcee061a56cd5","Social network based applications have experienced exponential growth in recent years. One of the reasons for this rise is that this application domain offers a particularly fertile place to test and develop the most advanced computational techniques to extract valuable information from the Web. The main contribution of this work is three-fold: (1) we provide an up-to-date literature review of the state of the art on social network analysis (SNA); (2) we propose a set of new metrics based on four essential features (or dimensions) in SNA; (3) finally, we provide a quantitative analysis of a set of popular SNA tools and frameworks. We have also performed a scientometric study to detect the most active research areas and application domains in this area. This work proposes the definition of four different dimensions, namely Pattern & Knowledge discovery, Information Fusion & Integration, Scalability, and Visualization, which are used to define a set of new metrics (termed degrees) in order to evaluate the different software tools and frameworks of SNA (a set of 20 SNA-software tools are analyzed and ranked following previous metrics). These dimensions, together with the defined degrees, allow evaluating and measure the maturity of social network technologies, looking for both a quantitative assessment of them, as to shed light to the challenges and future trends in this active area. © 2020 Elsevier B.V.","Big data; Data science; Social data visualization; Social media mining; Social network analysis"
"Pan-GAN: An unsupervised pan-sharpening method for remote sensing image fusion","2020","Information Fusion","10.1016/j.inffus.2020.04.006","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084634225&doi=10.1016%2fj.inffus.2020.04.006&partnerID=40&md5=dedd4ce965c307d547a20af2658b9785","Pan-sharpening in remote sensing image fusion refers to obtaining multi-spectral images of high-resolution by fusing panchromatic images and multi-spectral images of low-resolution. Recently, convolution neural network (CNN)-based pan-sharpening methods have achieved the state-of-the-art performance. Even though, two problems still remain. On the one hand, the existing CNN-based strategies require supervision, where the low-resolution multi-spectral image is obtained by simply blurring and down-sampling the high-resolution one. On the other hand, they typically ignore rich spatial information of panchromatic images. To address these issues, we propose a novel unsupervised framework for pan-sharpening based on a generative adversarial network, termed as Pan-GAN, which does not rely on the so-called ground-truth during network training. In our method, the generator separately establishes the adversarial games with the spectral discriminator and the spatial discriminator, so as to preserve the rich spectral information of multi-spectral images and the spatial information of panchromatic images. Extensive experiments are conducted to demonstrate the effectiveness of the proposed Pan-GAN compared with other state-of-the-art pan-sharpening approaches. Our Pan-GAN has shown promising performance in terms of qualitative visual effects and quantitative evaluation metrics. © 2020 Elsevier B.V.","Deep learning; Generative adversarial network; Image fusion; Pan-sharpening; Unsupervised learning"
"Multi-level information fusion to alleviate network congestion","2020","Information Fusion","10.1016/j.inffus.2020.06.006","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85087943431&doi=10.1016%2fj.inffus.2020.06.006&partnerID=40&md5=860c309bc48b6fc0dc44ddd1f8814bff","While increasing urban traffic can be an indicator of development, this inevitably results in traffic congestion in urban road networks. Is there a way to manage traffic flow through the control of traffic signals such that the overall network congestion is improved? Traffic light signals can be represented as two states of an Ising model. It is possible for traffic lights to ”communicate” with each other through a fusion process from a remote management control system. This requires collection of information which can be fed to a centralized decision-making control mechanism. We first explore the fusion process between traffic signals and show that it is possible for traffic flow in a city to follow the phase transition as exhibited in the 2D Ising model. The model will be extended to show that a random switching between signalling control mechanisms can result in congested traffic being susceptible to transit out of congestion. © 2020 Elsevier B.V.","Fusion process; Information flow; Ising model; Social dynamics; Traffic network; Urban flow"
"DependData: Data collection dependability through three-layer decision-making in BSNs for healthcare monitoring","2020","Information Fusion","10.1016/j.inffus.2020.03.004","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083706225&doi=10.1016%2fj.inffus.2020.03.004&partnerID=40&md5=a32830f6a6adc49aaf03495db43652dd","Recently, there have been extensive studies on applying security and privacy protocols in Body Sensor Networks (BSNs) for patient healthcare monitoring (BSN-Health). Though these protocols provide adequate security to data packets, the collected data may still be compromised at the time of acquisition and before aggregation/storage in the severely resource-constrained BSNs. This leads to data collection frameworks being meaningless or undependable, i.e., an undependable BSN-Health. We study data dependability concerns in the BSN-Health and propose a data dependability verification framework named DependData with the objective of verifying data dependability through the decision-making in three layers. The 1st decision-making (1-DM) layer verifies signal-level data at each health sensor of the BSN locally to guarantee that collected signals ready for processing and transmission are dependable so that undependable processing and transmission in the BSN can be avoided. The 2nd decision-making (2-DM) layer verifies data before aggregation at each local aggregator (like clusterhead) of the BSN to guarantee that data received for aggregation is dependable so that undependable data aggregation can be avoided. The 3rd decision-making (3-DM) layer verifies the stored data before the data appears to a remote healthcare data user to guarantee that data available to the owner end (such as smartphone) is dependable so that undependable information viewing can be avoided. Finally, we evaluate the performance of DependData through simulations regarding 1-DM, 2-DM, and 3-DM and show that up to 92% of data dependability concerns can be detected in the three layers. To the best of our knowledge, DependData would be the first framework to address data dependability aside from current substantial studies of security and privacy protocols. We believe the three layers decision-making framework would attract a wide range of applications in the future. © 2020 Elsevier B.V.","Body sensor networks; Data dependability; Data quality; Decision-making; Dependability; Healthcare monitoring; Security and privacy"
"Predicting and ranking box office revenue of movies based on big data","2020","Information Fusion","10.1016/j.inffus.2020.02.002","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85080968158&doi=10.1016%2fj.inffus.2020.02.002&partnerID=40&md5=17b534fef3acc090fe9dbcf9365f8398","Predicting box office revenue (BOR) of movies before releasing on big screens successfully becomes an emerging need, as it informs investment decisions on the stock market, the design of promotion strategies by advertisement companies, movie scheduling by cinemas, etc. However, the task is very challenging as it is affected by a lot of complex factors. In this paper, we first provide a strategic investigation of these influential factors. Then, we put forward a novel framework to predict a movie's BOR by modeling these factors using big data. Specifically, the framework consists of a series of feature learning models and a prediction and ranking model. In particular, there are two models devised for learning features: (1) a novel dynamic heterogeneous network embedding model to simultaneously learn latent representations of actors, directors, and companies, capable of capturing their cooperation relationship collectively; (2) a deep neural network-based model designed to uncover high-level representations of movie quality from trailers. Based on the learned features, we train a mutually-enhanced prediction and ranking model to obtain the BOR prediction results. Finally, we apply the framework to the Chinese film market and conduct a comprehensive performance evaluation using real-world data. Experimental results demonstrate the superior performance of both extracted knowledge and the prediction results. © 2020 Elsevier B.V.","Big data; Data fusion; Dynamic network embedding; Feature learning; Heterogeneous information network"
"Multi-level information fusion for learning a blood pressure predictive model using sensor data","2020","Information Fusion","10.1016/j.inffus.2019.12.008","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077336322&doi=10.1016%2fj.inffus.2019.12.008&partnerID=40&md5=4e6148885c8f8f35a0a6b5c2bf757a67","The availability of commercial wearable bio-sensors provides an opportunity for developing smart phone applications for real-time diagnosis that can be used to improve the health of the user. We propose a multi-level information fusion approach for learning a predictive model for blood pressure (BP) using electrocardiogram (ECG) sensor data. The approach fuses the information on five different levels: i) data collection, where data from multiple ECG sensors is collected; ii) feature extraction, where features are extracted from the collected data by different preprocessing methods; iii) information fusion, fusing the evaluation information from different classifiers; iv) information fusion using the information from multi-target regression models for each BP class; and v) information fusion using the information from multi-target regression models from all configurations as a single model. This is used for predicting the blood pressure values (systolic BP (SBP), diastolic BP (DBP), and mean arterial pressure (MAP)). Evaluating the methodology by using a separate test set indicates that the multi-level information fusion provides promising results, which are acceptable and comparable to the state-of-the-art results obtained for blood pressure prediction. © 2019 The Authors","Blood pressure prediction; Data fusion; Information fusion; Performance metric fusion; Sensor fusion"
"Prospect theory-based group decision-making with stochastic uncertainty and 2-tuple aspirations under linguistic assessments","2020","Information Fusion","10.1016/j.inffus.2019.10.001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85073475502&doi=10.1016%2fj.inffus.2019.10.001&partnerID=40&md5=3d0fbd46db9e2c6430b7fc37844a3da5","Linguistic distribution assessments with probabilistic information are a flexible means to express the opinions of decision makers (DMs) with importance degree of each linguistic term. Therefore, research on multi-attribute group decision making (MAGDM) problems with linguistic distribution assessments is increasing. However, the probability distribution is usually only partially known. In order to obtain the complete probability distribution information, we propose the concept of stochastic linguistic term (SLT) with the aid of stochastic analysis. The SLT is an extension of general linguistic terms. Linguistic assessments with different models can be expressed as SLTs with complete probability distributions. Then the weighted averaging operator and score function of SLTs are presented. Considering the psychological behavior of DMs in decision making, we combine prospect theory and SLTs to handle uncertainty in MAGDM problems. Considering 2-tuple aspirations on attributes, a new MAGDM method with stochastic uncertainty based on prospect theory under linguistic assessments is proposed. Finally, a numeric example and comparative analysis illustrate the effectiveness and feasibility of the proposed method. © 2019 Elsevier B.V.","2-tuple aspirations; Linguistic distribution assessments; Multi-attribute group decision making (MAGDM); Prospect theory; Stochastic linguistic term (SLT)"
"Urban flow prediction from spatiotemporal data using machine learning: A survey","2020","Information Fusion","10.1016/j.inffus.2020.01.002","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077950724&doi=10.1016%2fj.inffus.2020.01.002&partnerID=40&md5=290c9086c19e700312511f065ddcc99d","Urban spatiotemporal flow prediction is of great importance to traffic management, land use, public safety. This prediction task is affected by several complex and dynamic factors, such as patterns of human activities, weather, events, and holidays. Datasets evaluated the flow come from various sources in different domains, e.g. mobile phone data, taxi trajectories data, metro/bus swiping data, bike-sharing data. To summarize these methodologies of urban flow prediction, in this paper, we first introduced four main factors affecting urban flow. Second, in order to further analyze urban flow, we partitioned the preparation process of multi-source spatiotemporal data related with urban flow into three groups. Third, we chose the spatiotemporal dynamic data as a case study for the urban flow prediction task. Fourth, we analyzed and compared some representative flow prediction methods in detail, classifying them into five categories: statistics-based, traditional machine learning-based, deep learning-based, reinforcement learning-based, and transfer learning-based methods. Finally, we showed open challenges of urban flow prediction and discussed many recent research works on urban flow prediction. This paper will facilitate researchers to find suitable methods and public datasets for addressing urban spatiotemporal flow forecast problems. © 2020 Elsevier B.V.","Data fusion; Deep learning; Spatiotemporal data mining; Urban computing; Urban flow prediction"
"Ringing artifacts in wavelet based image fusion: Analysis, measurement and remedies","2020","Information Fusion","10.1016/j.inffus.2019.10.003","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85073498727&doi=10.1016%2fj.inffus.2019.10.003&partnerID=40&md5=beaa5272193c13ecfcabcc5e40b5f9b1","In this paper, we investigate an issue of the ringing artifacts inherent to wavelet based image fusion. A thorough analysis of the ringing phenomenon, by experimenting with different types of images and different wavelet families, with varying lengths of filters and varying levels of decomposition is performed to obtain deeper insights of the ringing artifacts. It is experimentally shown that wavelet based fusion results in the modification of the intra- and inter-scale dependencies, with the inter-scale dependency being the dominating factor causing the ringing artifacts. Also, these ringing artifacts are localized in the Fourier domain. Subsequently, a quantitative measure using structural dissimilarity is proposed to measure the ringing artifacts due to wavelet based fusion. Two possible solutions to compensate for the ringing artifacts are then proposed. In the first strategy, a filtering based method is proposed to reduce these ringing artifacts. It takes advantage of the localized nature of the ringing artifacts. Furthermore, the intra- and inter-scale dependencies are modeled using order-zero entropy. A second strategy using the inter-scale dependency is then proposed to reduce the ringing artifacts. Experimental results show that both these methods are able to reduce the ringing artifacts significantly and have further scope for improvement. Another critical finding of this work is selection of the wavelet filter and its levels of decomposition for the process of fusion. © 2019 Elsevier B.V.","Image fusion; Inter-scale dependency; Intra-scale dependency; Ringing artifacts; Structural dissimilarity; Wavelets"
"An overview on spectral and spatial information fusion for hyperspectral image classification: Current trends and challenges","2020","Information Fusion","10.1016/j.inffus.2020.01.007","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078216215&doi=10.1016%2fj.inffus.2020.01.007&partnerID=40&md5=3ae495e85f0f518d7a9e8387d4ebd00f","Hyperspectral images (HSIs) have a cube form containing spatial information in two dimensions and rich spectral information in the third one. The high volume of spectral bands allows discrimination between various materials with high details. Moreover, by utilizing the spatial features of image such as shape, texture and geometrical structures, the land cover discrimination will be improved. So, fusion of spectral and spatial information can significantly improve the HSI classification. In this work, the spectral-spatial information fusion methods are categorized into three main groups. The first group contains segmentation based methods where objects or super-pixels are used instead of pixels for classification or the obtained segmentation map is used for relaxation of the pixel-wise classification map. The second group consists of feature fusion methods which are divided into six sub-groups: features stacking, joint spectral-spatial feature extraction, kernel based classifiers, representation based classifiers, 3D spectral-spatial feature extraction and deep learning based classifiers. The third fusion methods are decision fusion based approaches where complementary information of several classifiers are contributed for achieving the final classification map. A review of different methods in each category, is presented. Moreover, the advantages and difficulties/disadvantages of each group are discussed. The performance of various fusion methods are assessed in terms of classification accuracy and running time using experiments on three popular hyperspectral images. The results show that the feature fusion methods although are time consuming but can provide superior classification accuracy compared to other methods. Study of this work can be very useful for all researchers interested in HSI feature extraction, fusion and classification. © 2020","Classification; Decision fusion; Feature fusion; Hyperspectral image"
"Continual learning for robotics: Definition, framework, learning strategies, opportunities and challenges","2020","Information Fusion","10.1016/j.inffus.2019.12.004","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077515262&doi=10.1016%2fj.inffus.2019.12.004&partnerID=40&md5=a68bff17452022cb32d567373368f714","Continual learning (CL) is a particular machine learning paradigm where the data distribution and learning objective change through time, or where all the training data and objective criteria are never available at once. The evolution of the learning process is modeled by a sequence of learning experiences where the goal is to be able to learn new skills all along the sequence without forgetting what has been previously learned. CL can be seen as an online learning where knowledge fusion needs to take place in order to learn from streams of data presented sequentially in time. Continual learning also aims at the same time at optimizing the memory, the computation power and the speed during the learning process. An important challenge for machine learning is not necessarily finding solutions that work in the real world but rather finding stable algorithms that can learn in real world. Hence, the ideal approach would be tackling the real world in a embodied platform: an autonomous agent. Continual learning would then be effective in an autonomous agent or robot, which would learn autonomously through time about the external world, and incrementally develop a set of complex skills and knowledge.Robotic agents have to learn to adapt and interact with their environment using a continuous stream of observations. Some recent approaches aim at tackling continual learning for robotics, but most recent papers on continual learning only experiment approaches in simulation or with static datasets. Unfortunately, the evaluation of those algorithms does not provide insights on whether their solutions may help continual learning in the context of robotics. This paper aims at reviewing the existing state of the art of continual learning, summarizing existing benchmarks and metrics, and proposing a framework for presenting and evaluating both robotics and non robotics approaches in a way that makes transfer between both fields easier. We put light on continual learning in the context of robotics to create connections between fields and normalize approaches. © 2019","Catastrophic Forgetting; Continual Learning; Deep Learning; Lifelong Learning; Reinforcement Learning; Robotics"
"Hyperspectral image visualization with edge-preserving filtering and principal component analysis","2020","Information Fusion","10.1016/j.inffus.2019.12.003","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076831900&doi=10.1016%2fj.inffus.2019.12.003&partnerID=40&md5=bf9e6ff66ad4c3be3b9dc6a1a886e7f1","In this paper, an edge-preserving filtering and principal component analysis (PCA)-based visualization method is proposed for hyperspectral images, in which both global and local image information of hyperspectral images (HSIs) are taken into account in the proposed visualization framework that consists of the following major steps. First, the band number of the original image is reduced with averaging-based image fusion (AIF). Then, the edge-preserving filtering is performed on the dimension reduced image so as to decompose it into two components, i.e., the base layers which contain the large-scale boundary information, and the detail layers which contain the mid- and small-scale edges and textures. Next, the base layers are fused with the principal component analysis method, and the detail layers are fused with the weighted sum method, in which the fusion weights are determined by the transform matrix of the base layers. Finally, the fused detail layers are enhanced with histogram equalization and combined with the fused base layers to visualize the hyperspectral image. Experimental results on four real hyperspectral data sets demonstrate that the proposed approach performs the best in improving image contrast and preserving the details. In addition, compared with seven state-of-the-art visualization methods, the quantitative metrics obtained by the proposed method on four data sets have been increased by 80.45%, 69.29%, 138.61%, and 23.21% on average in terms of separability of features (SF), standard deviation (SD), average gradient (AG), and entropy (EN). © 2019","Dimension reduction; Edge-preserving filtering; Hyperspectral image visualization; Principal component analysis"
"Fusing wearable and remote sensing data streams by fast incremental learning with swarm decision table for human activity recognition","2020","Information Fusion","10.1016/j.inffus.2020.02.001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081134400&doi=10.1016%2fj.inffus.2020.02.001&partnerID=40&md5=deca735b3b288afc6ed1dbc7831cbb2d","Human activity recognition (HAR) by machine learning finds wide applications ranging from posture monitoring for healthcare and rehabilitation to suspicious or dangerous actions detection for security surveillance. Infrared cameras such as Microsoft Kinect and wearable sensors have been the two most adopted devices for collecting data for measuring the bodily movements. These two types of sensors generally are categorized as contactless sensing and contact sensing respectively. Due to hardware limitation, each of the two sensor types has their inherent limitations. One most common problem associating with contactless sensing like Kinect is the distance and indirect angle between the camera and the subject. For wearable sensor, it is limited in recognizing complex human activities. In this paper, a novel data fusion framework is proposed for combining data which are collected from both sensors with the aim of enhancing the HAR accuracy. Kinect is able to capture details of bodily movements from complex activities, but the accuracy is dependent heavily on the angle of view; wearable sensor is relatively primitive in gathering spatial data but reliable for detecting basic movements. Fusing the data from the two sensor types enables complimenting each other by their unique strengths. In particular, a new scheme using incremental learning with decision table coupled with swarm-based feature selection is proposed in our framework for achieving fast and accurate HAR by fusing data of two sensors. Our experiment results show that HAR accuracy could be improved from 23.51% to 68.35% in a case of almost 90 degrees slanted view of Kinect sensing while a wearing sensor is used at the same time. The swarm feature selection in general is shown to enhance the HAR performance compared to standard feature selection method. The experiment results reported here contribute to the possibilities of using hybridized sensors from the machine learning perspective. © 2020","Classification model; Data mining; Feature selection; Kinect depth sensor; Wearable sensor"
"DeciTrustNET: A graph based trust and reputation framework for social networks","2020","Information Fusion","10.1016/j.inffus.2020.03.006","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083024260&doi=10.1016%2fj.inffus.2020.03.006&partnerID=40&md5=d92bce83d7623c3db977e6cbf5701b4d","The world wide success of large scale social information systems with diverse purposes, such as e-commerce platforms, facilities sharing communities and social networks, make them a very promising paradigm for large scale information sharing and management. However the anonymity, distributed and open nature of these frameworks, that, on the one hand, foster the communication capabilities of their users, may contribute, on the other hand, to the propagation of low quality information, attacks and manipulations from users with malicious intentions. All of these risks could end up decreasing users’ confidence in these systems and in a reduction of their utilisation. With these issues in mind, the objective of this contribution is to create DeciTrustNET, a trust and reputation based framework for social networks that takes into consideration the users relationships, the historic evolution of their reputations and their profile similarity to develop a tamper resilient network that guarantees trustworthy communications and transactions. An extensive experimental analysis of the developed framework has been carried out confirming that the proposed approach supports robust trust and reputation establishment among the users, even in social network under the presence of malicious users. © 2020 Elsevier B.V.","Decision making; Influence; Opinion dynamics; Reputation; Social networks; Trust"
"Multi-sensor fusion for body sensor network in medical human–robot interaction scenario","2020","Information Fusion","10.1016/j.inffus.2019.11.001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074973742&doi=10.1016%2fj.inffus.2019.11.001&partnerID=40&md5=6c641503fc7058ae389124fdadd483af","With the development of sensor and communication technologies, body sensor networks(BSNs) have become an indispensable part of smart medical services by monitoring the real-time state of users. Due to introducing of smart medical robots, BSNs are not related to users, but also responsible for data acquisition and multi-sensor fusion in medical human–robot interaction scenarios. In this paper, a hybrid body sensor network architecture based on multi-sensor fusion(HBMF) is designed to support the most advanced smart medical services, which combines various sensor, communication, robot, and data processing technologies. The infrastructure and system functions are described in detail and compared with other architectures. Especially, A multi-sensor fusion method based on interpretable neural network(MFIN) for BSNs in medical human–robot interaction scenario is designed and analyzed to improve the performance of fusion decision-making. Compared with the current multi-sensor fusion methods, our design guarantees both the flexibility and reliability of the service in the medical human–robot interaction scenario. © 2019 Elsevier B.V.","Body sensor network; Fusion decision; Medical human–robot interaction; Multi-sensor fusion; Neural network"
"Stacked penalized logistic regression for selecting views in multi-view learning","2020","Information Fusion","10.1016/j.inffus.2020.03.007","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083289753&doi=10.1016%2fj.inffus.2020.03.007&partnerID=40&md5=6c32769c57ca54cf6da949e0475ddd49","In biomedical research, many different types of patient data can be collected, such as various types of omics data and medical imaging modalities. Applying multi-view learning to these different sources of information can increase the accuracy of medical classification models compared with single-view procedures. However, collecting biomedical data can be expensive and/or burdening for patients, so that it is important to reduce the amount of required data collection. It is therefore necessary to develop multi-view learning methods which can accurately identify those views that are most important for prediction. In recent years, several biomedical studies have used an approach known as multi-view stacking (MVS), where a model is trained on each view separately and the resulting predictions are combined through stacking. In these studies, MVS has been shown to increase classification accuracy. However, the MVS framework can also be used for selecting a subset of important views. To study the view selection potential of MVS, we develop a special case called stacked penalized logistic regression (StaPLR). Compared with existing view-selection methods, StaPLR can make use of faster optimization algorithms and is easily parallelized. We show that nonnegativity constraints on the parameters of the function which combines the views play an important role in preventing unimportant views from entering the model. We investigate the performance of StaPLR through simulations, and consider two real data examples. We compare the performance of StaPLR with an existing view selection method called the group lasso and observe that, in terms of view selection, StaPLR is often more conservative and has a consistently lower false positive rate. © 2020 Elsevier B.V.","Feature selection; Group lasso; Multi-view learning; Stacked generalization"
"Image denoising review: From classical to state-of-the-art approaches","2020","Information Fusion","10.1016/j.inffus.2019.09.003","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072219831&doi=10.1016%2fj.inffus.2019.09.003&partnerID=40&md5=ff869e9ff84e08b69ea2d70f91750a3c","At the crossing of the statistical and functional analysis, there exists a relentless quest for an efficient image denoising algorithm. In terms of greyscale imaging, a plethora of denoising algorithms have been documented in the literature, in spite of which the level of functionality of these algorithms still holds margin to acquire desired level of applicability. Quite often noise affecting the pixels in image is Gaussian in nature and uniformly deters information pixels in image. Based on some specific set of assumptions all methods work optimally, however they tend to create artefacts and remove fine structural details under general conditions. This article focuses on classifying and comparing some of the significant works in the field of denoising. © 2019 Elsevier B.V.","Denoising; Filters; Hybrid; PSNR; Spatial; Transform"
"Neural architecture search for image saliency fusion","2020","Information Fusion","10.1016/j.inffus.2019.12.007","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076853749&doi=10.1016%2fj.inffus.2019.12.007&partnerID=40&md5=e0ce327c23d299390da9189f438c3b51","Saliency detection methods proposed in the literature exploit different rationales, visual clues, and assumptions, but there is no single best saliency detection algorithm that is able to achieve good results on all the different benchmark datasets. In this paper we show that fusing different saliency detection algorithms together by exploiting neural network architectures makes it possible to obtain better results. Designing the best architecture for a given task is still an open problem since the existing techniques have some limits with respect to the problem formulation, to the search space, and require very high computational resources. To overcome these problems, in this paper we propose a three-step fusion approach. In the first step, genetic programming techniques are exploited to combine the outputs of existing saliency algorithms using a set of provided operations. Having a discrete search space allows us a fast generation of the candidate solutions. In the second step, the obtained solutions are converted into backbone Convolutional Neural Networks (CNNs) where operations are all implemented with differentiable functions, allowing an efficient optimization of the corresponding parameters (in a continuous space) by backpropagation. In the last step, to enrich the expressiveness of the initial architectures, the networks are further extended with additional operations on intermediate levels of the processing that are once again efficiently optimized through backpropagation. Extensive experimental evaluations show that the proposed saliency fusion approach outperforms the state-of-the-art on the MSRAB dataset and it is able to generalize to unseen data of different benchmark datasets. © 2019","Evolutionary algorithms; Neural architecture search; Saliency fusion"
"A survey on machine learning for data fusion","2020","Information Fusion","10.1016/j.inffus.2019.12.001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076856977&doi=10.1016%2fj.inffus.2019.12.001&partnerID=40&md5=6f331e425befc954ac5e9ce3279c6bd9","Data fusion is a prevalent way to deal with imperfect raw data for capturing reliable, valuable and accurate information. Comparing with a range of classical probabilistic data fusion techniques, machine learning method that automatically learns from past experiences without explicitly programming, remarkably renovates fusion techniques by offering the strong ability of computing and predicting. Nevertheless, the literature still lacks a thorough review of the recent advances of machine learning for data fusion. Therefore, it is beneficial to review and summarize the state of the art in order to gain a deep insight on how machine learning can benefit and optimize data fusion. In this paper, we provide a comprehensive survey on data fusion methods based on machine learning. We first offer a detailed introduction to the background of data fusion and machine learning in terms of definitions, applications, architectures, processes, and typical techniques. Then, we propose a number of requirements and employ them as criteria to review and evaluate the performance of existing fusion methods based on machine learning. Through the literature review, analysis and comparison, we finally come up with a number of open issues and propose future research directions in this field. © 2019 Elsevier B.V.","Data fusion; Fusion criteria; Fusion methods; Machine learning"
"Indic handwritten script identification using offline-online multi-modal deep network","2020","Information Fusion","10.1016/j.inffus.2019.10.010","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074560991&doi=10.1016%2fj.inffus.2019.10.010&partnerID=40&md5=38c8150ecf2790eb40a28eac44a06711","In this paper, we propose a novel approach of word-level Indic script identification using only character-level data in training stage. Our method uses a multi-modal deep network which takes both offline and online modality of the data as input in order to explore the information from both the modalities jointly for script identification task. We take handwritten data in either modality as input and the opposite modality is generated through intermodality conversion. Thereafter, we feed this offline-online modality pair to our network. Hence, along with the advantage of utilizing information from both the modalities, the proposed framework can work for both offline and online script identification which alleviates the need for designing two separate script identification modules for individual modality. We also propose a novel conditional multi-modal fusion scheme to combine the information from offline and online modality which takes into account the original modality of the data being fed to our network and thus it combines adaptively. An exhaustive experimental study has been done on a data set including English(Roman) and 6 other official Indic scripts. Our proposed scheme outperforms traditional classifiers along with handcrafted features and deep learning based methods. Experiment results show that using only character level training data can achieve competitive performance against traditional training using word level data. © 2019 Elsevier B.V.","Character level training.; Deep neural network; Handwritten script identification; Multi-modal learning; Offline and online handwriting"
"Explainable Artificial Intelligence (XAI): Concepts, taxonomies, opportunities and challenges toward responsible AI","2020","Information Fusion","10.1016/j.inffus.2019.12.012","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077515399&doi=10.1016%2fj.inffus.2019.12.012&partnerID=40&md5=720e37936410af916e3efe40346dbeed","In the last few years, Artificial Intelligence (AI) has achieved a notable momentum that, if harnessed appropriately, may deliver the best of expectations over many application sectors across the field. For this to occur shortly in Machine Learning, the entire community stands in front of the barrier of explainability, an inherent problem of the latest techniques brought by sub-symbolism (e.g. ensembles or Deep Neural Networks) that were not present in the last hype of AI (namely, expert systems and rule based models). Paradigms underlying this problem fall within the so-called eXplainable AI (XAI) field, which is widely acknowledged as a crucial feature for the practical deployment of AI models. The overview presented in this article examines the existing literature and contributions already done in the field of XAI, including a prospect toward what is yet to be reached. For this purpose we summarize previous efforts made to define explainability in Machine Learning, establishing a novel definition of explainable Machine Learning that covers such prior conceptual propositions with a major focus on the audience for which the explainability is sought. Departing from this definition, we propose and discuss about a taxonomy of recent contributions related to the explainability of different Machine Learning models, including those aimed at explaining Deep Learning methods for which a second dedicated taxonomy is built and examined in detail. This critical literature analysis serves as the motivating background for a series of challenges faced by XAI, such as the interesting crossroads of data fusion and explainability. Our prospects lead toward the concept of Responsible Artificial Intelligence, namely, a methodology for the large-scale implementation of AI methods in real organizations with fairness, model explainability and accountability at its core. Our ultimate goal is to provide newcomers to the field of XAI with a thorough taxonomy that can serve as reference material in order to stimulate future research advances, but also to encourage experts and professionals from other disciplines to embrace the benefits of AI in their activity sectors, without any prior bias for its lack of interpretability. © 2019","Accountability; Comprehensibility; Data Fusion; Deep Learning; Explainable Artificial Intelligence; Fairness; Interpretability; Machine Learning; Privacy; Responsible Artificial Intelligence; Transparency"
"Aspect terms grouping via fusing concepts and context information","2020","Information Fusion","10.1016/j.inffus.2020.06.007","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086826894&doi=10.1016%2fj.inffus.2020.06.007&partnerID=40&md5=083cbe17a368d2c571e65f2e5f43e6eb","We introduce a neural method that is able to fuse concepts from a knowledge base with the context information for the task of grouping of aspect terms. Rather than only using context information, we use the corresponding concepts of aspect terms as additional information for aspect terms representation. We also introduce a location-based attention mechanism for accurately representing context features. As both the concept and the aspect term are same level features, i.e. aspect level features, we develop a model with gating mechanism to fuse them together. All of the above features are fed into a parallel metric learning network which has the ability to learn an easier grouping representation of samples. Experimental results demonstrate that our approach outperforms different baselines and model variants on five datasets. © 2020 Elsevier B.V.","Aspect grouping; Deep learning; Sentiment analysis; Text feature fusion"
"Optimal group selection model for large-scale group decision making","2020","Information Fusion","10.1016/j.inffus.2020.03.002","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082003073&doi=10.1016%2fj.inffus.2020.03.002&partnerID=40&md5=367b567b17fa4cc1d83d0a5764b42e0c","Research on large-scale group decision making (LSGDM) has generally focused on clustering and reaching a consensus. Often, participants (or decision makers) are unwilling to share their consensus or revise their preferences, which leads to the loss of time and money and even reduces the efficiency of decision making. Accordingly, in LSGDM, an optimal group derived from a large number of participants could improve the decision-making efficiency and reduce time consumption. In this paper, we investigate a model to select the optimal group for LSGDM with multiplicative preference relations. Notably, for individual and group preference relations, we define an individual logarithmic square compatibility measure and a group logarithmic square compatibility measure, respectively. Some properties associated with the individual logarithmic square compatibility measure and group logarithmic square compatibility measure are addressed. For a large number of preferences in LSGDM, the redundant preferences and optimal group are distinguished based on an optimal group selection model using the optimal participant weights obtained by minimizing the group logarithmic square compatibility model. Then, we demonstrate that the model is a convex quadratic programming problem. Moreover, the conditions for the existence of an optimal solution and the conditions for redundant preference relations in the group logarithmic square compatibility model are provided. In this context, the proposed model is verified to effectively identify the optimal group. © 2020","Compatibility measure; Large-scale group decision making; Optimal group; Redundant information"
"Multi-user activity recognition: Challenges and opportunities","2020","Information Fusion","10.1016/j.inffus.2020.06.004","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086711937&doi=10.1016%2fj.inffus.2020.06.004&partnerID=40&md5=e8ca289005afcbd77ed8be6049687383","Human activity recognition has attracted enormous research interest thanks to its fundamental importance in several domains spanning from health-care to security, safety, and entertainment. Robust and consolidated literature focused on the study of activities performed by single individuals, with a great variety of approaches in terms of sensing modalities, recognition techniques, a specific set of recognized activities, and final application objectives. However, much less research attention has been devoted to scenarios in which multiple people perform individual or joint actions and activities forming groups to achieve given common goals. This problem is often referred to as multi-user activity recognition. With the advent of the Internet-of-Things, smart objects are being pervasively spread in the environment and worn on the human body, enabling contextual and distributed recognition of group and multi-user activities. Therefore, this survey discusses clear motivations and advantages of multi-user activity recognition based on sensing methods, recognition approaches, and practical applications with attention to related data fusion challenges and techniques. By identifying the critical aspects of this multi-faceted problem, the survey aims to provide a systematic categorization and comparison framework of the state-of-the-art that drives the discussion to important open research challenges and future directions. © 2020 Elsevier B.V.","Collaboration; Data fusion; Group recognition; Multi-user activity recognition"
"Baptizo: A sensor fusion based model for tracking the identity of human poses","2020","Information Fusion","10.1016/j.inffus.2020.03.011","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083395090&doi=10.1016%2fj.inffus.2020.03.011&partnerID=40&md5=686682a8ab56ae663ea272cb107668a7","Recent advances in the capabilities of computing devices enable new methods to estimate the pose of humans. Human pose estimation techniques are relevant for several industry fields, such as surveillance and interactive entertainment. Further, encoded human poses provide a valuable input for behavioral analysis and activity recognition. Body part detectors offer millimetric accuracy thanks to state-of-the-art Computer Vision technology. However, they still suffer from issues, such as long-term occlusion, that hinder the identification of human subjects. Such problems are intrinsic to Computer Vision devices and can only be solved either with the use of heuristic methods or the deployment of more cameras, which are not always feasible. In turn, radiofrequency-based tracking systems do not suffer from occlusion or identity loss problems and, albeit not as precise as Computer Vision methods, can achieve a high accuracy level. Radiofrequency positioning systems and human pose estimation techniques can complement each other in different ways. For example, the prior can help to identify tracked humans and reduce occlusion errors, while the later can increase the accuracy of obtained positions. Thus, the combination of radiofrequency-based positioning and computer vision-based human pose estimation yields a solution that provides better tracking results. Therefore, this article proposes a system that generates identified pose data by fusing the unique identities of radiofrequency sensors with unidentified body poses while using estimated body parts for reducing radiofrequency position estimations errors. Experiments with a proof-of-concept demonstrate the feasibility of the sensor fusion technique and also show a potential reduction on positioning errors by nearly 46%. © 2020 Elsevier B.V.","Activity recognition; HPE; Radiofrequency tracking; RTLS; Sensor fusion; Vision tracking"
"A trust-similarity analysis-based clustering method for large-scale group decision-making under a social network","2020","Information Fusion","10.1016/j.inffus.2020.05.004","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085545988&doi=10.1016%2fj.inffus.2020.05.004&partnerID=40&md5=8a64ca685c8b572cc2bed76d5549714f","Large-scale group decision-making (LSGDM) under a social network context has attracted much attention in the field of decision science. The clustering of individual opinions and the handling of trust relationships are the main research topics. Opinion similarity and trust relationship are considered to be two important measurement attributes for implementing clustering. Traditional clustering methods often use a single attribute to divide the original group without requiring a combination of the above two attributes. However, these two attributes play different roles in the clustering process, insofar as opinion similarity is used to measure the level of difference among individual opinions, whereas the trust relationship represents the trustworthiness of decision makers. This paper develops a trust-similarity analysis (TSA)-based clustering method to manage the clustering operation in LSGDM events under a social network context. First, the trust-similarity matrix is established to collectively describe the decision information. Second, all measurement attribute values are mapped to a trust-similarity plot from which the joint threshold can be calculated. Finally, a TSA-based clustering method is proposed that considers the attributes of opinion similarity and trust relationship and that allocates their importance to achieve specific clustering objectives. The numerical experiment and comparative analysis reveal the feasibility and advantages of the proposed method. © 2020 Elsevier B.V.","Clustering method; Large-scale group decision-making (LSGDM); Opinion similarity; Social network analysis (SNA); Trust relationship; Trust-similarity analysis (TSA)"
"Target tracking in the framework of possibility theory: The possibilistic Bernoulli filter","2020","Information Fusion","10.1016/j.inffus.2020.04.008","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084602536&doi=10.1016%2fj.inffus.2020.04.008&partnerID=40&md5=4ed6146afb34eb5ba91e6404a4381cf4","The Bernoulli filter is a Bayes filter for joint detection and tracking of a target in the presence of false and miss detections. This paper presents a mathematical formulation of the Bernoulli filter in the framework of possibility theory, where uncertainty is represented using possibility functions, rather than probability distributions. Possibility functions model the uncertainty in a non-additive manner, and have the capacity to deal with partial (incomplete) problem specification. Thus, the main advantage of the possibilistic Bernoulli filter, derived in this paper, is that it can operate even in the absence of precise measurement and/or dynamic model parameters. This feature of the proposed filter is demonstrated in the context of target tracking using multi-static Doppler shifts as measurements. © 2020 Elsevier B.V.","Partially known probabilistic models; Possibility functions; Target tracking"
"Fusion of short-wave infrared and visible near-infrared WorldView-3 data","2020","Information Fusion","10.1016/j.inffus.2020.03.012","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082851079&doi=10.1016%2fj.inffus.2020.03.012&partnerID=40&md5=281f3c74521cac5c5cba5b2369c12848","Pansharpening refers to the fusion of a low spatial resolution multispectral image and a high spatial resolution panchromatic image in order to have a synthesized (fused) product with the same spatial resolution of the panchromatic image and the same spectral resolution of the multispectral data. In this work, the problem of fusing the entire set of bands acquired by the WorldView-3 sensor from the visible spectrum to the short-wave infrared spectrum is addressed. In particular, the goal is to enhance the spatial resolution of all the visible, near-infrared, and short-wave infrared bands in order to reach the spatial resolution of the panchromatic image. A framework is proposed exploiting the multispectral image at middle spatial resolution to improve the performance (which is assessed on both simulated and real WorldView-3 data) of the fusion between short-wave infrared and panchromatic data. © 2020 Elsevier B.V.","Image fusion; Pansharpening; Remote sensing; Short-wave infrared; WorldView-3"
"A smart healthcare monitoring system for heart disease prediction based on ensemble deep learning and feature fusion","2020","Information Fusion","10.1016/j.inffus.2020.06.008","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85087655069&doi=10.1016%2fj.inffus.2020.06.008&partnerID=40&md5=f6389bd79edbc399ed55353fd64705bc","The accurate prediction of heart disease is essential to efficiently treating cardiac patients before a heart attack occurs. This goal can be achieved using an optimal machine learning model with rich healthcare data on heart diseases. Various systems based on machine learning have been presented recently to predict and diagnose heart disease. However, these systems cannot handle high-dimensional datasets due to the lack of a smart framework that can use different sources of data for heart disease prediction. In addition, the existing systems utilize conventional techniques to select features from a dataset and compute a general weight for them based on their significance. These methods have also failed to enhance the performance of heart disease diagnosis. In this paper, a smart healthcare system is proposed for heart disease prediction using ensemble deep learning and feature fusion approaches. First, the feature fusion method combines the extracted features from both sensor data and electronic medical records to generate valuable healthcare data. Second, the information gain technique eliminates irrelevant and redundant features, and selects the important ones, which decreases the computational burden and enhances the system performance. In addition, the conditional probability approach computes a specific feature weight for each class, which further improves system performance. Finally, the ensemble deep learning model is trained for heart disease prediction. The proposed system is evaluated with heart disease data and compared with traditional classifiers based on feature fusion, feature selection, and weighting techniques. The proposed system obtains accuracy of 98.5%, which is higher than existing systems. This result shows that our system is more effective for the prediction of heart disease, in comparison to other state-of-the-art methods. © 2020","Deep learning; Feature extraction; Feature fusion; Heart disease prediction; Ontology"
"The fusion of Internet of Intelligent Things (IoIT) in remote diagnosis of obstructive Sleep Apnea: A survey and a new model","2020","Information Fusion","10.1016/j.inffus.2020.03.010","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083000042&doi=10.1016%2fj.inffus.2020.03.010&partnerID=40&md5=6ee24255c9ecdbc1ce158e69d98295b7","Obstructive Sleep Apnea (OSA) syndrome is one of the most widespread diseases that difficult to be detected and remedied. In particular, the examination of OSA by using the traditional Polysomnography (PSG) is one of formidable complexity as it requires full observation in a laboratory overnight. Meanwhile, the number of available laboratories and beds is minimal comparing to the number of OSA patients. What's more, the unusual environment and restricted mobility of patients may result in deficient diagnosis results. The Internet of Things (IoT) is the most appropriate solution for the previous diagnosis obstacles by allowing doctors to synchronize patient status. Besides, several studies have been introduced to consolidate the performance of IoT interoperability via the fusion with Artificial Intelligence (AI) resulting in the Internet of Intelligent Things (IoIT). This paper presents a literature survey about the intensification of IoT technologies for smart monitoring of sleep quality and OSA diagnosis. Mainly, the most recent enabling IoT and support technologies such as (smart devices, fog computing, cloud, big data, and machine learning) are covered via the discussion of more recent works of literature published from 2016 to 2019. Also, the roles of AI in optimizing the efficiency of OSA smart diagnosis are presented. Besides, a new comprehensive IoIT optimization framework is presented which employing AI for optimizing the performance of intelligent diagnosis of OSA. Finally, the open issues and challenges in this field are argued. This paper is, therefore, a major contributor to the compilation of all IoT innovative and efficient AI methods that improving the quality of OSA diagnosis. © 2020","Artificial Intelligence; Internet of Intelligent Things; Internet of Things; Obstructive Sleep Apnea; Optimization; Remote diagnosis"
"Distributed optimal linear fusion estimators","2020","Information Fusion","10.1016/j.inffus.2020.05.006","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086075181&doi=10.1016%2fj.inffus.2020.05.006&partnerID=40&md5=c91291feebb163b834ff37039c8b6c63","This paper is concerned with the distributed information fusion estimation problem in multi-sensor environments. A universal distributed optimal linear fusion estimation (DOLFE) algorithm, which has a Kalman-type structure with matrix gains, is presented under the linear unbiased minimum variance criterion. To reduce the computational burden, two suboptimal linear fusion estimation algorithms with diagonal-matrix gains and scalar gains are also presented. Based on the proposed DOLFE algorithm, a distributed optimal linear fusion filter (DOLFF) is presented for multi-sensor linear discrete-time stochastic systems. It has better accuracy than that based on the matrix-weighted fusion of local estimators but worse accuracy than the centralized fusion filter (CFF). The stability and steady-state property of the proposed DOLFF are analyzed. Then, the corresponding multi-step predictor and smoother are also developed based on DOLFF. To obtain the distributed fusion estimators, some estimation error cross-covariance matrices that are used to compute the gains are derived. At last, distributed optimal linear fusion estimators with feedback are also presented. Furthermore, it is strictly proved that the proposed distributed optimal linear fusion filter with feedback (DOLFFWF) has the same accuracy as the CFF. Two simulation examples show the effectiveness of the proposed algorithms. © 2020 Elsevier B.V.","Cross-covariance matrix; Distributed linear fusion estimation; Feedback; Multi-sensor system; Steady-state estimator"
"Radar networks: A review of features and challenges","2020","Information Fusion","10.1016/j.inffus.2020.03.005","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082858382&doi=10.1016%2fj.inffus.2020.03.005&partnerID=40&md5=b60b44a7f2f55f5f1a8878c0e0bc1d26","Networks of multiple radars are typically used for improving the coverage and tracking accuracy. Recently, such networks have facilitated deployment of commercial radars for civilian applications such as healthcare, gesture recognition, home security, and autonomous automobiles. They exploit advanced signal processing techniques together with efficient data fusion methods in order to yield high performance of event detection and tracking. This paper reviews outstanding features of radar networks, their challenges, and their state-of-the-art solutions from the perspective of signal processing. Each discussed subject can be evolved as a hot research topic. © 2020 Elsevier B.V.","Data fusion; Detection; Estimation; Radar network; Registration error; Sensor management; Signal processing; Target tracking; Wireless sensor network"
"Feature-level fusion approaches based on multimodal EEG data for depression recognition","2020","Information Fusion","10.1016/j.inffus.2020.01.008","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85079327800&doi=10.1016%2fj.inffus.2020.01.008&partnerID=40&md5=634bd81780c7c5931cc0b472c183e75a","This study aimed to construct a novel multimodal model by fusing different electroencephalogram (EEG) data sources, which were under neutral, negative and positive audio stimulation, to discriminate between depressed patients and normal controls. The EEG data of different modalities were fused using a feature-level fusion technique to construct a depression recognition model. The EEG signals of 86 depressed patients and 92 normal controls were recorded simultaneously while receiving different audio stimuli. Then, from the EEG signals of each modality, linear and nonlinear features were extracted and selected to obtain features of each modality. In addition, a linear combination technique was used to fuse the EEG features of different modalities to build a global feature vector and find several powerful features. Furthermore, genetic algorithms were used to perform feature weighting to improve the overall performance of the recognition framework. The classification accuracy of each classifier, namely the k-nearest neighbor (KNN), decision tree (DT), and support vector machine (SVM), was compared, and the results were encouraging. The highest classification accuracy of 86.98% was obtained by the KNN classifier in the fusion of positive and negative audio stimuli, demonstrating that the fusion modality could achieve higher depression recognition accuracy rate compared with the individual modality schemes. This study may provide an additional tool for identifying depression patients. © 2020","Audio stimulus; Depression recognition; EEG; Fusion; Multimodal"
"Optimizing consistency and consensus improvement process for hesitant fuzzy linguistic preference relations and the application in group decision making","2020","Information Fusion","10.1016/j.inffus.2019.10.002","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074146021&doi=10.1016%2fj.inffus.2019.10.002&partnerID=40&md5=bc6c7d6147bb3b85233143451edcb1c4","Hesitant fuzzy linguistic preference relations (HFLPRs) are commonly used by decision makers when they are hesitant to express preferences. The use of HFLPRs in group decision-making (GDM) requires that the consistency of each HFLPR and consensus of the HFLPRs be acceptable. To ensure the reliability of using HFLPRs in GDM, a novel GDM model based on HFLPRs integrating the consistency and consensus improvement process is introduced. First, some novel consistency and consensus improvement methods by using an optimization technique are proposed for three actual cases: (1) the decision makers refuse to modify their opinions and the problem is without time pressure; (2) the decision makers are willing to modify their opinions and the problem is without time pressure; (3) the decision-making problem is under time pressure. For the former two cases, two iterative consistency and consensus improvement methods are introduced, and, for the last case, a method based on optimization models is introduced to modify the decision makers’ weights. A novel GDM model is given based on the proposed methods. Finally, an example is solved by using the proposed GDM model, and a comparison analysis is given. © 2019 Elsevier B.V.","Best consensus level; Best consistency index; Hesitant fuzzy linguistic preference relation; Worst consensus level; Worst consistency index"
"IVFuseNet: Fusion of infrared and visible light images for depth prediction","2020","Information Fusion","10.1016/j.inffus.2019.12.014","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077245504&doi=10.1016%2fj.inffus.2019.12.014&partnerID=40&md5=d2ff5823bad3fcc428d20e8600e9b708","Depth prediction is an essential component in the research of unmanned driving. Most existing research works predict depth only based on visible light images or infrared images. However, both visible light images and infrared images have their own advantages and disadvantages, and these two kinds of images contain complementary information when the images are filmed from the same scence. In order to fuse the complementary information and predict depth under various conditions, this paper proposes a convolutional-neural-network-based architecture, called infrared and visible light images fusion network (IVFuseNet), for depth prediction. Specifically, we construct common-feature-fusion subnetwork, full-feature-fusion subnetwork, and high-resolution reconstruction subnetwork, aiming to leverage the complementarity of these two kinds of images. The common-feature-fusion subnetwork adopts a two-stream multilayer convolutional structure whose filters for each layer are partially coupled to fuse the common features extracted from infrared images and visible light images respectively. The full-feature-fusion subnetwork fuses the two-stream features generated from the common-feature-fusion subnetwork by adaptive fusion weights instead of prefixed fusion weights. Additional, residual dense convolution that can accurately map the fused low-resolution features to the corresponding high-resolution features is adopted in the high-resolution reconstruction subnetwork to enhance the reconstruction of the details for depth prediction. All three subnetworks collaborate together to conduct the depth prediction task. Our NUST-SR dataset is composed of the actual road scenes captured while unmanned vehicle driving. The proposed IVFuseNet obtains the best performances on this dataset. IVFuseNet decreases the root mean squared error to 3.4513 and the mean relative error to 0.1651 respectively and outperforms other methods. The model and dataset are available at https://github.com/liyuqi1234/IVFN. © 2019","Adaptive weighted fusion; Depth prediction; Infrared image; Partially coupled filter; Visible image"
"Opinion dynamics model based on the cognitive dissonance: An agent-based simulation","2020","Information Fusion","10.1016/j.inffus.2019.09.006","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85073555873&doi=10.1016%2fj.inffus.2019.09.006&partnerID=40&md5=9731a0eb6e900bd62cce900b5bd90ce6","In opinion dynamics, some agents may exhibit the cognitive dissonance behaviors owing to the contradictory belief, attitudes and opinions that they might confront with. This may greatly influence the evolutions of opinions and connections. To this end, this paper proposes an opinion dynamics model based on the cognitive dissonance (ODCD). In the ODCD model, with the consideration of bounded confidence effects, the methods for updating the opinions and network of agents are provided, respectively. Then, we design the simulation experiments with different initial opinion distributions to investigate the influences of bounded confidences and initial connection probabilities. Finally, we conduct a comparison analysis on the opinion dynamics with different initial opinion distributions. © 2019 Elsevier B.V.","Bounded confidence; Cognitive dissonance; Connection; Initial opinion distributions; Opinion dynamics"
"Synergetic information bottleneck for joint multi-view and ensemble clustering","2020","Information Fusion","10.1016/j.inffus.2019.10.006","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85073500129&doi=10.1016%2fj.inffus.2019.10.006&partnerID=40&md5=65b380c8bbd29f5e7b63842897ed83dd","Multi-view and ensemble clustering methods have been receiving considerable attention in exploiting multiple features of data. However, both of these methods have their own set of limitations. Specifically, the performance of multi-view clustering may degrade due to the conflict between heterogeneous features, while ensemble clustering relies heavily on the quality of basic clusterings since it discovers the final clustering partition without considering the original feature structures of the source data. In this study, we propose a novel clustering scheme called synergetic information bottleneck (SIB) for joint multi-view and ensemble clustering. First, the proposed SIB utilizes multiple original features to characterize data information from different views while exploiting the basic clusterings to relieve the conflict of heterogeneous features. Second, the SIB generally formulates the problem of joint multi-view and ensemble clustering as a function of mutual information maximization, in which the relatedness between the original features and auxiliary basic clusterings is maximally preserved with respect to the final clustering partition. Finally, to optimize the objective function of SIB, a novel “draw-and-merge” optimization method is proposed. In addition, we prove that this novel optimization method can ensure that the objective function of SIB converges to a stable optimal in a finite number of iterations. Extensive experiments conducted on several practical tasks demonstrate that the SIB outperforms the state-of-the-art multi-view and ensemble clustering methods. © 2019 Elsevier B.V.","Ensemble clustering; Information bottleneck; Multi-view clustering; Mutual information"
"A scheduler for SCADA-based multi-source fusion systems","2020","Information Fusion","10.1016/j.inffus.2020.05.007","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085919502&doi=10.1016%2fj.inffus.2020.05.007&partnerID=40&md5=6d497e530c583a76b9f3648bbb8dc46c","In this article, we report on our experience regarding devising, implementing, and deploying a scheduler for multi-source fusion in the context of SCADA systems (Supervisory Control and Data Acquisition). They are challenging because they commonly rely on low-end boards with very limited computing, memory, and storage capabilities, but have to run hundreds if not thousands of agents that co-ordinate by means of complex multi-way rendez-vouses. Our work was carried out in the context of a solar plant in which we could easily confirm that not scheduling the rendez-vouses fairly may easily drive the system into as many as 3 779.10 critical-failure states per hour, whereas a straightforward solution to the problem can reduce the figure to 1 094.76 critical-failure states per hour. Unfortunately, that is far from zero, which is the ideal number. In the literature, there are several proposals to deal with this problem, but most of them could not be adapted to our context, namely: some of them can deal with two-way rendez-vouses only, whereas ours involve an average of 12.89 agents; others require to instrument the agents, but many of them are hardware devices that cannot be modified; a few others cannot work with rendez-vouses that can get intermittently enabled and disabled along an execution, which makes them of little interest in our context; and some require to use shared memory, which is an advanced hardware feature that is not supported by our low-end computing boards. The two proposals that we managed to adapt were not efficient enough in our context since they led to an average of 1 102.77 and 1 458.65 critical-failure states per hour, respectively. That motivated us to work on a new proposal that does not have any of the previous problems. It relies on a incremental approach that was implemented very efficiently using bounded counters and queues. Furthermore, the experimental results and the corresponding statistical analysis confirm that it works very well in practice. © 2020","Multi-source fusion; SCADA systems; Schedulers"
"Recursive fusion estimation for stochastic discrete time-varying complex networks under stochastic communication protocol: The state-saturated case","2020","Information Fusion","10.1016/j.inffus.2020.01.012","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85080080117&doi=10.1016%2fj.inffus.2020.01.012&partnerID=40&md5=79bc891bffb8a7ac422812bcba666746","In this paper, we investigate the recursive fusion estimation problem for time-varying state-saturated complex networks under stochastic communication protocol (SCP). To cater for physical limitations of network components, the phenomenon of state saturations is taken into account in the complex network model. The underlying communication mechanism is to ensure that just one sensor node is permitted to send its collected measurement at each time, and the SCP determines the permission to use the network channel for each sensor at each transmission time. A key issue of the addressed problem is to construct a time-varying state estimator such that an upper bound is guaranteed on the filtering error covariance subjected to both the state saturations and the SCP. By applying two sets of matrix difference equations, we first derive an upper bound according to the error covariance of the state estimation and then minimize such an upper bound by precisely calculating the estimator parameters. Then, the performance analysis of the obtained state estimator is given in terms of the boundedness. Finally, we provide a simulation example to illustrate the validity of the designed state estimator. © 2020 Elsevier B.V.","Discrete-time complex networks; Recursive state estimator; State-saturated systems; Stochastic communication protocol; Time-varying systems"
"A Choquet integral-based hesitant fuzzy gained and lost dominance score method for multi-criteria group decision making considering the risk preferences of experts: Case study of higher business education evaluation","2020","Information Fusion","10.1016/j.inffus.2020.05.003","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084789898&doi=10.1016%2fj.inffus.2020.05.003&partnerID=40&md5=7ea81aa48180652c19a0b51ac8de7dc3","With the rapid development of higher business education, higher business education evaluation has attracted considerable attention of researchers and practitioners. The higher business education evaluation is an essential part of the development of a business school, which has a direct impact on its resource distribution. The higher business education evaluation can be considered as a multiple criteria group decision making (MCGDM) problem that involves a group of experts. Due to the complexity of the decision-making problem, decision criteria are not fully independent to each other, and the assumption of complete rationality of experts is usually invalid in many situations. In this paper, we propose a Choquet integral-based hesitant fuzzy gained and lost dominance score method to address the two important issues regarding the interactions among criteria and the behavior preference characteristics of experts in MCGDM problems. Firstly, a comprehensive distance measure of hesitant fuzzy sets is introduced by considering the relative importance of two separations. Then, a Choquet integral-based hesitant fuzzy gained and lost dominance score method based on the prospect theory is proposed to address the MCGDM problems in which experts make decision with the risk preference psychology. Finally, an illustrative example of higher business education evaluation is provided to demonstrate the applicability of the proposed method, and the sensitivity and comparative analysis are also completed to verify the validity of the proposed method. © 2020","Choquet integral; Gained and lost dominance score method; Hesitant fuzzy set; Multiple criteria group decision making; Prospect theory"
"Multi-dimensional belief fusion of multi-Gaussian structures","2020","Information Fusion","10.1016/j.inffus.2019.12.006","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076530677&doi=10.1016%2fj.inffus.2019.12.006&partnerID=40&md5=e5f301b31fa503627d02241060d9267b","This paper describes the mathematical formulation of belief fusion of multi-Gaussian probability distribution functions (PDFs) in N-D, as well as the construction of some useful non-Gaussian structures. An emphasis of this work is the development of concise algorithms for constructing and efficiently fusing these non-Gaussian structures in N-space. In order to address decision-making using multi-Gaussian PDFs, an efficient probabilistic decision-making scheme is introduced and validated here. We investigate the trade-off between precision and efficiency in comparison with spatially discretizing fusion methods, concluding that the proposed techniques offer an improvement in both accuracy and efficiency for many contexts requiring non-Gaussian representation of belief. The proposed framework can be implemented in a diverse range of scenarios, potentially with real-time capability, and often without substantial sacrifice in accuracy. © 2019","Bayesian inference; Belief fusion; Estimation; Non-Gaussian belief; Probabilistic methods; Sensor fusion"
"Parameter learning and applications of the inclusion-exclusion integral for data fusion and analysis","2020","Information Fusion","10.1016/j.inffus.2019.10.004","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85073531284&doi=10.1016%2fj.inffus.2019.10.004&partnerID=40&md5=01abc474cbe36d624b196989599b707e","Developments in the learning and interpretation of fuzzy integrals have paved the way for a myriad of applications in data analysis and prediction. The ability of the associated fuzzy measure to model heterogeneous interactions allow high flexibility when it comes to data fusion tasks – comparable to that of neural networks – however the fuzzy integral structure and properties also afford a degree of robustness and interpretability not enjoyed by such tools. On the other hand, neural network architectures can accommodate fuzzy integrals as a special case. In this paper, we propose that such a representation allows us to naturally extend and adapt the fuzzy integral framework toward specific applications. We focus on the inclusion-exclusion integral, which is a generalization of the Choquet integral, and detail methods for learning the various parameters, given its extended architecture. We then validate the performance and usefulness of this approach on some benchmark datasets. © 2019 Elsevier B.V.","Aggregation function; Fuzzy integral; Fuzzy measure; Inclusion-exclusion integral; Neural networks; Parameter learning; Weight learning"
"Attributed heterogeneous network fusion via collaborative matrix tri-factorization","2020","Information Fusion","10.1016/j.inffus.2020.06.012","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85087277071&doi=10.1016%2fj.inffus.2020.06.012&partnerID=40&md5=72229eda82b8781ee62befadebd4dbe2","Heterogeneous network based data fusion can encode diverse inter- and intra-relations between objects, and has been sparking increasing attention in recent years. Matrix factorization based data fusion models have been invented to fuse multiple data sources. However, these models generally suffer from the widely-witnessed insufficient relations between nodes and from information loss when heterogeneous attributes of diverse network nodes are transformed into ad-hoc homologous networks for fusion. In this paper, we introduce a general data fusion model called Attributed Heterogeneous Network Fusion (AHNF). AHNF firstly constructs an attributed heterogeneous network composed with different types of nodes and the diverse attribute vectors of these nodes. It uses indicator matrices to differentiate the observed inter-relations from the latent ones, and thus reduces the impact of insufficient relations between nodes. Next, it collaboratively factorizes multiple adjacency matrices and attribute data matrices of the heterogeneous network into low-rank matrices to explore the latent relations between these nodes. In this way, both the network topology and diverse attributes of nodes are fused in a coordinated fashion. Finally, it uses the optimized low-rank matrices to approximate the target relational data matrix of objects and to effectively accomplish the relation prediction. We apply AHNF to predict the lncRNA-disease associations using diverse relational and attribute data sources. AHNF achieves a larger area under the receiver operating curve 0.9367 (by at least 2.14%), and a larger area under the precision-recall curve 0.5937 (by at least 28.53%) than competitive data fusion approaches. AHNF also outperforms competing methods on predicting de novo lncRNA-disease associations, and precisely identifies lncRNAs associated with breast, stomach, prostate, and pancreatic cancers. AHNF is a comprehensive data fusion framework for universal attributed multi-type relational data. The code and datasets are available at http://mlda.swu.edu.cn/codes.php?name=AHNF. © 2020 Elsevier B.V.","Attributed heterogeneous networks; Data fusion; Insufficient relations; LncRNA-disease associations; Matrix factorization"
"Cooperative positioning for emergency responders using self IMU and peer-to-peer radios measurements","2020","Information Fusion","10.1016/j.inffus.2019.10.009","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85073607468&doi=10.1016%2fj.inffus.2019.10.009&partnerID=40&md5=c38f4203fd2d9c1f800102f370b00c61","Positioning between multiple users without any given infrastructure is essential for many applications, such as emergency response in disaster areas. Traditional approaches based on inertial-measurement units (IMU) are able to measure position changes without any reference, but the accuracy deteriorates due to error accumulation for long terms. Particularly, it is challenging to deal with irregular walking patterns of users. This paper proposes to combine IMU and radio measurements (i.e., peer-to-peer Wifi received signal strength and peer-to-peer UWB ranging) for the positioning of a group of mobile users in emergency response, where no fixed anchors and no infrastructure are available. We incorporate the IMU and radio measurements into the particle filtering, which has the capability to cooperatively position a group of mobile users and recover from any potential tracking failures. By fusing the long-range Wifi RSS and short-range UWB ranging measurements, we can take the advantages of both sensors and achieve an accurate and robust positioning system. We have conducted experiments to validate the proposed approach both in a simulation and a real world experiment. Our experimental results show that the combination of Wifi and UWB measurements provides a positioning accuracy of 2.6 m, which is an improvement of 26% and 10% as compared with Wifi (3.5 m) and UWB (2.9 m) alone. © 2019 Elsevier B.V.","Cooperative positioning; Dead reckoning; Particle filtering; Received signal strength; UWB (Ultra-wideband) ranging"
"Decentralised multi-platform search for a hazardous source in a turbulent flow","2020","Information Fusion","10.1016/j.inffus.2019.12.011","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077315036&doi=10.1016%2fj.inffus.2019.12.011&partnerID=40&md5=75c5c7080b1d55841cd1344fa6d9b78b","The paper presents a cognitive strategy that enables an interconnected group of autonomous vehicles (moving robots) to search and localise a source of hazardous emissions (gas, biochemical particles) in a coordinated manner. Dispersion of the emitted substance is assumed to be affected by turbulence, resulting in the absence of concentration gradients. The key feature of the proposed search strategy is that it can be applied in a completely decentralised manner as long as the communication network of autonomous vehicles forms a connected graph. By decentralised operation we mean that each moving robot performs computations (i.e. source estimation and robot motion control) locally. Coordination is achieved by exchanging the data with the neighbours only, in a manner which does not require global knowledge of the communication network topology. © 2019 Elsevier B.V.","Autonomous search; Decentralised multi-sensor fusion; Infotaxi; Sensor control; Sequential Monte Carlo estimation"
"Classical and deep learning methods for recognizing human activities and modes of transportation with smartphone sensors","2020","Information Fusion","10.1016/j.inffus.2020.04.004","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083902633&doi=10.1016%2fj.inffus.2020.04.004&partnerID=40&md5=0230792250e889d5a18948e2947c8f1d","The Sussex-Huawei Locomotion-Transportation Recognition Challenge presented a unique opportunity to the activity-recognition community to test their approaches on a large, real-life benchmark dataset with activities different from those typically recognized. The goal of the challenge was to recognize, as accurately as possible, eight locomotion activities (Still, Walk, Run, Bike, Car, Bus, Train, Subway) using smartphone sensor data. This paper describes the method we developed to win this challenge, and provides an analysis of the effectiveness of its components. We used complex feature extraction and selection methods to train classical machine learning models. In addition, we trained deep learning models using a novel end-to-end architecture for deep multimodal spectro-temporal fusion. All the models were fused into an ensemble with the final predictions smoothed by a hidden Markov model to account for temporal dependencies of the activities. The presented method achieved an F1 score of 94.9% on the challenge test data. We tested different sampling frequencies, window sizes, feature types, classification models and the importance of stand-alone sensors and their fusion for the task. Finally, we present an energy-efficient smartphone implementation of the method. © 2020 Elsevier B.V.","Activity recognition; Competition; Deep learning; Ensembles; Hidden markov models; Machine learning"
"Mean, variance and covariance of joint measure based uncertain variables","2020","Information Fusion","10.1016/j.inffus.2019.07.003","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072193416&doi=10.1016%2fj.inffus.2019.07.003&partnerID=40&md5=2bde3e16edaa3941d6316c8ff2a36bc5","We introduce the idea of a measure-based representation of uncertain information as a generalization of probabilistic uncertainty. We look at the situation of uncertain joint variables where our knowledge of the uncertain joint variable is captured by a measure µ on the joint space. We introduce the formulation of the Choquet integral of a function of a joint variable with respect to the measure modeling the underlying uncertainty. This allows us to calculate a mean like value of the joint function with respect to the uncertainty captured by the measure µ. By appropriately selecting the function we are able to extend the formulation of some fundamental concepts used in probabilistic uncertainty to the more general case of measure-based uncertainty. Among the concepts investigated are the means and variances of the individual variables, the covariance and correlation between the joint variables. We also look at the mean and variance of the sum of the joint variables. © 2019 Elsevier B.V.","Choquet integral; Correlation; Joint variables; Measure; Uncertainty"
"Contextual deep learning-based audio-visual switching for speech enhancement in real-world environments","2020","Information Fusion","10.1016/j.inffus.2019.08.008","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85079856117&doi=10.1016%2fj.inffus.2019.08.008&partnerID=40&md5=b543bf78fe38662776f8fe23ed99d7c1","Human speech processing is inherently multi-modal, where visual cues (e.g. lip movements) can help better understand speech in noise. Our recent work [1] has shown that lip-reading driven, audio-visual (AV) speech enhancement can significantly outperform benchmark audio-only approaches at low signal-to-noise ratios (SNRs). However, consistent with our cognitive hypothesis, visual cues were found to be relatively less effective for speech enhancement at high SNRs, or low levels of background noise, where audio-only (A-only) cues worked adequately. Therefore, a more cognitively-inspired, context-aware AV approach is required, that contextually utilises both visual and noisy audio features, and thus more effectively accounts for different noisy conditions. In this paper, we introduce a novel context-aware AV speech enhancement framework that contextually exploits AV cues with respect to different operating conditions, in order to estimate clean audio, without requiring any prior SNR estimation. In particular, an AV switching module is developed by integrating a convolutional neural network (CNN) and long-short-term memory (LSTM) network, that learns to contextually switch between visualonly (V-only), A-only and both AV cues at low, high and moderate SNR levels, respectively. For testing, the estimated clean audio features are utilised using an innovative, enhanced visually-derived Wiener filter (EVWF) for noisy speech filtering. The context-aware AV speech enhancement framework is evaluated in dynamic real-world scenarios (including cafe, street, bus, and pedestrians) at different SNR levels (ranging from low to high SNRs), using benchmark Grid and ChiME3 corpora. For objective testing, perceptual evaluation of speech quality (PESQ) is used to evaluate the quality of the restored speech. For subjective testing, the standard mean-opinion-score (MOS) method is used. Comparative experimental results show the superior performance of our proposed context-aware AV approach, over A-only, V-only, spectral subtraction (SS), and log-minimum mean square error (LMMSE) based speech enhancement methods, at both low and high SNRs. The preliminary findings demonstrate the capability of our novel approach to deal with spectro-temporal variations in real-world noisy environments, by contextually exploiting the complementary strengths of audio and visual cues. In conclusion, our contextual deep learning-driven AV framework is posited as a benchmark resource for the multi-modal speech processing and machine learning communities. © 2019","Audio-visual; Context-aware learning; Deep learning; Multi-modal speech enhancement; Wiener filtering"
"Fusion estimation for multi-rate linear repetitive processes under weighted try-once-discard protocol","2020","Information Fusion","10.1016/j.inffus.2019.08.013","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072612285&doi=10.1016%2fj.inffus.2019.08.013&partnerID=40&md5=abcce204070a4520e844affbe9e3c0ac","In this paper, the fusion estimation problem is studied for a class of discrete time-varying multi-rate linear repetitive processes (LRPs) under weighted try-once-discard protocol. The LRPs are measured by multiple sensors that are allowed to have different sampling periods, and the state updating period of the LRPs is also allowed to be different from the sampling periods of the asynchronous sensors. To facilitate the estimator design, the lifting technique is applied to transform the multi-rate LRPs to single-rate ones. Moreover, due to limited communication capability, the weighted try-once-discard protocol is adopted to schedule the asynchronous sensors. A set of local estimators is designed such that the upper bounds on the local estimation error covariances are guaranteed, and such upper bounds are then minimized by appropriately designing the estimator gains. Furthermore, the estimates from the local estimators are fused by recurring to the sequential covariance intersection fusion method. Finally, a simulation example is given to demonstrate the effectiveness of the proposed fusion estimation scheme. © 2019 Elsevier B.V.","Fusion estimation; Linear repetitive processes; Multi-rate sampling; Sequential covariance intersection fusion.; Weighted try-once-discard protocol"
"MNIST-NET10: A heterogeneous deep networks fusion based on the degree of certainty to reach 0.1% error rate. ensembles overview and proposal","2020","Information Fusion","10.1016/j.inffus.2020.04.002","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084323142&doi=10.1016%2fj.inffus.2020.04.002&partnerID=40&md5=b078d0653db45a213ce3cd0482adc896","Ensemble methods have been widely used for improving the results of the best single classification model. A large body of works have achieved better performance mainly by applying one specific ensemble method. However, very few works have explored complex fusion schemes using heterogeneous ensembles with new aggregation strategies. This paper is three-fold: 1) It provides an overview of the most popular ensemble methods, 2) analyzes several fusion schemes using MNIST as guiding thread and 3) introduces MNIST-NET10, a complex heterogeneous fusion architecture based on a degree of certainty aggregation approach; it combines two heterogeneous schemes from the perspective of data, model and fusion strategy. MNIST-NET10 reaches a new record in MNIST with only 10 misclassified images. Our analysis shows that such complex heterogeneous fusion architectures based on the degree of certainty can be considered as a way of taking benefit from diversity. © 2020 Elsevier B.V.","Deep learning; Ensemble methods; Fusion; MNIST"
"An overview on feedback mechanisms with minimum adjustment or cost in consensus reaching in group decision making: Research paradigms and challenges","2020","Information Fusion","10.1016/j.inffus.2020.03.001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081116403&doi=10.1016%2fj.inffus.2020.03.001&partnerID=40&md5=28eb94f3c9c1d05b175a00bf1a05967d","Consensus reaching process is a very powerful decision tool to eliminate the preference conflict in group decision making. In general, the consensus is achieved by the decision makers modifying their preferences (or opinions) toward a point of mutual consent, and the feedback mechanism aims to provide preference-modifications suggestions. In many situations, the preference-modifications mean cost and the resources for the consensus reaching process are limited. So, in the last decade, the feedback mechanism with minimum adjustment or cost (FMMA/C) has been developed and widely used in various group decision making contexts to improve consensus efficiency. In this review, we first analyze the origin and basic research paradigm of the FMMA/C. Then, we review the FMMA/C in two decision contexts: (1) the FMMA/C in classical group decision making problems, and (2) the FMMA/C in complex group decision making problems (e.g., social network, large-scale, and opinion dynamic group decision making problems). Finally, we identify research challenges and propose future research direction. © 2020","Consensus reaching process; Feedback mechanism; Group decision making; Minimum adjustment; Minimum cost; Optimization model"
"Diffusion self-triggered square-root cubature information filter for nonlinear non-Gaussian systems and its application to the optic-electric sensor network","2020","Information Fusion","10.1016/j.inffus.2019.08.011","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072263451&doi=10.1016%2fj.inffus.2019.08.011&partnerID=40&md5=cbb1d13b4171f85e84126d89d0db9443","This article focuses on the problem of the distributed estimation for a class of discrete-time nonlinear non-Gaussian systems. In this paper, the non-Gaussian noises are approximated by the Gaussian mixture model. A novel method to merge the Gaussian components has been proposed in this article to improve its numerical stability. A diffusion Gaussian mixture square-root cubature information filter has been proposed in this paper. To ease the internode communication cost further, we design a self-triggered mechanism in this article. With the proposed mechanism, each sensor node transmits its information to its neighbors only when it's necessary. The effectiveness of the proposed algorithm is verified through its application to an optic-electric sensor network. © 2019 Elsevier B.V.","Distributed estimation; Gaussian mixture; Self-triggered strategy; Square-root cubature information filter"
"Fusing absolute and relative information for augmenting the method of nearest neighbors for ordinal classification","2020","Information Fusion","10.1016/j.inffus.2019.10.011","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074199336&doi=10.1016%2fj.inffus.2019.10.011&partnerID=40&md5=4ca24aae051a489747dbfbd64de99bf0","Ordinal classification is a special case of multiclass classification in which there exists a natural order on the set of class labels. Due to the nature of the problem, datasets for ordinal classification are typically rather small, having a negative impact on performance. A possible way out is to look for additional information. In this paper, firstly, we make use of order relations for unlabeled examples to generate relative information. Secondly, we incorporate this relative information into the method of k nearest neighbors, thus exploiting absolute and relative information at the same time. More specifically, we bring together notions from the fields of information fusion and machine learning to integrate both types of information. Finally, we test the proposed method on some classical machine learning datasets. The experimental results show the effectiveness of our approach. © 2019 Elsevier B.V.","Absolute information; Information fusion; Nearest neighbors; Ordinal classification; Relative information"
"Online detection of anomaly behaviors based on multidimensional trajectories","2020","Information Fusion","10.1016/j.inffus.2019.12.009","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077377557&doi=10.1016%2fj.inffus.2019.12.009&partnerID=40&md5=245473c788bb8977818b3aa356ec172f","In the surveillance domain, timely detection of anomaly behaviors is very important and is a great challenge to human operators due to information overload, fatigue and inattention. Many anomaly detection algorithms based on trajectories have been proposed for this problem. However, these algorithms generally have problems such as complex parameter setting, unfaithful statistical model, not well-calibrated false alarm rate, poor ability of online learning and sequential anomaly detection, etc. The theory of conformal prediction was introduced to solve these problems by constructing the sequential Hausdorff nearest neighbor conformal anomaly detector. Yet, it only considers position information of the targets and is not sensitive to velocity and course anomaly behaviors. And the run times are increasing as the increase of the data size, which is not appropriate for early warning surveillance application. In order to solve these problems, sequential multi-factor Hausdorff nearest neighbor conformal anomaly detector (SMFHNN[sbnd]CAD) and sequential multi-factor Hausdorff nearest neighbor inductive conformal anomaly detector (SMFHNN[sbnd]ICAD) based on multidimensional trajectories are proposed in this paper. Experiments in both simulated military scenario and realistic civilian scenario show the presented algorithm has a good performance to online detect anomaly behaviors and would have a wide prospect in early warning surveillance systems. © 2019 Elsevier B.V.","Anomaly behavior; Multidimensional; Online detection; Trajectory"
"The state-of-art of the generalizations of the Choquet integral: From aggregation and pre-aggregation to ordered directionally monotone functions","2020","Information Fusion","10.1016/j.inffus.2019.10.005","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075309330&doi=10.1016%2fj.inffus.2019.10.005&partnerID=40&md5=81881fca2480155fa481e5fa7f13fd93","In 2013, Barrenechea et al. used the Choquet integral as an aggregation function in the fuzzy reasoning method (FRM) of fuzzy rule-based classification systems. After that, starting from 2016, new aggregation-like functions generalizing the Choquet integral have appeared in the literature, in particular in the works by Lucca et al. Those generalizations of the Choquet integral, namely CT-integrals (by t-norm T), CF-integrals (by a fusion function F satisfying some specific properties), CC-integrals (by a copula C), CF1F2-integrals (by a pair of fusion functions (F1, F2) under some specific constraints) and their generalization gCF1F2-integrals, achieved excellent results in classification problems. The works by Lucca et al. showed that the aggregation task in a FRM may be performed by either aggregation, pre-aggregation or just ordered directional monotonic functions satisfying some boundary conditions, that is, it is not necessary to have an aggregation function to obtain competitive results in classification. The aim of this paper is to present and discuss such generalizations of the Choquet integral, offering a general panorama of the state of the art, showing the relations and intersections among such five classes of generalizations. First, we present them from a theoretical point of view. Then, we also summarize some applications found in the literature. © 2019","Aggregation functions; C<sub>F</sub>-integral; C<sub>F</sub>-Integral; C<sub>T</sub>-integral; CC-integral; Choquet integral; gC<sub>F</sub>-Integral; Ordered directionally monotonicity; Pre-aggregation functions; Pseudo pre-aggregation function pair"
"Knowledge graph fusion for smart systems: A Survey","2020","Information Fusion","10.1016/j.inffus.2020.03.014","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082863973&doi=10.1016%2fj.inffus.2020.03.014&partnerID=40&md5=c4a058baf5d230566ad029aceab43da0","The emergence of various disruptive technologies such as big data, Internet of Things, and artificial intelligence have instigated our society to generate enormous volumes of data. The effective, efficient, and transparent capture and fusion of knowledge from a massive amount data is becoming an increasingly popular and crucial topic. In this study, we aim to provide a broad, complete, and systematic overview of the definitions and challenges of the knowledge graph fusion, which represents a holistic approach for integrating, enhancing, and unifying knowledge graphs. Further, advanced techniques for handling knowledge graph fusion along with the pragmatic smart systems leveraging it are discussed as a part of multiple perspectives. We believe that this survey study can be used as a potential reference for system practitioners and researchers in surpassing current obstacles as well as shaping their future direction. © 2020 Elsevier B.V.","Big data; Disruptive technologies; Knowledge graph; Knowledge graph fusion; Smart systems"
"Extended Kalman filtering subject to random transmission delays: Dealing with packet disorders","2020","Information Fusion","10.1016/j.inffus.2020.02.006","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081114586&doi=10.1016%2fj.inffus.2020.02.006&partnerID=40&md5=7d52931be914301cb021ea5c19ecc4bf","This paper studies the extended Kalman filtering problem for a class of nonlinear discrete-time systems with random transmission delays (RTDs) and RTD-induced packet disorders. The relationship between the RTDs and the resulting packet disorders is discussed. The bounded RTDs, which take place in the sensor-to-filter channel, are modeled as independent and identically distributed random variables obeying a certain probability distribution. A novel filter structure is proposed that utilizes an integer-valued function of the mathematical expectation of the RTDs so as to compensate the RTD-induced effects. Under the proposed extended Kalman filter, an upper bound for the filtering error covariance is derived by solving two Riccati-like difference equations, and subsequently minimized (in the sense of trace) by appropriately designing the filter gains. A numerical simulation is provided to verify the validity of the developed filter design scheme. © 2020 Elsevier B.V.","extended Kalman filter; Nonlinear systems; packet disorders; random transmission delays; recursive filtering scheme"
"Overview and comparative study of dimensionality reduction techniques for high dimensional data","2020","Information Fusion","10.1016/j.inffus.2020.01.005","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078168635&doi=10.1016%2fj.inffus.2020.01.005&partnerID=40&md5=975838aba0e0d30022aa7507c6f81b9f","The recent developments in the modern data collection tools, techniques, and storage capabilities are leading towards huge volume of data. The dimensions of data indicate the number of features that have been measured for each observation. It has become a challenging task to analyze high dimensional data. Different dimensionality reduction techniques are available in literature to eliminate irrelevant and redundant features. Selection of an appropriate dimension reduction technique can help to enhance the processing speed and reduce the time and effort required to extract valuable information. This paper presents the state-of-the art dimensionality reduction techniques and their suitability for different types of data and application areas. Furthermore, the issues of dimensionality reduction techniques have been highlighted that can affect the accuracy and relevance of results. © 2020","Dimensionality reduction; Features; High dimensional data; Linear techniques; Nonlinear techniques"
"Towards perceptual image fusion: A novel two-layer framework","2020","Information Fusion","10.1016/j.inffus.2019.12.002","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076866572&doi=10.1016%2fj.inffus.2019.12.002&partnerID=40&md5=03efeddcee3581d0e82bf507660fdfe7","Recent studies in neuroscience indicate that the human visual system perceives regular and irregular contents separately: the former mainly illustrate primary visual information such as image structures; while the latter are generally messy and independent, and seem to be less important in perception. However, without any reference to such perceptual theory, the existing image fusion algorithms treat these two types of contents equally, and may not preserve the most perceptually important information in source images. In this work, we propose a new two-layer image fusion framework towards consistency with human perception. The main contributions are as follows: (1) We firstly explore the recently revealed perceptual theory and characterize perceptual significance from regular and irregular image contents in image fusion. This creates the possibilities to develop fusion algorithms towards consistency with human perception and preserve more desirable information in the fused result. (2) Following the concept of active inference mechanisms in perception, we present a perceptual image decomposition model with a local regression method to separate images into regular and irregular layers. In this way, we could treat these two kinds of image contents discriminatively, with elaborately selected fusion strategies based on sparse representation and local energy. We conduct extensive experiments including subjective evaluation, objective evaluation and perceptual assessment, and the experimental results demonstrate the superiority of the proposed model. © 2019","Image fusion; Information; Irregular layer; Perceptual importance; Regular layer"
"Pixel level fusion techniques for SAR and optical images: A review","2020","Information Fusion","10.1016/j.inffus.2020.01.003","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078213705&doi=10.1016%2fj.inffus.2020.01.003&partnerID=40&md5=66b9352e79a9f9779b5a09f634aec472","Image Fusion is a process of combining two or more images into a single image which is more informative and hence more useful from an interpretation point of view. With the rapid development of different remote sensing satellites capturing information from the earth by sensing energy in different portions of the electromagnetic spectrum, complementary information about the area captured by different satellites is available. A fusion of these images is much more helpful in different remote sensing applications than that of single sensor image data. This paper discusses the necessity of fusing synthetic aperture radar (SAR) and optical imagery. A survey is presented for various pixel level approaches used for the fusion of SAR and optical images. Quality metrics used to evaluate the performance of a fusion algorithm, are briefly introduced and visual as well as quantitative evaluation of basic component substitution and wavelet-based fusion approaches is presented for the fusion of RISAT-1 SAR and Resourcesat-2 multispectral data. Finally, the review concludes that there is scope for further research of fusion of SAR and optical images due to various microwave and optical sensors with the improved resolution being launched regularly. © 2020 Elsevier B.V.","Image fusion; Optical imagery; Quality metrics; SAR imagery"
"A multiple k-means clustering ensemble algorithm to find nonlinearly separable clusters","2020","Information Fusion","10.1016/j.inffus.2020.03.009","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082879649&doi=10.1016%2fj.inffus.2020.03.009&partnerID=40&md5=0ed44b4d0df262e9a3aa87975dfef9cd","Cluster ensemble is an important research content of ensemble learning, which is used to aggregate several base clusterings to generate a single output clustering with improved robustness and quality. Since clustering is unsupervised, where the “accuracy” does not have a clear meaning, most of existing ensemble methods try to obtain the most consistent clustering result with base clusterings. However, it is difficult for these methods to realize “Multi-weaks equal to a Strong”. For example, on a data set with nonlinearly separable clusters, if the base clusterings are produced by some linear clusterers, these methods generally cannot integrate them to obtain a good nonlinear clustering. In this paper, we select k-means as a base clusterer and provide an ensemble clusterer (algorithm) of multiple k-means clusterings based on a local hypothesis. In the new algorithm, we study the extraction of the local-credible labels from a base clustering, the production of different base clusterings, the construction of cluster relation and the final assignment of each object. The proposed ensemble clusterer not only inherits the scalability of k-means but also overcomes its limitation that it only can find linearly separable clusters. Finally, the experimental results illustrate its effectiveness and efficiency. © 2020 Elsevier B.V.","Cluster ensemble; k-means; Local hypothesis; Nonlinearly separable clustering"
"A dynamic ensemble outlier detection model based on an adaptive k-nearest neighbor rule","2020","Information Fusion","10.1016/j.inffus.2020.05.001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085551171&doi=10.1016%2fj.inffus.2020.05.001&partnerID=40&md5=f04e93819f5ce072f3b9dcf646b10963","Ensembles of outlier detectors are drawing increasing attentions recently, in spite of the difficulty on developing ensembles in the framework of unsupervised learning. We have noted that existing outlier ensembles often use certain fusion rules (e.g. majority voting) to aggregate individual learners. Theoretically, these individuals are assumed to be error-independent so that single models can be outperformed by the ensemble. However, it is of great difficulty to satisfy this assumption in practical applications. By dynamic selecting more competent individual(s) for each test pattern, this problem can be alleviated effectively. Inspired by this idea, this paper proposes a dynamic ensemble outlier detection model using one-class classifiers as base learners. As the competences of base detectors are estimated totally on data points in the validation set, its impact on the selection is significant. In order to achieve an efficient selection, we propose an adaptive k-nearest neighbor (KNN) rule, instead of traditional KNN algorithm, to constitute the validation set for each test pattern. Our adaptive KNN rule firstly uses algorithm support vector data description (SVDD) to mine the local area where class conditional probabilities are not constant in terms of the corresponding test pattern. Competences estimated with neighbor patterns in this area should thus be more accurate than that by traditional KNN rule. A probabilistic model that uses posterior probabilities of one-class classifiers is used then to estimate classifier competences. We present experimental evidence of the detection performance improvement over single models and over a variety of static ensemble models, by using data sets from UCI repository. © 2020","Adaptive k-nearest neighbor; Dynamic classifier selection; Ensemble learning; Outlier detection"
"Anaphora and coreference resolution: A review","2020","Information Fusion","10.1016/j.inffus.2020.01.010","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85079634946&doi=10.1016%2fj.inffus.2020.01.010&partnerID=40&md5=89b0035cfeb65a5ade8ee75910ac8746","Coreference resolution aims at resolving repeated references to an object in a document and forms a core component of natural language processing (NLP) research. When used as a component in the processing pipeline of other NLP fields like machine translation, sentiment analysis, paraphrase detection, and summarization, coreference resolution has a potential to highly improve accuracy. A direction of research closely related to coreference resolution is anaphora resolution. Existing literature is often ambiguous in its usage of these terms and often uses them interchangeably. Through this review article, we clarify the scope of these two tasks. We also carry out a detailed analysis of the datasets, evaluation metrics and research methods that have been adopted to tackle these NLP problems. This survey is motivated by the aim of providing readers with a clear understanding of what constitutes these two tasks in NLP research and their related issues. © 2020 Elsevier B.V.","Anaphora resolution; Coreference resolution; Deep learning; Natural language processing; Sentiment analysis"
"Explainable decision forest: Transforming a decision forest into an interpretable tree","2020","Information Fusion","10.1016/j.inffus.2020.03.013","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083315261&doi=10.1016%2fj.inffus.2020.03.013&partnerID=40&md5=8fdcb4bbeaffca7565028650c74d85b9","Decision forests are considered the best practice in many machine learning challenges, mainly due to their superior predictive performance. However, simple models like decision trees may be preferred over decision forests in cases in which the generated predictions must be efficient or interpretable (e.g. in insurance or health-related use cases). This paper presents a novel method for transforming a decision forest into an interpretable decision tree, which aims at preserving the predictive performance of decision forests while enabling efficient classifications that can be understood by humans. This is done by creating a set of rule conjunctions that represent the original decision forest; the conjunctions are then hierarchically organized to form a new decision tree. We evaluate the proposed method on 33 UCI datasets and show that the resulting model usually approximates the ROC AUC gained by random forest while providing an interpretable decision path for each classification. © 2020 Elsevier B.V.","Classification Trees; Decision forest; Ensemble learning"
"Social network community analysis based large-scale group decision making approach with incomplete fuzzy preference relations","2020","Information Fusion","10.1016/j.inffus.2020.02.005","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081139735&doi=10.1016%2fj.inffus.2020.02.005&partnerID=40&md5=584976e5bd22dec1031cf1016e62def4","Large-scale group decision making (LSGDM) is characterized by a large number of participators, multiple groups and a mass of decision data provided by the participators. With the development of social media and e-democracy technologies, the social relationships among group decision makers should be taken into consideration when we address LSGDM problems with incomplete fuzzy preference relations. In this paper, a social network community detection approach of social networks based on the fuzzy clustering method is proposed. Then, a method of repairing incomplete fuzzy preference relations based on the divided communities is proposed. Moreover, we have proposed a two-stage consensus reaching method to balance the number of iterations and modification range of original decision information, in which the group closeness centrality of community is applied to measure its importance. Also, the procedure for LSGDM with fuzzy preference relations based on social network community analysis is established. The feasibility and advantages of the proposed method for LSGDM based on social network community analysis are illustrated by an illustrative example of a flexible manufacturing system. © 2020","Community analysis; Consensus; Fuzzy preference relation; Large-scale group decision making; Social network"
"A survey on secure communication techniques for 5G wireless heterogeneous networks","2020","Information Fusion","10.1016/j.inffus.2020.04.009","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084568969&doi=10.1016%2fj.inffus.2020.04.009&partnerID=40&md5=72c83213128d5f432795207ed4a8c783","With the increasing number of emerging robust networks, the challenges to design new security protocols and techniques are never ending. With the enlargement of 5G paradigm, there is a remarkable makeshift in how the distributed devices perform to achieve a common goal. The 5G technology has been significantly revolutionized by the advent of the Internet of Things, and its quick and pervasive evolution. However, it remains imperative that all these devices work in a sequential manner to execute a collective and secure operation. Despite computing being focused around cloud infrastructures in the last two decades, the 5G networks and the huge amount of data it generates is presently inverting this trend, shifting computing power back to where data is generated from. To encompass different autonomous and collaborative systems with functions of data sensing and authentication between such systems in a predictive and adaptive manner is a challenging task. Wireless network design in 5G is expected to emphasize broadly on three facets: security, privacy and energy efficiency. Therefore, this paper investigates the role of various data security and privacy techniques for different generation networks, but emphasis is on 5G. It addresses encryption schemes with the focus on the challenges faced such as side channel and ciphertext attacks, inherent key generation, sharing and distribution, key escrow, analysis of various overheads, and potential techniques, and solutions to address such challenges by leveraging 5G network devices. With the proliferation of ubiquitous computing and wide adoption of hybrid encryption techniques, various attacks will be circumvent in an intelligent manner. © 2020 Elsevier B.V.","5G Heterogeneous Networks; Attacks and Chaotic Encryption; Encryption Algorithms; Internet of Things"
"Cooperative and distributed decision-making in a multi-agent perception system for improvised land mines detection","2020","Information Fusion","10.1016/j.inffus.2020.06.009","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086902566&doi=10.1016%2fj.inffus.2020.06.009&partnerID=40&md5=c3254cc816515782146960f3a18af7cd","This work presents a novel intelligent system designed using a multi-agent hardware platform to detect improvised explosive devices concealed in the ground. Each agent is equipped with a different sensor, (i.e. a ground-penetrating radar, a thermal sensor and three cameras each covering a different spectrum) and processes dedicated AI decision-making capabilities. The proposed system has a unique hardware structure, with a distributed design and effective selection of sensors, and a novel multi-phase and cooperative decision-making framework. Agents operate independently via a customised logic adjusting their sensor positions - to achieve optimal acquisition; performing a preliminary “local decision-making” - to classify buried objects; sharing information with the other agents. Once sufficient information is shared by the agents, a collaborative behaviour emerges in the so-called “cooperative decision-making” process, which performs the final detection. In this paper, 120 variations of the proposed system, obtained by combining both classic aggregation operators as well as advanced neural and fuzzy systems, are presented, tested and evaluated. Results show a good detection accuracy and robustness to environmental and data sets changes, in particular when the cooperative decision-making is implemented with the neuroevolution paradigm. © 2020 Elsevier B.V.","Feature extraction; Genetic fuzzy systems; Improvised explosive device; Land mine detection; Neuroevolution; Sensor fusion"
"Modeling of multi-sensor tightly aided BDS triple-frequency precise point positioning and initial assessments","2020","Information Fusion","10.1016/j.inffus.2019.08.012","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071566827&doi=10.1016%2fj.inffus.2019.08.012&partnerID=40&md5=109652d8b9a0178483fa47cda6e759d3","The BeiDou global navigation satellite system (BDS), which is the first satellite navigation system that provides triple-frequency signals on B1, B2, and B3 for civil applications, has been applied widely around the Asian-Pacifica region. The current BDS precise point positioning (PPP) approaches are mainly based on the B1&B2 dual-frequency observations. To make full use of BDS’ triple-frequency observations, the motion sensors measurements, and the platform motion information, this paper proposes an inertial sensor, odometer, and heading measurement tightly aided BDS triple-frequency PPP model. In this model, inertial sensor biases, odometer scale factor, residuals of slant ionospheric delays, and inter-frequency code biases are estimated simultaneously in a unique extended Kalman filter. The Rauch-Tung-Striebel (RTS) smoother is further adopted to reduce the solution's noises and enhance the stability and relative measuring accuracy. To evaluate the capability of this method, a set of triple-frequency BDS raw observations, inertial measurements, odometer data, and heading measurements collected by a customized hardware system on Lanzhou-Urumqi high speed railway track in China, are processed and analyzed. Results illustrated that both positioning accuracy and cycle slip detection capability are upgraded significantly by applying B3 frequency observations in BDS PPP. About 13–55% position accuracy enhancements from B3 observations, inertial sensors, and RTS smoother, and over 70% heading improvements from the aids of heading measurements can be obtained. Moreover, such multi-sensor tight integration system can directly provide millimeter-level positioning accuracy in term of repeatability and provide sub-millimeter-level accuracy indirectly by transforming attitude solutions into distance solutions. Such accuracy is much higher than the state-of-art GNSS and such method presents potential capability in 3D geometry measuring. © 2019 Elsevier B.V.","BeiDou global navigation satellite system (BDS); Inertial navigation system (INS); Odometer and heading measurement constraint; Relative measuring accuracy; Triple-frequency precise point positioning (TF-PPP)"
"Information fusion in visual question answering: A Survey","2019","Information Fusion","10.1016/j.inffus.2019.03.005","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85063637577&doi=10.1016%2fj.inffus.2019.03.005&partnerID=40&md5=98486a5a759d31c7b24d7daa4e8f2ce0","Visual question answering automatically answers natural language questions according to the content of an image or video. The task is challenging because it requires the understanding of semantic information in the textual and visual channels, as well as their interplay. A typical solver is composed of three components: feature extraction from singular modality, feature fusion between visual and textual channels, and answer prediction based on the learnt joint representation. Among them, information fusion plays a key role in enhancing the overall accuracy and various types of approaches have been proposed, such as simple vector operators, deep neural networks, bilinear pooling, attention mechanisms, and memory networks. The primary objective of this survey is to provide a clear organization and comprehensive review on the ever-proposed fusion techniques in the domain of visual question answering. We propose an abstract fusion framework that can fit the majority of existing VQA models, making it convenient for readers to quickly understand their key contributions. Finally, we summarize the effective fusion strategies that have been widely adopted so as to benefit readers in their model design. © 2019 Elsevier B.V.","Information fusion; Survey; Visual question answering"
"Multi-class Arrhythmia detection from 12-lead varied-length ECG using Attention-based Time-Incremental Convolutional Neural Network","2020","Information Fusion","10.1016/j.inffus.2019.06.024","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85067829138&doi=10.1016%2fj.inffus.2019.06.024&partnerID=40&md5=af8f276bfc5e5fbf9e1640a75fe18ae0","Automatic arrhythmia detection from Electrocardiogram (ECG) plays an important role in early prevention and diagnosis of cardiovascular diseases. Convolutional neural network (CNN) is a simpler, more noise-immune solution than traditional methods in multi-class arrhythmia classification. However, suffering from lack of consideration for temporal feature of ECG signal, CNN couldn't accept varied-length ECG signal and had limited performance in detecting paroxysmal arrhythmias. To address these issues, we proposed attention-based time-incremental convolutional neural network (ATI-CNN), a deep neural network model achieving both spatial and temporal fusion of information from ECG signals by integrating CNN, recurrent cells and attention module. Comparing to CNN model, this model features flexible input length, halved parameter amount as well as more than 90% computation reduction in real-time processing. The experiment result shows that, ATI-CNN reached an overall classification accuracy of 81.2%. In comparison with a classical 16-layer CNN named VGGNet, ATI-CNN achieved accuracy increases of 7.7% in average and up to 26.8% in detecting paroxysmal arrhythmias. Combining all these excellent features, ATI-CNN offered an exemplification for all kinds of varied-length signal processing problems. © 2019 The Authors","Arrhythmia detection; Attention module; Convolutional neural network; Recurrent cells; Spatial temporal fusion"
"Multi-view spectral clustering via integrating nonnegative embedding and spectral embedding","2020","Information Fusion","10.1016/j.inffus.2019.09.005","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072188121&doi=10.1016%2fj.inffus.2019.09.005&partnerID=40&md5=6a5bdf495a9d93d0fd66a8f171aaaa03","The application of most existing multi-view spectral clustering methods is generally limited by the following three deficiencies. First, the requirement to post-processing, such as K-means or spectral rotation. Second, the susceptibility to parameter selection. Third, the high computation cost. To this end, in this paper we develop a novel method that integrates nonnegative embedding and spectral embedding into a unified framework. Two promising advantages of proposed method include 1) the learned nonnegative embedding directly reveals the consistent clustering result, such that the uncertainty brought by post-processing can be avoided; 2) the involved model is parameter-free, which makes our method more applicable than existing algorithms that introduce many additional parameters. Furthermore, we develop an efficient inexact Majorization-Minimization method to solve the involved model which is non-convex and non-smooth. Experiments on multiple benchmark datasets demonstrate that our method achieves state-of-the-art performance. © 2019 Elsevier B.V.","Clustering; Majorization-Minimization; Multi-view; Nonnegative matrix factorization"
"Fusion of EEG response and sentiment analysis of products review to predict customer satisfaction","2019","Information Fusion","10.1016/j.inffus.2018.11.001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057340776&doi=10.1016%2fj.inffus.2018.11.001&partnerID=40&md5=b4e7f0e0db5c1a6a92a5b57d783b52de","This paper proposes a novel multimodal framework for rating prediction of consumer products by fusing different data sources, namely physiological signals, global reviews obtained separately for the product and its brand. The reviews posted by global viewers are retrieved and processed using Natural Language Processing (NLP) technique to compute compound score considered as global rating. Also, electroencephalogram (EEG) signals of the participants were recorded simultaneously while watching different products on computer's screen. From EEG, valence scores in terms of product rating are obtained using self-report towards each viewed product for acquiring local rating. A higher valence score corresponds to intrinsic attractiveness of the participant towards a product. Random forest based regression techniques is used to model EEG data to build a rating prediction framework considered as local rating. Furthermore, Artificial Bee Colony (ABC) based optimization algorithm is used to boost the overall performance of the framework by fusing global and local ratings. EEG dataset of 40 participants including 25 male and 15 female is recorded while viewing 42 different products available on e-commerce website. Experiment results are encouraging and suggest that the proposed ABC optimization approach can achieve lower Root Mean Square Error (RMSE) in rating prediction as compared to individual unimodal schemes. © 2018 Elsevier B.V.","ABC; EEG; Multimodal; Neuroscience; Rating prediction; Sentiment analysis"
"A method based on the disappointment almost stochastic dominance degree for the multi-attribute decision making with linguistic distributions","2020","Information Fusion","10.1016/j.inffus.2019.06.027","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85068914098&doi=10.1016%2fj.inffus.2019.06.027&partnerID=40&md5=76e76f18c51f0d85151212d08bbdf5dd","In the existing studies of the multi-attribute decision making problem (MADM) with linguistic distributions, the decision makers are assumed to be completely rational. However, in real life MADM problems, the decision makers sometimes exhibit the disappointment behaviors over different linguistic assessments. Thus, in this paper a method is proposed for the MADM with the linguistic distributions, in which the disappointment behaviors of decision makers are considered. In the proposed method, the decision matrix with numerical distribution is obtained by the numerical scale model. Based on the defined disappointment almost stochastic dominance (DASD) relationship and DASD degree, the DASD relationship and the DASD degree matrices with respect to all criteria are then calculated, respectively. Next, the ranking results are determined based on the net DASD degrees. Finally, a numerical example and a comparison analysis are provided to discuss the effectiveness of the proposal. © 2019 Elsevier B.V.","Disappointment almost stochastic dominance; Linguistic distribution; Multi-attribute decision making; Ranking"
"Managing personalized individual semantics and consensus in linguistic distribution large-scale group decision making","2020","Information Fusion","10.1016/j.inffus.2019.06.003","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85067065816&doi=10.1016%2fj.inffus.2019.06.003&partnerID=40&md5=dc9d79b114205eebdf7482bedc3ca215","A linguistic distribution assessment is an effective approach to represent uncertain preferences in large-scale group decision making (LSGDM). The same word often signifies different things for different decision makers in linguistic distribution assessments, which is called personalized individual semantics (PIS). Moreover, preference conflicts widely exist in LSGDM. This paper develops a new framework to address PIS and consensus in LSGDM using linguistic distribution preference relations (LDPRs). In the proposed LSGDM framework, a consistency-driven optimization model is put forward to produce the numerical scales with the PIS by maximizing the consistency of the additive preference relation that is transformed from its LDPR. Then, a preference clustering technique is employed to decompose decision makers into different clusters for managing their preferences. Next, the paper devises a two-stage-based consensus reaching model to manage the individual consistency and group consensus, which seeks to minimize the preference information loss. The first stage aims to assist decision makers in achieving a consensus within each obtained cluster, and the second stage is devoted to facilitating the consensus building among the different clusters. Finally, a case study that evaluates water management plans and a comparative analysis with the existing baseline approach are conducted to assess the feasibility and validity of the proposed LSGDM framework. © 2019 Elsevier B.V.","2-tuple linguistic model; Consensus; Consistency-driven methodology; Large-scale group decision making; Linguistic distribution assessments; Personalized individual semantics"
"iFusion: Towards efficient intelligence fusion for deep learning from real-time and heterogeneous data","2019","Information Fusion","10.1016/j.inffus.2019.02.008","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062022353&doi=10.1016%2fj.inffus.2019.02.008&partnerID=40&md5=0272c5d1378831cc96366d66885a7980","Deep learning has shown great strength in many fields and has allowed people to live more conveniently and intelligently. However, deep learning requires a considerable amount of uniform training data, which introduces difficulties in many application scenarios. On the one hand, in real-time systems, training data are constantly generated, but users cannot immediately obtain this vast amount of training data. On the other hand, training data from heterogeneous sources have different data formats. Therefore, existing deep learning frameworks are not able to train all data together. In this paper, we propose the iFusion framework, which achieves efficient intelligence fusion for deep learning from real-time data and heterogeneous data. For real-time data, we train only newly arrived data to obtain a new discrimination model and fuse the previously trained models to obtain the discrimination result. For heterogeneous data, different types of data are trained separately; then, we fuse the different discrimination models so that it is not necessary to consider heterogeneous data formats. We use a method based on Dempster-Shafer theory (DST) to fuse the discrimination models. We apply iFusion to the deep learning of medical image data, and the results of the experiments show the effectiveness of the proposed method. © 2019 Elsevier B.V.","Deep learning; Heterogeneous data; Information fusion; Real-time data"
"An intelligent quality-based approach to fusing multi-source possibilistic information","2020","Information Fusion","10.1016/j.inffus.2019.08.003","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85070678217&doi=10.1016%2fj.inffus.2019.08.003&partnerID=40&md5=5c7555aabbf2b28536f9b9c6af2e60dc","Recently, Yager and Petry were proposing a quality-based methodology to combine data provided by multiple probabilistic sources to improve the quality of information for decision-makers. This paper offers a sort of companion paper that adapts this methodology to possibilistic sources. Possibility theory is particularly well suited to cope with incomplete information from poor-data sources. The methodology and algorithms used for the probabilistic approach are adapted for the possibilistic case. Both approaches are then compared by the means of a numerical example and four experimental benchmark datasets: one, the IRIS data set, being data-poorer than the three other ones (Diabetes dataset, Glass dataset and Liver-disorder dataset). A vector representation is introduced for a possibility distribution as in the probabilistic case and, the Gini's formulation of entropy is being used. However, the Gini's entropy has to be used differently than with the probabilistic case. This has an impact on the selection of subsets. A fusion scheme is designed to select the best-quality subsets according to two information quality factors: quantity of information and source credibility. Results obtained from comparison of both approaches on the four experimental benchmarks confirm the superiority of the possibilistic approach in the presence of information scarcity or incompleteness. © 2019 Elsevier B.V.","Gini entropy; Information fusion; Possibility theory; Quality of information; Source credibility; Uncertainty"
"Environment-fusion multipath routing protocol for wireless sensor networks","2020","Information Fusion","10.1016/j.inffus.2019.06.001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85066999566&doi=10.1016%2fj.inffus.2019.06.001&partnerID=40&md5=283d8893336a1cee939d61b7f25edf41","In most cases, wireless sensor networks (WSNs) are deployed in unattended scenarios and are featured by energy sensitivity and low cost, thus making the performance of WSNs prone to the impact of external environment and internal energy. Existing routing protocols attempted to optimize the energy efficiency and routing reliability from the perspective of the network itself and failed to take into consideration the environmental impact from outside, causing them cannot make prompt reactions to the dynamic changes of the environments (e.g., wildfire). Thus, in these routing protocols the routing survivability under harsh environments is questionable. To tackle this issue, the paper proposes an environment-fusion multipath routing protocol (EFMRP) to provide sustainable message forwarding service under harsh environments. In EFMRP, routing decisions are made according to a mixed potential field in terms of depth, residual energy and environment. The basic idea of this approach is to instruct data packets to select routes with the best trade-off among latency, energy conservation and routing survivability. As the environmental field is constructed and updated using the sensing capability of WSN itself, constructed routes can avoid crossing through the danger zones to keep the paths safe. To enhance the performance of EFMRP, specific maintenance, traffic allocation and retreat mechanisms are proposed. We investigate the impact of configuration parameters and paths number on the routing performance respectively and compare EFMRP with respect to commonly used routing protocols. The experimental results show that EFMRP can obtain significant improvements in packet delivery ratio and network lifetime under harsh environments. © 2019 Elsevier B.V.","Environment-aware; Multipath routing; Potential field; Wireless sensor networks"
"An influence-driven feedback system for preference similarity network clustering based consensus group decision making model","2019","Information Fusion","10.1016/j.inffus.2019.03.004","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062909184&doi=10.1016%2fj.inffus.2019.03.004&partnerID=40&md5=db53910ab4245229cffb9e58112de44d","Consensus group decision making (CGDM) allows the integration within this area of study of other advanced frameworks such as Social Network Analysis (SNA), Social Influence Network (SIN), clustering and trust-based concepts, among others. These complementary frameworks help to bridge the gap between their corresponding theories in such a way that important elements are not overlooked and are appropriately taken into consideration. In this paper, a new influence-driven feedback mechanism procedure is introduced for a preference similarity network clustering based consensus reaching process. The proposed influence-driven feedback mechanism aims at identifying the network influencer for the generation of advices. This procedure ensures that valuable recommendations are coming from the expert with most similar preferences with the other experts in the group. This is achieved by adapting, from the SIN theory into the CGDM context, an eigenvector-like measure of centrality for the purpose of: (i) measuring the influence score of experts, and (ii) determining the network influencer. Based on the initial evaluations on a set of alternatives provide by the experts in a group, the proposed influence score measure, which is named the σ-centrality, is used to define the similarity social influence network (SSIN) matrix. The σ-centrality is obtained by taking into account both the endogenous (internal network connections) and exogenous (external) factors, which means that SSIN connections as well as the opinion contribution from third parties are permitted in the nomination of the network influencer. The influence-driven feedback mechanism process is designed based on the satisfying of two important conditions to ensure that (1) the revised consensus degree is above the consensus threshold and that (2) the clustering solution is improved. © 2019 Elsevier B.V.","Agglomerative hierarchical clustering; Centrality; Consensus; Feedback mechanism; Preference similarity; Social influence network"
"Data fusion based coverage optimization in heterogeneous sensor networks: A survey","2019","Information Fusion","10.1016/j.inffus.2018.11.020","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85059069923&doi=10.1016%2fj.inffus.2018.11.020&partnerID=40&md5=47814856f041a41fd7b9316e769da7fd","Sensor networks, as a promising network paradigm, have been widely applied in a great deal of critical real-world applications. A key challenge in sensor networks is how to improve and optimize coverage quality which is a fundamental metric to characterize how well a point or a region or a barrier can be sensed by the geographically deployed heterogeneous sensors. Because of the resource-limited, battery-powered and type-diverse features of the sensors, maintaining and optimizing coverage quality includes a significant amount of challenges in heterogeneous sensor networks. Many researchers from both academic and industrial communities have performed numerous significant works on coverage optimization problem in the past decades. Some of them also have surveyed the current models, theories and solutions on the problem of coverage optimization. However, most of the existing surveys and analytical studies ignore how to exploit data fusion and cooperation of the deployed sensors to enhance coverage performance. In this paper, we provide an insightful and comprehensive summarization and classification on the data fusion based coverage optimization problem and techniques. Aiming at overcoming the shortcomings existed in current solutions, we also discuss the future issues and challenges in this area and sketch a general research framework in the context of reinforcement learning. © 2018 Elsevier B.V.","Coverage optimization; Data fusion; Heterogeneous sensor networks; Reinforcement learning; Survey"
"Collaborative detection and power allocation framework for target tracking in multiple radar system","2020","Information Fusion","10.1016/j.inffus.2019.08.010","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071643387&doi=10.1016%2fj.inffus.2019.08.010&partnerID=40&md5=5c27ae1d3983ec9b972625fd7f437b6e","In reality, multiple radar system (MRS) may have some limited resource, such as the data computation capacity of the fusion center and the transmit energy of each radar. To better exploit its limited system resource, a collaborative detection and power allocation (CDPA) scheme is developed for the application of target tracking in clutter. The basis of the CDPA scheme is to use optimization technique to control the false alarm rate (FAR) and transmit power of each radar in view of the aforementioned resource constraints, while achieving better target state estimation accuracy. The Bayesian Cramér–Rao lower bound is derived, relaxed, and subsequently utilized, as the optimization criterion for the CDPA strategy. The resulting nonlinear and nonconvex optimization problem consists of two adaptable vectors, one for FAR selection and the other for power allocation. By introducing an auxiliary vector, a fast two-step solution technique is presented to jointly select the FAR and distribute the transmit power. Simulation results demonstrate that, with given data computation capability and system total power budget, the CDPA scheme can evidently expand the detection range, increase the resource utilization efficiency of the MRS, and improve the target tracking accuracy. © 2019 Elsevier B.V.","Collaborative detection; Multiple radar system; Nonconvex optimization; Power allocation; Target tracking"
"Convolution–deconvolution word embedding: An end-to-end multi-prototype fusion embedding method for natural language processing","2020","Information Fusion","10.1016/j.inffus.2019.06.009","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85067208742&doi=10.1016%2fj.inffus.2019.06.009&partnerID=40&md5=6c74a44e96488a5b15780ec7ec50df94","Existing unsupervised word embedding methods have been proved to be effective to capture latent semantic information on various tasks of Natural Language Processing (NLP). However, existing word representation methods are incapable of tackling both the polysemous-unaware and task-unaware problems that are common phenomena in NLP tasks. In this work, we present a novel Convolution–Deconvolution Word Embedding (CDWE), an end-to-end multi-prototype fusion embedding that fuses context-specific information and task-specific information. To the best of our knowledge, we are the first to extend deconvolution (e.g. convolution transpose), which has been widely used in computer vision, to word embedding generation. We empirically demonstrate the efficiency and generalization ability of CDWE by applying it to two representative tasks in NLP: text classification and machine translation. The models of CDWE significantly outperform the baselines and achieve state-of-the-art results on both tasks. To validate the efficiency of CDWE further, we demonstrate how CDWE solves the polysemous-unaware and task-unaware problems via analyzing the Text Deconvolution Saliency, which is an existing strategy for evaluating the outputs of deconvolution. © 2019 Elsevier B.V.","Multi-prototype; Natural language processing; Neural network; Word embedding"
"Short-long term anomaly detection in wireless sensor networks based on machine learning and multi-parameterized edit distance","2019","Information Fusion","10.1016/j.inffus.2018.11.010","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057342329&doi=10.1016%2fj.inffus.2018.11.010&partnerID=40&md5=fe97733c25964b4d96609605e7f0fc58","Heterogeneous wireless sensor networks are a source of large amount of different information representing environmental aspects such as light, temperature, and humidity. A very important research problem related to the analysis of the sensor data is the detection of relevant anomalies. In this work, we focus on the detection of unexpected sensor data resulting either from the sensor system itself or from the environment under scrutiny. We propose a novel approach for automatic anomaly detection in heterogeneous sensor networks based on coupling edge data analysis with cloud data analysis. The former exploits a fully unsupervised artificial neural network algorithm, whereas cloud data analysis exploits the multi-parameterized edit distance algorithm. The experimental evaluation of the proposed method is performed applying the edge and cloud analysis on real data that has been acquired in an indoor building environment and then distorted with a range of synthetic impairments. The obtained results show that the proposed method can self-adapt to the environment variations and correctly identify the anomalies. We show how the combination of edge and cloud computing can mitigate the drawbacks of purely edge-based analysis or purely cloud-based solutions. © 2018 Elsevier B.V.","Anomaly detection; Cloud-assisted sensing; Intelligent sensing; Internet of Things; Sensor fusion"
"An overview on managing additive consistency of reciprocal preference relations for consistency-driven decision making and fusion: Taxonomy and future directions","2019","Information Fusion","10.1016/j.inffus.2018.12.004","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061965530&doi=10.1016%2fj.inffus.2018.12.004&partnerID=40&md5=fc1e90f1a5933525398f026c489c44e3","The reciprocal preference relation (RPR) is a powerful tool to represent decision makers’ preferences in decision making problems. In recent years, various types of RPRs have been reported and investigated, some of them being the ‘classical’ RPRs, interval-valued RPRs and hesitant RPRs. Additive consistency is one of the most commonly used property to measure the consistency of RPRs, with many methods developed to manage additive consistency of RPRs. To provide a clear perspective on additive consistency issues of RPRs, this paper reviews the consistency measurements of the different types of RPRs. Then, consistency-driven decision making and information fusion methods are also reviewed and classified into four main types: consistency improving methods; consistency-based methods to manage incomplete RPRs; consistency control in consensus decision making methods; and consistency-driven linguistic decision making methods. Finally, with respect to insights gained from prior researches, further directions for the research are proposed. © 2018 Elsevier B.V.","Additive consistency; Consistency-driven method; Decision making; Reciprocal preference relation"
"Variational bimodal image fusion with data-driven tight frame","2020","Information Fusion","10.1016/j.inffus.2019.08.007","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071296168&doi=10.1016%2fj.inffus.2019.08.007&partnerID=40&md5=c9a35c9160cb32748fac5fdfe735d4b7","The purpose of multimodal image fusion is to combine information from different modal images of the same investigated object and create an image that is suitable for human vision and subsequent image processing. This paper proposes a three-step method for bimodal image fusion. A tight frame system is first adaptively learned from bimodal images for capturing source images features as much as possible. Further, a fused coefficient set is constructed by integrating the frame coefficients from both modalities. Finally, a variational model is designed to reconstruct a fused image based on the fused coefficients, and the intensity information of those smooth regions. The alternating iteration scheme and alternating direction method of multipliers are used to solve the resulted variational problems. Numerical experiments on multimodal medical image fusion and multifocused natural image fusion indicate that the proposed approach outperforms some existing methods. © 2019 Elsevier B.V.","Bimodal image fusion; Data-driven tight frame; Variational method"
"Gradient structural similarity based gradient filtering for multi-modal image fusion","2020","Information Fusion","10.1016/j.inffus.2019.06.025","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85068372045&doi=10.1016%2fj.inffus.2019.06.025&partnerID=40&md5=a291aa7fbf1003b1a24a84085c9bc595","In the conventional structure tensor-based gradient domain image fusion methods, a structure tensor is exploited to calculate the fused gradient, from which the fused image can be derived using a variational model. However, in these conventional methods, because the direction of fused gradient at every position is determined by the inner product between the average of multiple source gradients and the biggest eigenvalue of structure tensor, its accuracy would be suffered by the canceling effect in calculating the average source gradient. To address such issue, we propose a novel local structural similarity metric to determine the dominant source gradient and correct the direction of fused gradient by the inner product between the biggest eigenvalue of structure tensor and the dominant source gradient. Moreover, in order to highlight salient features of the source images with the dominant source gradients, we propose a structural similarity based gradient filtering scheme which simultaneously performs filtering and fusion on both the source gradients and the corrected fused gradients to obtain the final fused gradients. Finally, the fused image can be reconstructed from the final fused gradients using a variational model like the conventional structure tensor-based fusion schemes. The comprehensive experiment results have revealed that our image fusion method can obtain better objective and subjective fusion performances compared to the state-of-the-art image fusion methods. © 2019 Elsevier B.V.","Adaptive gradient filtering; Image fusion; Local structural similarity; Multi-modal; Structure tensor"
"Social context in sentiment analysis: Formal definition, overview of current trends and framework for comparison","2019","Information Fusion","10.1016/j.inffus.2019.05.003","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85066018316&doi=10.1016%2fj.inffus.2019.05.003&partnerID=40&md5=2f21661a6bc1db3505202fcea4c480c4","Sentiment analysis in social media is harder than in other types of text due to limitations such as abbreviations, jargon, and references to existing content or concepts. Nevertheless, social media provides more information beyond text, such as linked media, user reactions, and relations between users. We refer to this information as social context. Recent works have successfully leveraged the fusion of text with social context for sentiment analysis tasks. However, these works are usually limited to specific aspects of social context, and there have not been any attempts to analyze and apply social context systematically. This work aims to bridge this gap by providing three main contributions: 1) a formal definition of social context; 2) a framework for classifying and comparing approaches that use social context; 3) a review of existing works based on the defined framework. © 2019 The Authors","Online social networks; Sentiment analysis; Social context; Social network analysis"
"A survey on big data-driven digital phenotyping of mental health","2019","Information Fusion","10.1016/j.inffus.2019.04.001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85064434822&doi=10.1016%2fj.inffus.2019.04.001&partnerID=40&md5=8c8bce1e30ef776adb664ed0f6bd3b2c","The landscape of mental health has undergone tremendous changes within the last two decades, but the research on mental health is still at the initial stage with substantial knowledge gaps and the lack of precise diagnosis. Nowadays, big data and artificial intelligence offer new opportunities for the screening and prediction of mental problems. In this review paper, we outline the vision of digital phenotyping of mental health (DPMH) by fusing the enriched data from ubiquitous sensors, social media and healthcare systems, and present a broad overview of DPMH from sensing and computing perspectives. We first conduct a systematical literature review and propose the research framework, which highlights the key aspects related with mental health, and discuss the challenges elicited by the enriched data for digital phenotyping. Next, five key research strands including affect recognition, cognitive analytics, behavioral anomaly detection, social analytics, and biomarker analytics are unfolded in the psychiatric context. Finally, we discuss various open issues and the corresponding solutions to underpin the digital phenotyping of mental health. © 2019 Elsevier B.V.","Big data; Data mining; Digital phenotyping; Information fusion; Mental health"
"Selective encryption on ECG data in body sensor network based on supervised machine learning","2020","Information Fusion","10.1016/j.inffus.2019.07.012","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85070704840&doi=10.1016%2fj.inffus.2019.07.012&partnerID=40&md5=4b7e924bfe8d5335abc166a7160255a0","Body Sensor Networks (BSNs) are developing rapidly in recent years as it combines the Internet-of-Things (IoT) and data analytic techniques for building a remote healthcare system. However, as BSNs are implemented on the existing wireless communication systems, the security and privacy in the BSN are facing many challenges. Performing standard encryption schemes on the health data before outsourcing at the sensors’ ends are not suitable for this BSN environment as it is costly both in energy and time consumption for the BSN sensors. Traditional lightweight encryption schemes such as Selective Encryption (SE) schemes could be used in this environment by reducing the data volume to be encrypted. In this paper, we re-define the SE schemes in a practical scenario of securely outsourcing the electrocardiogram (ECG) data in the untrusted BSN environment. Specifically, if the ECG data is outsourced for disease classification based on a machine learning model, we prove that the classic SE schemes are not the correct designs. Then, we give our SE design based on this classification use case to protect the ECG data against illegal classification at the attacker sides which further protects the patients’ data privacy. Intensive tests are experimented to prove the effectiveness of our proposed SE method. © 2019 Elsevier B.V.","ECG fusion; Machine learning; Privacy; Selective encryption; SVM"
"The axiomatization of asymmetric disjunction and conjunction","2020","Information Fusion","10.1016/j.inffus.2019.06.018","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85067814416&doi=10.1016%2fj.inffus.2019.06.018&partnerID=40&md5=0500d5b76f24b6cff71e4cdbee521f81","In many real–world cases, disjunction is expressed as the fusion of full alternatives and less relevant ones, which leads to an OR ELSE connective. Obviously, this connective, so-called intensified disjunction, should provide a solution lower than or equal to the MAX operator, and higher than or equal to the projection of the full alternative. Further, to cover the cases when higher satisfaction degrees to the less relevant alternative cause that it becomes the full alternative, non–continuous asymmetric disjunction is required. The dual observation holds for the fusion of constraints (hard conditions) and wishes (soft conditions) expressed by an AND IF POSSIBLE connective. In order to cover these requirements, the paper focuses on developing a full axiomatization of asymmetric disjunction and asymmetric conjunction by averaging functions. Next, the necessity and sufficiency for associative behaviour have been proven. Moreover, the non–dual cases are also documented. Finally, the obtained results are illustrated on examples, and their applicability is also discussed. © 2019 Elsevier B.V.","And if possible operators; Averaging functions; Axiomatization; Continuous and non–continuous fusion functions; Or else operators"
"EmbraceNet: A robust deep learning architecture for multimodal classification","2019","Information Fusion","10.1016/j.inffus.2019.02.010","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062447851&doi=10.1016%2fj.inffus.2019.02.010&partnerID=40&md5=12886dc8877a059778eb03ede35e10bd","Classification using multimodal data arises in many machine learning applications. It is crucial not only to model cross-modal relationship effectively but also to ensure robustness against loss of part of data or modalities. In this paper, we propose a novel deep learning-based multimodal fusion architecture for classification tasks, which guarantees compatibility with any kind of learning models, deals with cross-modal information carefully, and prevents performance degradation due to partial absence of data. We employ two datasets for multimodal classification tasks, build models based on our architecture and other state-of-the-art models, and analyze their performance on various situations. The results show that our architecture outperforms the other multimodal fusion architectures when some parts of data are not available. © 2019 Elsevier B.V.","classification; data loss; deep learning; Multimodal data fusion"
"A multimodal smartphone sensor system for behaviour measurement and health status inference","2020","Information Fusion","10.1016/j.inffus.2019.06.008","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85067179202&doi=10.1016%2fj.inffus.2019.06.008&partnerID=40&md5=196937afb3e9c34955ec829512e6f1e6","Smartphones are becoming increasingly pervasive in almost every aspect of daily life. With smartphones being equipped with multiple sensors, they provide an opportunity to automatically extract information relating to daily life. Information relating to daily life could have major benefits in the area of health informatics. Research shows that there is a need for more objective and accurate means of measuring health status. Hence, this work investigates the use of multi-modal smartphone sensors to measure human behaviour and generate behaviour profiles which can be used to make objective predictions related to health status. Three sensor modalities are used to compute behaviour profiles for three different components of human behaviour. Motion sensors are utilised to measure physical activity, location sensors are utilised to measure travel behaviour and sound sensors are used to measure voice activity related behaviour. Sensor fusion, using a genetic algorithm, is performed to find complementary and co-operative features. Using a behaviour feature composed of motion, sound and locations data, results show that a Support Vector Machine (SVM) can predict 10 different health metrics with an error that does not exceed a clinical error benchmark. © 2019 Elsevier B.V.","Health status; Location; Machine learning; Motion; Sound"
"Dynamic identification of coal-rock interface based on adaptive weight optimization and multi-sensor information fusion","2019","Information Fusion","10.1016/j.inffus.2018.09.007","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056600624&doi=10.1016%2fj.inffus.2018.09.007&partnerID=40&md5=0156089989843d43781f46a6f4430b6b","Traditional coal-rock interface identification methods have been developed under the assumption that the interface is either coal or rock, when this is apparently not the case. In this study, a new method of dynamic identification in a coal-rock interface is proposed based on the fusion of adaptive weight optimization and multi-sensor information. In accordance with significant differences in the signals such as the cutting current, vibration, acoustic emission, and infrared thermography under diverse cutting ratios, seven coal-rock mixture test specimens with different proportions were poured. During the cutting of the given test specimens, various signals measured by sensors were gathered and analyzed to establish feature databases. Moreover, combined with the fuzziness of multiple signals, the optimal thresholds of the membership functions (MFs) were calculated based on particle swarm optimization (PSO) and minimum fuzzy entropy (MFE). On this basis, a coal-rock interface identification model was developed. In particular, an adaptive weight optimization model was adopted to improve the identification accuracy of the proposed model according to the conflict characteristics between multi-evidence bodies. As a result, a cutting experiment on a random coal-rock interface verified both the accuracy and speed of the proposed identification model, in comparison with the single signal, adaptive Network-based fuzzy inference system (ANFIS) fusion, and improved PSO-BP. Both the coal residual and rock erosion were reduced, and the total recognition error declined to 1.89%. The proposed identification model of a coal-rock interface provided the theoretical foundation and technical premise to realize automatic and intelligent mining. © 2018 Elsevier B.V.","Adaptive weight optimization; Coal-rock interface; Dynamic identification; Information fusion; Multi-sensor; Particle swarm optimization"
"AI-Skin: Skin disease recognition based on self-learning and wide data collection through a closed-loop framework","2020","Information Fusion","10.1016/j.inffus.2019.06.005","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85068990864&doi=10.1016%2fj.inffus.2019.06.005&partnerID=40&md5=58ed2dabb024de2d69bb92257a669bab","There are a lot of hidden dangers in the change of human skin conditions, such as the sunburn caused by long-time exposure to ultraviolet radiation, which not only has aesthetic impact causing psychological depression and lack of self-confidence, but also may even be life-threatening due to skin canceration. Current skin disease researches adopt the auto-classification system for improving the accuracy rate of skin disease classification. However, the excessive dependence on the image sample database is unable to provide individualized diagnosis service for different population groups. To overcome this problem, a medical AI framework based on data width evolution and self-learning is put forward in this paper to provide skin disease medical service meeting the requirement of real time, extendibility and individualization. First, the wide collection of data in the close-loop information flow of user and remote medical data center is discussed. Next, a data set filter algorithm based on information entropy is given, to lighten the load of edge node and meanwhile improve the learning ability of remote cloud analysis model. In addition, the framework provides an external algorithm load module, which can be compatible with the application requirements according to the model selected. Three kinds of deep learning model, i.e., LeNet-5, AlexNet and VGG16, are loaded and compared, which have verified the universality of the algorithm load module. The experiment platform for the proposed real-time, individualized and extensible skin disease recognition system is built. And the system's computation and communication delay under the interaction scenario between tester and remote data center are analyzed. It is demonstrated that the system we put forward is reliable and effective. © 2019 Elsevier B.V.","Data width evolution; Deep learning model; Self-learning process; Skin disease recognition"
"Integrating model- and data-driven methods for synchronous adaptive multi-band image fusion","2020","Information Fusion","10.1016/j.inffus.2019.07.009","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85069922870&doi=10.1016%2fj.inffus.2019.07.009&partnerID=40&md5=48724a617d9c3b878df602bfb4ebd35b","A novel synchronous adaptive framework for multi-band image fusion is proposed, based on integrated model- and data-driven (MDDR) techniques. This approach includes a deep stack convolutional neural network (DSCNN) for multi-band images, established by redefining convolutional kernels in the first layer using Gaussian and Gaussian-Laplace filters. The structure of the convolutional neural network (CNN) was improved by removing a sample CNN layer to reduce information loss, prior to decomposing and reconstructing input images in an adaptive framework. A deep gate convolution neural network (DGCNN) was then established using a gate structure principle common in long short-term memory (LSTM) techniques. As a result, the network can adaptively fuse high- and low-frequency components, similar to conventional image fusion rules in model-driven algorithms. Finally, a synchronous adaptive multi-band image fusion neural network (SAMIFNN) was constructed by embedding the DGCNN into decompose- and reconstruct-subnets in the DSCNN. Data from ImageNet IL SVRC2013 and TNO image fusion datasets were used for training (80%) and testing (20%). SAMIFNN was then compared with seven state-of-the-art methods applied to eight groups of representative images, the TRICLOBS dynamic multiband image dataset, and a series of medical CT, MR, and PET scans. The proposed network required significantly lower runtimes than conventional algorithms, producing satisfactory results across 21 different evaluation metrics (compared with a maximum of 15 achieved by conventional techniques). These experimental results demonstrate that the proposed algorithm can successfully implement synchronous adaptive multi-band image fusion with higher contrast, better visual perception, and less distortion, without requiring a priori knowledge or manual intervention. © 2019 Elsevier B.V.","Adaptive fusion algorithm; Data-driven; Deep learning; Image fusion; Model-driven; Multi-band images"
"Scalable entity resolution for Web product descriptions","2020","Information Fusion","10.1016/j.inffus.2019.06.002","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85067202468&doi=10.1016%2fj.inffus.2019.06.002&partnerID=40&md5=3ad670bbe2b4f868ec3f46a449270a2d","Consumers are increasingly using the Web to find product information and make online purchases. This is reflected by the ongoing growth of worldwide e-commerce sales figures. Entity resolution is an important task that supports many services that have arisen from this growth, such as Web shop aggregators. In this paper, we propose a scalable framework for multi-source entity resolution. Our blocking approach employs model words to produce blocks that make our solution highly effective and efficient for the considered domains. An in-depth evaluation, performed using millions of experiments and three large datasets (on consumer electronics and software products), shows that our model words-based approach outperforms other approaches in most cases. Furthermore, we also evaluate our approach with an imperfect similarity function and find that model words-based blocking schemes provide the best blocks with respect to the F1-measure. © 2019 Elsevier B.V.","Blocking schemes; E-commerce; Entity resolution; Web shop aggregators"
"Choosing the proper autoencoder for feature fusion based on data complexity and classifiers: Analysis, tips and guidelines","2020","Information Fusion","10.1016/j.inffus.2019.07.004","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85069698850&doi=10.1016%2fj.inffus.2019.07.004&partnerID=40&md5=0781c47c9a81ae4f283af611ac6e3e1e","Classifying data patterns is one of the most recurrent applications in machine learning. The number of input features influences the predictive performance of many classification models. Most classifiers work with high-dimensional spaces. Therefore, there is a great interest in facing the task of reducing the input space. Manifold learning has been shown to perform better than classical dimensionality reduction approaches, such as Principal Component Analysis and Linear Discriminant Analysis. In this sense, Autoencoders (AEs) provide an automated way of performing feature fusion, finding the best manifold to reconstruct the data. There are several models and architectures of AEs. For this reason, in this study an exhaustive analysis of the predictive performance of different AEs models with a large number of datasets is proposed, aiming to provide a set of useful guidelines. These will allow users to choose the appropriate AE model for each case, depending on data traits and the classifier to be used. A thorough empirical analysis is conducted including four AE models, four classification paradigms and a group of datasets with a variety of traits. A convenient set of rules to follow is obtained as a result. © 2019 Elsevier B.V.","Autoencoders; Classification; Deep learning; Dimensionality reduction; Feature fusion"
"Using Hellinger and Bures metrics to construct two-dimensional quantum metric space for weather data fusion","2020","Information Fusion","10.1016/j.inffus.2019.09.004","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072157048&doi=10.1016%2fj.inffus.2019.09.004&partnerID=40&md5=dec6f7dcae058092cb395fb962cd2869","Motivated by obtaining more concise and reliable fusion results for relevant applications, such as, in sector monitoring, risk managing, early-warning, dynamic prediction, this paper explores the detection and fusion models of weather data from multiple perspectives. We represent the weather data as the collection of quantum states, and study construction of the quantum metric space in which the related weather data fusion method is developed. Since weather data usually contain raw (image or sensor) data, feature data, or decision data, the weather data fusion belongs to normal three levels of data fusion, i.e., pixel level, feature level or decision level. In this paper we represent weather data units as density matrixes, and take the quantified data units as the basis for constructing the two-dimensional quantum metric space consisting of Hellinger and Bures metrics. All the density matrix units in this space are transformed into the rectangle nodes for detection and fusion. Then, according to the neighborhood relationships between rectangle nodes and the density of rectangle nodes in a specified rectangle, the source weather dataset is divided into different subsets. The key to the fusion of the rectangle nodes in a subset is to calculate the presupposing central node in this subset's corresponding rectangle. And the corresponding object node depends on the areas of the rectangles including rectangle nodes and the central node. The experimental evaluation demonstrates that, compared with the already developed fusion methods, the proposed weather data fusion method can obtain more concise and reliable fusion results for decision applications. © 2019 Elsevier B.V.","Bures metric; Hellinger metric; Rectangle nodes; Two-dimensional metric space; Weather data fusion"
"Android malware detection through hybrid features fusion and ensemble classifiers: The AndroPyTool framework and the OmniDroid dataset","2019","Information Fusion","10.1016/j.inffus.2018.12.006","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85060977441&doi=10.1016%2fj.inffus.2018.12.006&partnerID=40&md5=f7dd9e5f8fc3bd87ec366fcb830f682d","Cybersecurity has become a major concern for society, mainly motivated by the increasing number of cyber attacks and the wide range of targeted objectives. Due to the popularity of smartphones and tablets, Android devices are considered an entry point in many attack vectors. Malware applications are among the most used tactics and tools to perpetrate a cyber attack, so it is critical to study new ways of detecting them. In these detection mechanisms, machine learning has been used to build classifiers that are effective in discerning if an application is malware or benignware. However, training such classifiers require big amounts of labelled data which, in this context, consist of categorised malware and benignware Android applications represented by a set of features able to describe their behaviour. For that purpose, in this paper we present OmniDroid, a large and comprehensive dataset of features extracted from 22,000 real malware and goodware samples, aiming to help anti-malware tools creators and researchers when improving, or developing, new mechanisms and tools for Android malware detection. Furthermore, the characteristics of the dataset make it suitable to be used as a benchmark dataset to test classification and clustering algorithms or new representation techniques, among others. The dataset has been released under a Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License and was built using AndroPyTool, our automated framework for dynamic and static analysis of Android applications. Finally, we test a set of ensemble classifiers over this dataset and propose a malware detection approach based on the fusion of static and dynamic features through the combination of ensemble classifiers. The experimental results show the feasibility and potential usability (for the machine learning, soft computing and cyber security communities) of our automated framework and the publicly available dataset. © 2018 Elsevier B.V.","Android; Hybrid features fusion; Malware analysis; Malware dataset"
"Second-order statistics analysis and comparison between arithmetic and geometric average fusion: Application to multi-sensor target tracking","2019","Information Fusion","10.1016/j.inffus.2019.02.009","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062220911&doi=10.1016%2fj.inffus.2019.02.009&partnerID=40&md5=bb0c9a7c410167911dc2eef671bcee93","Two fundamental approaches to information averaging are based on linear and logarithmic combination, yielding the arithmetic average (AA) and geometric average (GA) of the fusing data, respectively. In the context of multi-sensor target tracking, the two most common formats of data to be fused are random variables and probability density functions, namely v-fusion and f-fusion, respectively. In this work, we analyze and compare the second-order statistics (including variance and mean square error) of AA and GA in terms of both v-fusion and f-fusion. The case of weighted Gaussian mixtures representing multitarget densities in the presence of false alarms and missed detections (whose weight sums are not necessarily unit) is also considered, the result of which turns out to be significantly different from that of a single target. In addition to exact derivation, exemplifying analyses and illustrations are also provided. © 2019 Elsevier B.V.","Aggregation operator; Arithmetic mean; Average consensus; Covariance intersection; Distributed tracking; Geometric mean; Linear pool; Log-linear pool; Multisensor fusion"
"Cooperative information-driven source search and estimation for multiple agents","2020","Information Fusion","10.1016/j.inffus.2019.07.007","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85069650878&doi=10.1016%2fj.inffus.2019.07.007&partnerID=40&md5=d5231a07e7439d3d7280f3f61b391dc5","This paper proposes different levels of coordination methods for information-driven source search and estimation in a stochastic and turbulent atmospheric dispersion event. Multiple mobile sensors are assumed to communicate one another over a wireless network and share the minimal data (e.g. current position, sensor measurements, and control decision) to reduce the communication burden. The particle filter, sampling-based sequential Monte Carlo method, suitable for highly non-linear and non-Gaussian systems and the measurement sensor fusion method are used for the estimation of the source position and release rate. For efficient autonomous search, three coordination methods are introduced based on the Infotaxis algorithm: non-coordination, passive coordination, and negotiated coordination. To demonstrate the benefit of the proposed cooperative multi-mobile sensor system, extensive simulations on simulated and real experimental data are performed for different levels of coordination methods and the number of mobile sensors. © 2019 Elsevier B.V.","Autonomous search; Bayesian inference; Dispersion modelling; Multi-sensor network; Sensor management; Sequential Monte Carlo"
"A multi-sensor data fusion enabled ensemble approach for medical data from body sensor networks","2020","Information Fusion","10.1016/j.inffus.2019.06.021","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85067795482&doi=10.1016%2fj.inffus.2019.06.021&partnerID=40&md5=085143d642c1761bfa028898066d8b66","Wireless Body Sensor Network (BSNs) are wearable sensors with varying sensing, storage, computation, and transmission capabilities. When data is obtained from multiple devices, multi-sensor fusion is desirable to transform potentially erroneous sensor data into high quality fused data. In this work, a data fusion enabled Ensemble approach is proposed to work with medical data obtained from BSNs in a fog computing environment. Daily activity data is obtained from a collection of sensors which is fused together to generate high quality activity data. The fused data is later input to an Ensemble classifier for early heart disease prediction. The ensembles are hosted in a Fog computing environment and the prediction computations are performed in a decentralised manners. The results from the individual nodes in the fog computing environment are then combined to produce a unified output. For the classification purpose, a novel kernel random forest ensemble is used that produces significantly better quality results than random forest. An extensive experimental study supports the applicability of the solution and the obtained results are promising, as we obtain 98% accuracy when the tree depth is equal to 15, number of estimators is 40, and 8 features are considered for the prediction task. © 2019","Body sensor network; Disease prediction; Ensemble methods; Fog computing; Multi-sensor data fusion"
"Managing incomplete preferences and consistency improvement in hesitant fuzzy linguistic preference relations with applications in group decision making","2019","Information Fusion","10.1016/j.inffus.2018.10.011","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056222833&doi=10.1016%2fj.inffus.2018.10.011&partnerID=40&md5=dca6113cf1a331c38ad506918e7f0bd8","Incomplete hesitant fuzzy linguistic preference relations (IHFLPRs) are useful in decision making which combine advantages of hesitant fuzzy linguistic term sets and incomplete fuzzy preference relations. The existing researches on IHFLPRs pay little attention to missing elements, and the consistency improvement processes change original information greatly. Inspired by the worst and the best consistency indexes of hesitant fuzzy linguistic preference relations, this paper constructs several optimization models to calculate the missing elements of IHFLPRs. As a result, a complete hesitant fuzzy linguistic preference relation is obtained. Furthermore, an algorithm is introduced to improve the additive consistency of the hesitant fuzzy linguistic preference relation to an acceptable level. Finally a group decision making model based on IHFLPRs is introduced and an example is presented. © 2018 Elsevier B.V.","Best consistency index; Hesitant fuzzy linguistic term set; Incomplete hesitant fuzzy linguistic preference relation; Worst consistency index"
"A novel multi-criteria group decision-making method for heterogeneous and dynamic contexts using multi-granular fuzzy linguistic modelling and consensus measures","2020","Information Fusion","10.1016/j.inffus.2019.06.028","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85068233716&doi=10.1016%2fj.inffus.2019.06.028&partnerID=40&md5=169bd4c5cd5f78b98c682b23d961f066","This paper presents a novel multi-criteria group decision-making method that is capable of working in heterogeneous and dynamic environments. It is applicable in non-static frameworks where the decision context can vary at any time during the process. It also makes experts comfortable by allowing them to provide information using their most preferred means. By using multi-granular fuzzy linguistic modelling, the experts can provide preferences using their preferred linguistic label set. Furthermore, they also can choose the criteria values that they want to provide preferences for. Also, experts, alternatives and criteria can be added at any time during the decision process. Finally, consensus measures are applied in order to promote further debate and to help the experts reach an agreement. © 2019 Elsevier B.V.","Computing with words; Consensus measures; Multi-criteria group decision-making; Multi-granular fuzzy linguistic modelling"
"Networked fusion estimation with multiple uncertainties and time-correlated channel noise","2020","Information Fusion","10.1016/j.inffus.2019.07.008","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85069966777&doi=10.1016%2fj.inffus.2019.07.008&partnerID=40&md5=f63324a8eb08c404f2a35136fc17012b","This paper is concerned with the fusion filtering and fixed-point smoothing problems for a class of networked systems with multiple random uncertainties in both the sensor outputs and the transmission connections. To deal with this kind of systems, random parameter matrices are considered in the mathematical models of both the sensor measurements and the data available after transmission. The additive noise in the transmission channel from each sensor is assumed to be sequentially time-correlated. By using the time-differencing approach, the available measurements are transformed into an equivalent set of observations that do not depend on the time-correlated noise. The innovation approach is then applied to obtain recursive distributed and centralized fusion estimation algorithms for the filtering and fixed-point smoothing estimators of the signal based on the transformed measurements, which are equal to the estimators based on the original ones. The derivation of the algorithms does not require the knowledge of the signal evolution model, but only the mean and covariance functions of the processes involved (covariance information). A simulation example illustrates the utility and effectiveness of the proposed fusion estimation algorithms, as well as the applicability of the current model to deal with different network-induced random phenomena. © 2019 Elsevier B.V.","Centralized fusion estimation; Covariance information; Distributed fusion estimation; Random parameter matrices; Time-correlated noise"
"Adjusting forwarder nodes and duty cycle using packet aggregation routing for body sensor networks","2020","Information Fusion","10.1016/j.inffus.2019.06.020","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85067821237&doi=10.1016%2fj.inffus.2019.06.020&partnerID=40&md5=4d723d11576e9abfee6fb113f7ceff19","In the body sensor networks (BSNs), the data redundancy and transmission delay are two problems for improving network performance. In the previous scheme, multi-sensor fusion is used to reduce the energy consumption of the sensor network, but it causes larger delay. To reduce the amount of redundant data and transmission delay, an adjusting forwarder nodes and duty cycle using packet aggregation routing (AFNDCAR) scheme is proposed for BSNs. The main contributions of the AFNDCAR scheme are as follows: (a) nodes select forwarder nodes based on the higher energy consumption, longer queue length of packets and waiting time of packets aggregation to reduce the transmission delay. (b) In the dense network, the number of forwarder nodes and the probability for generating data packets are adjusted to minimize the transmission delay and maximum the packet transmission success ratio. (c) In the sparse network, the duty cycle of nodes can be adjusted using the energy left of nodes. The theoretical analysis show that the amount of redundancy data, the transmission delay and energy efficiency of nodes improved significantly. © 2019 Elsevier B.V.","Body sensor networks; Data aggregation; Duty cycle; Energy efficiency; Transmission delay"
"Content based image retrieval using image features information fusion","2019","Information Fusion","10.1016/j.inffus.2018.11.004","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056599357&doi=10.1016%2fj.inffus.2018.11.004&partnerID=40&md5=b87b09c816425276b9798aa7fd282280","Recent image retrieval techniques are focusing on multiple image features for the efficient image retrieval. It has been an inevitable requirement to fetch the images from a variety of semantic groups and datasets. It is vital to retrieve the images based on their primitive features shape, texture, color and spatial information to cater the versatile image datasets. State-of-the-art detectors and descriptors are capable of finding the interest points based on their specialty. To encompass the strength of the image features for the information fusion purpose this contribution presents a novel technique to fuse the spatial color information with shaped extracted features and object recognition. For RGB channels L2 spatial color arrangements are applied and features are extracted, thereby fused with intensity ranged shapes formed by connecting the discovered edges and corners for the grey level image. Perifoveal receptive field estimation with 128-bit cascade matching with symmetric sampling on the detected interest points that discovers the potential information for the complex, overlay, foreground and background objects. Firstly the process is accomplished by reducing the massive features vectors, selecting high variance coefficient and secondly obtaining the indexing and retrieval by employing a Bag-of-Words approach. Extensive experiments are conducted on ten highly recognized image dataset benchmarks, specialized for texture, shapes, colors and objects including ImageNet, Caltech-256, Caltech-101, 102-Flower, Corel-10,000, 17-Flower, Corel-1000, COIL, ALOT and FTVL tropical fruits. To check the affectivity and robustness of the proposed method, it is compared with state-of-the-art detectors and descriptors SIFT, SURF, HOG, LBP, DoG, MSER and RGBLBP. Encouraging results reported that the proposed method has a remarkable performance in most of the image categories of versatile image datasets and can gain better precision to those of the state-of-the-art detectors and descriptors. © 2018 Elsevier B.V.","Bag of words; Content based image retrieval; Features fusion; Features selection; Image descriptor; Information fusion; Interest point detection; Objects recognition; Shape features; Spatial color features"
"MIMR-DGSA: Unsupervised hyperspectral band selection based on information theory and a modified discrete gravitational search algorithm","2019","Information Fusion","10.1016/j.inffus.2019.02.005","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061838106&doi=10.1016%2fj.inffus.2019.02.005&partnerID=40&md5=17aa459d38c98cd8c343772699b6c7d6","Band selection plays an important role in hyperspectral data analysis as it can improve the performance of data analysis without losing information about the constitution of the underlying data. We propose a MIMR-DGSA algorithm for band selection by following the Maximum-Information-Minimum-Redundancy (MIMR) criterion that maximises the information carried by individual features of a subset and minimises redundant information between them. Subsets are generated with a modified Discrete Gravitational Search Algorithm (DGSA) where we definine a neighbourhood concept for feature subsets. A fast algorithm for pairwise mutual information calculation that incorporates variable bandwidths of hyperspectral bands called VarBWFastMI is also developed. Classification results on three hyperspectral remote sensing datasets show that the proposed MIMR-DGSA performs similar to the original MIMR with Clonal Selection Algorithm (CSA) but is computationally more efficient and easier to handle as it has fewer parameters for tuning. © 2019 Elsevier B.V.","Band selection; Discrete optimisation; Entropy; Evolutionary computation; Feature selection; Gravitational search algorithm; Hyperspectral imaging; Maximum-Information-Minimum-Redundancy; Mutual information."
"Multi-sensor fusion based intelligent sensor relocation for health and safety monitoring in BSNs","2020","Information Fusion","10.1016/j.inffus.2019.07.002","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85069727187&doi=10.1016%2fj.inffus.2019.07.002&partnerID=40&md5=75537a460e01f053006c92556237e153","The body sensor networks (BSNs) have attracted great attention due to their numerous important features and wide applications in health and safety monitoring, especially in some hostile or potentially dangerous workplaces. In this paper, aiming to provide continuous coverage from the initial Region of Interest (ROI) to a New Region of Interest (NROI) to trace the BSNs for human health and safety monitoring, we formulate and define the novel confident information coverage (CIC)-based Intelligent Sensor Relocation for NROI (CIC-ISR-NROI) problem in mobile wireless sensor networks (MWSNs) based on the novel CIC model. For handing the CIC-ISR-NROI problem, we develop two energy-efficient intelligent sensor relocation algorithms based on multi-sensor fusion, the Rapid Relocation Time Low Energy Consumption (RRTLEC) algorithm and optimized RRTLEC algorithm, to relocate redundant mobile sensors from the ROI to cover the NROI in a timely and energy-efficient manner while constructing the communication chain to connect the ROI and the NROI. To verify the effectiveness and efficiency of the proposed schemes, we conduct a series of experiments which correspond to the realistic scenarios in health and safety monitoring in the 272 uranium tailing. Experimental results show that the performance of our approaches is better than the other typical peer approaches by the metrics of the total moving energy consumption and the maximum relocation time. © 2019 Elsevier B.V.","Body sensor networks (BSNs); Health and safety monitoring; Mobile wireless sensor networks (MWSNs); Multi-Sensor fusion; Sensor relocation"
"MARESye: A hybrid imaging system for underwater robotic applications","2020","Information Fusion","10.1016/j.inffus.2019.07.014","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85070677193&doi=10.1016%2fj.inffus.2019.07.014&partnerID=40&md5=7a90b0ff67e7e380f9e28426becfc9b4","This article presents an innovative hybrid imaging system that provides dense and accurate 3D information from harsh underwater environments. The proposed system is called MARESye and captures the advantages of both active and passive imaging methods: multiple light stripe range (LSR) and a photometric stereo (PS) technique, respectively. This hybrid approach fuses information from these techniques through a data-driven formulation to extend the measurement range and to produce high density 3D estimations in dynamic underwater environments. This hybrid system is driven by a gating timing approach to reduce the impact of several photometric issues related to the underwater environments such as, diffuse reflection, water turbidity and non-uniform illumination. Moreover, MARESye synchronizes and matches the acquisition of images with sub-sea phenomena which leads to clear pictures (with a high signal-to-noise ratio). Results conducted in realistic environments showed that MARESye is able to provide reliable, high density and accurate 3D data. Moreover, the experiments demonstrated that the performance of MARESye is less affected by sub-sea conditions since the SSIM index was 0.655 in high turbidity waters. Conventional imaging techniques obtained 0.328 in similar testing conditions. Therefore, the proposed system represents a valuable contribution for the inspection of maritime structures as well as for the navigation procedures of autonomous underwater vehicles during close range operations. © 2019 Elsevier B.V.","Active imaging; Image fusion; Passive imaging; Robotics; Underwater; Underwater imaging"
"Infrared and visible image fusion via detail preserving adversarial learning","2020","Information Fusion","10.1016/j.inffus.2019.07.005","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85069882474&doi=10.1016%2fj.inffus.2019.07.005&partnerID=40&md5=f2498d10bf50cfba306a92c1158de4e8","TargefTablets can be detected easily from the background of infrared images due to their significantly discriminative thermal radiations, while visible images contain textural details with high spatial resolution which are beneficial to the enhancement of target recognition. Therefore, fused images with abundant detail information and effective target areas are desirable. In this paper, we propose an end-to-end model for infrared and visible image fusion based on detail preserving adversarial learning. It is able to overcome the limitations of the manual and complicated design of activity-level measurement and fusion rules in traditional fusion methods. Considering the specific information of infrared and visible images, we design two loss functions including the detail loss and target edge-enhancement loss to improve the quality of detail information and sharpen the edge of infrared targets under the framework of generative adversarial network. Our approach enables the fused image to simultaneously retain the thermal radiation with sharpening infrared target boundaries in the infrared image and the abundant textural details in the visible image. Experiments conducted on publicly available datasets demonstrate the superiority of our strategy over the state-of-the-art methods in both objective metrics and visual impressions. In particular, our results look like enhanced infrared images with clearly highlighted and edge-sharpened targets as well as abundant detail information. © 2019 Elsevier B.V.","Convolution neural network; Detail preserving; Generative adversarial network; Image fusion; Infrared"
"Subspace segmentation-based robust multiple kernel clustering","2020","Information Fusion","10.1016/j.inffus.2019.06.017","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85067793458&doi=10.1016%2fj.inffus.2019.06.017&partnerID=40&md5=9e77e764d79a5e3740554378497d4b7a","Multiple kernel clustering (MKC) is an important research topic during the last few decades. It optimally combines a group of pre-specified base kernels to improve clustering performance. Though demonstrating promising performance in various applications, this task is still challenging due to lack of reliable discriminative guidance for the base kernel combination. Moreover, noise from either corrupted data or inappropriately selected base kernel parameters would undermine the intrinsic manifold and makes the problem even harder. In this paper, we integrate subspace segmentation into MKC and propose a robust subspace segmentation-based multiple kernel clustering (SS-MKC) algorithm to address these issues. In our formulation, we unify the constrained kernel polarization and subspace segmentation into a single procedure, where the resultant affinity matrix embedded with robust subspace structural information is utilized to guide the linear combination of base kernels. In addition, we carefully design the noise representation matrix as well as two sparse constraints, i.e., the ℓ1-norm and the probability constraints, to eliminate the adverse effect of noise among base kernels. We then propose a novel Alternative Direction Method of Multiplier (ADMM)-based algorithm to solve the resulting optimization problem. Extensive experiments have been conducted on both synthetic and public benchmark datasets, and the results well demonstrate the superiority of the proposed algorithm when compared with the state-of-the-art MKC methods. © 2019 Elsevier B.V.","Multiple kernel clustering; Noisy data; Subspace segmentation"
"Knowledge fusion patterns: A survey","2019","Information Fusion","10.1016/j.inffus.2018.11.007","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057299109&doi=10.1016%2fj.inffus.2018.11.007&partnerID=40&md5=f47487459b6605ee1d41b4823532d08e","The survey analyzes, summarizes, and classifies knowledge fusion patterns reported in different studies. It provides overview of the patterns explicitly declared in the found studies and proposes some patterns that have been recognized as such. Namely, some knowledge fusion models are considered as patterns. The patterns are classified from the perspective of the types of resources that provide knowledge for the fusion process. Two types of resources are distinguished: knowledge worker and knowledge repository. Three groups of patterns are differentiated: (1) patterns fusing knowledge stored in knowledge repositories; (2) patterns fusing knowledge of knowledge workers; and (3) patterns fusing knowledge of knowledge workers and knowledge accumulated in repositories. The patterns are specified in terms of the pattern names, the inputs and outputs, the methods supporting knowledge fusion, and the references to the sources introducing these patterns. © 2018 Elsevier B.V.","Knowledge fusion; Knowledge fusion patterns"
"Remote sensing image fusion based on two-stream fusion network","2020","Information Fusion","10.1016/j.inffus.2019.07.010","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85070680080&doi=10.1016%2fj.inffus.2019.07.010&partnerID=40&md5=0b2e217fe3e59d3ce911b495b6de938e","Remote sensing image fusion (also known as pan-sharpening) aims at generating a high resolution multi-spectral (MS) image from inputs of a high spatial resolution single band panchromatic (PAN) image and a low spatial resolution multi-spectral image. Inspired by the astounding achievements of convolutional neural networks (CNNs) in a variety of computer vision tasks, in this paper we propose a Two-stream Fusion Network (TFNet) to address the problem of pan-sharpening. Unlike many previous CNN based methods that consider pan-sharpening as a super-resolution problem and perform pan-sharpening through mapping the stacked PAN and MS to the target high resolution MS image, the proposed TFNet aims to fuse PAN and MS images in feature domain and reconstruct the pan-sharpened image from the fused features. The TFNet mainly consists of three parts. The first part is comprised of two networks extracting features from PAN and MS images, respectively. The subsequent network fuses them together to form compact features that represent both spatial and spectral information of PAN and MS images, simultaneously. Finally, the desired high spatial resolution MS image is recovered from the fused features through an image reconstruction network. Experiments on Quickbird and GaoFen-1 images demonstrate that the proposed TFNet can fuse PAN and MS images effectively, and produce pan-sharpened images competitive with even superior to state of the arts. © 2019 Elsevier B.V.","Convolutional neural networks; Deep learning; Image fusion; Pan-sharpening; Remote Sensing"
"Adaptive gait detection based on foot-mounted inertial sensors and multi-sensor fusion","2019","Information Fusion","10.1016/j.inffus.2019.03.002","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062518614&doi=10.1016%2fj.inffus.2019.03.002&partnerID=40&md5=e16675cfae6943ac12634c00362d920a","Gait detection plays an important role in areas where spatial-temporal gait parameters are needed. Inertial sensors are now sufficiently small in size and light in weight for collection of human gait data with body sensor networks (BSNs). However, gait detection methods usually rely on careful sensor alignment and a set of rule-based thresholds, which are brittle or difficult to implement. This paper presents an adaptive method for gait detection, which models human gait with a hidden Markov model (HMM), and employs a neural network (NN) to deal with the raw measurements and feed the HMM with classifications. Six gait events are involved for a detailed analysis, i.e., heel strike, foot flat, mid-stance, heel off, toe off, and mid-swing. In order to obtain enough gait data for training a gait model, the gait events are labeled by a rule-based detection method, in which the predefined rules are verified with an optical motion capture system. Experiments were conducted by nine subjects, based on a dual-sensor configuration with one sensor on each foot. Detection performance is quantified using metrics of accuracy, sensitivity and specificity, and the averaged performance values are 98.11%, 94.32% and 98.86% respectively with a timing error less than 2.5 ms. © 2019 Elsevier B.V.","Body-worn sensors; Gait analysis; Hidden Markov model (HMM); Machine learning; Neural network (NN)"
"On identification of driving-induced stress using electroencephalogram signals: A framework based on wearable safety-critical scheme and machine learning","2020","Information Fusion","10.1016/j.inffus.2019.06.006","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85067210870&doi=10.1016%2fj.inffus.2019.06.006&partnerID=40&md5=ec4a333ea29138443d5566d455301690","Driving an automobile under high stress level reduces driver's control on vehicle and risk-assessment capabilities, often resulting in road accidents. Driver's anxiety therefore is a key factor to consider in accident prevention and road safety. This emphasizes the modern computing techniques to assist drivers by continuous stress level monitoring. Development of such a system requires designing a framework, which can recognize the drivers’ affective state and take preventive measures to account for escalating stress level. This work presents a machine learning-based approach to identify driving-induced stress patterns. For this, electroencephalograph (EEG) signals are utilized as the physiological signals. The ongoing brain activity is logged as EEG signal to determine the link between brain dynamics and emotional states. Three classifiers are utilized in this work, namely: Support Vector Machine (SVM), Neural Network (NN), and Random Forest (RF) to classify EEG patterns on the basis of the subject's self-reported emotional states while driving in various situations. A framework is proposed to recognize emotions based on EEG patterns by systematically identifying emotion-specific features from the raw EEG signal and investigating the classifiers’ effectiveness. A comprehensive analysis of various performance measures concludes that among the three classifiers employed in this study, SVM performs better to distinguish between rest and stress state. The evaluation obtained an average classification accuracy of 97.95% ± 2.65%, precision of 89.23%, sensitivity of 88.83%, and specificity of 94.92%; when tested over 50 automotive drivers. © 2019 Elsevier B.V.","Driving-induced stress; EEG; Emotion recognition; Information fusion; Stress prediction"
"Distributed estimation over a low-cost sensor network: A Review of state-of-the-art","2020","Information Fusion","10.1016/j.inffus.2019.06.026","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85068989578&doi=10.1016%2fj.inffus.2019.06.026&partnerID=40&md5=0698d6953531a940b769fbb4a4fd2d5c","Proliferation of low-cost, lightweight, and power efficient sensors and advances in networked systems enable the employment of multiple sensors. Distributed estimation provides a scalable and fault-robust fusion framework with a peer-to-peer communication architecture. For this reason, there seems to be a real need for a critical review of existing and, more importantly, recent advances in the domain of distributed estimation over a low-cost sensor network. This paper presents a comprehensive review of the state-of-the-art solutions in this research area, exploring their characteristics, advantages, and challenging issues. Additionally, several open problems and future avenues of research are highlighted. © 2019 The Authors","Challenging issues; Distributed estimation; Fusion methodology; Low-cost sensor network"
"Multi-task emotion communication system with dynamic resource allocations","2019","Information Fusion","10.1016/j.inffus.2019.03.003","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062640339&doi=10.1016%2fj.inffus.2019.03.003&partnerID=40&md5=5fbede35fc922e48a5289548928a1efa","The research of long-distance emotion communication and interaction without time and space constraints is an important area in human-robot interaction (HRI) systems. Although many methods of emotion recognition have been studied for analyzing various emotion signals, the resource allocation of transmission for emotion communication signals of many pairs of users has not been fully considered nor solved at the same time. This paper proposes a new multi-task emotion communication system (MEmSys), where the transmission resources allocation issue is considered. Specifically, we firstly establish the architecture of MEmSys, and the entire emotion interaction process of the proposed system is introduced. By analyzing fairness and urgency of different tasks, the mathematical expressions of the minimum task transmission rates for all user pairs are derived. Then, a dynamic optimal resource allocation scheme is presented to maximize the sum of the task transmission rates in the proposed system. Moreover, simulation experiment results and performance analyses show that the resource utilization ratio of the proposed allocation scheme for multiple user pairs is significantly improved compared to the single user pair system. Finally, future works are discussed to provide insights for our next research. © 2019 Elsevier B.V.","Dynamic optimal resource allocation; Emotion communication; Multi-task scheduling; The minimum task transmission rate"
"An information fusion framework for person localization via body pose in spectator crowds","2019","Information Fusion","10.1016/j.inffus.2018.11.011","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061377746&doi=10.1016%2fj.inffus.2018.11.011&partnerID=40&md5=6c58c6d24f1d44bd0bffbe1c41409e0e","Person localization or segmentation in low resolution crowded scenes is important for person tracking and recognition, action detection and anomaly identification. Due to occlusion and lack of inter-person space, person localization becomes a difficult task. In this work, we propose a novel information fusion framework to integrate a Deep Head Detector and a body pose detector. A more accurate body pose showing limb positions will result in more accurate person localization. We propose a novel Deep Head Detector (DHD) to detect person heads in crowds. The proposed DHD is a fully convolutional neural network and it has shown improved head detection performance in crowds. We modify Deformable Parts Model (DPM) pose detector to detect multiple upper body poses in crowds. We efficiently fuse the information obtained by the proposed DHD and the modified DPM to obtain a more accurate person pose detector. The proposed framework is named as Fusion DPM (FDPM) and it has exhibited improved body pose detection performance on spectator crowds. The detected body poses are then used for more accurate person localization by segmenting each person in the crowd. © 2018","Body pose detection; Crowd analysis; Information fusion; Person localization; Person segmentation; Upper body detection"
"Network traffic fusion and analysis against DDoS flooding attacks with a novel reversible sketch","2019","Information Fusion","10.1016/j.inffus.2018.10.013","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056573181&doi=10.1016%2fj.inffus.2018.10.013&partnerID=40&md5=ec6ba5a5b478cf53a170eda0170b8c87","Distributed Denial of Service (DDoS) flooding attacks are one of the typical attacks over the Internet. They aim to prevent normal users from accessing specific network resources. How to detect DDoS flooding attacks arises a significant and timely research topic. However, with the continuous increase of network scale, the continuous growth of network traffic brings great challenges to the detection of DDoS flooding attacks. Incomplete network traffic collection or non-real-time processing of big-volume network traffic will seriously affect the accuracy and efficiency of attack detection. Recently, sketch data structures are widely applied in high-speed networks to compress and fuse network traffic. But sketches suffer from a reversibility problem that it is difficult to reconstruct a set of keys that exhibit abnormal behavior due to the irreversibility of hash functions. In order to address the above challenges, in this paper, we first design a novel Chinese Remainder Theorem based Reversible Sketch (CRT-RS). CRT-RS is not only capable of compressing and fusing big-volume network traffic but also has the ability of reversely discovering the anomalous keys (e.g., the sources of malicious or unwanted traffic). Then, based on traffic records generated by CRT-RS, we propose a Modified Multi-chart Cumulative Sum (MM-CUSUM) algorithm that supports self-adaptive and protocol independent detection to detect DDoS flooding attacks. The performance of the proposed detection method is experimentally examined by two open source datasets. The experimental results show that the method can detect DDoS flooding attacks with efficiency, accuracy, adaptability, and protocol independability. Moreover, by comparing with other attack detection methods using sketch techniques, our method has quantifiable lower computation complexity when recovering the anomalous source addresses, which is the most important merit of the developed method. © 2018 Elsevier B.V.","Attack detection; Bloom filter; Chinese Remainder Theorem; DDoS flooding attacks; Decision fusion; Multi-chart Cumulative Sum; Network traffic fusion; Reversible sketch"
"Maximal c consensus meets","2019","Information Fusion","10.1016/j.inffus.2018.09.011","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056612105&doi=10.1016%2fj.inffus.2018.09.011&partnerID=40&md5=2a7ef2e5b8e78f1b28827628fdba90e2","Given a set S of subsets of a reference set X, we define the problem of finding c subsets of X that maximize the size of the intersection among the included subsets. Maximizing the size of the intersection means that they are subsets of the sets in S and they are as large as possible. We can understand the result of this problem as c consensus sets of S, or c consensus representatives of S. From the perspective of lattice theory, each representative will be a meet of some sets in S. In this paper we define formally this problem, and present heuristic algorithms to solve it. We also discuss the relationship with other established problems in the literature. © 2018 Elsevier B.V.","clustering; consensus clustering; heuristic algorithms; Maximal c consensus meets"
"Urban big data fusion based on deep learning: An overview","2020","Information Fusion","10.1016/j.inffus.2019.06.016","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85067654235&doi=10.1016%2fj.inffus.2019.06.016&partnerID=40&md5=60e85c74366ceaf10ba0ecaa2e296455","Urban big data fusion creates huge values for urban computing in solving urban problems. In recent years, various models and algorithms based on deep learning have been proposed to unlock the power of knowledge from urban big data. To clarify the methodologies of urban big data fusion based on deep learning (DL), this paper classifies them into three categories: DL-output-based fusion, DL-input-based fusion and DL-double-stage-based fusion. These methods use deep learning to learn feature representation from multi-source big data. Then each category of fusion methods is introduced and some examples are shown. The difficulties and ideas of dealing with urban big data will also be discussed. © 2019 Elsevier B.V.","Big data; Data fusion; Deep learning; Urban computing"
"Robust three-stage unscented Kalman filter for Mars entry phase navigation","2019","Information Fusion","10.1016/j.inffus.2018.11.003","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056473049&doi=10.1016%2fj.inffus.2018.11.003&partnerID=40&md5=b5ef2ee8769a63356cefad3ceb9c8d0b","A high-precision Mars entry navigation algorithm under parameter uncertainties and unknown inputs is developed via a robust three-stage unscented Kalman filter. The uncertainties lie in the atmosphere density, ballistic coefficient and lift-to-drag ratio are the most important error source of state estimation, which have been investigated in this paper. As the robust three-stage unscented Kalman filter has great advantages in parameter estimation and state estimation for nonlinear system with unknown input, it is proposed to compensate the effect of those parameter uncertainties and unknown inputs and obtain more accurate estimation. In the numerical simulation of Mars entry navigation, this filter algorithm has shown its advantages by resulting a high precision navigation with position error less than 100 m and velocity error less than 2 m/s, which fulfills the requirement of future pinpoint Mars landing missions. © 2018 Elsevier B.V.","Mars entry navigation; Nonlinear system; Parameter uncertainties; Robust three-stage unscented Kalman filter; Unknown input"
"Outlier detection based on a dynamic ensemble model: Applied to process monitoring","2019","Information Fusion","10.1016/j.inffus.2019.02.006","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062277424&doi=10.1016%2fj.inffus.2019.02.006&partnerID=40&md5=94dbd1abc8867bfc69cb01acd9be570b","This paper focuses on outlier detection and its application to process monitoring. The main contribution is that we propose a dynamic ensemble detection model, of which one-class classifiers are used as base learners. Developing a dynamic ensemble model for one-class classification is challenging due to the absence of labeled training samples. To this end, we propose a procedure that can generate pseudo outliers, prior to which we transform outputs of all base classifiers to the form of probability. Then we use a probabilistic model to evaluate competence of all base classifiers. Friedman test along with Nemenyi test are used together to construct a switching mechanism. This is used for determining whether one classifier should be nominated to make the decision or a fusion method should be applied instead. Extensive experiments are carried out on 20 data sets and an industrial application to verify the effectiveness of the proposed method. © 2019 Elsevier B.V.","Dynamic classifier selection; Ensemble learning; One-class classification; Outlier detection; Process monitoring"
"Online heart monitoring systems on the internet of health things environments: A survey, a reference model and an outlook","2020","Information Fusion","10.1016/j.inffus.2019.06.004","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85068125262&doi=10.1016%2fj.inffus.2019.06.004&partnerID=40&md5=bdf5c268b7aa395aaed2ba7d6bd7fe41","The Internet of Health Things promotes personalized and higher standards of care. Its application is diverse and attracts the attention of a substantial section of the scientific community. This approach has also been applied by people looking to enhance quality of life by using this technology. In this paper, we perform a survey that aims to present and analyze the advances of the latest studies based on medical care and assisted environment. We focus on articles for online monitoring, detection, and support of the diagnosis of cardiovascular diseases. Our research covers published manuscripts in scientific journals and recognized conferences since the year 2015. Also, we present a reference model based on the evaluation of the resources used from the selected studies. Finally, our proposal aims to help future enthusiasts to discover and enumerate the required factors for the development of a prototype for online heart monitoring purposes. © 2019 Elsevier B.V.","Bio sensors; Heart; Internet of health things; Online monitoring; Reference model"
"The fusion of panchromatic and multispectral remote sensing images via tensor-based sparse modeling and hyper-Laplacian prior","2019","Information Fusion","10.1016/j.inffus.2018.11.014","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057518666&doi=10.1016%2fj.inffus.2018.11.014&partnerID=40&md5=a437fd1d15fdbe07bc323df4928f7395","In this paper, we propose a tensor-based non-convex sparse modeling approach for the fusion of panchromatic and multispectral remote sensing images, and this kind of fusion is generally called pansharpening. We first upsample the low spatial-resolution multispectral image by a classical interpolation method to get an initial upsampled multispectral image. Based on the hyper-Laplacian distribution of errors between the upsampled multispectral image and the ground-truth high resolution multispectral image on gradient domain, we formulate a ℓp(0 < p < 1)-norm term to more reasonably describe the relation of these two datasets. In addition, we also model a tensor-based weighted fidelity term for the panchromatic and low resolution multispectral images, aiming to recover more spatial details. Moreover, total variation regularization is also employed to depict the sparsity of the latent high resolution multispectral image on the gradient domain. For the model solving, we design an alternating direction method of multipliers based algorithm to efficiently solve the proposed model. Furthermore, the involved non-convex ℓp subproblem is handled by an efficient generalized shrinkage/thresholding algorithm. Finally, extensive experiments on many datasets collected by different sensors demonstrate the effectiveness of our method when compared with several state-of-the-art image fusion approaches. © 2018 Elsevier B.V.","Alternating direction method of multipliers; hyper-Laplacian; Pansharpening; Tensor-based sparse modeling"
"Class-imbalanced dynamic financial distress prediction based on Adaboost-SVM ensemble combined with SMOTE and time weighting","2020","Information Fusion","10.1016/j.inffus.2019.07.006","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85069914950&doi=10.1016%2fj.inffus.2019.07.006&partnerID=40&md5=dad7150fa9e6ff16b591820ba87faacd","This paper focuses on how to effectively construct dynamic financial distress prediction models based on class-imbalanced data streams. Two class-imbalanced dynamic financial distress prediction approaches are proposed based on the synthetic minority oversampling technique (SMOTE) combined with the Adaboost support vector machine ensemble integrated with time weighting (ADASVM-TW). One is the simple integration model of SMOTE with ADASVM-TW, which uses SMOTE to make each data batch class-balanced before ADASVM-TW is applied for dynamic financial distress prediction modeling. The other is the embedding integration model of SMOTE with ADASVM-TW, which embeds SMOTE into the iteration of ADASVM-TW and creatively designs a new sample weighting mechanism. Namely, in each round of iteration, it does not only resample the majority financial normal samples by time weighting, but also generates more synthetic minority samples around new and difficult minority samples and less synthetic minority samples around old and easy minority samples to make the training dataset class-balanced. The empirical experiments are carried out based on the financial data of totally 2628 Chinese listed companies. Since there is certain degree of randomness in the proposed models, 50 times of experiments were performed under the same computational environment, so that the experimental results of model performance can be statistically compared and tested. The results indicate that both the simple integration model and the embedding integration model can greatly improve the recognition ability for the minority financial distress samples, and the embedding integration model is even more preferred because it also significantly outperforms the simple integration model. © 2019 Elsevier B.V.","Adaboost; Class imbalance; Dynamic financial distress prediction; SMOTE; Support vector machine; Time weighting"
"Consensus evolution networks: A consensus reaching tool for managing consensus thresholds in group decision making","2019","Information Fusion","10.1016/j.inffus.2019.05.005","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85066262255&doi=10.1016%2fj.inffus.2019.05.005&partnerID=40&md5=0b67cf8257ac827f59610caec9032149","The consensus reaching process (CRP)is a critical part of group decision making (GDM). In order to explore the evolution of consensus, a new CRP tool is proposed based on consensus evolution networks (CENs). The CENs are built based on the consensus degrees among decision makers (DMs)and allow us to manage the consensus thresholds and its evolution. A new consensus index is introduced based on the structured and numerical aspects of the CENs. The new consensus index can not only deeply analyze the constitution of consensus, but also determine the weights of DMs. According to the clustering coefficient, the sensitive consensus threshold is identified and the sensitive consensus evolution network (SCEN)is built. Based on the complementary SCEN, a pairwise feedback adjustment method is proposed to improve consensus. Besides, the sparsity of the CENs can act as a reference to determine the agreed consensus thresholds, which is considered an important issue in traditional models. A numerical example is used to verify the usefulness of the proposed CRP tool. The numerical results show that the evolution of consensus can be clearly found based on CENs and the pairwise method can improve consensus in only four rounds. © 2019 Elsevier B.V.","Consensus evolution networks; Consensus reaching process; Group decision making"
"IFCNN: A general image fusion framework based on convolutional neural network","2020","Information Fusion","10.1016/j.inffus.2019.07.011","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85069843770&doi=10.1016%2fj.inffus.2019.07.011&partnerID=40&md5=1c643fc10b7e833e835eb606ce734594","In this paper, we propose a general image fusion framework based on the convolutional neural network, named as IFCNN. Inspired by the transform-domain image fusion algorithms, we firstly utilize two convolutional layers to extract the salient image features from multiple input images. Afterwards, the convolutional features of multiple input images are fused by an appropriate fusion rule (elementwise-max, elementwise-min or elementwise-mean), which is selected according to the type of input images. Finally, the fused features are reconstructed by two convolutional layers to produce the informative fusion image. The proposed model is fully convolutional, so it could be trained in the end-to-end manner without any post-processing procedures. In order to fully train the model, we have generated a large-scale multi-focus image dataset based on the large-scale RGB-D dataset (i.e., NYU-D2), which owns ground-truth fusion images and contains more diverse and larger images than the existing datasets for image fusion. Without finetuning on other types of image datasets, the experimental results show that the proposed model demonstrates better generalization ability than the existing image fusion models for fusing various types of images, such as multi-focus, infrared-visual, multi-modal medical and multi-exposure images. Moreover, the results also verify that our model has achieved comparable or even better results compared to the state-of-the-art image fusion algorithms on four types of image datasets. © 2019 Elsevier B.V.","Better generalization ability; Convolutional neural network; General image fusion framework; Large-scale multi-focus image dataset"
"Unbalanced double hierarchy linguistic term set: The TOPSIS method for multi-expert qualitative decision making involving green mine selection","2019","Information Fusion","10.1016/j.inffus.2019.04.002","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85064413630&doi=10.1016%2fj.inffus.2019.04.002&partnerID=40&md5=eac1454df89be9570b0a94ede3fdd479","The double hierarchy linguistic term set is a linguistic technique to elaborately and accurately represent complex linguistic information for qualitative decision-making problems. Considering that unbalanced semantics may appear in the first and second hierarchy linguistic term sets, the unbalanced double hierarchy linguistic term set (UDHLTS) is proposed in this paper. To characterize the unbalanced distribution of semantics of the second hierarchy linguistic terms, we propose three linguistic scale functions with cognitive bias parameters. Then, a non-linear fitting method is presented to determine these parameters. Combining the first and second hierarchy linguistic term set, we construct eight semantic models with distinct risk appetite parameters and linguistic cognitive bias parameters to capture the semantics of linguistic terms in the UDHLTS. In this way, we can use specific semantic model to represent experts’ opinions associated with the UDHLTS. In addition, by using the semantic model of the UDHLTS, linguistic information from different experts can be compared and aggregated quantitatively. To illustrate the applicability of the UDHLTS, we develop a UDHL-TOPSIS method for multi-expert qualitative decision making problems. An engineering example concerning green mine selection is given to illustrate the proposed method. © 2019 Elsevier B.V.","Green mine; Linguistic sale function; Qualitative decision making; Semantic model; TOPSIS; Unbalanced double hierarchy linguistic term set"
"β-SLAM: Simultaneous localization and grid mapping with beta distributions","2019","Information Fusion","10.1016/j.inffus.2018.11.005","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057471474&doi=10.1016%2fj.inffus.2018.11.005&partnerID=40&md5=71b59c1cbc3f8e712c9080b82f2a60cf","Simultaneous localization and mapping (SLAM) is one of the most frequently studied problems in mobile robotics. Different map representations have been proposed in the past and a popular one are occupancy grid maps, which are particularly well suited for navigation tasks. The uncertainty in these maps is usually modeled as a single Bernoulli distribution per grid cell. This has the disadvantage that one cannot distinguish between uncertainty caused by different phenomena like missing or conflicting information. In this paper, we overcome this limitation by modeling the occupancy probabilities as random variables. Those are assumed to be beta-distributed and account for the different causes of uncertainty. Based on this map representation, we derive a SLAM algorithm, including all necessary sensor models, for building maps composed of beta-distributed random variables and using these maps for localization. Furthermore, we propose measures for quantifying uncertainty in the resulting maps and for solving navigation tasks. We evaluate our approach using real-world as well as simulation-based datasets and we compare it to a state-of-the-art SLAM algorithm for building classical grid maps. © 2018 Elsevier B.V.","Beta distribution; Mobile robots; Occupancy grid maps; Rao-Blackwellized particle filter (RBPF); Simultaneous localization and mapping (SLAM)"
"CI-SNF: Exploiting contextual information to improve SNF based information retrieval","2019","Information Fusion","10.1016/j.inffus.2018.08.004","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85065514203&doi=10.1016%2fj.inffus.2018.08.004&partnerID=40&md5=100c822c42afe352fb0c2f4de7cde080","Similarity networks contain important topological features and patterns critical to understanding interactions among samples in a large dataset. To create a comprehensive view of the interactions within a dataset, the Similarity Network Fusion (SNF) technique has been proposed to fuse the similarity networks based on different data types into one similarity network that represents the full spectrum of underlying data. In this paper, a modified version of SNF, which is named as Contextual Information based SNF (CI-SNF), is proposed. In CI-SNF, first, modified Jaccard distance is performed on the SNF fused similarity to utilize the contextual information contained in the fused similarity network. Second, the local consistency of samples from the same category is enhanced by speculating that the samples which are located high in the Jaccard distance based ranking list of a specific query are from the same category as the query. Third, the inverted index technique is introduced to utilize the sparsity property of the locally consistent similarity network to enhance the computational efficiency. To verify the effectiveness and efficiency of CI-SNF model, it is applied in four different tasks, Cover Song Identification (CSI), image classification, cancer subtype identification, and drug taxonomy, respectively. Extensive experiments on thirteen challenging datasets demonstrate that CI-SNF scheme outperforms state-of-the-art similarity fusion algorithms including SNF in all four tasks. It is also verified that utilizing the contextual information contained in the SNF-based similarity network helps to enhance the performance of the SNF-based scheme, further. © 2018 Elsevier B.V.","Contextual re-ranking; Information retrieval; Similarity fusion"
"A snapshot research and implementation of multimodal information fusion for data-driven emotion recognition","2020","Information Fusion","10.1016/j.inffus.2019.06.019","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85067959783&doi=10.1016%2fj.inffus.2019.06.019&partnerID=40&md5=072df1e207acde56d191047af805dfb8","With the rapid development of artificial intelligence and mobile Internet, the new requirements for human-computer interaction have been put forward. The personalized emotional interaction service is a new trend in the human-computer interaction field. As a basis of emotional interaction, emotion recognition has also introduced many new advances with the development of artificial intelligence. The current research on emotion recognition mostly focuses on single-modal recognition such as expression recognition, speech recognition, limb recognition, and physiological signal recognition. However, the lack of the single-modal emotional information and vulnerability to various external factors lead to lower accuracy of emotion recognition. Therefore, multimodal information fusion for data-driven emotion recognition has been attracting the attention of researchers in the affective computing filed. This paper reviews the development background and hot spots of the data-driven multimodal emotion information fusion. Considering the real-time mental health monitoring system, the current development of multimodal emotion data sets, the multimodal features extraction, including the EEG, speech, expression, text features, and multimodal fusion strategies and recognition methods are discussed and summarized in detail. The main objective of this work is to present a clear explanation of the scientific problems and future research directions in the multimodal information fusion for data-driven emotion recognition field. © 2019 Elsevier B.V.","Artificial intelligence; Data-driven emotion recognition; Multimodal information fusion"
"Adaptive sliding window based activity recognition for assisted livings","2020","Information Fusion","10.1016/j.inffus.2019.06.013","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85067172144&doi=10.1016%2fj.inffus.2019.06.013&partnerID=40&md5=f2a4768c089480684b1d2f697b8765d6","The incessant diffusion of smart wearable devices and Body Area Networks (BANs) systems is pushing more and more researches on human activity recognition. Previous studies usually adopted fixed time window or chose an optimal window size depending on the characteristics of the activity. In this paper, we propose an adaptive time window-based algorithm of activity recognition, which addresses the problem of different types of activities having different time duration that usually causes poor recognition results. Multivariate Gaussian Distribution (MGD) method was used to detect the signal difference between each determined time window and the defined activity characteristics, and we more accurately define the time window size for each activity. To evaluate the proposed algorithm, we focused on the activities performed by wheelchair users in their daily life, so as to provide them with better healthcare services. We construct two different datasets, respectively considering static and dynamic wheelchair user activities on different ground surfaces. Then, we use time window expansion and contraction method to determine and dynamically adjust the window size for each activity. Different comparison criteria such as recognition precision and F-score were used to evaluate our algorithm. Experiment results revealed that, according to F-score, the proposed algorithm performs 15.3% better than traditional methods in static conditions. In dynamic scenarios we observed 6.4% and 24.5% improvements on flat and rough floors, respectively. © 2019 Elsevier B.V.","Activity recognition; Adaptive sliding window; Multivariate gauss distribution; Sitting posture; Smart cushion"
"Local comparison of cup to disc ratio in right and left eyes based on fusion of color fundus images and OCT B-scans","2019","Information Fusion","10.1016/j.inffus.2018.10.010","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056226736&doi=10.1016%2fj.inffus.2018.10.010&partnerID=40&md5=0c8cc17ce3c449351dd776376d732c28","Symmetry analysis of Optical Coherence Tomography (OCT) images in right and left eyes can lead to introduction of new biomarkers for early detection of eye diseases. In this study, we investigate the symmetry between two eyes by calculating local cup to disc ratio (CDR) from each B-scan based on fusion of fundus images and OCT B-scans. For this purpose, in the first phase, the OCT data of Optic Nerve Head (ONH) in right and left eyes are aligned by finding the equivalent B-scans of both eyes based on the fovea-ONH axes. Since the fovea-ONH axes in OCT data are not available, at first, left and right fundus images are aligned according to their automatically detected fovea-ONH axes. Then, OCT data are registered to corresponding fundus images based on maximum similarity between en-face OCT data and fundus image in each eye. This two-stage alignment procedure depends on 1) the blood vessels, automatically extracted by Hessian analysis of directional curvelet sub-bands, and 2) the disc contour of ONH in fundus images, detected by Distance Regularized Level Set Evolution (DRLSE) algorithm. In the second phase, in order to calculate the local CDRs, the disc and cup boundaries are extracted from the aligned B-scans in left and right eyes. The disc boundary is limited by Bruch-Membrane opening, and the cup boundary is defined by retinal layer border. Therefore, Inner Limiting Membrane (ILM) and Retinal Pigment Epithelium (RPE) layers are extracted using ridgelet transform to find the disc-edge point and cup-edge point in each B-scan. Finally, the ratio of summed areas of cups to summed areas of discs is calculated in corresponding local regions to find the local CDRs. Using this method, we can also introduce a new index called local volumetric CDR (VCDR) by dividing the volume of cup in a specific region to the corresponding volume of disc extracted from OCT images of ONH. Forty healthy OCT datasets of size 650 × 512 × 128 (acquired from Topcon 3D OCT-1000) and corresponding 1536 × 1612 fundus images were used in this study. In addition to point-by-point comparison of CDRs in equivalent B-scans of aligned OCTs, the CDRs in upper, middle and lower regions were calculated and the maximum symmetry is observed in middle region. In addition, using local VCDR, the symmetry of 3D OCTs of both eyes is analyzed in 24 volumetric sectors. © 2018 Elsevier B.V.","Color fundus image; Cup to disc ratio; Local analysis; Optical coherence tomography; Ridgelet transform; Symmetry"
"A survey of data fusion in smart city applications","2019","Information Fusion","10.1016/j.inffus.2019.05.004","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85066074486&doi=10.1016%2fj.inffus.2019.05.004&partnerID=40&md5=38d4bd3f76f9bfdd456998359f5ab57b","The advancement of various research sectors such as Internet of Things (IoT), Machine Learning, Data Mining, Big Data, and Communication Technology has shed some light in transforming an urban city integrating the aforementioned techniques to a commonly known term - Smart City. With the emergence of smart city, plethora of data sources have been made available for wide variety of applications. The common technique for handling multiple data sources is data fusion, where it improves data output quality or extracts knowledge from the raw data. In order to cater evergrowing highly complicated applications, studies in smart city have to utilize data from various sources and evaluate their performance based on multiple aspects. To this end, we introduce a multi-perspectives classification of the data fusion to evaluate the smart city applications. Moreover, we applied the proposed multi-perspectives classification to evaluate selected applications in each domain of the smart city. We conclude the paper by discussing potential future direction and challenges of data fusion integration. © 2019 Elsevier B.V.","Big data; Data fusion; Internet of things; Multi-perspectives classification; Sensor fusion; Smart city"
"A taxonomy of monotonicity properties for the aggregation of multidimensional data","2019","Information Fusion","10.1016/j.inffus.2019.05.006","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85066038026&doi=10.1016%2fj.inffus.2019.05.006&partnerID=40&md5=fc494da246f05276fc5ece3bba0ec16d","The property of monotonicity, which requires a function to preserve a given order, has been considered the standard in the aggregation of real numbers for decades. In this paper, we argue that, for the case of multidimensional data, an order-based definition of monotonicity is far too restrictive. We propose several meaningful alternatives to this property not involving the preservation of a given order by returning to its early origins stemming from the field of calculus. Numerous aggregation methods for multidimensional data commonly used by practitioners are studied within our new framework. © 2019 Elsevier B.V.","Aggregation; Centroid; Monotonicity; Multidimensional data; Spatial median"
"Decision-making in semi-democratic contexts","2019","Information Fusion","10.1016/j.inffus.2019.04.003","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85064452319&doi=10.1016%2fj.inffus.2019.04.003&partnerID=40&md5=4a4501f71cfee5e052b6f1f053e685fc","A general problem, which may concern practical contexts of different nature, is to aggregate multi-experts rankings on a set of alternatives into a single fused ranking. Aggregation should also take into account the experts’ importance, which may not necessarily be the same for all of them. We synthetically define this context as semi-democratic. The main aim of the paper is the analysis of the possible semi-democratic paradigms that can be conceived when the experts’ importance is not the same: (i) the importance is described by means of a weighting vector; (ii) the importance is expressed by a weak order on the set of experts; (iii) the importance is described by a weak order on the set of experts with additional information on the ordinal proximities among them. The three paradigms can be applied in different decision-making situations, where some experts perform multiple assignments. In this paper various situations are discussed and analyzed in detail. A series of examples, in the field of interior design of a new car, will complement the description. © 2019 Elsevier B.V.","Aggregation; Fusion techniques; Group decision-making; Ordinal proximity measures; Preferences; Qualitative scales; Semi-democratic decisions"
"A tutorial on uncertainty modeling for machine reasoning","2020","Information Fusion","10.1016/j.inffus.2019.08.001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85070713736&doi=10.1016%2fj.inffus.2019.08.001&partnerID=40&md5=49859075415076cf0505c4af4a3548e1","Increasingly we rely on machine intelligence for reasoning and decision making under uncertainty. This tutorial reviews the prevalent methods for model-based autonomous decision making based on observations and prior knowledge, primarily in the context of classification. Both observations and the knowledge-base available for reasoning are treated as being uncertain. Accordingly, the central themes of this tutorial are quantitative modeling of uncertainty, the rules required to combine such uncertain information, and the task of decision making under uncertainty. The paper covers the main approaches to uncertain knowledge representation and reasoning, in particular, Bayesian probability theory, possibility theory, reasoning based on belief functions and finally imprecise probability theory. The main feature of the tutorial is that it illustrates various approaches with several testing scenarios, and provides MATLAB solutions for them as a supplementary material for an interested reader. © 2019","Bayesian; Belief function theory; Imprecise probability; Imprecision; Information fusion; Model based classification; Possibility functions; Random sets; Uncertainty"
"Imaging and fusing time series for wearable sensor-based human activity recognition","2020","Information Fusion","10.1016/j.inffus.2019.06.014","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85067212272&doi=10.1016%2fj.inffus.2019.06.014&partnerID=40&md5=896037ae7d1c0f68b22318f9e1f77e42","To facilitate data-driven and informed decision making, a novel deep neural network architecture for human activity recognition based on multiple sensor data is proposed in this work. Specifically, the proposed architecture encodes the time series of sensor data as images (i.e., encoding one time series into a two-channel image), and leverages these transformed images to retain the necessary features for human activity recognition. In other words, based on imaging time series, wearable sensor-based human activity recognition can be realized by using computer vision techniques for image recognition. In particular, to enable heterogeneous sensor data to be trained cooperatively, a fusion residual network is adopted by fusing two networks and training heterogeneous data with pixel-wise correspondence. Moreover, different layers of deep residual networks are used to deal with dataset size differences. The proposed architecture is then extensively evaluated on two human activity recognition datasets (i.e., HHAR dataset and MHEALTH dataset), which comprise various heterogeneous mobile device sensor combinations (i.e., acceleration, angular velocity, and magnetic field orientation). The findings demonstrate that our proposed approach outperforms other competing approaches, in terms of accuracy rate and F1-value. © 2019 Elsevier B.V.","Body sensor networks; Deep residual network; Human activity recognition; Multi-sensor data fusion"
"OWA aggregation with an uncertainty over the arguments","2019","Information Fusion","10.1016/j.inffus.2018.12.009","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062872629&doi=10.1016%2fj.inffus.2018.12.009&partnerID=40&md5=fec7de4292205dbebe698e1dcd7eded8","We discuss the OWA aggregation operation and the role the OWA weights play in determining the type of aggregation being performed. We introduce the idea of a weight generating function and describe its use in obtaining the OWA weights. We emphasize the importance of the weight generating function in prescribing the type of aggregation to be performed. We consider the problem of performing a prescribed OWA aggregation in the case when we have a probability distribution over the argument values. We show how we use the weight generating function to enable this type of aggregation. Next we consider the situation when we have a more general measure based uncertainty over the argument values. Here again we show how we can use the weight generating function to aid in performing the prescribed OWA aggregation in the face of this more general type of uncertainty. Finally we look at the task of obtaining a weight generating function from a given set of OWA weights. © 2018","Aggregation; Choquet integral; Measure-based uncertainty; Weight generating function"
"Scalable and efficient learning from crowds with Gaussian processes","2019","Information Fusion","10.1016/j.inffus.2018.12.008","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061003837&doi=10.1016%2fj.inffus.2018.12.008&partnerID=40&md5=804a19d759bf497eccf756bb106594a0","Over the last few years, multiply-annotated data has become a very popular source of information. Online platforms such as Amazon Mechanical Turk have revolutionized the labelling process needed for any classification task, sharing the effort between a number of annotators (instead of the classical single expert). This crowdsourcing approach has introduced new challenging problems, such as handling disagreements on the annotated samples or combining the unknown expertise of the annotators. Probabilistic methods, such as Gaussian Processes (GP), have proven successful to model this new crowdsourcing scenario. However, GPs do not scale up well with the training set size, which makes them prohibitive for medium-to-large datasets (beyond 10K training instances). This constitutes a serious limitation for current real-world applications. In this work, we introduce two scalable and efficient GP-based crowdsourcing methods that allow for processing previously-prohibitive datasets. The first one is an efficient and fast approximation to GP with squared exponential (SE) kernel. The second allows for learning a more flexible kernel at the expense of a heavier training (but still scalable to large datasets). Since the latter is not a GP-SE approximation, it can be also considered as a whole new scalable and efficient crowdsourcing method, useful for any dataset size. Both methods use Fourier features and variational inference, can predict the class of new samples, and estimate the expertise of the involved annotators. A complete experimentation compares them with state-of-the-art probabilistic approaches in synthetic and real crowdsourcing datasets of different sizes. They stand out as the best performing approach for large scale problems. Moreover, the second method is competitive with the current state-of-the-art for small datasets. © 2019 Elsevier B.V.","Bayesian modelling; Classification; Fourier features; Gaussian processes; Scalable crowdsourcing; Variational inference"
"Employing online social networks in precision-medicine approach using information fusion predictive model to improve substance use surveillance: A lesson from Twitter and marijuana consumption","2020","Information Fusion","10.1016/j.inffus.2019.08.006","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071039996&doi=10.1016%2fj.inffus.2019.08.006&partnerID=40&md5=4b87d08ced16f5ebd0708bc29794047b","The impact that connected community have on precision health or medicine and vice versa offers opportunities for any type of research and survey information, e. g, to predict trends in health-related issues, specifically people behavior towards drug use. Here, precision medicine influences the way to treat the information and get a better outcome to support the stakeholder decision. Online social networks analysis seems to be good tools to quickly monitor the population behavior where users freely share large amounts of information related to their own lives on day- to- day basis. This novel kind of data can be used to get additional real time insights from people to understand their actual behavior related to drug use (Cortés et al., 2017). The aim of this research is to generated an information fusion model of marijuana use tendency confident enough to be employed by stakeholders. So, we will: (a) collect and process the data from Twitter; (b) design a set of algorithms to estimate the tendency of marijuana use in relation to age, localization and gender, moreover, used a set of processes and activities to verify if our model were performing as expected; and (c) fusion of the information in a model to fully characterize the marijuana use population comparable to the national marijuana consume survey for policy makers utilization to improve drug use prevention. First,we collect the data from Twitter accounts based in Chile using an algorithm for traversing graph data structures, we collected the data from Twitter accounts based in Chile. Then, we estimated marijuana user prevalence during a period from 2006 to 2018 and, within each of the years we predicted the prevalence of user population in relation with age (in range), the localization (regions) and gender. Finally, we built indicators to explore the similarity between data obtained through Twitter (our results) and the actual data collected by the National Service for the Prevention and Rehabilitation of Drug and Alcohol (SENDA) under the same variables analyze in their own survey. When we compare the results of the algorithms and methods developed by us with those provided by the SENDA, we observed that most of the indicators present similar trends, i.e., the variation of the prevalence by years in the age, location and gender, showed similar changes in both analyzes. Also, the algorithms effectiveness and capacity to predict variations of complex cases like marijuana use in Chilean population. This study is a key opportunity to obtain in a faster, low cost and continuous way information about marijuana use, also, is an excellent tool for marijuana surveillance to get information to support policy makers and stakeholder decisions. © 2019 Elsevier B.V.","Decision making; Machine learning; Opinion mining; Precision medicine; Prevalence; Preventive; Social networks analysis; Substance-use disorders (SUDs) Prevention"
"DeepMTT: A deep learning maneuvering target-tracking algorithm based on bidirectional LSTM network","2020","Information Fusion","10.1016/j.inffus.2019.06.012","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85069627586&doi=10.1016%2fj.inffus.2019.06.012&partnerID=40&md5=566d40e756de9dd9de50153c4b3224fe","In the field of radar data processing, traditional maneuvering target-tracking algorithms assume that target movements can be modeled by pre-defined multiple mathematical models. However, the changeable and uncertain maneuvering movements cannot be timely and precisely modeled because it is difficult to obtain sufficient information to pre-define multiple models before tracking. To solve this problem, we propose a deep learning maneuvering target-tracking (DeepMTT) algorithm based on a DeepMTT network, which can quickly track maneuvering targets once it has been well trained by abundant off-line trajectory data from existent maneuvering targets. To this end, we first build a LArge-Scale Trajectory (LAST) database to offer abundant off-line trajectory data for network training. Second, the DeepMTT algorithm is developed to track the maneuvering targets using a DeepMTT network, which consists of three bidirectional long short-term memory layers, a filtering layer, a maxout layer and a linear output layer. The simulation results verify that our DeepMTT algorithm outperforms other state-of-the-art maneuvering target-tracking algorithms. © 2019 Elsevier B.V.","Bidirectional long short-term memory network; Maneuvering target-tracking; Multiple models; Trajectory database"
"Gait-based identification for elderly users in wearable healthcare systems","2020","Information Fusion","10.1016/j.inffus.2019.06.023","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85067677018&doi=10.1016%2fj.inffus.2019.06.023&partnerID=40&md5=e5f97834e6d3cd3554471982b58b1a4c","The increasing scope of sensitive personal information that is collected and stored in wearable healthcare devices includes physical, physiological, and daily activities, which makes the security of these devices very essential. Gait-based identity recognition is an emerging technology, which is increasingly used for the access control of wearable devices, due to its outstanding performance. However, gait-based identity recognition of elderly users is more challenging than that of young adults, due to significant intra-subject gait fluctuation, which becomes more pronounced with user age. This study introduces a gait-based identity recognition method used for the access control of elderly people-centred wearable healthcare devices, which alleviates the intra-subject gait fluctuation problem and provides a significant recognition rate improvement, as compared to available methods. Firstly, a gait template synthesis method is proposed to reduce the intra-subject gait fluctuation of elderly users. Then, an arbitration-based score level fusion method is defined to improve the recognition accuracy. Finally, the proposed method feasibility is verified using a public dataset containing acceleration signals from three IMUs worn by 64 elderly users with the age range from 50 to 79 years. The experimental results obtained prove that the average recognition rate of the proposed method reaches 96.7%. This makes the proposed method quite lucrative for the robust gait-based identification of elderly users of wearable healthcare devices. © 2019 The Authors","Accelerometer sensors; Gait recognition; Score level fusion; User identification; Wearable healthcare system"
"Ensemble of CNN for multi-focus image fusion","2019","Information Fusion","10.1016/j.inffus.2019.02.003","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062016163&doi=10.1016%2fj.inffus.2019.02.003&partnerID=40&md5=411f0ec863f466454b30a55260e59b1b","The Convolutional Neural Networks (CNNs) based multi-focus image fusion methods have recently attracted enormous attention. They greatly enhanced the constructed decision map compared with the previous state of the art methods that have been done in the spatial and transform domains. Nevertheless, these methods have not reached to the satisfactory initial decision map, and they need to undergo vast post-processing algorithms to achieve a satisfactory decision map. In this paper, a novel CNNs based method with the help of the ensemble learning is proposed. It is very reasonable to use various models and datasets rather than just one. The ensemble learning based methods intend to pursue increasing diversity among the models and datasets in order to decrease the problem of the overfitting on the training dataset. It is obvious that the results of an ensemble of CNNs are better than just one single CNNs. Also, the proposed method introduces a new simple type of multi-focus images dataset. It simply changes the arranging of the patches of the multi-focus datasets, which is very useful for obtaining the better accuracy. With this new type arrangement of datasets, the three different datasets including the original and the Gradient in directions of vertical and horizontal patches are generated from the COCO dataset. Therefore, the proposed method introduces a new network that three CNNs models which have been trained on three different created datasets to construct the initial segmented decision map. These ideas greatly improve the initial segmented decision map of the proposed method which is similar, or even better than, the other final decision map of CNNs based methods obtained after applying many post-processing algorithms. Many real multi-focus test images are used in our experiments, and the results are compared with quantitative and qualitative criteria. The obtained experimental results indicate that the proposed CNNs based network is more accurate and have the better decision map without post-processing algorithms than the other existing state of the art multi-focus fusion methods which used many post-processing algorithms. © 2019","Convolutional neural network; Decision map; Deep learning; Ensemble learning; Multi-focus image fusion"
"Human emotion recognition using deep belief network architecture","2019","Information Fusion","10.1016/j.inffus.2018.10.009","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056201045&doi=10.1016%2fj.inffus.2018.10.009&partnerID=40&md5=a6adcb24e3a654e65c18d692a2cd712c","Recently, deep learning methodologies have become popular to analyse physiological signals in multiple modalities via hierarchical architectures for human emotion recognition. In most of the state-of-the-arts of human emotion recognition, deep learning for emotion classification was used. However, deep learning is mostly effective for deep feature extraction. Therefore, in this research, we applied unsupervised deep belief network (DBN) for depth level feature extraction from fused observations of Electro-Dermal Activity (EDA), Photoplethysmogram (PPG) and Zygomaticus Electromyography (zEMG) sensors signals. Afterwards, the DBN produced features are combined with statistical features of EDA, PPG and zEMG to prepare a feature-fusion vector. The prepared feature vector is then used to classify five basic emotions namely Happy, Relaxed, Disgust, Sad and Neutral. As the emotion classes are not linearly separable from the feature-fusion vector, the Fine Gaussian Support Vector Machine (FGSVM) is used with radial basis function kernel for non-linear classification of human emotions. Our experiments on a public multimodal physiological signal dataset show that the DBN, and FGSVM based model significantly increases the accuracy of emotion recognition rate as compared to the existing state-of-the-art emotion classification techniques. © 2018 Elsevier B.V.","Deep belief network; Emotion recognition; Fine Gaussian support vector machine; Fusion model; Physiological signals"
"Robust AdaBoost based ensemble of one-class support vector machines","2020","Information Fusion","10.1016/j.inffus.2019.08.002","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85070611804&doi=10.1016%2fj.inffus.2019.08.002&partnerID=40&md5=5e83eba92eb86114c6fa0edddbcf12e1","One-class support vector machine (OCSVM) is a commonly used one-class classification method for tackling novelty detection problems. Unfortunately, employing the traditional AdaBoost on it may not produce satisfying performance when there are outliers within training samples. In this paper, the conventional loss function of AdaBoost is redesigned, i.e., substituting the exponential loss function by a more robust one to enhance the robustness of the traditional AdaBoost based ensemble of OCSVMs. The proposed loss function is defined as the weighted combination of the modified exponential loss function and the squared loss function. The robust AdaBoost based on the proposed loss function is introduced by redesigning the update formulae for the weights of base classifiers and the probability distribution of training samples. The upper bounds of empirical error and generalization error for the robust AdaBoost based ensemble of OCSVMs are derived. Experimental results on the synthetic and benchmark data sets demonstrate that the proposed ensemble method is superior to its related approaches. © 2019 Elsevier B.V.","AdaBoost; Loss function; One-class classification; One-class support vector machine"
"Multi-channel fusion convolutional neural network to classify syntactic anomaly from language-related ERP components","2019","Information Fusion","10.1016/j.inffus.2018.10.008","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057354596&doi=10.1016%2fj.inffus.2018.10.008&partnerID=40&md5=a68888cda5317f36fb5da69c484c63fa","Event-Related Potential (ERP) analyses have revealed several language-related components in sentence processing literature. More recently, researchers attempted to apply machine-learning techniques to classify the language-structure dependent ERP signals in a more reliable and efficient way. The purpose of the current paper is to propose a classification technique based on data-driven approach to detect syntactic anomaly from language-related ERP components. We specifically examined whether sentences with syntactic violations elicited differential patterns of ERP signals and the abnormal patterns can be reliably classified by machine-learning techniques. The specific aim of the study is to develop a multi-channel fusion convolutional neural network (MCF-CNN) including two branches of CNNs and a trunk merged by an intermediate fusion layer to obtain trained linguistic features from the raw data and perform the classification. We extracted different linguistic ERP components from syntactic violations and put them in the fusion. As a next procedure we combined the features in the fusion layer of the proposed neural network architecture. Experimental results demonstrate that the proposed method provides more than 92% classification accuracy. © 2018 Elsevier B.V.","Convolutional neural network; Event-related potential signals; Linguistic feature fusion; Neurological signal processing; Sentence classification"
"A chest-based continuous cuffless blood pressure method: Estimation and evaluation using multiple body sensors","2020","Information Fusion","10.1016/j.inffus.2019.07.001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85069811050&doi=10.1016%2fj.inffus.2019.07.001&partnerID=40&md5=be507fd2e751a84d6771c055b8f1d77e","Blood pressure (BP) is a critical vital sign in health, measured millions of times per day worldwide. Current BP measurement requires cumbersome tools, is painful and can be inconvenient. Non-invasive cuffless BP measurement based on pulse arrival time (PAT) techniques allow an alternative way of monitoring BP in healthcare settings with refined wearability and user-friendly features. PAT extraction requires at least two measurements, one as a time reference and another to obtain time delay; there are several approaches to calculate the PAT from various sensors placed on the body. Commonly used signals are electrocardiography (ECG) and photoplethysmography (PPG), which can be recorded from a patients body using more than two separate sensors attachment set-ups. In this work, cuffless BP calculation based on five different PAT readings using Bio-impedance (BImp) at the shoulder as an alternative to PPG, has been investigated. Sensor placement is on the patients chest; which hides them beneath the patient's clothes making them more suitable for ambulatory monitoring systems. Technology performance was assessed using different postures, exercises and Glyceryl Trinitrate (GTN) spray doses; which provided stable, rising and falling BPs for evaluation. Data were collected from 41 participants who were sitting, standing and supine. Twenty-four of 41 participants undertook experiments including a handgrip task (isometric exercise), three periods of cycling on an exercise bike with light, moderate and heavy resistance settings and an observed rest period at the end. The remaining 17 of 41 subjects received GTN spray for predefined times with variable recovery periods afterwards. Different methods of PAT extraction from BImp data were compared for accuracy. Comparisons were made between PAT readings alone and PAT combined with Heart Rate and the combination model performed better when calculating BP. Simultaneously, data were collected using PPG-based PATs compared to BImp-based PATs. BImp-based PATs proved 3% more accurate than PPG-based PATs, demonstrating the potential superiority of BImp-based BP calculations. © 2019 The Authors","Bio-Impedance; Cuffless blood pressure; On-body sensors; Pulse arrival time"
"A body sensor data fusion and deep recurrent neural network-based behavior recognition approach for robust healthcare","2020","Information Fusion","10.1016/j.inffus.2019.08.004","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85070886618&doi=10.1016%2fj.inffus.2019.08.004&partnerID=40&md5=7a11173ba0386cf9142af5df121e5189","Recently, human healthcare from body sensor data has been getting remarkable research attentions by a huge range of human-computer interaction and pattern analysis researchers due to its practical applications such as smart health care systems. For example, smart wearable-based behavior recognition system can be used to assist the rehabilitation of patients in a smart clinic to improve the rehabilitation process and to prolong their independent life. Although there are many ways of using distributed sensors to monitor vital signs and behavior of people, physical human action recognition via body sensors provides valuable data regarding an individual's functionality and lifestyle. In this work, we propose a body sensor-based system for behavior recognition using deep Recurrent Neural Network (RNN), a promising deep learning algorithm based on sequential information. We perform data fusion from multiple body sensors such as electrocardiography (ECG), accelerometer, magnetometer, etc. The extracted features are further enhanced via kernel principal component analysis (KPCA). The robust features are then used to train an activity RNN, which is later used for behavior recognition. The system has been compared against the conventional approaches on three publicly available standard datasets. The experimental results show that the proposed approach outperforms the available state-of-the-art methods. © 2019 Elsevier B.V.","Behavior recognition; Body sensor data fusion; Deep recurrent neural network; Robust healthcare"
"Affective video content analysis based on multimodal data fusion in heterogeneous networks","2019","Information Fusion","10.1016/j.inffus.2019.02.007","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062038505&doi=10.1016%2fj.inffus.2019.02.007&partnerID=40&md5=1d5c0d39b3437e6bd4a02189cfff60ef","In heterogeneous networks, different modalities are coexisting. For example, video sources with certain lengths usually have abundant time-varying audiovisual data. From the users’ perspective, different video segments will trigger different kinds of emotions. In order to better interact with users in heterogeneous networks and improve their user experiences, affective video content analysis to predict users’ emotions is essential. Academically, users’ emotions can be evaluated by arousal and valence values, and fear degree, which provides an approach to quantize the prediction accuracy of the reaction of the audience and users towards videos. In this paper, we propose the multimodal data fusion method for integrating the visual and audio data in order to perform the affective video content analysis. Specifically, to align the visual and audio data, the temporal attention filters are proposed to obtain the time-span features of the entire video segments. Then, by using the two-branch network structure, matched visual and audio features are integrated in the common space. At last, the fused audiovisual feature is employed for the regression and classification subtasks in order to measure the emotional responses of users. Simulation results show that the proposed method can accurately predict the subjective feelings of users towards the video contents, which provides a way to predict users’ preferences and recommend videos according to their own demand. © 2019 Elsevier B.V.","Affective video content; Common space learning; Data fusion; Deep learning; Multimodal data"
"Multimodal feature fusion by relational reasoning and attention for visual question answering","2020","Information Fusion","10.1016/j.inffus.2019.08.009","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85070854474&doi=10.1016%2fj.inffus.2019.08.009&partnerID=40&md5=7f02ce64902d016e10937e0981194442","The recently emerged research of Visual Question Answering (VQA) has become a hot topic in computer vision. A key solution to VQA exists in how to fuse multimodal features extracted from image and question. In this paper, we show that combining visual relationship and attention together achieves more fine-grained feature fusion. Specifically, we design an effective and efficient module to reason complex relationship between visual objects. In addition, a bilinear attention module is learned for question guided attention on visual objects, which allows us to obtain more discriminative visual features. Given an image and a question in natural language, our VQA model learns visual relational reasoning network and attention network in parallel to fuse fine-grained textual and visual features, so that answers can be predicted accurately. Experimental results show that our approach achieves new state-of-the-art performance of single model on both VQA 1.0 and VQA 2.0 datasets. © 2019 Elsevier B.V.","Attention mechanism; Multimodal fusion; Visual question answering; Visual relational reasoning"
"An overview of multirate multisensor systems: Modelling and estimation","2019","Information Fusion","10.1016/j.inffus.2019.05.002","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85065970497&doi=10.1016%2fj.inffus.2019.05.002&partnerID=40&md5=2a4c4364ade5b2d96c8193ee86fdfa0d","In this paper, research advances in modelling and estimation algorithms for multirate multisensor systems are reviewed. Multirate multisensor sampling schemes can be classified into two cases: uniform sampling and nonuniform sampling. A general method to solve an asynchronous estimation problem for multirate multisensor systems is to transform the asynchronous problem into a synchronous one. Then, synchronous estimation algorithms can be applied. Therefore, modelling synchronisation approaches are summarised for uniform and nonuniform sampling cases. Meanwhile, the corresponding estimation algorithms are reviewed according to different synchronised models. Last, future research topics are discussed. © 2019 Elsevier B.V.","Asynchronous estimation; Multirate multisensor system; Nonuniform sampling; Synchronisation"
"Hierarchical method for cataract grading based on retinal images using improved Haar wavelet","2020","Information Fusion","10.1016/j.inffus.2019.06.022","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85067794230&doi=10.1016%2fj.inffus.2019.06.022&partnerID=40&md5=24169e4389a3cbb02c205942c08c24a0","Cataracts, which are lenticular opacities that may occur at different lens locations, are the leading cause of visual impairment worldwide. Accurate and timely diagnosis can improve the quality of life of cataract patients. In this paper, a feature extraction-based method for grading cataract severity using retinal images is proposed. To obtain more appropriate features for the automatic grading, the Haar wavelet is improved according to the characteristics of retinal images. Retinal images of non-cataract, as well as mild, moderate, and severe cataracts, are automatically recognized using the improved Haar wavelet. A hierarchical strategy is used to transform the four-class classification problem into three adjacent two-class classification problems. Three sets of two-class classifiers based on a neural network are trained individually and integrated together to establish a complete classification system. The accuracies of the two-class classification (cataract and non-cataract) and four-class classification are 94.83% and 85.98%, respectively. The performance analysis demonstrates that the improved Haar wavelet feature achieves higher accuracy than the original Haar wavelet feature, and the fusion of three sets of two-class classifiers is superior to a simple four-class classifier. The discussion indicates that the retinal image-based method offers significant potential for cataract detection. © 2019 Elsevier B.V.","Cataract detection; Classification; Improved Haar wavelet; Retinal images"
"Consensus model for large-scale group decision making based on fuzzy preference relation with self-confidence: Detecting and managing overconfidence behaviors","2019","Information Fusion","10.1016/j.inffus.2019.03.001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85063063734&doi=10.1016%2fj.inffus.2019.03.001&partnerID=40&md5=6707813ae31b293869337fa3a1f664e3","With the development of intelligent decision-making, one kind of decision modes involves a large number of decision-makers (DMs), which is called large scale group decision making (LSGDM). In LSGDM, overconfidence is one of the common behaviors because of many DMs’ participation and the bounded rationality of human decision. Overconfidence usually has a negative impact on LSGDM and can even lead to failure in the final decision(s). To achieve consensus is very important for LSGDM. Different consensus models of LSGDM have been proposed, while the DMs’ overconfidence behaviors in the consensus have not been concerned. Hence, the purpose of this paper is to propose a consensus model which considers overconfidence behaviors, and the paper mainly focuses on LSGDM based on fuzzy preference relations with self-confidence (FPRs-SC). In the proposed model, a DM clustering method, which combines fuzzy preference values similarity and self-confidence similarity, is used to classify the DMs with similar opinions into a subgroup. A group consensus index which considers both the fuzzy preference values and self-confidence is presented to measure the consensus level among DMs. An overconfidence measurement is given to detect the DMs’ overconfidence behaviors in the consensus. Subsequently, the detailed overconfidence behavior analysis is presented involving two aspects: fuzzy preference values consensus and self-confidence consensus. A dynamic weight punishment mechanism is implemented for overconfident DMs to improve the consensus efficiently. The effectiveness and advantages of the presented consensus model are validated by a numerical example and comparative analysis. © 2019 Elsevier B.V.","Consensus model; Fuzzy preference relations with self-confidence (FRPS-SC); Large-scale group decision making (LSGDM); Overconfidence behaviors"
"Ensembles for feature selection: A review and future trends","2019","Information Fusion","10.1016/j.inffus.2018.11.008","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057342026&doi=10.1016%2fj.inffus.2018.11.008&partnerID=40&md5=a03d3bd82d7a218be310f6c171c8ca28","Ensemble learning is a prolific field in Machine Learning since it is based on the assumption that combining the output of multiple models is better than using a single model, and it usually provides good results. Normally, it has been commonly employed for classification, but it can be used to improve other disciplines such as feature selection. Feature selection consists of selecting the relevant features for a problem and discard those irrelevant or redundant, with the main goal of improving classification accuracy. In this work, we provide the reader with the basic concepts necessary to build an ensemble for feature selection, as well as reviewing the up-to-date advances and commenting on the future trends that are still to be faced. © 2018 Elsevier B.V.","Ensemble learning; Feature selection"
"Adaptive lq-norm constrained general nonlocal self-similarity regularizer based sparse representation for single image super-resolution","2020","Information Fusion","10.1016/j.inffus.2019.06.010","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85067197840&doi=10.1016%2fj.inffus.2019.06.010&partnerID=40&md5=4aa346f3a7ae4d8846fdf7a68a24ba48","Sparse representation (SR) with the traditional nonlocal self-similarity (NLSS) regularizer has a brilliant future in handling single image super-resolution (SISR) inverse problem. However, such NLSS regularizers proposed so far always favor the fixed lq-norm constraint, making it difficult to cater the statistical diversity of the image content. As a result, the reconstruction capability of SR model is adversely influenced. To cope with the drawback, we first devise an adaptive lq-norm constrained general NLSS regularizer, which can integrate the advantages of the traditional NLSS prior and the row NLSS prior and adaptively assign different q values to handle the different image contents, and then incorporate it into SR model. Moreover, previous works only consider the additive white Gaussian noise case and neglect to research the impulse noise case in SR based SISR framework. For this purpose, our work will further consider these factors. Finally, both the iteratively reweighted least squares and the standard iterative shrinkage algorithms are adopted for solving our SR model. Experiments reveal that the reconstruction capability of our method is better than many outstanding SISR reconstruction methods. © 2019 Elsevier B.V.","General nonlocal self-similarity regularizer; Iteratively reweighted least squares algorithm; Single image super-resolution; Sparse representation; Standard iterative shrinkage algorithm"
"Diversified binary relation-based fuzzy multigranulation rough set over two universes and application to multiple attribute group decision making","2020","Information Fusion","10.1016/j.inffus.2019.07.013","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85070685456&doi=10.1016%2fj.inffus.2019.07.013&partnerID=40&md5=02e65f8558f327678874304466c699d8","This article considers a kind of multiple attribute group decision making problem which the decision-makers have different evaluation index set over the attribute set for all candidate alternatives. We firstly transform the multiple attribute group decision making into a fuzzy multigranulation decision making problem under the framework of different universes. We then construct a diversified binary fuzzy relation over the evaluation attribute index set associated to different decision-makers. Furthermore, using the idea of multigranulation methodology over two different universes, we define the lower and upper approximations of any fuzzy decision making object based on the diversified binary fuzzy relation. Subsequently, we establish the diversified binary fuzzy relation-based optimistic and pessimistic fuzzy multigranulation rough set over two universes. At the same time, Several interesting and important properties and conclusions are presented for the defined two types multigranulation fuzzy rough set over two universes in detail. Meanwhile, we propose an approach to multiple attribute group decision making with different evaluation index set by using the diversified binary fuzzy relation-based fuzzy multigranulation rough set over two universes. At last, a detailed comparison to the traditional studies is given and a numerical example is tested to illustrate the idea and the process of the decision making given in the new model and method. © 2019 Elsevier B.V.","Diversified binary fuzzy relation; Fuzzy multigranulation rough set; Multiple attribute group decision making; Rough set; Two universes"
"A new approach to Zadeh's Z-numbers: Mixed-discrete Z-numbers","2020","Information Fusion","10.1016/j.inffus.2019.06.015","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85066984466&doi=10.1016%2fj.inffus.2019.06.015&partnerID=40&md5=0f1186d9a4afce9dedf02f90d75f1f4d","One of the main goals of computing with words is the accurate modeling of natural language. In this direction, Z-numbers were introduced by Zadeh in 2011 as a pair of fuzzy numbers, (A, B), where A is interpreted as a fuzzy restriction on the values of a variable, while B is interpreted as a measure of certainty or sureness of A. This structure allows to model many imprecise sentences of the natural language, but has the drawback of the complexity and hight computational cost of their operations, because the second component is usually considered from a probabilistic point of view. Since the computational problems are caused by the second component, we present in this paper a new approach called mixed-discrete Z-numbers. In this new approach the first component will be managed as a usual fuzzy number, and the second one as a discrete fuzzy number with support in a finite chain. That is, the second component B of a Z-number is modeled as a linguistic valuation based on a discrete fuzzy number and the operations on these second components are managed through aggregation functions on discrete fuzzy numbers. Understanding B as a measure of certainty and not as a measure of probability, greatly improves experts’ flexibility, allows to model situations where no probability distribution is known, and reduces greatly the computational complexity of Z-numbers operations. After studying these new Z-numbers and their operations, an application to reach a decision from a group of experts is presented in order to show the potential of this approach. © 2019 Elsevier B.V.","Aggregation functions; Discrete fuzzy numbers; Zadeh's Z-numbers"
"Differentially private data publishing via cross-moment microaggregation","2020","Information Fusion","10.1016/j.inffus.2019.06.011","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85069672338&doi=10.1016%2fj.inffus.2019.06.011&partnerID=40&md5=ab1d8c0950757d8b7ad1e96da978b6d3","Differential privacy is one of the most prominent privacy notions in the field of anonymization. However, its strong privacy guarantees very often come at the expense of significantly degrading the utility of the protected data. To cope with this, numerous mechanisms have been studied that reduce the sensitivity of the data and hence the noise required to satisfy this notion. In this paper, we present a generalization of classical microaggregation, where the aggregated records are replaced by the group mean and additional statistical measures, with the purpose of evaluating it as a sensitivity reduction mechanism. We propose an anonymization methodology for numerical microdata in which the target of protection is a data set microaggregated in this generalized way, and the disclosure risk limitation is guaranteed through differential privacy via record-level perturbation. Specifically, we describe three anonymization algorithms where microaggregation can be applied to either entire records or groups of attributes independently. Our theoretical analysis computes the sensitivities of the first two central cross moments; we apply fundamental results from matrix perturbation theory to derive sensitivity bounds on the eigenvalues and eigenvectors of the covariance and coskewness matrices. Our extensive experimental evaluation shows that data utility can be enhanced significantly for medium to large sizes of the microaggregation groups. For this range of group sizes, we find experimental evidence that our approach can provide not only higher utility but also higher privacy than traditional microaggregation. © 2019 Elsevier B.V.","Data utility; Differential privacy; Microaggregation"
"An overview and comprehensive comparison of ensembles for concept drift","2019","Information Fusion","10.1016/j.inffus.2019.03.006","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062893726&doi=10.1016%2fj.inffus.2019.03.006&partnerID=40&md5=6daf1ea2526b85b5fd75d22479af690c","Online learning is about extracting information from large data streams which may be affected by changes in the distribution of the data, events known as concept drift. Concept drift detectors are small programs that try to detect these changes and make it possible to replace the base classifier, improving the overall accuracy. Ensembles of classifiers are also common in this application area and some of them are configurable with a drift detector. This article summarizes a large-scale comparison of six ensemble algorithms, configured with 10 different drift detectors, for learning from fully labeled data streams, using a large number of artificial datasets and two popular base learners in the area: Naive Bayes and Hoeffding Tree. In addition, the code of one the ensembles (Leveraging Bagging) was modified to permit its configuration with any drift detector: its original implementation only uses ADWIN. The goal is to assess how good the existing ensemble algorithms configurable with detectors really are and also to verify and challenge a common belief in the area. The results of the experiments suggest that, in most datasets, the choice of ensemble algorithm has much more impact on the final accuracy than the choice of drift detector used in its configuration. They also suggest the best auxiliary detectors to configure the ensembles, i.e. those that maximize the accuracy of the ensembles, are only marginally different from the best detectors in the same datasets in terms of their accuracies (recently reported in another article). © 2019 Elsevier B.V.","Concept drift; Data stream; Detectors; Ensembles; Large-scale comparison; Online learning"
"An overview of MULTIMOORA for multi-criteria decision-making: Theory, developments, applications, and challenges","2019","Information Fusion","10.1016/j.inffus.2018.12.002","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061035119&doi=10.1016%2fj.inffus.2018.12.002&partnerID=40&md5=4258e61bb384e7f158a9b29d538023e6","MULTIMOORA is a useful multi-criteria decision-making technique. The output of the MULTIMOORA is a ranking obtained by aggregating the results of the ternary ranking methods: Ratio System, Reference Point Approach, and Full Multiplicative Form. In the literature of MULTIMOORA, there is not a comprehensive review study. In this paper, we conduct an overview of MULTIMOORA by categorizing and analyzing main researches, theoretically and practically. First, we go through an theoretical survey of MULTIMOORA in terms of the subordinate ranking methods, ranking aggregation tools, weighting methods, group decision-making, combination with other models, and the robustness of the method. We scrutinize the developments of MULTIMOORA based on uncertainty theories accompanied by analyzing the mathematical formulations of breakthrough models. Practical problems of MULTIMOORA are categorized into application sectors concerning industries, economics, civil services and environmental policy-making, healthcare management, and information and communications technologies. Bibliometric analyses are implemented into all studies. Also, we pose major theoretical and practical challenges. From the theoretical viewpoint, extensions of Reference Point Approach, cooperative group decision-making structure, and utilization of new uncertainty sets in MULTIMOORA model are the main challenges. From the practical viewpoint, industrial and socio-economic fields are appealing to be studied intensively. © 2018","Bibliometric analysis; Fuzzy set theory; Linguistic term theory; Multi-criteria decision-making; MULTIMOORA; Uncertainty theories"
"A comprehensive overview of biometric fusion","2019","Information Fusion","10.1016/j.inffus.2018.12.003","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062866931&doi=10.1016%2fj.inffus.2018.12.003&partnerID=40&md5=091a11a3e86cb458427e36e70ef72ae7","The performance of a biometric system that relies on a single biometric modality (e.g., fingerprints only) is often stymied by various factors such as poor data quality or limited scalability. Multibiometric systems utilize the principle of fusion to combine information from multiple sources in order to improve recognition accuracy whilst addressing some of the limitations of single-biometric systems. The past two decades have witnessed the development of a large number of biometric fusion schemes. This paper presents an overview of biometric fusion with specific focus on three questions: what to fuse, when to fuse, and how to fuse. A comprehensive review of techniques incorporating ancillary information in the biometric recognition pipeline is also presented. In this regard, the following topics are discussed: (i) incorporating data quality in the biometric recognition pipeline; (ii) combining soft biometric attributes with primary biometric identifiers; (iii) utilizing contextual information to improve biometric recognition accuracy; and (iv) performing continuous authentication using ancillary information. In addition, the use of information fusion principles for presentation attack detection and multibiometric cryptosystems is also discussed. Finally, some of the research challenges in biometric fusion are enumerated. The purpose of this article is to provide readers a comprehensive overview of the role of information fusion in biometrics. © 2019 Elsevier B.V.","Biometrics; Continuous authentication; Cryptosystems; Information fusion; Multibiometrics; Privacy; Security; Social networks; Soft biometrics; Spoof detection"
"Multi-view information fusion in mammograms: A comprehensive overview","2019","Information Fusion","10.1016/j.inffus.2019.05.001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85065543473&doi=10.1016%2fj.inffus.2019.05.001&partnerID=40&md5=94f42d4843a65edf12aeaec5679e0674","In the framework of computer-aided diagnosis of breast cancer, many systems were designed for the detection, the classification and/or the content-based mammogram retrieval (CBMR); in order to serve as a second source of decision for the radiologists. Nevertheless, to improve the final decision-making, the concept of multi-view information fusion (MVIF)was recently introduced. Indeed, this concept has been successfully applied in the context of breast cancer, since screening mammography provides two views for each breast: MedioLateral-Oblique (MLO)and CranioCaudal (CC)views. As these two views are complementary, MVIF methods widely proved their effectiveness. In this paper, we review the main methods that have been proposed for MVIF in the context of the detection (abnormality vs. non abnormality), the classification (normal vs. benign vs. malignant)and the content-based retrieval of mammograms. In fact, we classified detection based on MVIF methods into two main sub-classes, including ipsilateral analysis and bilateral analysis. Besides, classification based on MVIF methods were regrouped into two sub-classes, namely classification of breast masses based on MVIF and classification of breast microcalcifications based on MVIF. Lastly, CBMR based on MVIF methods were also classified into two sub-classes: early fusion-based MVIF-CBMR and late fusion-based MVIF-CBMR. © 2019","Classification; Content-based mammogram retrieval; Detection; Mammograms; Multi-view; Visual information fusion"
"Multi-view diffusion maps","2020","Information Fusion","10.1016/j.inffus.2019.08.005","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85070862936&doi=10.1016%2fj.inffus.2019.08.005&partnerID=40&md5=4ccb0607a8a88ccb684c9ff8d33490a7","In this paper, we address the challenging task of achieving multi-view dimensionality reduction. The goal is to effectively use the availability of multiple views for extracting a coherent low-dimensional representation of the data. The proposed method exploits the intrinsic relation within each view, as well as the mutual relations between views. The multi-view dimensionality reduction is achieved by defining a cross-view model in which an implied random walk process is restrained to hop between objects in the different views. The method is robust to scaling and insensitive to small structural changes in the data. We define new diffusion distances and analyze the spectra of the proposed kernel. We show that the proposed framework is useful for various machine learning applications such as clustering, classification, and manifold learning. Finally, by fusing multi-sensor seismic data we present a method for automatic identification of seismic events. © 2019 Elsevier B.V.","Diffusion maps; Dimensionality reduction; Manifold learning; Multi-view"
"A survey on data fusion in internet of things: Towards secure and privacy-preserving fusion","2019","Information Fusion","10.1016/j.inffus.2018.12.001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061066511&doi=10.1016%2fj.inffus.2018.12.001&partnerID=40&md5=4dfba9d6e0e89a39f763960d0bee0e93","Internet of Things (IoT) aims to create a world that enables the interconnection and integration of things in physical world and cyber space. With the involvement of a great number of wireless sensor devices, IoT generates a diversity of datasets that are massive, multi-sourcing, heterogeneous, and sparse. By taking advantage of these data to further improve IoT services and offer intelligent services, data fusion is always employed first to reduce the size and dimension of data, optimize the amount of data traffic and extract useful information from raw data. Although there exist some surveys on IoT data fusion, the literature still lacks comprehensive insight and discussion on it with regard to different IoT application domains by paying special attention to security and privacy. In this paper, we investigate the properties of IoT data, propose a number of IoT data fusion requirements including the ones about security and privacy, classify the IoT applications into several domains and then provide a thorough review on the state-of-the-art of data fusion in main IoT application domains. In particular, we employ the requirements of IoT data fusion as a measure to evaluate and compare the performance of existing data fusion methods. Based on the thorough survey, we summarize open research issues, highlight promising future research directions and specify research challenges. © 2018 Elsevier B.V.","Data fusion; Data privacy; Internet of Things; Security; Smart grid; Smart home; Smart transportation"
"Data fusion in cyber-physical-social systems: State-of-the-art and perspectives","2019","Information Fusion","10.1016/j.inffus.2018.11.002","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056239746&doi=10.1016%2fj.inffus.2018.11.002&partnerID=40&md5=384496d1003fb259691f5c6690054fbb","Cyber-Physical-Social systems (CPSSs) are the extension of Cyber-Physical systems (CPS), which seamlessly integrate cyber space, physical space and social space. CPSSs promote the information resource from single space to tri-space, so as to lead a revolution in data science (DS). This paper aims to provide a comprehensive review of data fusion in CPSSs for readers. We firstly analyze data collection and representation in CPSS and propose to use tensors to represent CPSS data, then a general definition of CPSS data fusion is proposed to clarify the concept of information fusion in CPSS. After that, some representative data fusion methods related to CPSS are reviewed. Furthermore, we propose a series of tensor based data fusion methods for CPSS data. Also, we review the design of data fusion frameworks and propose a comprehensive data fusion framework for CPSS. Some challenges and future works are discussed as well. © 2018","CPSS; Data fusion; Data fusion framework design; Tensor"
"A survey on region based image fusion methods","2019","Information Fusion","10.1016/j.inffus.2018.07.010","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053420684&doi=10.1016%2fj.inffus.2018.07.010&partnerID=40&md5=24d8de08c87be603334f8b0362e09b8a","Image fusion has been emerging as an important area of research. It has attracted many applications such as surveillance, photography, medical diagnosis, etc. Image fusion techniques are developed at three levels: pixel, feature and decision. Region based image fusion is one of the methods of feature level. It possesses certain advantages – less sensitive to noise, more robust and avoids misregistration. This paper presents a review of region based fusion approaches. A first hand classification of region based fusion methods is carried out. A comprehensive list of objective fusion evaluation metrics is highlighted to compare the existing methods. A detailed analysis is carried out and results are presented in tabular form. This may attract researchers to further explore the research in this direction. © 2018 Elsevier B.V.","Image fusion; Region based fusion; Segmentation"
"A robust D–S fusion algorithm for multi-target multi-sensor with higher reliability","2019","Information Fusion","10.1016/j.inffus.2018.06.009","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050218878&doi=10.1016%2fj.inffus.2018.06.009&partnerID=40&md5=832f42ca33265016b7c7096f37d2d4f3","This paper addresses the problem of track fusion for unordered distributed sensors with unknown measurement noise. A robust Dempster–Shafer (D–S) fusion algorithm is proposed, which includes three parts, namely, the local track estimation, the track association, and the state fusion. First, a labeling VB-PHD filter is derived to present target states with track labels and the unknown measurement noises of local sensors. Next, a heuristic D–S method is proposed to determine the relationship of local tracks and fused tracks, where the accumulated information is taken into account. Finally, a fusion method is given to show the state fusion results, which can fully utilize local state estimates and measurement noise information. Simulation results are provided to illustrate the high precision of tracking and good robustness, comparing with the traditional methods. © 2018","Dempster-Shafer evidence theory; Multi-target multi-sensor fusion; State fusion; Track association; Variational Bayesian probability hypothesis density"
"A clustering method for large-scale group decision-making with multi-stage hesitant fuzzy linguistic terms","2019","Information Fusion","10.1016/j.inffus.2019.02.001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061810765&doi=10.1016%2fj.inffus.2019.02.001&partnerID=40&md5=1e794d9ea96de52efbb7f893cb557006","A large-scale group decision-making (LGDM) problem is studied from the perspective of multi-stage hesitant fuzzy linguistic term sets (MHFLTSs). Solving an LGDM problem requires two processes: a clustering process is helpful for breaking down the larger problem into smaller pieces for simplification purposes, and a selection process is utilized for obtaining a final solution. Along with the MHFLTSs, the decision-making process should include consideration of the distinctiveness of the term sets. With this idea in mind, we propose a clustering method and a selection method based on consideration of multiple reference points derived from the MHFLTSs. First, taking into account the HFLTS characteristics, an expert similarity measurement is proposed based on both the expectation distance and hesitancy similarity between two HFLTSs. Second, multiple reference points are examined: a positive ideal reference point and a development reference point. Reference similarity is then measured by combining these two points. With the goal of maximizing the reference similarity of the alternatives, the third element is the establishment of an optimization model for determining the stage and attribute weights based on consideration of the sensitivity of these two weights to the problem. In the fourth step, a fuzzy clustering method is applied in order to create expert clusters based on expert similarity as well as on the stage and attribute weights. An additional feature is a selection analysis based on the reference similarity between the cluster centers, which entails consideration of the degree of certainty of each cluster as a measure of cluster weighting. The final phase of the research is the application of the proposed method to two cases as a means of illustrating the applicability and feasibility of the new method. © 2019 Elsevier B.V.","Decision analysis; Expert clustering; Hesitancy similarity; Large-scale group decision making; Multi-stage HFLTSs; Reference similarity"
"Learning deep compact similarity metric for kinship verification from face images","2019","Information Fusion","10.1016/j.inffus.2018.07.011","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053191349&doi=10.1016%2fj.inffus.2018.07.011&partnerID=40&md5=2d0bbfd6b800ac0010b731ebb59eed83","Recent advances in kinship verification have shown that learning an appropriate kinship similarity metric on human faces plays a critical role in this problem. However, most of existing distance metric learning (DML) based solutions rely on linearity assumption of the kinship metric model, and the domain knowledge of large cross-generation discrepancy (e.g., large age span and gender difference between parent and child images) has not been considered in metric learning, leading to degraded performance for genetic similarity measure on human faces. To address these limitations, we propose in this work a new kinship metric learning (KML) method with a coupled deep neural network (DNN) model. KML explicitly models the cross-generation discrepancy inherent on parent-child pairs, and learns a coupled deep similarity metric such that the image pairs with kinship relation are pulled close, while those without kinship relation (but with high appearance similarity) are pushed as far away as possible. Moreover, by imposing the intra-connection diversity and inter-connection consistency over the coupled DNN, we introduce the property of hierarchical compactness into the coupled network to facilitate deep metric learning with limited amount of kinship training data. Empirically, we evaluate our algorithm on several kinship benchmarks against the state-of-the-art DML alternatives, and the results demonstrate the superiority of our method. © 2018 Elsevier B.V.","Deep neural network; Face recognition; Hierarchical compactness; Kinship verification; Metric learning"
"Fusing information from tickets and alerts to improve the incident resolution process","2019","Information Fusion","10.1016/j.inffus.2018.01.011","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041483432&doi=10.1016%2fj.inffus.2018.01.011&partnerID=40&md5=6f47f6f3483f4417d7fb8ba54f74f534","In the context of network incident monitoring, alerts are useful notifications that provide IT management staff with information about incidents. They are usually triggered in an automatic manner by network equipment and monitoring systems, thus containing only technical information available to the systems that are generating them. On the other hand, ticketing systems play a different role in this context. Tickets represent the business point of view of incidents. They are usually generated by human intervention and contain enriched semantic information about ongoing and past incidents. In this article, our main hypothesis is that incorporating tickets information into the alert correlation process will be beneficial to the incident resolution life-cycle in terms of accuracy, timing, and overall incident's description. We propose a methodology to validate this hypothesis and suggest a solution to the main challenges that appear. The proposed correlation approach is based on the time alignment of the events (alerts and tickets) that affect common elements in the network. For this we use real alert and ticket datasets obtained from a large telecommunications network. The results have shown that using ticket information enhances the incident resolution process, mainly by reducing and aggregating a higher percentage of alerts compared with standard alert correlation systems that only use alerts as the main source of information. Finally, we also show the applicability and usability of this model by applying it to a case study where we analyze the performance of the management staff. © 2018 Elsevier B.V.","Alert correlation; Data analysis; Network management systems; Quality of service; Ticket-alert correlation"
"Understanding behavioral dynamics of social anxiety among college students through smartphone sensors","2019","Information Fusion","10.1016/j.inffus.2018.09.002","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054193694&doi=10.1016%2fj.inffus.2018.09.002&partnerID=40&md5=fc98a378f6a01a5eb7eb4e3c1177d221","The way people use smartphones provides a window into the relationship between behaviors and mental health. This relationship is of particular significance to individuals with elevated social anxiety, as it helps to reveal when and where their stress increases in relation to social interactions, ultimately leading to more precise treatment delivery and interventions. In this collaboration between engineers and psychologists, we present the first study to use smartphone sensors to examine socially anxious individuals’ fine-grained behaviors around periods in which they engage in some form of social interaction, and how these behaviors differ as a function of location (e.g., at home, at work, or at an unfamiliar location). In a two-week study of 52 college students, we show that there is a significant difference in behaviors for individuals based on social anxiety levels and locations, in that individuals higher (vs. lower) in social anxiety symptoms exhibit more movement (as tracked by the accelerometer) around the time of phone calls, especially in an unfamiliar location (i.e., not home or at work). Finally, we discuss the implications of these findings for developing better interventions for socially anxious individuals. © 2018 Elsevier B.V.","Behavioral dynamics; Sensor fusion; Smartphone use; Social anxiety"
"Expertise-based consensus building for MCGDM with hesitant fuzzy linguistic information","2019","Information Fusion","10.1016/j.inffus.2018.10.003","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054923204&doi=10.1016%2fj.inffus.2018.10.003&partnerID=40&md5=921e4e8166b892d85404fb08f454d248","The integration of a consensus reaching process (CRP) becomes paramount to make highly accepted group decisions in complex real-life multi-criteria group decision making (MCGDM) problems. Notwithstanding, existing CRPs for MCGDM do neither exhaustively analyse the diversity in decision makers’ expertise levels, nor they consider that (because of such diversity) individuals might exhibit distinct perceptions on the relative importance of evaluation criteria. In this study, we present a novel expertise-based consensus building model for MCGDM under a hesitant fuzzy linguistic setting. Firstly, an expertise identification approach is devised to objectively determine the expertise degree of each decision maker based on multiple features. The proposed approach allows to dynamically assigning importance weights to the decision makers’ opinions based on their expertise, as well as intelligently combining their individually elicited subjective and objective criteria weights into meaningful expertise-dependent combinative weights. Then, a CRP for MCGDM problems is introduced based on an improved consensus measurement process and an expertise-based feedback mechanism that provides a highly tailored, personalised means of direction rules to guide decision makers during the consensus building process. A numerical example is provided to illustrate the application of the CRP, and a detailed comparison analysis is presented to verify the validity and accuracy of this study's proposal. © 2018 Elsevier B.V.","Consensus reaching process (CRP); Criteria weighting; Expertise identification; Hesitant fuzzy linguistic term sets (HFLTSs); Multi-criteria group decision making (MCGDM)"
"Machine learning for integrating data in biology and medicine: Principles, practice, and opportunities","2019","Information Fusion","10.1016/j.inffus.2018.09.012","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055032025&doi=10.1016%2fj.inffus.2018.09.012&partnerID=40&md5=1076e202c13aadd6f8cd4029cd6f7561","New technologies have enabled the investigation of biology and human health at an unprecedented scale and in multiple dimensions. These dimensions include a myriad of properties describing genome, epigenome, transcriptome, microbiome, phenotype, and lifestyle. No single data type, however, can capture the complexity of all the factors relevant to understanding a phenomenon such as a disease. Integrative methods that combine data from multiple technologies have thus emerged as critical statistical and computational approaches. The key challenge in developing such approaches is the identification of effective models to provide a comprehensive and relevant systems view. An ideal method can answer a biological or medical question, identifying important features and predicting outcomes, by harnessing heterogeneous data across several dimensions of biological variation. In this Review, we describe the principles of data integration and discuss current methods and available implementations. We provide examples of successful data integration in biology and medicine. Finally, we discuss current challenges in biomedical integrative methods and our perspective on the future development of the field. © 2018 Elsevier B.V.","Computational biology; Heterogeneous data; Machine learning; Personalized medicine; Systems biology"
"Evidence gathering for hypothesis resolution using judicial evidential reasoning","2019","Information Fusion","10.1016/j.inffus.2018.09.010","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054179543&doi=10.1016%2fj.inffus.2018.09.010&partnerID=40&md5=9f66c3ef08724ac1a4b9bbb6db99f167","Realistic decision-making often occurs with insufficient time to gather all possible evidence before a decision must be rendered, requiring an efficient process for prioritizing between potential action sequences. This work aims to develop a rigorous framework for gathering evidence to resolve hypotheses notwithstanding ambiguous, incomplete, and uncertain evidence. Studies have shown that decision-makers demonstrate several biases in decisions involving probability judgment, so decision-makers must be confident that the evidence-based hypothesis resolution is strong and impartial before declaring a resolution. The proposed Judicial Evidential Reasoning framework encodes decision-maker questions as rigorously testable hypotheses to be interrogated through evidence-gathering actions. Dempster–Shafer theory is applied to model hypothesis knowledge and quantify ambiguity, and an equal-effort heuristic is proposed to balance time-efficiency and impartiality. Adversarial optimization techniques are used to make many-hypothesis resolution computationally tractable. This work includes derivation of the generalized formulation, computational tractability considerations for improved performance, several illustrative examples, and application to a space situational awareness sensor network tasking scenario. The results show strong hypothesis resolution and robustness to fixation due to poor prior evidence. © 2018 Elsevier B.V.","Ambiguity aversion; Confirmation bias; Decision support; Dempster–Shafer theory; Hypothesis resolution"
"Feature selection with multi-view data: A survey","2019","Information Fusion","10.1016/j.inffus.2018.11.019","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061028120&doi=10.1016%2fj.inffus.2018.11.019&partnerID=40&md5=cefabf6ef1277596739d0e61a5da170f","This survey aims at providing a state-of-the-art overview of feature selection and fusion strategies, which select and combine multi-view features effectively to accomplish associated tasks. The existing literatures on feature selection approaches are classified into three categories including filter method, wrapper method, and embedded method. Based on the feature selection methods mentioned above, feature-level fusion or known as low-level fusion methodology is further investigated from the perspective of the basic concept, procedure, and applications in analysis tasks as presented in the literatures. Moreover, several distinctive issues that influence the information fusion process such as the use of correlation, confidence level, synchronization, and the optimal features are also emphasized. Finally, we present the adaptive multi-view issues for further research in the area of feature selection and fusion by learning view-specific weights to each view data automatically. © 2018","Feature selection; Information fusion; Multi-view"
"Pedestrian detection with unsupervised multispectral feature learning using deep neural networks","2019","Information Fusion","10.1016/j.inffus.2018.06.005","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050213615&doi=10.1016%2fj.inffus.2018.06.005&partnerID=40&md5=0bcd289a84db8bb3076d1bb7df905a83","Multispectral pedestrian detection is an important functionality in various computer vision applications such as robot sensing, security surveillance, and autonomous driving. In this paper, our motivation is to automatically adapt a generic pedestrian detector trained in a visible source domain to a new multispectral target domain without any manual annotation efforts. For this purpose, we present an auto-annotation framework to iteratively label pedestrian instances in visible and thermal channels by leveraging the complementary information of multispectral data. A distinct target is temporally tracked through image sequences to generate more confident labels. The predicted pedestrians in two individual channels are merged through a label fusion scheme to generate multispectral pedestrian annotations. The obtained annotations are then fed to a two-stream region proposal network (TS-RPN) to learn the multispectral features on both visible and thermal images for robust pedestrian detection. Experimental results on KAIST multispectral dataset show that our proposed unsupervised approach using auto-annotated training data can achieve performance comparable to state-of-the-art deep neural networks (DNNs) based pedestrian detectors trained using manual labels. © 2018 Elsevier B.V.","Auto-annotation; Deep neural networks; Multispectral pedestrian detection; Semantic feature fusion; Unsupervised learning"
"Real-time path planning to dispatch a mobile sensor into an operational area","2019","Information Fusion","10.1016/j.inffus.2018.01.010","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041464361&doi=10.1016%2fj.inffus.2018.01.010&partnerID=40&md5=e7945db59d296eac7c8765c00b444447","This paper addresses problems of large planning time and cost uncertainty for informative path planning of a mobile sensor where the location of sensor deployment is different of that of an operational area. The first problem is that the cost has no term dependent on sensor state before arriving at the operational area and it causes large planning time. The information of the state of interest dissipates over time during the planning time and it degrades performance of sensing operation. The other problem is that the cost is dependent on the parameters to be estimated. To assess the cost, the target state in the future should be predicted by integrating the system model based on noisy initial estimate. The limitation of the informative path planning has a greater impact on performance in this specific problem. A strategy to cope with these problems is to devise a real-time path planning algorithm by using online optimization. The proposed algorithm is divided into two phases; determining the path to the boundary of the operational area and guiding the sensor by an informative potential field in the area. Detailed analysis on performance of the proposed algorithm compared to an optimal solution by nonlinear programming is given. The simulation results have demonstrated that the proposed algorithm can cope with performance degradation observed in the optimal solution. © 2018 Elsevier B.V.","Fisher information matrix; Gradient-descent method; Mobile sensor; Online optimization; Path planning"
"Review of the pansharpening methods for remote sensing images based on the idea of meta-analysis: Practical discussion and challenges","2019","Information Fusion","10.1016/j.inffus.2018.05.006","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048316089&doi=10.1016%2fj.inffus.2018.05.006&partnerID=40&md5=d42efdb768ecc91cf5f9c79ed2419084","In this paper, the development of pansharpening methods from traditional understanding to the current understanding is comprehensively reviewed. Furthermore, the performance of the different categories of pansharpening methods developed between 2000 and 2016 is evaluated based on the idea of meta-analysis. This is innovatively performed by making a statistical analysis of the studies ever published. In the proposed scheme, based on strict selection criteria, 48 representative articles, which were selected from more than 1000 articles, were applied for the statistical analysis. This paper aims to provide a holistic review of the pansharpening methods, and highlights the development process from the traditional understanding to the current understanding. In addition, the experiments were implemented from a new perspective based on the idea of meta-analysis. © 2018","Image fusion; Meta-analysis; Multispectral; Panchromatic; Pansharpening; Remote sensing"
"Bio-inspired smog sensing model for wireless sensor networks based on intracellular signalling","2019","Information Fusion","10.1016/j.inffus.2018.09.005","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054195467&doi=10.1016%2fj.inffus.2018.09.005&partnerID=40&md5=001a12e6ea930791396bfaebc7918eb1","The progression of wireless sensor networks has been formulated a new orientation of research particularly in the monitoring and surveillance areas. Smog pollution is a threat throughout the world presently. Smog affects on public along with plants life. This article proposes a wireless sensor network based smog sensing model for a city by mimicking of biological intracellular signalling. The proposed model is designed and simulated using QualNet 7.1. The several performance features like energy consumption, signals transmission, data transmission of AODV, Bellman–Ford and IERP routing protocols have been evaluated through the proposed model. The simulation result shows that the AODV routing protocol is at least 18.73% and utmost 6.14% energy efficient than Bellman–Ford and IERP routing protocol subsequently. Finally, the merits of the proposed model have been addressed. © 2018 Elsevier B.V.","Intracellular signalling; Smog sensing model; Wireless sensor network"
"Multi-sensor data fusion based on the belief divergence measure of evidences and the belief entropy","2019","Information Fusion","10.1016/j.inffus.2018.04.003","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046491626&doi=10.1016%2fj.inffus.2018.04.003&partnerID=40&md5=798b397e89a0315193787eae12839822","Multi-sensor data fusion technology plays an important role in real applications. Because of the flexibility and effectiveness in modeling and processing the uncertain information regardless of prior probabilities, Dempster–Shafer evidence theory is widely applied in a variety of fields of information fusion. However, counter-intuitive results may come out when fusing the highly conflicting evidences. In order to deal with this problem, a novel method for multi-sensor data fusion based on a new belief divergence measure of evidences and the belief entropy was proposed. First, a new Belief Jensen–Shannon divergence is devised to measure the discrepancy and conflict degree between the evidences; then, the credibility degree can be obtained to represent the reliability of the evidences. Next, considering the uncertainties of the evidences, the information volume of the evidences are measured by making use of the belief entropy to indicate the relative importance of the evidences. Afterwards, the credibility degree of each evidence is modified by taking advantage of the quantitative information volume which will be utilized to obtain an appropriate weight in terms of each evidence. Ultimately, the final weights of the evidences are applied to adjust the bodies of the evidences before using the Dempster's combination rule. A numerical example is illustrated that the proposed method is feasible and effective in handling the conflicting evidences, where the belief value of target increases to 99.05%. Furthermore, an application in fault diagnosis is given to demonstrate the validity of the proposed method. The results show that the proposed method outperforms other related methods where the basic belief assignment (BBA) of the true target is 89.73%. © 2018 Elsevier B.V.","Belief divergence measure; Belief entropy; Dempster–Shafer evidence theory; Evidential conflict; Fault diagnosis; Jensen–Shannon divergence; Sensor data fusion"
"QoE-Aware wireless video communications for emotion-aware intelligent systems: A multi-layered collaboration approach","2019","Information Fusion","10.1016/j.inffus.2018.06.007","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049904494&doi=10.1016%2fj.inffus.2018.06.007&partnerID=40&md5=5e40e15844046ea144adfd677634cbcd","With the ever increasing demand on high-quality visual information for emotion-aware intelligent systems, wireless video traffic explosively grows and causes great energy consumption. Therefore, providing high quality of experience (QoE) for connected users becomes increasingly important. Aiming to establish a new paradigm to solve this challenging problem, in this article we propose a multi-layered collaboration approach to provide energy-efficient QoE-aware wireless video communications by efficiently utilizing the limited transmission resources of wireless networks for 5G. We first investigate the emotion-aware intelligent system QoE measurement based on objective metrics of quality of service (QoS). Then, we utilize the multi-layered collaborations of physical, network and application layers among the connected users to achieve energy-efficient QoE-aware video communications. By developing a profound understanding of the interplay between the video applications and wireless networks, we qualitatively analyze how QoE can benefit from the multi-layered collaborations, and quantitatively assess the achievable gains in a typical wireless-connected emotion-aware application scenario. © 2018","Emotion-aware; Energy-efficiency; Multi-layered collaboration; Quality of experience (QoS); Wireless video communications"
"Trust-based distributed Kalman filtering for target tracking under malicious cyber attacks","2019","Information Fusion","10.1016/j.inffus.2018.04.002","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047443532&doi=10.1016%2fj.inffus.2018.04.002&partnerID=40&md5=24fd9119d0f65c5de72f00a6005be4ad","As one of the widely used applications in wireless sensor networks, target tracking has attracted considerable attention. Although many tracking techniques have been developed, it is still a challenging problem if the network is under cyber attacks. Inaccurate or false information is maliciously broadcast by the compromised nodes to their neighbors. They are likely to threaten the security of the system and result in performance deterioration. In this paper, a distributed Kalman filtering technique with trust-based dynamic combination strategy is developed to improve resilience against cyber attacks. Furthermore, it is efficient in terms of communication load, only local instantaneous estimates are exchanged with the neighboring nodes. Numerical results are provided to evaluate the performance of the proposed approach by considering random, false data injection and replay attacks. © 2018 Elsevier B.V.","Cyber attack; Distributed Kalman filtering; Information fusion; State estimation; Target tracking; Wireless sensor networks"
"Deep learning with multi-scale feature fusion in remote sensing for automatic oceanic eddy detection","2019","Information Fusion","10.1016/j.inffus.2018.09.006","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054181910&doi=10.1016%2fj.inffus.2018.09.006&partnerID=40&md5=ec61a80d4b72d48d197fc67c0d3d594a","Oceanic eddies are ubiquitous in global oceans and play a major role in ocean energy transfer and nutrients distribution, thus being significant for understanding ocean current circulation and marine climate change. They are characterized by a combination of high-speed vertical rotations and horizontal movements, leading to irregular three-dimensional spiral structures. While the ability to detect eddies automatically and remotely is crucial to monitoring important spatial–temporal dynamics, existing methods are inaccurate because eddies are highly dynamic and the underlying physical processes are not well understood. Typically, remote sensing is used to detect eddies based on physical parameters, geometrics or other handcrafted features. In this paper, we show how Deep Learning may be used to reliably extract higher-level features and then fuse multi-scale features to identify eddies, regardless of their structures and scales. We learn eddy features using two principal component analysis convolutional layers, then perform a non-linear transformation of the features through a binary hashing layer and block-wise histograms. To handle the difficult problem of spatial variability across synthetic aperture radar (SAR) images, we introduce a spatial pyramid model to allow multi-scale features fusion. Finally, a linear support vector machine classifier recognizes the eddies. Our method, dubbed DeepEddy, is benchmarked against a dataset of 20,000 SAR image samples, achieving a 97.8 ± 1% accuracy of detection. © 2018 Elsevier B.V.","Deep learning; Eddy detection; Feature fusion; Remote sensing; SAR images"
"Free Double Hierarchy Hesitant Fuzzy Linguistic Term Sets: An application on ranking alternatives in GDM","2019","Information Fusion","10.1016/j.inffus.2018.07.002","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050528750&doi=10.1016%2fj.inffus.2018.07.002&partnerID=40&md5=78ab99cb08aceb6c611ee33d3d9ccba1","Hesitant fuzzy linguistic term sets have been an active field of research in recent times. Notwithstanding its usefulness to capture the human way of reasoning using linguistic expressions involving different levels of precision, in some situations they do not depict enough details. In this paper, we present a new kind of linguistic term sets, called free double hierarchy linguistic term sets, and their corresponding free double hierarchy hesitant fuzzy linguistic elements, in order to describe the complexity of linguistic expressions used by the decision makers in a more accurate and precise way. Furthermore, an order and a distance between free double hierarchy hesitant fuzzy linguistic elements are introduced to present an approach based on the TOPSIS method to rank alternatives with free double hierarchy hesitant fuzzy linguistic information by taking into consideration the opinions of a group of decision makers. A case study based on tourism management in Barcelona is also provided to illustrate the usefulness of the presented approach. © 2018 Elsevier B.V.","Free double hierarchy hesitant fuzzy linguistic term sets; Free double hierarchy linguistic term sets; Group decision-making; Linguistic modeling; TOPSIS; Tourism management"
"Multi-scale fidelity measure for image fusion quality assessment","2019","Information Fusion","10.1016/j.inffus.2019.01.003","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061624773&doi=10.1016%2fj.inffus.2019.01.003&partnerID=40&md5=66906159f063199615bebd5eff64d1de","                             Image fusion is considered an effective enhancing methodology widely included in high-quality imaging systems. Nevertheless, like other enhancing techniques, output quality assessment is made within small sample subjective evaluation studies which are very limited in predicting the human-perceived quality of general image fusion outputs. Simple, blind, universal and perceptual-like methods for assessing composite image quality are still a challenge, partially solved only in particular applications. In this paper, we propose a fidelity measure, called MS-Q                             W                              with two major characteristics related to natural image statistics framework: A multi-scale computation and a structural similarity score. In our experiments, we correlate the scores of our measure with subjective ratings and state of the art measures included in the 2015 Waterloo IVC multi-exposure fusion (MEF) image database. We also use the measure to rank correctly the classical general fusion methods included in the Image Fusion Toolbox for medical, infra-red and multi-focus image examples. Moreover, we study the scores variability and statistical discrimination power with the TNO night vision database using the Friedman test. Finally, we define a new leave one out procedure based on our fidelity measure that selects the best subset of images (within a collection of distorted and unregistered cell phone type images) that provides a defect-free composite output. We exemplify the procedure with the fusion of a collection of images from Latour and Van Dongen paintings suffering from glass highlights and speckle noise, among other artifacts. The proposed multiscale quality measure MS-Q                             W                              demonstrates improvement over the previous single-scale similarity measures towards a fidelity assessment between quantitative image fusion quality metrics and human perceptual qualitative scores.                          © 2019 Elsevier B.V.","High quality photographs of paintings; Image fusion quality assessment; Multi-scale measures; Statistical performance assessment; Structural similarity"
"Multicriteria decision making under conditions of uncertainty in application to multiobjective allocation of resources","2019","Information Fusion","10.1016/j.inffus.2018.12.010","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061581788&doi=10.1016%2fj.inffus.2018.12.010&partnerID=40&md5=9c6655187dcea7ecd198dde8dba3a940","This study is concerned with a multiobjective allocation of resources (or their shortages), delivering an answer to the fundamental question “How to do?” arising in different types of planning activities (strategic, innovation, new business, research and development, expansion, operational, maintenance, etc. planning). The solution to the problem is associated with the extension of the general scheme of multicriteria decision making under uncertainty. This scheme is based on a possibilistic approach and involves a fuzzy set-based generalization of the classic approach to deal with the uncertainty to produce solutions, including robust solutions, in multicriteria analysis. Its usage, in the original form, helps one to use available quantitative information to the highest extent to reduce the decision uncertainty regions. If the quantitative information does not lead to a unique solution, the scheme presumes the application of information of qualitative character (based on knowledge, experience, and intuition of experts) used at the final decision stage. However, increasingly, we encounter problems whose essence requires the consideration of the objectives (investment attractiveness, political effect, maintenance flexibility, etc.) formed on the basis of qualitative information, at all decision process stages. Considering this, the study is aimed at generating multicriteria solutions, including multicriteria robust solutions, by constructing representative combinations of initial data, states of nature or scenarios with direct using qualitative information (with the possibility for experts to apply diverse preference formats processed by transformation functions) presented along with quantitative information, realizing a process of information fusion within the multiobjective models. The corresponding results are of a universal character and applicable to diverse classes of multiobjective problems. The paper also proposes a new approach to the homogeneous and expert-acceptable formulation of specific allocation objectives. Examples are presented to illustrate the study results. © 2019 Elsevier B.V.","Allocation of resources or their shortages; Multicriteria robust solutions; Multiobjective decision making; Possibilistic approach; Qualitative information processing; Transformation functions"
"Alternating diffusion maps for multimodal data fusion","2019","Information Fusion","10.1016/j.inffus.2018.01.007","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046732425&doi=10.1016%2fj.inffus.2018.01.007&partnerID=40&md5=5a264d09b118f639934ce70b4dc9a974","The problem of information fusion from multiple data-sets acquired by multimodal sensors has drawn significant research attention over the years. In this paper, we focus on a particular problem setting consisting of a physical phenomenon or a system of interest observed by multiple sensors. We assume that all sensors measure some aspects of the system of interest with additional sensor-specific and irrelevant components. Our goal is to recover the variables relevant to the observed system and to filter out the nuisance effects of the sensor-specific variables. We propose an approach based on manifold learning, which is particularly suitable for problems with multiple modalities, since it aims to capture the intrinsic structure of the data and relies on minimal prior model knowledge. Specifically, we propose a nonlinear filtering scheme, which extracts the hidden sources of variability captured by two or more sensors, that are independent of the sensor-specific components. In addition to presenting a theoretical analysis, we demonstrate our technique on real measured data for the purpose of sleep stage assessment based on multiple, multimodal sensor measurements. We show that without prior knowledge on the different modalities and on the measured system, our method gives rise to a data-driven representation that is well correlated with the underlying sleep process and is robust to noise and sensor-specific effects. © 2018 Elsevier B.V.","Alternating diffusion maps; Common manifold learning; Diffusion maps; Multimodal sensor fusion; Nonlinear-filtering"
"Integrating expert and novice evaluations for augmenting ordinal regression models","2019","Information Fusion","10.1016/j.inffus.2018.10.012","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056181009&doi=10.1016%2fj.inffus.2018.10.012&partnerID=40&md5=6835cf98ff2f9cf0d570448b5d4e947b","We consider a predictive modelling problem, where the goal is to predict the absolute evaluation of an object on an ordinal scale, traditionally known as an ordinal regression problem. We present a framework that is capable of learning such a model while combining different types of information: absolute evaluations by experts and relative evaluations by novices. We propose and solve a linearly constrained convex optimization problem that takes both types of information into account, and is capable of attributing an ordinal label to a new object based on its features. We do this by relying on principles from machine learning and optimization theory, combined with ideas from information fusion. Experimental results demonstrate the enhanced performance of ordinal regression models when incorporating relative evaluations in the form of rankings. © 2018 Elsevier B.V.","Constrained optimization; Ordinal regression; Preference integration"
"Iris sensor identification in multi-camera environment","2019","Information Fusion","10.1016/j.inffus.2017.11.004","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044779183&doi=10.1016%2fj.inffus.2017.11.004&partnerID=40&md5=b7f9d9ef700dc3fe3b2934c7c88a2e1d","Large-scale identity projects such as the Unique Identification Authority of India (UIDAI) comprise of multiple individual organizations, which may use different sensors for enrolling the individuals while the data obtained at the time of verification can be collected from a different sensor. In such multi-camera scenario, it is imperative to perform image-based iris sensor identification. In this research, we propose an efficient algorithm to identify the sensor from which the iris image is captured. The proposed algorithm is the amalgamation of SVM fitness function based Bacteria Foraging (BF) feature selection and fusion of multiple features such as Block Image Statistical Measure (BISM), High Order Wavelet Entropy (HOWE), Texture Measure (TM), Single-level Multi-orientation Wavelet Texture (SlMoWT), and Image Quality Measures (IQM). The selected features are then given input to a supervised classification algorithm for iris sensor identification. The second contribution of this research is developing two sets of multisensor iris image databases that, in total, contain 6000 images with over 150 subjects. The results show that the proposed sensor classification algorithm is computationally very fast and yields an accuracy of over 99% on multiple databases. © 2018 Elsevier B.V.","Cross-Sensor; Haralick; Iris interoperability; Sensor classification; SVM"
"Dynamic defense strategy against advanced persistent threat under heterogeneous networks","2019","Information Fusion","10.1016/j.inffus.2019.01.001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061623725&doi=10.1016%2fj.inffus.2019.01.001&partnerID=40&md5=1a94263b852badb9ed8b101aab0dde5b","Advanced persistent threats (APTs) pose a grave threat in cyberspace because of their long latency and concealment. In this paper, we propose a hybrid strategy game-based dynamic defense model to optimally allocate constrained secure resources for the target network. In addition, values of profits of players in this game are computed by a novel data-fusion method called NetF. Based on network protocols and log documents, the NetF deciphers data packets collected from different networks to natural language to make them comparable. Using this algorithm, data observed from the Internet and wireless sensor networks (WSNs) can be fused to calculate the comprehensive payoff of every node precisely. The Nash equilibrium can be computed using the value to detect the possibility of a node being a malicious node. Using this method, the dynamic optimal defense strategy can be allocated to every node at different times, which enhances the security of the target network obviously. In experiments, we illustrate the obtained results via case studies of a cluster of heterogeneous networks. The results guide planning of optimal defense strategies for different kinds of nodes at different times. © 2019 Elsevier B.V.","Advanced persistent threat; Dynamic defense strategy; Game theory; Heterogeneous network; Information fusion"
"An intelligent system for spam detection and identification of the most relevant features based on evolutionary Random Weight Networks","2019","Information Fusion","10.1016/j.inffus.2018.08.002","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053357143&doi=10.1016%2fj.inffus.2018.08.002&partnerID=40&md5=6f4b91e0aeaa7a315c037065a03d1a86","With the incremental use of emails as an essential and popular communication mean over the Internet, there comes a serious threat that impacts the Internet and the society. This problem is known as spam. By receiving spam messages, Internet users are exposed to security issues, and minors are exposed to inappropriate contents. Moreover, spam messages waste resources in terms of storage, bandwidth, and productivity. What makes the problem worse is that spammers keep inventing new techniques to dodge spam filters. On the other side, the massive data flow of hundreds of millions of individuals, and the large number of attributes make the problem more cumbersome and complex. Therefore, proposing evolutionary and adaptable spam detection models becomes a necessity. In this paper, an intelligent detection system that is based on Genetic Algorithm (GA) and Random Weight Network (RWN) is proposed to deal with email spam detection tasks. In addition, an automatic identification capability is also embedded in the proposed system to detect the most relevant features during the detection process. The proposed system is intensively evaluated through a series of extensive experiments based on three email corpora. The experimental results confirm that the proposed system can achieve remarkable results in terms of accuracy, precision, and recall. Furthermore, the proposed detection system can automatically identify the most relevant features of the spam emails. © 2018 Elsevier B.V.","Email spam detection; Evolutionary; Feature analysis; Feature selection; Hybrid machine learning; Random Weight Network; Spam filtering"
"An incremental graph-partitioning algorithm for entity resolution","2019","Information Fusion","10.1016/j.inffus.2018.06.001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049037223&doi=10.1016%2fj.inffus.2018.06.001&partnerID=40&md5=c049ced5ffe8a5dc4c393ef88b8c4f2c","Entity resolution is an important data association task when fusing information from multiple sources. Oftentimes the information arrives continuously and the entity resolution algorithm needs to efficiently update its solution upon receiving new information. In this work, we introduce an incremental entity resolution algorithm based on a graph partitioning formulation. The developed algorithm is able to handle both incrementally arriving entity references, as well as incrementally arriving information which changes the pairwise similarity scores between the references. New information is handled in a way that allows the algorithm to reconsider past decisions when contradicting information arrives. Because the graph partitioning formulation used is NP-Hard, a heuristic algorithm is developed to produce good solutions, which is also compatible with a blocking technique to limit the number of required comparisons. The algorithm is tested on a variety of datasets (randomly generated and real) and it is shown that allowing the algorithm to consider revised scores and revisit prior decisions offers a substantial improvement to accuracy (approximately 30–40% better F-Score on a natural language dataset), compared to other greedy heuristics on the same set of coefficients. It is also shown that, on a test set with 100 references, the incremental algorithm is up to an order of magnitude faster than a batch algorithm approach that re-solves the entire problem. © 2018","Data association; Entity resolution; Graph partitioning; Incremental algorithm"
"Multi-focus image fusion using Content Adaptive Blurring","2019","Information Fusion","10.1016/j.inffus.2018.01.009","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041463604&doi=10.1016%2fj.inffus.2018.01.009&partnerID=40&md5=4d7e8c8de7cabd057f26eda0c3c5e84d","Multi-focus image fusion has emerged as an important research area in information fusion. It aims at increasing the depth-of-field by extracting focused regions from multiple partially focused images, and merging them together to produce a composite image in which all objects are in focus. In this paper, a novel multi-focus image fusion algorithm is presented in which the task of detecting the focused regions is achieved using a Content Adaptive Blurring (CAB) algorithm. The proposed algorithm induces non-uniform blur in a multi-focus image depending on its underlying content. In particular, it analyzes the local image quality in a neighborhood and determines if the blur should be induced or not without losing image quality. In CAB, pixels belonging to the blur regions receive little or no blur at all, whereas the focused regions receive significant blur. Absolute difference of the original image and the CAB-blurred image yields initial segmentation map, which is further refined using morphological operators and graph-cut techniques to improve the segmentation accuracy. Quantitative and qualitative evaluations and comparisons with current state-of-the-art on two publicly available datasets demonstrate the strength of the proposed algorithm. © 2018 Elsevier B.V.","Content Adaptive Blurring; Image composition; Image enhancement; Multi-focus image fusion; Non-uniform blurring"
"KLD sampling with Gmapping proposal for Monte Carlo localization of mobile robots","2019","Information Fusion","10.1016/j.inffus.2018.09.003","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054165962&doi=10.1016%2fj.inffus.2018.09.003&partnerID=40&md5=4c49fce47ee3f39e4ac0dc66f361b0ab","The paper proposes an algorithm for mobile robot navigation that integrates the Gmapping proposal distribution with the Kullback–Leibler divergence for adapting the number of particles. This results in a very effective particle filter with adaptive sample size. The algorithm has been evaluated in both simulation and experimental studies, using the standard KLD—sampling MCL as a benchmark. Simulation results show that the proposed algorithm achieves higher localization accuracy with a smaller number of particles compared to the benchmark algorithm. In a more realistic scenario using experimental data and simulated robot odometry with drift, the proposed algorithm again has greater accuracy using a lower number of particles. © 2018 Elsevier B.V.","Mobile robots; Monte Carlo localization; Particle filter"
"Robust weighted state fusion Kalman estimators for networked systems with mixed uncertainties","2019","Information Fusion","10.1016/j.inffus.2018.01.014","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85043360119&doi=10.1016%2fj.inffus.2018.01.014&partnerID=40&md5=c7482fbb1a99dca7bc1358fda378abfc","This paper is concerned with robust weighted state fusion estimation problem for a class of time-varying multisensor networked systems with mixed uncertainties including uncertain-variance multiplicative and linearly correlated additive white noises, and packet dropouts. By augmented state method and fictitious noise technique, the original system is converted into one with only uncertain noise variances. According to the minimax robust estimation principle, based on the worst-case system with the conservative upper bounds of uncertain noise variances, four weighted state fusion robust Kalman estimators (filter, predictor and smoother) are presented in a unified form that the robust filter and smoother are designed based on the robust Kalman predictor. Their robustness is proved by the Lyapunov equation approach in the sense that their actual estimation error variances are guaranteed to have the corresponding minimal upper bounds for all admissible uncertainties. Their accuracy relations are proved. The corresponding robust local and fused steady-state Kalman estimators are also presented, and the convergence in a realization between the time-varying and steady-state robust Kalman estimators is proved by the dynamic error system analysis (DESA) method. Finally, a simulation example applied to uninterruptible power system (UPS) shows the correctness and effectiveness of the proposed results. © 2018 Elsevier B.V.","Lyapunov equation approach; Minimax robust Kalman filtering; Multiplicative noises; Packet dropouts; Uncertain noise variance; Weighted state fusion"
"Audio-visual emotion fusion (AVEF): A deep efficient weighted approach","2019","Information Fusion","10.1016/j.inffus.2018.06.003","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049075298&doi=10.1016%2fj.inffus.2018.06.003&partnerID=40&md5=7725acbb1ddde858d6a44d22344db8b8","The multi-modal emotion recognition lacks the explicit mapping relation between emotion state and audio and image features, so extracting the effective emotion information from the audio/visual data is always a challenging issue. In addition, the modeling of noise and data redundancy is not solved well, so that the emotion recognition model is often confronted with the problem of low efficiency. The deep neural network (DNN) performs excellently in the aspects of feature extraction and highly non-linear feature fusion, and the cross-modal noise modeling has great potential in solving the data pollution and data redundancy. Inspired by these, our paper proposes a deep weighted fusion method for audio-visual emotion recognition. Firstly, we conduct the cross-modal noise modeling for the audio and video data, which eliminates most of the data pollution in the audio channel and the data redundancy in visual channel. The noise modeling is implemented by the voice activity detection(VAD), and the data redundancy in the visual data is solved through aligning the speech area both in audio and visual data. Then, we extract the audio emotion features and visual expression features via two feature extractors. The audio emotion feature extractor, audio-net, is a 2D CNN, which accepting the image-based Mel-spectrograms as input data. On the other hand, the facial expression feature extractor, visual-net, is a 3D CNN to which facial expression image sequence is feeded. To train the two convolutional neural networks on the small data set efficiently, we adopt the strategy of transfer learning. Next, we employ the deep belief network(DBN) for highly non-linear fusion of multi-modal emotion features. We train the feature extractors and the fusion network synchronously. And finally the emotion classification is obtained by the support vector machine using the output of the fusion network. With consideration of cross-modal feature fusion, denoising and redundancy removing, our fusion method show excellent performance on the selected data set. © 2018","Deep learning; Multi-modality emotion recognition; Transfer learning"
"EARS: Emotion-aware recommender system based on hybrid information fusion","2019","Information Fusion","10.1016/j.inffus.2018.06.004","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048977367&doi=10.1016%2fj.inffus.2018.06.004&partnerID=40&md5=d6a9091f59301e6ecacfd4dbd2892777","Recommender systems suggest items that users might like according to their explicit and implicit feedback information, such as ratings, reviews, and clicks. However, most recommender systems focus mainly on the relationships between items and the user's final purchasing behavior while ignoring the user's emotional changes, which play an essential role in consumption activity. To address the challenge of improving the quality of recommender services, this paper proposes an emotion-aware recommender system based on hybrid information fusion in which three representative types of information are fused to comprehensively analyze the user's features: user rating data as explicit information, user social network data as implicit information and sentiment from user reviews as emotional information. The experimental results verify that the proposed approach provides a higher prediction rating and significantly increases the recommendation accuracy. © 2018 Elsevier B.V.","Emotion-aware intelligent system; Hybrid information fusion; Matrix factorization; Recommender systems"
"Necessary and possible hesitant fuzzy sets: A novel model for group decision making","2019","Information Fusion","10.1016/j.inffus.2018.05.005","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048488100&doi=10.1016%2fj.inffus.2018.05.005&partnerID=40&md5=c8bc28feb83c75ee8150ab7e306a68ba","We propose an extension of Torra's notion of hesitant fuzzy set, which appears to be well suited to group decision making. In our model, indecisiveness in judgements is described by two nested hesitant fuzzy sets: the smaller, called necessary, collects membership values determined according to a rigid evaluation, whereas the larger, called possible, comprises socially acceptable membership values. We provide several instances of application of our methodology, and accordingly design suitable individual and group decision procedures. This novel approach displays structural similarities with Atanassov's intuitionistic fuzzy set theory, but has rather different goals. Our source of inspiration comes from preference theory, where a bi-preference approach has proven to be a useful extension of the classical mono-preference modelization in the fields of decision theory and operations research. © 2018 Elsevier B.V.","Aggregation operator; Decision making; Hesitant fuzzy set; Necessary and possible preference; Score"
"Multi-sensor fusion methodology for enhanced land vehicle positioning","2019","Information Fusion","10.1016/j.inffus.2018.04.006","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047169794&doi=10.1016%2fj.inffus.2018.04.006&partnerID=40&md5=f5112444a2a8ad7cf24ddbe76f55e5d1","It is a main challenge for land vehicles to achieve reliable and low-cost navigation solution in various situations, especially when Global Positioning System (GPS) is not available. To address this challenge, we propose an enhanced multi-sensor fusion methodology to fuse the information from low-cost GPS, MEMS Inertial Measurement Unit (IMU), and digital compass in this paper. First, a key data preprocessing algorithm based on Empirical Mode Decomposition (EMD) interval threshold filter is developed to remove the noises in inertial sensors so as to offer more accurate information for subsequent modeling. Then, a Least-Squares Support Vector Machine (LSSVM)-based nonlinear autoregressive with exogenous input (NARX) model (LSSVM-NARX) is designed and augmented with Kalman filter (KF) to construct a novel LSSVM-NARX/KF hybrid strategy. In case of GPS outages, the recently updated LSSVM-NARX is adopted to predict and compensate for the INS position errors. Finally, the performance of proposed methodology was evaluated with real-world data collected in urban settings including typical driving maneuvers. The results indicate that the proposed methodology can achieve remarkable enhancement in positioning accuracy in GPS-denied environments. © 2018 Elsevier B.V.","Empirical mode decomposition; INS/GPS; MEMS; NARX; Vehicle positioning"
"Score-HeDLiSF: A score function of hesitant fuzzy linguistic term set based on hesitant degrees and linguistic scale functions: An application to unbalanced hesitant fuzzy linguistic MULTIMOORA","2019","Information Fusion","10.1016/j.inffus.2018.08.006","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053108767&doi=10.1016%2fj.inffus.2018.08.006&partnerID=40&md5=1a81842a63c4bb6da5e81000c0c65230","The Hesitant Fuzzy Linguistic Term Set (HFLTS) is a powerful tool to depict experts’ cognitive complex linguistic information. This paper aims to propose a new score function of HFLTS to eliminate the defects of the subscript-based operations on HFLTSs. Hesitant degree is an intrinsic feature of HFLTS, and the greater the hesitant degree is, the lower the quality of the HFLTS will be. The asymmetric and non-uniform distributed linguistic term set is commonly used when expressing cognitive complex linguistic information. Considering both the hesitant degrees and the unbalanced linguistic terms in evaluations, a new score function of HFLTS, named the Score-HeDLiSF, is proposed based on the psychology of experts. The Score-HeDLiSF shows many advantages over the existing score function of HFLTS in terms of representing both the balanced and unbalanced linguistic information with hesitant degree and linguistic scale functions. Afterward, a hesitant degree-based weighting method is proposed to determine the weights of experts and criteria. To derive robust decision results, the MULTIMOORA method is improved by integrating the ORESTE method, and then we extend it to the unbalanced hesitant fuzzy linguistic context based on the introduced score function of HFLTS. Finally, an investment problem regarding the shared bicycles is solved by the proposed unbalanced HFL-MULTIMOORA method. The advantages of the unbalanced HFL-MULTIMOORA are highlighted by comparative analyses with two well-known multi-criteria decision-making methods. © 2018","Bicycle-sharing service; Hesitant degree; Hesitant fuzzy linguistic term set; Multiple criteria decision analysis; Score function; Unbalanced HFL-MULTIMOORA"
"Improving automated latent fingerprint identification using extended minutia types","2019","Information Fusion","10.1016/j.inffus.2018.10.001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054739072&doi=10.1016%2fj.inffus.2018.10.001&partnerID=40&md5=73fa67ca4aacbe3a814657ef8fc63a5d","Latent fingerprints are usually processed with Automated Fingerprint Identification Systems (AFIS) by law enforcement agencies to narrow down possible suspects from a criminal database. AFIS do not commonly use all discriminatory features available in fingerprints but typically use only some types of features automatically extracted by a feature extraction algorithm. In this work, we explore ways to improve rank identification accuracies of AFIS when only a partial latent fingerprint is available. Towards solving this challenge, we propose a method that exploits extended fingerprint features (unusual/rare minutiae) not commonly considered in AFIS. This new method can be combined with any existing minutiae-based matcher. We first compute a similarity score based on least squares between latent and tenprint minutiae points, with rare minutiae features as reference points. Then the similarity score of the reference minutiae-based matcher at hand is modified based on a fitting error from the least square similarity stage. We use a realistic forensic fingerprint casework database in our experiments which contains rare minutiae features obtained from Guardia Civil, the Spanish law enforcement agency. Experiments are conducted using three minutiae-based matchers as a reference, namely: NIST-Bozorth3, VeriFinger-SDK and MCC-SDK. We report significant improvements in the rank identification accuracies when these minutiae matchers are augmented with our proposed algorithm based on rare minutiae features. © 2018 Elsevier B.V.","Extended feature sets; Forensics; Latent fingerprints; Rare minutiae features"
"A machine learning based intrusion detection scheme for data fusion in mobile clouds involving heterogeneous client networks","2019","Information Fusion","10.1016/j.inffus.2019.01.002","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061633099&doi=10.1016%2fj.inffus.2019.01.002&partnerID=40&md5=679376e2704069c1870c17867ed1fb19","The combination of traditional cloud computing and mobile computing leads to the novel paradigm of mobile cloud computing. Due to the mobility of network nodes in mobile cloud computing, security has been a challenging problem of paramount importance. When a mobile cloud involves heterogeneous client networks, such as Wireless Sensor Networks and Vehicular Networks, the security problem becomes more challenging because the client networks often have different security requirements in terms of computational complexity, power consumption, and security levels. To securely collect and fuse the data from heterogeneous client networks in complex systems of this kind, novel security schemes need to be devised. Intrusion detection is one of the key security functions in mobile clouds involving heterogeneous client networks. A variety of different rule-based intrusion detection methods could be employed in this type of systems. However, the existing intrusion detection schemes lead to high computation complexity or require frequent rule updates, which seriously harms their effectiveness. In this paper, we propose a machine learning based intrusion detection scheme for mobile clouds involving heterogeneous client networks. The proposed scheme does not require rule updates and its complexity can be customized to suit the requirements of the client networks. Technically, the proposed scheme includes two steps: multi-layer traffic screening and decision-based Virtual Machine (VM) selection. Our experimental results indicate that the proposed scheme is highly effective in terms of intrusion detection. © 2019 Elsevier B.V.","Data fusion; Heterogeneous networks; Intrusion detection; Machine learning; Mobile cloud computing"
"Managing information measures for hesitant fuzzy linguistic term sets and their applications in designing clustering algorithms","2019","Information Fusion","10.1016/j.inffus.2018.10.002","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054614655&doi=10.1016%2fj.inffus.2018.10.002&partnerID=40&md5=0e87c039fdaf5fdf7e56ace9f1d49185","Recently, the Hesitant Fuzzy Linguistic Term Sets (HFLTSs) have been widely used to address cognitive complex linguistic information because of its advantage in representing vagueness and hesitation in qualitative decision-making process. Information measures, including distance measure, similarity measure, entropy measure, inclusion measure and correlation measure, are used to characterize the relationships between linguistic elements. Many decision-making theories are based on information measures. Up to now, distance, similarity, entropy and correlation measures have been proposed by scholars but there is no paper focuses on inclusion measure. This paper dedicates to filling this gap and the inclusion measure between HFLTSs are proposed. We discuss the relationships among distance, similarity, inclusion and entropy measures of HFLTSs. Given that clustering algorithm is an important application of information measures but there are few papers related to clustering algorithm based on information measures in the environment of HFLTS, in this paper, we propose two clustering algorithms based on correlation measure and distance measure, respectively. After that, a case study concerning water resource bearing capacity is illustrated to verify the applicability of the proposed clustering algorithms. © 2018 Elsevier B.V.","Clustering algorithm; Hesitant fuzzy linguistic term set; Inclusion measure; Information measure; Water resource bearing capacity"
"A Partial-Nodes-Based Information fusion approach to state estimation for discrete-Time delayed stochastic complex networks","2019","Information Fusion","10.1016/j.inffus.2018.12.011","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061630261&doi=10.1016%2fj.inffus.2018.12.011&partnerID=40&md5=0832fb66b926c8667e897bd308a16aef","This paper is concerned with the information-fusion-based state estimation problem for a class of discrete-time complex networks with time-varying delays and stochastic perturbations. The measurement outputs available for state estimation are from a fraction of network nodes, and the addressed problem is therefore referred to as the so-called Partial-Nodes-Based (PNB) state estimation problem. By employing the Lyapunov stability theory, a novel framework is established to cope with the PNB state estimation problem by the measurement outputs collected from partial network nodes. By constructing specific Lyapunov-Krasovskii functionals, sufficient criteria are derived for the existence of the desired exponentially ultimately bounded state estimator in mean square for the complex networks. Moreover, a special case is considered where the complex network under investigation is free of stochastic perturbations and the corresponding analysis issue is discussed to ensure the existence of an exponential state estimator. In addition, the explicit expressions of the gains of the desired estimators are characterized. Finally, a numerical illustrative example is presented to demonstrate the effectiveness of the obtained theoretical results. © 2019 Elsevier B.V.","Complex networks; Discrete-time network; Exponentially ultimately bounded estimator; Measurements from partial nodes; State estimation"
"Maximal fusion of facts on the web with credibility guarantee","2019","Information Fusion","10.1016/j.inffus.2018.07.009","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053318742&doi=10.1016%2fj.inffus.2018.07.009&partnerID=40&md5=cfb2e8187e03d299a40d1d4dfc53a7bf","The Web became the central medium for valuable sources of information fusion applications. However, such user-generated resources are often plagued by inaccuracies and misinformation as a result of the inherent openness and uncertainty of the Web. While finding objective data is non-trivial, assessing their credibility with a high confidence is even harder due to the conflicts of information between Web sources. In this work, we consider the novel setting of fusing factual data from the Web with a credibility guarantee and maximal recall. The ultimate goal is that not only the information should be extracted as much as possible but also its credibility must satisfy a threshold requirement. To this end, we formulate the problem of instantiating a maximal set of factual information such that its precision is larger than a pre-defined threshold. Our proposed approach is a learning process to optimize the parameters of a probabilistic model that captures the relationships between data sources, their contents, and the underlying factual information. The model automatically searches for best parameters without pre-trained data. Upon convergence, the parameters are used to instantiate as much as factual information with a precision guarantee. Our evaluations of real-world datasets show that our approach outperforms the baselines up to 6 times. © 2018","Credibility analysis; Information fusion; Knowledge extraction; Precision guarantee; Probabilistic model"
"Simultaneous calibration and navigation (SCAN) of multiple ultrasonic local positioning systems","2019","Information Fusion","10.1016/j.inffus.2018.01.005","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041473760&doi=10.1016%2fj.inffus.2018.01.005&partnerID=40&md5=453109f6d3d9ad3ac9722da35f3093d1","This paper proposes a Simultaneous Calibration and Navigation (SCAN) algorithm of a multiple Ultrasonic Local Positioning Systems (ULPSs) that cover an extensive indoor area. The idea is the development of the same concept than SLAM (Simultaneous Localization and Mapping), in which a Mobile Robot (MR) estimates the map while it is navigating. In our approach, the MR calibrates the beacons of several ULPSs while it is moving inside the localization area. The concept of calibration is the estimation of the position of the beacons referenced to a known map. The scenario is composed of some calibrated ULPSs that we denote as Globally Referenced Ultrasonic Local Positioning Systems (GRULPSs) that are located in strategic points like entrances covering the start and the end of a possible trajectory in the environment. Additionally, there are several non-calibrated ULPSs named Locally Referenced Ultrasonic Local Positioning Systems (LRULPSs) that are placed around the localization area. The proposal uses a MR with odometer for calibrating the beacons of the LRULPSs while it is navigating on their coverage area and go from one GRULPS to another. The algorithm is based on multiple filters running in parallel (one filter for each LRULPS and another one for the GRULPSs) that estimate the global and local trajectories of the MR (one trajectory for each local reference system of the LRULPSs) fusing the information related to the Ultrasound Signals (US) and the odometer of the MR. The position of the beacons of the LRULPSs are obtained by a transformation vector for each LRULPS that converts the local coordinates to the global reference system. This transformation vector is calculated using several points of a local trajectory and the corresponding points of the global one. The method is independent of the type of filter, provided that it works properly with non-linear systems and possibly non-Gaussian noise. Extended Kalman Filter (EKF), Unscented Kalman Filter (UKF) and H-∞ Filter have been tested, in simulations and real experiments, in order to compare their performance in this case. © 2018 Elsevier B.V.","Local positioning system, Fusion; SCAN (Simultaneous Calibration and Navigation); Ultrasound"
"Semi-supervised multi-view maximum entropy discrimination with expectation Laplacian regularization","2019","Information Fusion","10.1016/j.inffus.2018.03.002","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044542306&doi=10.1016%2fj.inffus.2018.03.002&partnerID=40&md5=3f020327b4ebf4882e6854b7e0f67259","Semi-supervised multi-view learning has attracted considerable attention and achieved great success in the machine learning field. This paper proposes a semi-supervised multi-view maximum entropy discrimination approach (SMVMED) with expectation Laplacian regularization for data classification. It takes advantage of the geometric information of the marginal distribution embedded in unlabeled data to construct a semi-supervised classifier. Different from existing methods using Laplacian regularization, we propose to use expectation Laplacian regularization for semi-supervised learning in probabilistic models. We give two implementations of SMVMED and provide their kernel variants. One of them can be relaxed and formulated as a quadratic programming problem that is solved easily. Therefore, for this implementation, we provided two versions which are approximate and exact ones. The experiments on one synthetic and multiple real-world data sets show that SMVMED demonstrates superior performance over semi-supervised single-view maximum entropy discrimination, MVMED and other state-of-the-art semi-supervised multi-view learning methods. © 2018 Elsevier B.V.","Kernel method; Large-margin; Maximum entropy discrimination; Multi-view learning; Semi-supervised learning"
"FLM-TOPSIS: The fuzzy linguistic multiset TOPSIS method and its application in linguistic decision making","2019","Information Fusion","10.1016/j.inffus.2018.01.013","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85043393915&doi=10.1016%2fj.inffus.2018.01.013&partnerID=40&md5=d8a558d81b6cb02492436c722824a2c2","Linguistic decision making is an important subject in decision making, many interesting and important linguistic decision making methods have been proposed, in which, alternatives-criteria decision matrix are uniformly used to express linguistic assessments of alternatives provided by decision makers with respect to criteria. Alternatives-criteria decision matrixes have some limitations when we use them to distinguish distinct, partial unknown or hesitant linguistic decision making or carry out linguistic decision making in the huge amounts of decision information and alternatives. In this paper, we propose alternatives-linguistic terms decision matrix to represent linguistic assessments of alternatives, analyze advantages of the decision matrix in representing linguistic assessments and distinguishing distinct, partial unknown or hesitant linguistic decision making. To simple and fast fuse alternatives-linguistic terms decision matrixes, we further provide linguistic multiset or fuzzy linguistic multiset to represent linguistic assessments in alternatives-linguistic terms decision matrixes, analyze the function properties of the fuzzy linguistic multiset. Motivated by fuzzy multiset and the TOPSIS method, we develop the fuzzy linguistic multiset TOPSIS method for linguistic decision making, the method is mainly consisted of transformation, aggregation and exploitation phases. In transformation phase, linguistic assessments of alternatives are transformed into fuzzy linguistic multisets by using alternatives-linguistic terms decision matrixes. In aggregation phase, we use Union, Intersection and Sum operations of multisets to obtain the positive and negative ideal solutions of linguistic decision making, which are different with the positive and negative ideal solutions of the traditional TOPSIS method, in addition, we provide a pseudo-distance between two fuzzy linguistic multisets to fast fuse linguistic assessments of alternatives. In exploitation phase, we define a new closeness degree of alternative by using pseudo-distances between the alternative and the positive and negative ideal solutions, which can be used to obtain the set of most satisfying alternatives. We also design an algorithm to carry out linguistic decision making based on the proposed method. In cases study, we use two practical examples to illustrate the practicality of the proposed method and compare it with the symbolic aggregation-based method, the hesitant fuzzy linguistic TOPSIS method, the hesitant fuzzy linguistic VIKOR method and the probabilistic linguistic term sets TOPSIS method, results indicate that alternatives-linguistic terms decision matrix and fuzzy linguistic multiset are alternative, useful and flexible tools for linguistic decision method and the fuzzy linguistic multiset TOPSIS method is suitable to deal with partial unknown or hesitant linguistic decision making. © 2018 Elsevier B.V.","Decision matrix; Hesitant fuzzy set; Linguistic decision making; Multiset; The 2-tuple linguistic model; The TOPSIS method"
"On developing an automatic threshold applied to feature selection ensembles","2019","Information Fusion","10.1016/j.inffus.2018.02.007","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85043257405&doi=10.1016%2fj.inffus.2018.02.007&partnerID=40&md5=b53e00b9e4f6f260a5f38f2ee8896aa4","Feature selection ensemble methods are a recent approach aiming at adding diversity in sets of selected features, improving performance and obtaining more robust and stable results. However, using an ensemble introduces the need for an aggregation step to combine all the output methods that confirm the ensemble. Besides, when trying to improve computational efficiency, ranking methods that order all initial features are preferred, and so an additional thresholding step is also mandatory. In this work two different ensemble designs based on ranking methods are described. The main difference between them is the order in which the combination and thresholding steps are performed. In addition, a new automatic threshold based on the combination of three data complexity measures is proposed and compared with traditional thresholding approaches based on retaining a fixed percentage of features. The behavior of these methods was tested, according to the SVM classification accuracy, with satisfactory results, for three different scenarios: synthetic datasets and two types of real datasets (where sample size is much higher than feature size, and where feature size is much higher than sample size). © 2018 Elsevier B.V.","Automatic thresholding; Ensemble learning; Feature selection"
"Knowledge-based multimodal information fusion for role recognition and situation assessment by using mobile robot","2019","Information Fusion","10.1016/j.inffus.2018.10.007","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055314928&doi=10.1016%2fj.inffus.2018.10.007&partnerID=40&md5=06639e069a49c020fdbe35d3479a25e5","Decision-making is the key for autonomous systems to achieve real intelligence and autonomy. This paper presents an integrated probabilistic decision framework for a robot to infer roles that humans fulfill in specific missions. The framework also enables the assessment of the situation and necessity of interaction with the person fulfilling the target role. The target role is the person who is distinctive in movement or holds a mission-critical object, where the object is pre-specified in the corresponding mission. The proposed framework associates prior knowledge with spatial relationships between the humans and objects as well as with their temporal changes. Distance-Based Inference (DBI) and Knowledge-Based Inference (KBI) support recognition of human roles. DBI deduces the role based on the relative distance between humans and the specified objects. KBI focuses on human actions and objects existence. The role is estimated using weighted fusion scheme based on the information entropy. The situation is assessed by analyzing the action of the person fulfilling the target role and relative position of this person to the mission-related entities, where the entity is something that has a particular function in the corresponding mission. This assessment determines the robot decision on what actions it should take. A series of experiments has proofed that the proposed framework provides a reasonable assessment of the situation. Moreover, it outperforms other approaches on accuracy, efficiency, and robustness. © 2018 Elsevier B.V.","Decision making; Multimodal information fusion; Probabilistic inference; Role recognition; Situation assessment"
"Fusing pattern discovery and visual analytics approaches in tweet propagation","2019","Information Fusion","10.1016/j.inffus.2018.05.004","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047918019&doi=10.1016%2fj.inffus.2018.05.004&partnerID=40&md5=587a81bda963e4f08e7da4e99dc1f89f","Over the past several years, social networks have become a major channel for information delivery. At present, social networks are being used to obtain more followers and exert influence over people during political campaigns. However, the propagation of a social network post is dependent on numerous factors. Some of these are known; for example, the post contents, the time when it was posted, and the person or entity by whom it was posted. However, other factors remain unknown, such as what makes a post more successful than others, and how posts from similar profiles evolve and propagate differently over time. The main subject of this work is addressing these types of questions. Our approach relies on a three-fold methodology for studying the influence and propagation of posts: graph-based, semantic, and contrast pattern recognition analysis. The results obtained are complemented by a dynamic visualization that encompasses all of the variables involved. In order to corroborate our results, we collected all posts from the Twitter accounts of the most prominent Mexican political figures and analyzed the influence and propagation of each post issued. © 2018 Elsevier B.V.","Influence modeling; Pattern recognition; Social networks; Twitter; Visual analytics"
"Multispectral and hyperspectral image fusion with spatial-spectral sparse representation","2019","Information Fusion","10.1016/j.inffus.2018.11.012","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061924285&doi=10.1016%2fj.inffus.2018.11.012&partnerID=40&md5=a25fe5104b2dbf415f23bae15cd38f38","Fusing a high spatial resolution multispectral image (HR-MSI) with a low spatial resolution hyperspectral image (LR-HSI) of the same scenario to acquire a high spatial resolution hyperspectral image (HR-HSI) has recently attracted more and more attention. We propose a novel spatial-spectral sparse representation (SSSR) based approach for the fusion of an HR-MSI and an LR-HSI of the same scenario in this paper. In the proposed SSSR method, we formulate the fusion problem as the estimation of spectral basis and coefficients from the LR-HSI and HR-MSI. To better model the spatial and spectral characteristics of the HR-HSI, we incorporate the non-local spatial similarities, priors of the spectral unmixing, and a sparse prior to the fusion problem. Meanwhile, instead of keeping the spectral basis fixed, we design the alternative optimization algorithm for the estimation of spectral basis and coefficients, which can achieve the accurate reconstruction. Experimental results on both non-blind fusion and blind fusion cases demonstrate the effectiveness of the SSSR approach. © 2019 Elsevier B.V.","Hyperspectral image super-resolution; Hyperspectral imaging; Image fusion; Spatial-spectral sparse representation"
"Revealing causality between heterogeneous data sources with deep restricted Boltzmann machines","2019","Information Fusion","10.1016/j.inffus.2018.11.016","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061035830&doi=10.1016%2fj.inffus.2018.11.016&partnerID=40&md5=1e87a28a2f9b89cc6d8464a1ed14e353","In a number of real life applications, scientists do not have access to temporal data, since budget for data acquisition is always limited. Here we challenge the problem of causal inference between groups of heterogeneous non-temporal observations obtained from multiple sources. We consider a family of probabilistic algorithms for causal inference based on an assumption that in case where X causes Y, P(X) and P(Y|X) are statistically independent. For a number of real world applications, deep learning methods were reported to achieve the most accurate empirical performance, what motivates us to use deep Boltzmann machines to approximate the marginal and conditional probabilities of heterogeneous observations as accurate as possible. We introduce a novel algorithm to infer causal relationships between blocks of variables. The proposed method was tested on a benchmark of multivariate cause-effect pairs. We show by our experiments that our method achieves the state-of-the-art empirical accuracy, and sometimes outperforms the state-of-the-art methods. An important part of our contribution is an application of the proposed algorithm to an original medical data set, where we explore relations between alimentary patters, human gut microbiome composition, and health status. © 2018 Elsevier B.V.","Causal inference; Heterogeneous data sources; Principal component analysis; Probabilistic deep models"
"Energy-aware scheduling for information fusion in wireless sensor network surveillance","2019","Information Fusion","10.1016/j.inffus.2018.08.005","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053294303&doi=10.1016%2fj.inffus.2018.08.005&partnerID=40&md5=77aa3874d8739a2cea947cbc7675b1d2","Effective energy control while maintaining reliable monitoring performance becomes a key issue in wireless sensor networks (WSNs) based surveillance applications. While importance difference of surveillance zone, limited energy and dynamic network topology pose great challenges to surveillance performance. It is necessary to adjust sensor nodes’ awakening frequency dynamically for information fusion. Thus an energy-aware scheduling with quality guarantee method named ESQG is proposed in this paper which considers sensor nodes’ residual energy, different importance degrees of the surveillance zone and network topology comprehensively. It first uses a Voronoi diagram to determine the effective scope of each sensor node and then calculates node importance according to its residual energy and the importance degree of the effective scope. Then ESQG utilizes the importance of individual sensing scope and current forwarding costs to further compute node importance and awakening frequency for information fusion. In this way, ESQG can dynamically adapts each nodes awakening frequency to its dynamic network topology and importance degree of each individual sensing scope. The nodes are then turned on stochasticlly via the node awakening probability and node importance based information fusion is conducted for target detection. Besides, an adaptive process of perception factor C is proposed to match actual situation, and automatically change according to the detected data. Experiments results demonstrate that the proposed method ESQG can reduce the number of awakening nodes to a large extent while maintaining high reliability via information fusion. © 2018 Elsevier B.V.","Detection efficiency; Network topology; Voronoi diagram; Wireless sensor networks"
"Approximate computational approaches for Bayesian sensor placement in high dimensions","2019","Information Fusion","10.1016/j.inffus.2018.06.006","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049329861&doi=10.1016%2fj.inffus.2018.06.006&partnerID=40&md5=600a4f580a307519ec351628c4656805","Since the cost of installing and maintaining sensors is usually high, sensor locations should always be strategically selected to extract most of the information. For inferring certain quantities of interest (QoIs) using sensor data, it is desirable to explore the dependency between observables and QoIs to identify optimal placement of sensors. Mutual information is a popular dependency measure, however, its estimation in high dimensions is challenging as it requires a large number of samples. This also comes at a significant computational cost when samples are obtained by simulating complex physics-based models. Similarly, identifying the optimal design/location requires a large number of mutual information evaluations to explore a continuous design space. To address these challenges, two novel approaches are proposed. First, instead of estimating mutual information in high-dimensions, we map the limited number of samples onto a lower dimensional space while capturing dependencies between the QoIs and observables. We then estimate a lower bound of the original mutual information in this low dimensional space, which becomes our new dependence measure between QoIs and observables. Second, we use Bayesian optimization to search for optimal sensor locations in a continuous design space while reducing the number of lower bound evaluations. Numerical results on both synthetic and real data are provided to compare the performance of the lower bound with the estimate of mutual information in high dimensions, and a puff-based dispersion model is used to evaluate the sensor placement of the Bayesian optimization for a chemical release problem. The results show that the proposed approaches are both effective and efficient in capturing dependencies and inferring the QoIs. © 2018","Bayesian inference; Bayesian optimization; Canonical correlation analysis; Low dimensional projection; Mutual information"
"Variable augmented neural network for decolorization and multi-exposure fusion","2019","Information Fusion","10.1016/j.inffus.2018.05.007","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048308956&doi=10.1016%2fj.inffus.2018.05.007&partnerID=40&md5=c4fccec6df24c6c2c9cbf4a8018ae0c2","This paper shows how to convert a color image to grayscale using convolutional neural network (CNN), that preserves visual contrast via gradient domain modeling. We propose to explore the auxiliary variable principle to make the input and output variable dimensions to be the same, and use L1-norm error of the image gradients as the loss function criterion. The similarity measure calculates the summation of the gradient correlation between each channel of the color image and the transformed grayscale image. The final gray mapping result is then obtained by reconstruction from a globally initial grayscale image and locally derived gradient images. A weighted objective is proposed to balance the robustness and visual appearance of color images. Furthermore, by revealing the relation between color-to-gray and multi-exposure fusion, the network is applied to multi-exposure fusion. Both quantitative and qualitative evaluations on decolorization and multi-exposure fusion consistently demonstrate the potential of the proposed method against existing state-of-the-art algorithms. © 2018","Auxiliary variables; Color-to-gray conversion; Convolutional neural network; Gradient domain; L1-norm; Multi-exposure fusion"
"Social network analysis-based conflict relationship investigation and conflict degree-based consensus reaching process for large scale decision making using sparse representation","2019","Information Fusion","10.1016/j.inffus.2019.02.004","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061829238&doi=10.1016%2fj.inffus.2019.02.004&partnerID=40&md5=7cdc7c92b4116d32fa715ee41b4478e2","Large-Scale Decision Making (LSDM) scenarios, such as public participation events, are becoming increasingly common in human life. Decision makers (DMs) in LSDM events present different interest preferences, leading to different relationships being created between them. In LSDM scenarios, a conflict relationship, which is a type of negative relationship among DMs, has the biggest negative impact on reaching the consensus. The conflict relationships can be divided into two parts: the opinion conflict and the behavior conflict. In this paper, a Social network analysis-based Conflict Relationship Investigation Process (S-CRIP) is presented to detect the conflict relationships among DMs for LSDM events, in which sparse representation is used. Besides, a Conflict Degree-based Consensus Reaching Process (CD-CRP) is proposed for LSDM problems, which is using group conflict degree to check whether the consensus is reached or not. In the decision selection process, DMs’ weights are calculated by their conflict performances, which can reduce the negative influence of those DMs that present conflict in the LSDM event. The proposed S-CRIP can not only investigate the conflict relationships among DMs, but can also recognize the two types of conflict relationships according to their features. The three processes constitute the S-CRIP and CD-CRIP-based LSDM model, which is suitable for any numerical representations. Illustrative experiments not only show the feasibility and veracity of S-CRIP in LSDM scenarios, but also prove the practicability and effectiveness of S-CRIP and CD-CRP-based LSDM model. © 2019 Elsevier B.V.","Conflict degree-based consensus reaching process; Conflict relationship investigation; Large-scale decision making; Social network analysis; Sparse representation"
"A new approach to distributed fusion filtering for networked systems with random parameter matrices and correlated noises","2019","Information Fusion","10.1016/j.inffus.2018.02.006","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044508831&doi=10.1016%2fj.inffus.2018.02.006&partnerID=40&md5=625643dfdc9f205551254e5aafd3eb5c","This paper is concerned with the distributed filtering problem for a class of discrete-time stochastic systems over a sensor network with a given topology. The system presents the following main features: (i) random parameter matrices in both the state and observation equations are considered; and (ii) the process and measurement noises are one-step autocorrelated and two-step cross-correlated. The state estimation is performed in two stages. At the first stage, through an innovation approach, intermediate distributed least-squares linear filtering estimators are obtained at each sensor node by processing available output measurements not only from the sensor itself but also from its neighboring sensors according to the network topology. At the second stage, noting that at each sampling time not only the measurement but also an intermediate estimator is available at each sensor, attention is focused on the design of distributed filtering estimators as the least-squares matrix-weighted linear combination of the intermediate estimators within its neighborhood. The accuracy of both intermediate and distributed estimators, which is measured by the error covariance matrices, is examined by a numerical simulation example where a four-sensor network is considered. The example illustrates the applicability of the proposed results to a linear networked system with state-dependent multiplicative noise and different network-induced stochastic uncertainties in the measurements; more specifically, sensor gain degradation, missing measurements and multiplicative observation noises are considered as particular cases of the proposed observation model. © 2018 Elsevier B.V.","Correlated noises; Distributed filtering; Random parameter matrices; Sensor networks"
"Combining univariate approaches for ensemble change detection in multivariate data","2019","Information Fusion","10.1016/j.inffus.2018.02.003","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85043269907&doi=10.1016%2fj.inffus.2018.02.003&partnerID=40&md5=ec98c784a4180d5c223d3b5d93f5e362","Detecting change in multivariate data is a challenging problem, especially when class labels are not available. There is a large body of research on univariate change detection, notably in control charts developed originally for engineering applications. We evaluate univariate change detection approaches —including those in the MOA framework — built into ensembles where each member observes a feature in the input space of an unsupervised change detection problem. We present a comparison between the ensemble combinations and three established ‘pure’ multivariate approaches over 96 data sets, and a case study on the KDD Cup 1999 network intrusion detection dataset. We found that ensemble combination of univariate methods consistently outperformed multivariate methods on the four experimental metrics. © 2018 Elsevier B.V.",""
"Entailment for measure based belief structures","2019","Information Fusion","10.1016/j.inffus.2018.07.003","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053772420&doi=10.1016%2fj.inffus.2018.07.003&partnerID=40&md5=410724274f8bc82c1009cdb9c5e88f37","We discuss the Dempster–Shafer belief structure on finite universes and note its use for modeling variables that have both probabilistic uncertainty as well as imprecision. We note for these structures the probability that the variable lies in a subset cannot be precisely known but only be known to an interval value. We discuss methods for deducing this uncertainty interval. We next discuss the issue of entailment of belief structures, inferring the validity of additional belief model of a variable from an already established belief model of the variable. We next discuss a more general belief structure were the underling uncertainty rather tha0n being based on a probability distribution is based on a general measure type of uncertainty. We then extend the concept of entailment to the case where the belief structures are these more general measure based belief structures. In order to accomplish this we must extend the idea of containment from classic Dempster–Shafer belief structures to measure based belief structures. © 2018 Elsevier B.V.","Choquet integral; Deduction; Dempster–Shafer; Measure type uncertainty; Uncertainty"
"Multimodal data fusion for sensitive scene localization","2019","Information Fusion","10.1016/j.inffus.2018.03.001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044525595&doi=10.1016%2fj.inffus.2018.03.001&partnerID=40&md5=e42e7de499f9102f48eaeda766d06e22","The very idea of hiring humans to avoid the indiscriminate spread of inappropriate sensitive content online (e.g., child pornography and violence) is daunting. The inherent data deluge and the tediousness of the task call for more adequate approaches, and set the stage for computer-aided methods. If running in the background, such methods could readily cut the stream flow at the very moment of inadequate content exhibition, being invaluable for protecting unwary spectators. Except for the particular case of violence detection, related work to sensitive video analysis has mostly focused on deciding whether or not a given stream is sensitive, leaving the localization task largely untapped. Identifying when a stream starts and ceases to display inappropriate content is key for live streams and video on demand. In this work, we propose a novel multimodal fusion approach to sensitive scene localization. The solution can be applied to diverse types of sensitive content, without the need for step modifications (general purpose). We leverage the multimodality data nature of videos (e.g., still frames, video space-time, audio stream, etc.) to effectively single out frames of interest. To validate the solution, we perform localization experiments on pornographic and violent video streams, two of the commonest types of sensitive content, and report quantitative and qualitative results. The results show, for instance, that the proposed method only misses about five minutes in every hour of streamed pornographic content. Finally, for the particular task of pornography localization, we also introduce the first frame-level annotated pornographic video dataset to date, which comprises 140 h of video, freely available for downloading. © 2018 Elsevier B.V.","Multimodal data fusion; Pornography localization; Sensitive scene localization; Violence localization"
"Emotion recognition using deep learning approach from audio–visual emotional big data","2019","Information Fusion","10.1016/j.inffus.2018.09.008","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054161545&doi=10.1016%2fj.inffus.2018.09.008&partnerID=40&md5=9def2ea1839b9d8ca2d5c7ca34af1611","This paper proposes an emotion recognition system using a deep learning approach from emotional Big Data. The Big Data comprises of speech and video. In the proposed system, a speech signal is first processed in the frequency domain to obtain a Mel-spectrogram, which can be treated as an image. Then this Mel-spectrogram is fed to a convolutional neural network (CNN). For video signals, some representative frames from a video segment are extracted and fed to the CNN. The outputs of the two CNNs are fused using two consecutive extreme learning machines (ELMs). The output of the fusion is given to a support vector machine (SVM) for final classification of the emotions. The proposed system is evaluated using two audio–visual emotional databases, one of which is Big Data. Experimental results confirm the effectiveness of the proposed system involving the CNNs and the ELMs. © 2018 Elsevier B.V.",""
"A binocular image fusion approach for minimizing false positives in handgun detection with deep learning","2019","Information Fusion","10.1016/j.inffus.2018.11.015","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062060307&doi=10.1016%2fj.inffus.2018.11.015&partnerID=40&md5=c6332250ab48d94fa9e967374f247510","Object detection models have known important improvements in the recent years. The state-of-the art detectors are end-to-end Convolutional Neural Network based models that reach good mean average precisions, around 73%, on benchmarks of high quality images. However, these models still produce a large number of false positives in low quality videos such as, surveillance videos. This paper proposes a novel image fusion approach to make the detection model focus on the area of interest where the action is more likely to happen in the scene. We propose building a low cost symmetric dual camera system to compute the disparity map and exploit this information to improve the selection of candidate regions from the input frames. From our results, the proposed approach not only reduces the number of false positives but also improves the overall performance of the detection model which make it appropriate for object detection in surveillance videos. © 2018 Elsevier B.V.","Classification; Convolutional neural networks (CNNs); Deep learning; Detection; Faster R-CNN; Region proposals; Selective research; VGG-16"
"AHNG: Representation learning on attributed heterogeneous network","2019","Information Fusion","10.1016/j.inffus.2019.01.005","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061708990&doi=10.1016%2fj.inffus.2019.01.005&partnerID=40&md5=86b649812e080bd04621dbf73b64a2eb","Network embedding aims to encode nodes into a low-dimensional space with the structure and inherent properties of the networks preserved. It is an upstream technique for network analyses such as link prediction and node clustering. Most existing efforts are devoted to homogeneous or heterogeneous plain networks. However, networks in real-world scenarios are usually heterogeneous and not plain, i.e., they contain multi-type nodes/links and diverse node attributes. We refer such kind of networks with both heterogeneities and attributes as attributed heterogeneous networks (AHNs). Embedding AHNs faces two challenges: (1) how to fuse heterogeneous information sources including network structures, semantic information and node attributes; (2) how to capture uncertainty of node embeddings caused by diverse attributes. To tackle these challenges, we propose a unified embedding model which represents each node in an AHN with a Gaussian distribution (AHNG). AHNG fuses multi-type nodes/links and diverse attributes through a two-layer neural network and captures the uncertainty by embedding nodes as Gaussian distributions. Furthermore, the incorporation of node attributes makes AHNG inductive, embedding previously unseen nodes or isolated nodes without additional training. Extensive experiments on a large real-world dataset validate the effectiveness and efficiency of the proposed model. © 2019 Elsevier B.V.","Attributed heterogeneous network; Gaussian distribution; Network embedding"
"Emotion-aware system design for the battlefield environment","2019","Information Fusion","10.1016/j.inffus.2018.07.008","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050958425&doi=10.1016%2fj.inffus.2018.07.008&partnerID=40&md5=43c725c55871afae5a0c5d433a63c144","With the increasing amount of information and the growth of data sources on the battlefield, it is important to achieve better battlefield decision-making through the faster and more accurate emotion awareness provided by big data. Existing battlefield systems are mainly focused on logical information acquisition, rarely considering emotion factors. In this paper, an emotion-aware system for the battlefield environment (ESBE) is proposed to achieve various functions, including target localization, target recognition, motion behavior identification, etc., to support intelligent decision-making based on the emotional state of soldiers and other valuable information about the battlefield environment. The ESBE architecture consists of three layers: data-sensing, data-transmission, and data-processing. A heterogeneous network is introduced in data-transmission layer to speed up the transmission ratio and increase the network throughput. In the data-processing layer, cloud technology is introduced to store the big data while information fusion based on a variety of technologies is executed to process the big data. Then, the elaborated function of each architecture layer, such as the fundamental process of the ESBE system, as well as some function provided by the ESBE, is presented separately. Last but not least, the ESBE system is compared with four other existing systems in terms of functions and technologies. © 2018 Elsevier B.V.","Battlefield big data; Emotion-Aware; Heterogeneous network; Information fusion; Narrow-band IoT"
"Infrared and visible image fusion methods and applications: A survey","2019","Information Fusion","10.1016/j.inffus.2018.02.004","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042943977&doi=10.1016%2fj.inffus.2018.02.004&partnerID=40&md5=8b2eecdf3c4ea0b0c5bded9361cd78a6","Infrared images can distinguish targets from their backgrounds based on the radiation difference, which works well in all-weather and all-day/night conditions. By contrast, visible images can provide texture details with high spatial resolution and definition in a manner consistent with the human visual system. Therefore, it is desirable to fuse these two types of images, which can combine the advantages of thermal radiation information in infrared images and detailed texture information in visible images. In this work, we comprehensively survey the existing methods and applications for the fusion of infrared and visible images. First, infrared and visible image fusion methods are reviewed in detail. Meanwhile, image registration, as a prerequisite of image fusion, is briefly introduced. Second, we provide an overview of the main applications of infrared and visible image fusion. Third, the evaluation metrics of fusion performance are discussed and summarized. Fourth, we select eighteen representative methods and nine assessment metrics to conduct qualitative and quantitative experiments, which can provide an objective performance reference for different fusion methods and thus support relative engineering with credible and solid evidence. Finally, we conclude with the current status of infrared and visible image fusion and deliver insightful discussions and prospects for future work. This survey can serve as a reference for researchers in infrared and visible image fusion and related fields. © 2018 Elsevier B.V.","Evaluation metric; Image fusion; Image registration; Infrared image; Visible image"
"Hierarchical multi-modal fusion FCN with attention model for RGB-D tracking","2019","Information Fusion","10.1016/j.inffus.2018.09.014","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054826334&doi=10.1016%2fj.inffus.2018.09.014&partnerID=40&md5=6c7c4136ae90b32b8a5eacd6f4a8eea1","In this paper, we propose a RGB-D tracking algorithm, built upon hierarchical multi-modal fusion fully convolutional neural network (FCN) with attention model. First, we encode the depth images into three channels using the HHA representation to obtain the similar structure to the RGB images. Second, a multi-modal fusing features learning FCN with attention model is constructed, which can extract hierarchical multi-modal fusing features of the samples in RGB-D data. The attention model is adopted to exploit the importance weight of RGB and depth to fuse the features of the two modalities at multiple layers effectively, rather than concatenating the feature vectors of the two channels simply. Finally, the hierarchical multi-modal fusing features of the samples are input to the Efficient Convolution Operators (ECO) tracker, and the update strategy is improved by the occlusion detection in the depth images. Experimental results datasets demonstrate that the proposed RGB-D tracker achieves new state-of-art performance on the large-scale Princeton RGB-D Tracking Benchmark (PTB) dataset and the University of Birmingham RGB-D Tracking Benchmark (BTB). © 2018 Elsevier B.V.","Attention model; ECO tracker; Hierarchical multi-modal feature fusion FCN; RGB-D tracking"
"FORA: An OWO based framework for finding outliers in web usage mining","2019","Information Fusion","10.1016/j.inffus.2018.08.003","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053119248&doi=10.1016%2fj.inffus.2018.08.003&partnerID=40&md5=7ad70bf2cef6b28d8fd232a4456e8ec3","Handling outliers are one of the primary concerns of today's data mining techniques. The concept of outliers, it's handling, and diagnosis is context specific and varies according to the field of application. The existence of outliers while mining web data is inevitable by virtue of unique characteristic features exhibited by a typical web user. As the output of a regression algorithm is always different from the actual value, it poses a challenge to the knowledge workers and researchers about the notion of an outlier in such cases. In this paper, we propose to develop the concept of an outlier with respect to regression analysis of any Web-based dataset. A framework to find outliers in the output of a regression algorithm is being formulated with the help of Ordered Weighted operators. The underlying idea is to find an error rectification value, ϵ that will work, in association with the predicted value from the regression model and then help to distinguish an outlier. This will, in addition, also provide a possible range of deviation from the predicted output. A case study on a web dataset is being done to show the usefulness of the proposed approach. © 2018 Elsevier B.V.","Business intelligence; Fuzzy logic; Outliers; Regression; World wide web"
"Combining time-series and textual data for taxi demand prediction in event areas: A deep learning approach","2019","Information Fusion","10.1016/j.inffus.2018.07.007","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054192390&doi=10.1016%2fj.inffus.2018.07.007&partnerID=40&md5=1c6a547ca8cff51e1d8151180dfa36fb","Accurate time-series forecasting is vital for numerous areas of application such as transportation, energy, finance, economics, etc. However, while modern techniques are able to explore large sets of temporal data to build forecasting models, they typically neglect valuable information that is often available under the form of unstructured text. Although this data is in a radically different format, it often contains contextual explanations for many of the patterns that are observed in the temporal data. In this paper, we propose two deep learning architectures that leverage word embeddings, convolutional layers and attention mechanisms for combining text information with time-series data. We apply these approaches for the problem of taxi demand forecasting in event areas. Using publicly available taxi data from New York, we empirically show that by fusing these two complementary cross-modal sources of information, the proposed models are able to significantly reduce the error in the forecasts. © 2018 Elsevier B.V.","Cross modality learning; Data fusion; Deep learning; Special events; Taxi demand; Textual data; Time series forecasting; Urban mobility"
"Distributed decision fusion under nonideal communication channels with adaptive topology","2019","Information Fusion","10.1016/j.inffus.2018.02.001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85043351393&doi=10.1016%2fj.inffus.2018.02.001&partnerID=40&md5=02a2dc1761382424bc92146a98238811","Multi-sensor decision fusion has attracted some attention in information fusion field, meanwhile, the distributed target detection has been a well-studied topic in the multi-sensor detection theory. This paper investigates the increase in detection reliability that an adaptive network (with adaptive topologies and nonideal channels and decision fusion rules) can provide, compared with a fixed topology network. We consider a network, consisting of K-local uncertainty sensors and a Fusion Center (FC) tasked with detecting the presence or absence of a target in the Region of Interest (ROI). Sensors transmit binary modulated local decisions over nonideal channels modeled as Gaussian noise or fading channels. Assuming that the signal intensity emitted by a target follows the isotropic attenuation power model, we consider three classes of network topology architectures: (1) serial topology; (2) tree topology, and (3) parallel topology. Under the Neyman–Pearson (NP) criterion, we derive the optimal threshold fusion rule with adaptive topology to minimize the error probability. Extensive simulations are conducted to validate the correctness and effectiveness of the proposed algorithms. © 2018 Elsevier B.V.","Decision fusion; Distributed detection; Neyman–Pearson criterion; Nonideal channels; Topology architecture"
"Exploring the synergetic effects of sample types on the performance of ensembles for credit risk and corporate bankruptcy prediction","2019","Information Fusion","10.1016/j.inffus.2018.07.004","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050882351&doi=10.1016%2fj.inffus.2018.07.004&partnerID=40&md5=0405b799a2b83fb8d4454d3b45611031","Credit risk and corporate bankruptcy prediction has widely been studied as a binary classification problem using both advanced statistical and machine learning models. Ensembles of classifiers have demonstrated their effectiveness for various applications in finance using data sets that are often characterized by imperfections such as irrelevant features, skewed classes, data set shift, and missing and noisy data. However, there are other corruptions in the data that might hinder the prediction performance mainly on the default or bankrupt (positive) cases, where the misclassification costs are typically much higher than those associated to the non-default or non-bankrupt (negative) class. Here we characterize the complexity of 14 real-life financial databases based on the different types of positive samples. The objective is to gain some insight into the potential links between the performance of classifier ensembles (BAGGING, AdaBoost, random subspace, DECORATE, rotation forest, random forest, and stochastic gradient boosting) and the positive sample types. Experimental results reveal that the performance of the ensembles indeed depends on the prevalent type of positive samples. © 2018 Elsevier B.V.","Bankruptcy; Classifier ensemble; Credit risk; Imbalance; Types of samples"
"Linguistic intuitionistic fuzzy preference relations and their application to multi-criteria decision making","2019","Information Fusion","10.1016/j.inffus.2018.05.001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047938865&doi=10.1016%2fj.inffus.2018.05.001&partnerID=40&md5=ce4b7159b36a2f2358b51f9507bbaf22","Linguistic intuitionistic fuzzy sets can be regarded as a qualitative form of intuitionistic fuzzy sets. This type of fuzzy sets uses a linguistic membership degree and a linguistic non-membership degree to represent the qualitative preferred and non-preferred judgments of decision makers. Preference relation is a useful and efficient tool for decision making that only requires the decision makers to compare two objects at one time. Taking the advantages of linguistic intuitionistic fuzzy sets and preference relations, this paper introduces linguistic intuitionistic fuzzy preference relations (LIFPRs) and studies their application to decision making. To ensure the ranking of objects reasonably, an additive consistency concept is introduced, and several of its desirable properties are discussed. To cope with inconsistent and incomplete LIFPRs, programming model-based methods to derive additively consistent LIFPRs and determine missing values are constructed, respectively. Subsequently, an approach to multi-criteria decision making with LIFPRs is offered, and the application of the new approach is illustrated by using a decision-making problem about evaluating mobile phones. © 2018","Additive consistency; Linguistic intuitionistic fuzzy preference relation; Multi-criteria decision making; Programming model"
"An evolutionary approach to build ensembles of multi-label classifiers","2019","Information Fusion","10.1016/j.inffus.2018.11.013","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061448344&doi=10.1016%2fj.inffus.2018.11.013&partnerID=40&md5=2a6b563b538c4c0431d0f9cde9306cc9","In recent years, the multi-label classification task has gained the attention of the scientific community given its ability to solve problems where each of the instances of the dataset may be associated with several class labels at the same time instead of just one. The main problems to deal with in multi-label classification are the imbalance, the relationships among the labels, and the high complexity of the output space. A large number of methods for multi-label classification has been proposed, but although they aimed to deal with one or many of these problems, most of them did not take into account these characteristics of the data in their building phase. In this paper we present an evolutionary algorithm for automatic generation of ensembles of multi-label classifiers by tackling the three previously mentioned problems, called Evolutionary Multi-label Ensemble (EME). Each multi-label classifier is focused on a small subset of the labels, still considering the relationships among them but avoiding the high complexity of the output space. Further, the algorithm automatically designs the ensemble evaluating both its predictive performance and the number of times that each label appears in the ensemble, so that in imbalanced datasets infrequent labels are not ignored. For this purpose, we also proposed a novel mutation operator that considers the relationship among labels, looking for individuals where the labels are more related. EME was compared to other state-of-the-art algorithms for multi-label classification over a set of fourteen multi-label datasets and using five evaluation measures. The experimental study was carried out in two parts, first comparing EME to classic multi-label classification methods, and second comparing EME to other ensemble-based methods in multi-label classification. EME performed significantly better than the rest of classic methods in three out of five evaluation measures. On the other hand, EME performed the best in one measure in the second experiment and it was the only one that did not perform significantly worse than the control algorithm in any measure. These results showed that EME achieved a better and more consistent performance than the rest of the state-of-the-art methods in MLC. © 2018 Elsevier B.V.","Ensemble; Evolutionary algorithm; Multi-label classification"
"Stereo and ToF data fusion by learning from synthetic data","2019","Information Fusion","10.1016/j.inffus.2018.11.006","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061060679&doi=10.1016%2fj.inffus.2018.11.006&partnerID=40&md5=582f0810d322ca2978618fefce888988","Time-of-Flight (ToF) sensors and stereo vision systems are both capable of acquiring depth information but they have complementary characteristics and issues. A more accurate representation of the scene geometry can be obtained by fusing the two depth sources. In this paper we present a novel framework for data fusion where the contribution of the two depth sources is controlled by confidence measures that are jointly estimated using a Convolutional Neural Network. The two depth sources are fused enforcing the local consistency of depth data, taking into account the estimated confidence information. The deep network is trained using a synthetic dataset and we show how the classifier is able to generalize to different data, obtaining reliable estimations not only on synthetic data but also on real world scenes. Experimental results show that the proposed approach increases the accuracy of the depth estimation on both synthetic and real data and that it is able to outperform state-of-the-art methods. © 2018 Elsevier B.V.","Deep learning; Sensor fusion; Stereo; Time-of-Flight"
"Graph kernel based link prediction for signed social networks","2019","Information Fusion","10.1016/j.inffus.2018.04.004","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046646763&doi=10.1016%2fj.inffus.2018.04.004&partnerID=40&md5=9fcf30a290b817693f56f39c3d508bd4","By revealing potential relationships between users, link prediction has long been considered as a fundamental research issue in singed social networks. The key of link prediction is to measure the similarity between users. Existing works use connections between target users or their common neighbors to measure user similarity. Rich information available for link prediction is missing since use similarity is widely influenced by many users via social connections. We therefore propose a novel graph kernel based link prediction method, which predicts links by comparing user similarity via signed social network's structural information: we first generate a set of subgraphs with different strength of social relations for each user, then calculate the graph kernel similarities between subgraphs, in which Bhattacharyya kernel is used to measure the similarity of the k-dimensional Gaussian distributions related to each k-order Krylov subspace generated for each subgraph, and finally train SVM classifier with user similarity information to predict links. Experiments held on real application datasets show that our proposed method has good link prediction performances on both positive and negative link prediction. Our method has significantly higher link prediction accuracy and F1-score than existing works. © 2018 Elsevier B.V.","Graph kernel; Link prediction; Sign prediction; Signed social network"
"Utility-preserving privacy protection of nominal data sets via semantic rank swapping","2019","Information Fusion","10.1016/j.inffus.2018.02.008","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058371333&doi=10.1016%2fj.inffus.2018.02.008&partnerID=40&md5=a1be13dbf8e2ff445ca33427c15d6bfc","Personal data are of great interest for research but, at the same time, they pose a serious privacy risk. Therefore, appropriate data protection measures should be undertaken by the data controller before making personal data available for secondary use. Also, such data protection should be done in a way that data are still useful for analysis. In the last years, a plethora of data protection mechanisms have been proposed. Among them, rank swapping is considered one of the best with respect to disclosure risk minimization and data utility preservation. Because rank swapping is based on sorting input data to swap values that are close to each other, in principle, it is a method restricted to numerical and ordinal categorical data. However, a significant amount of personal data currently compiled and used in data analysis are nominal, and their utility depends on the semantics they convey. To properly cope with this type of data, in this paper, we present rank swapping methods capable of protecting nominal data from a semantic perspective. Specifically, by exploiting ontologies, our methods are able to protect nominal data while properly preserving their semantics and, thus, their analytical utility. For that, we provide a suitable binary relation to semantically sort nominal data. Our proposal is capable of managing both independent individual attributes and non-independent multivariate data sets, being the latter especially relevant for data analysis. Empirical experiments carried on real clinical records and using a standard medical ontology show that our methods are able to preserve the semantic features of nominal data significantly better than standard permutation mechanisms. © 2018","Nominal data; Ontologies; Rank swapping; Semantics"
"Confidence factor weighted Gaussian function induced parallel fuzzy rank-level fusion for inference and its application to face recognition","2019","Information Fusion","10.1016/j.inffus.2018.07.005","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050810081&doi=10.1016%2fj.inffus.2018.07.005&partnerID=40&md5=a21f2c21e9b2a23d373e97cf75e796a1","This paper proposes a novel approach for inference using fuzzy rank-level fusion and explores it application to face recognition using multiple biometric representations. Multiple representations of single biometric (trait) aim to increase the reliability or acceptance of a biometric system, as it exploits the underlying essential characteristics provided by different sensors. In this paper, we propose a new scheme for generating fuzzy ranks induced by a Gaussian function based on the confidence of a classifier. In contrast to the conventional ranking, this fuzzy ranking reflects some associations among the outputs (confidence factors) of a classifier. These fuzzy ranks, yielded by multiple representations of a face image, are fused weighted by the corresponding confidence factors of the classifier to generate the final ranks while recognizing a face. In many real-world applications, where multiple traits of a person are unavailable, the proposed method is highly effective. However, it can easily be extended to multimodal biometric systems utilizing multiple classifiers. The experimental results using different feature vectors of a face image employing different classifiers show that the proposed method can significantly improve recognition accuracy as compared to those from individual feature vectors and as well as some commonly used rank-level fusion methods. © 2018 Elsevier B.V.","Biometric identification system; Face recognition; Fuzzy ranks; Rank-level fusion"
"Health risk assessment and decision-making for patient monitoring and decision-support using Wireless Body Sensor Networks","2019","Information Fusion","10.1016/j.inffus.2018.06.008","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049886723&doi=10.1016%2fj.inffus.2018.06.008&partnerID=40&md5=fbb48c2e41c7eda36b685dde54453f55","This paper proposes a generalized multi-sensor fusion approach and a health risk assessment and decision-making (Health-RAD) algorithm for continuous and remote patient monitoring purposes using a Wireless Body Sensor Network (WBSN). Health-RAD determines the patient's health condition severity level routinely and each time a critical issue is detected based on vital signs scores. Hence, a continuous health assessment and a monitoring of the improvement or the deterioration of the state of the patient is ensured. The severity level is represented by a risk variable whose values range between 0 and 1. The higher the risk value, the more critical the patient's health condition is and the more it requires medical attention. Moreover, we calculate the score of a vital sign using its past and current value, thus assessing its status based on its evolution during a period of time and not only on sudden deviations. We propose a generalized multi-sensor data fusion approach regardless of the number of monitored vital signs. The latter is employed by Health-RAD to find the severity level of the patient's health condition based on his/her vital signs scores. It is based on a fuzzy inference system (FIS) and early warning score systems (EWS). This approach is tested with a previously proposed energy-efficient data collection approach, thus forming a complete framework. The proposed approach is evaluated on real healthcare datasets and the results are compared with another approach from the literature in terms of data reduction, energy consumption, risk assessment of vital signs, the patient's health risk level determination and accuracy. The results show that both approaches have coherently assessed the health condition of different Intensive Care Unit (ICU) patients. Yet, our proposed approach overcomes the other approach in terms of energy consumption (around 86% less energy consumption) and data reduction (around 70% for sensing and more than 90% for transmission). Additionally, contrary to our proposed framework, the approach taken from the literature requires an offline model building and depends on available patient datasets. © 2018","Decision-making; EWS; Fuzzy theory; Multi-sensor data fusion; Patient's health risk level; WBSN"
"Homogeneous functionals and Bayesian data fusion with unknown correlation","2019","Information Fusion","10.1016/j.inffus.2018.02.002","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85043290998&doi=10.1016%2fj.inffus.2018.02.002&partnerID=40&md5=79250370c509ad51f6975c7a0b7e1dea","Information or data fusion concerns the aggregation, or combination, of probability measures. For example, in machine learning, statistics and signal processing, one may seek to ‘combine’ posterior distributions, [e.g. 1) Bayes classifiers or 2) posteriors over target states etc], arising from distinct but not necessarily independent sources. For example, sources might include partially disjoint trainers, or spatially distinct sensors correlated via state dependent measurements, etc. Data fusion is common in risk analysis where one is broadly interested in pooling expert opinions described by probability measures, and where it is often hard to assess and account for correlation among experts. The contribution of this work is the introduction of a broad class of data fusion rules that seek the combination of two (or more) probability distributions in the presence of non-zero, but unknown, correlation. We introduce rules that are improved in the sense that they are ‘closer’ to the true Bayesian result that would be computed if one could exploit knowledge of the correlation between the input distributions. We introduce these rules under the common algorithmic constraint of avoiding the so-called ‘double-counting’ of correlated information. The general framework proposed is based on homogeneous functionals. We examine the fusion performance and computational properties when using these functionals. We also consider distributed data fusion on (possibly) time-varying and incomplete network topologies and related convergence properties. © 2018","Consensus; Conservative estimators; Data fusion; Distributed data fusion"
"Cross-modality interactive attention network for multispectral pedestrian detection","2019","Information Fusion","10.1016/j.inffus.2018.09.015","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054752251&doi=10.1016%2fj.inffus.2018.09.015&partnerID=40&md5=f506fd3f126f88cda2729125f40cce23","Multispectral pedestrian detection is an emerging solution with great promise in many around-the-clock applications, such as automotive driving and security surveillance. To exploit the complementary nature and remedy contradictory appearance between modalities, in this paper, we propose a novel cross-modality interactive attention network that takes full advantage of the interactive properties of multispectral input sources. Specifically, we first utilize the color (RGB) and thermal streams to build up two detached feature hierarchy for each modality, then by taking the global features, correlations between two modalities are encoded in the attention module. Next, the channel responses of halfway feature maps are recalibrated adaptively for subsequent fusion operation. Our architecture is constructed in the multi-scale format to better deal with different scales of pedestrians, and the whole network is trained in an end-to-end way. The proposed method is extensively evaluated on the challenging KAIST multispectral pedestrian dataset and achieves state-of-the-art performance with high efficiency. © 2018","Cross-modality attention; Deep neural networks; Modality fusion; Pedestrian detection"
"Data fusion and machine learning for industrial prognosis: Trends and perspectives towards Industry 4.0","2019","Information Fusion","10.1016/j.inffus.2018.10.005","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055203735&doi=10.1016%2fj.inffus.2018.10.005&partnerID=40&md5=7974a4792473c362841d0c27b24f804a","The so-called “smartization” of manufacturing industries has been conceived as the fourth industrial revolution or Industry 4.0, a paradigm shift propelled by the upsurge and progressive maturity of new Information and Communication Technologies (ICT) applied to industrial processes and products. From a data science perspective, this paradigm shift allows extracting relevant knowledge from monitored assets through the adoption of intelligent monitoring and data fusion strategies, as well as by the application of machine learning and optimization methods. One of the main goals of data science in this context is to effectively predict abnormal behaviors in industrial machinery, tools and processes so as to anticipate critical events and damage, eventually causing important economical losses and safety issues. In this context, data-driven prognosis is gradually gaining attention in different industrial sectors. This paper provides a comprehensive survey of the recent developments in data fusion and machine learning for industrial prognosis, placing an emphasis on the identification of research trends, niches of opportunity and unexplored challenges. To this end, a principled categorization of the utilized feature extraction techniques and machine learning methods will be provided on the basis of its intended purpose: analyze what caused the failure (descriptive), determine when the monitored asset will fail (predictive) or decide what to do so as to minimize its impact on the industry at hand (prescriptive). This threefold analysis, along with a discussion on its hardware and software implications, intends to serve as a stepping stone for future researchers and practitioners to join the community investigating on this vibrant field. © 2018 Elsevier B.V.","Data fusion; Data-driven prognosis; Industry 4.0; Machine learning"
"Multibiometric fusion strategy and its applications: A review","2019","Information Fusion","10.1016/j.inffus.2018.11.018","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061389196&doi=10.1016%2fj.inffus.2018.11.018&partnerID=40&md5=ad77cd4e86feda8c747b419d59d8c42e","The unimodal biometric based system faced several inherent problems like lack of uniqueness, intra-class variation, non-universality, noisy data (presence of dirt on the sensor), restricted degree of freedom, unacceptable error rate, failure-to-enroll and spoofing attack. Multibiometric is one of the best choices to overcome these problems. Multibiometric fusion plays an important role to enhance the overall performance of the system, in which two or more individual biometric are combined together to form a better performance system. The proper use of fusion strategy is very important in the multibiometric system because it can affect the overall performance and accuracy level of the systems. In designing a multibiometric based system we can use various methods and fusion strategies to combine information from multiple sources. This paper is an in-depth study on multibiometric (multimodal, multialgorithm, multi-sample, multi-sensor and multi-instance) fusion strategy and its different applications. In addition, this paper also discusses the different methodology used in a fusion process (Sensor, Feature, Score, Decision, Rank) of multibiometric systems from last three decades and examines the methods used, to explore their successes and failure. © 2018 Elsevier B.V.","Multibiometric; Multibiometric-fusion; Unimodal7"
"Fusion of multispectral data through illumination-aware deep neural networks for pedestrian detection","2019","Information Fusion","10.1016/j.inffus.2018.11.017","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061031387&doi=10.1016%2fj.inffus.2018.11.017&partnerID=40&md5=3632723ff6450fb3bbd3345947e7800c","Multispectral pedestrian detection has received extensive attention in recent years as a promising solution to facilitate robust human target detection for around-the-clock applications (e.g., security surveillance and autonomous driving). In this paper, we demonstrate illumination information encoded in multispectral images can be utilized to boost the performance of pedestrian detection significantly. A novel illumination-aware weighting mechanism is present to depict illumination condition of a scene accurately. Such illumination information is incorporated into two-stream deep convolutional neural networks to learn multispectral human-related features under different illumination conditions (daytime and nighttime). Moreover, we utilized illumination information together with multispectral data to generate more accurate semantic segmentation which is used to supervise the training of pedestrian detector. Putting all of the pieces together, we present an effective framework for multispectral pedestrian detection based on multi-task learning of illumination-aware pedestrian detection and semantic segmentation. Our proposed method is trained end-to-end using a well-designed multi-task loss function and outperforms state-of-the-art approaches on KAIST multispectral pedestrian dataset. © 2018 Elsevier B.V.","Deep neural networks; Illumination-aware; Multispectral fusion; Pedestrian detection; Semantic segmentation"
"Emotion-relevant activity recognition based on smart cushion using multi-sensor fusion","2019","Information Fusion","10.1016/j.inffus.2018.08.001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053076479&doi=10.1016%2fj.inffus.2018.08.001&partnerID=40&md5=f656829147d5d332e43f402fd1541545","More and more common activities are leading to a sedentary lifestyle forcing us to sit several hours every day. In-seat actions contain significant hidden information, which not only reflects the current physical health status but also can report mental states. Considering this, we design a system, based on body-worn inertial sensors (attached to user's wrists) combined with a pressure detection module (deployed on the seat), to recognise and monitor in-seat activities through sensor- and feature-level fusion techniques. Specifically, we focus on four common basic emotion-relevant activities (i.e. interest-, frustration-, sadness- and happiness-related). Our results show that the proposed method, by fusion of time- and frequency-domain feature sets from all the different deployed sensors, can achieve high accuracy in recognising the considered activities. © 2018","Activity recognition; Body language; Multi-sensor fusion; Sequence feature; Smart cushion"
"Multi-view learning for visual violence recognition with maximum entropy discrimination and deep features","2019","Information Fusion","10.1016/j.inffus.2018.10.004","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055022117&doi=10.1016%2fj.inffus.2018.10.004&partnerID=40&md5=b1b96e90cbc89212c98e7b974cbb459c","Harmful information full of violence, whose transmission is difficult to control, is one of the negative effects that the Internet brings to us today. Such corrosive information in the network environment infiltrates the mental health of adolescents. Many young people who lack judgment tend to imitate violent behaviors that are propagated on the network. This study applies multi-view learning to violent behavior recognition of still images, and can be useful for the research of network image or video information monitoring and filtering. In this paper, to start with, we construct a violence image recognition database, which contains 5974 violence images and 11,516 non-violence images. From this database, different datasets can be constructed for model and algorithm evaluations. Then we propose a multi-view maximum entropy discriminant (MVMED+) model for learning with different numbers of views. It can combine various features of the images and thus classify the images with the complementary information between the views. For efficient optimization, we further derive a sequential minimal optimization algorithm to train the model. In the experiments, we use handcrafted features and deep learning features to validate the effectiveness of the proposed model, respectively. As a useful byproduct, large performance improvements on visual violence recognition are further observed with deep learning features. © 2018 Elsevier B.V.","Maximum entropy discrimination; Multi-view learning; Sequential minimal optimization; Violence image recognition"
"Data fusion and multiple classifier systems for human activity detection and health monitoring: Review and open research directions","2019","Information Fusion","10.1016/j.inffus.2018.06.002","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048959618&doi=10.1016%2fj.inffus.2018.06.002&partnerID=40&md5=6a1a5dd79c9c9bf1e73e4a7bf8a51227","Activity detection and classification using different sensor modalities have emerged as revolutionary technology for real-time and autonomous monitoring in behaviour analysis, ambient assisted living, activity of daily living (ADL), elderly care, rehabilitations, entertainments and surveillance in smart home environments. Wearable devices, smart-phones and ambient environments devices are equipped with variety of sensors such as accelerometers, gyroscopes, magnetometer, heart rate, pressure and wearable camera for activity detection and monitoring. These sensors are pre-processed and different feature sets such as time domain, frequency domain, wavelet transform are extracted and transform using machine learning algorithm for human activity classification and monitoring. Recently, deep learning algorithms for automatic feature representation have also been proposed to lessen the burden of reliance on handcrafted features and to increase performance accuracy. Initially, one set of sensor data, features or classifiers were used for activity recognition applications. However, there are new trends on the implementation of fusion strategies to combine sensors data, features and classifiers to provide diversity, offer higher generalization, and tackle challenging issues. For instances, combination of inertial sensors provide mechanism to differentiate activity of similar patterns and accurate posture identification while other multimodal sensor data are used for energy expenditure estimations, object localizations in smart homes and health status monitoring. Hence, the focus of this review is to provide in-depth and comprehensive analysis of data fusion and multiple classifier systems techniques for human activity recognition with emphasis on mobile and wearable devices. First, data fusion methods and modalities were presented and also feature fusion, including deep learning fusion for human activity recognition were critically analysed, and their applications, strengths and issues were identified. Furthermore, the review presents different multiple classifier system design and fusion methods that were recently proposed in literature. Finally, open research problems that require further research and improvements are identified and discussed. © 2018","Activity detection; Data fusion; Deep learning; Health monitoring; Multimodal sensors; Multiple classifier systems"
"Characterizing online health and wellness information consumption: A study","2019","Information Fusion","10.1016/j.inffus.2018.04.005","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046857929&doi=10.1016%2fj.inffus.2018.04.005&partnerID=40&md5=49aca8d732823407e3f9436f42f1a743","To seek answers to health queries, we often find ourselves on a quest to assimilate information from varied online sources. This information search and fusion from different sources elicits user preferences, which can be driven by demographics, context, and socio-economic factors. To that end, we study these factors as part of health-information seeking behavior of users on a large health and wellness-based knowledge sharing online platform. We begin by identifying the topical interests of users from different content consumption sources. Using these topical preferences, we explore information consumption and health-seeking behavior across three contextual dimensions: user-based demographic attributes, time-related features, and community-based socioeconomic factors. We then study how these context signals can be used to explain specific user health topic preferences. Our findings suggest that linking demographic features to user profiles is more effective in explaining health preferences than other features. Our work demonstrates the value of using contextual factors to characterize and understand the content consumption of users seeking health and wellness information online. © 2018","Content consumption; Factorization models; Online health seeker; User behavioral analysis"
"Information fusion in rough set theory : An overview","2019","Information Fusion","10.1016/j.inffus.2018.08.007","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053423383&doi=10.1016%2fj.inffus.2018.08.007&partnerID=40&md5=338fec27b6fb612b7d1f1238e4af6c30","Rough set theory is an efficient tool for dealing with inexact and uncertain information. Numerous studies have focused on rough set theory and associated methodologies, and in recent decades, various models and algorithms have been proposed. To clarify the application of information fusion in rough set theory, this paper presents an overview of existing information fusion approaches and methods for multi-source, multi-modality, multi-scale, and multi-view information systems from the perspective of objects, attributes, rough approximations, attribute reduction, and decision making. We provide a survey of recent applications of these theories and methods in various fields, and identify some potential challenges that require further research. © 2018 Elsevier B.V.","Information fusion; Multi-granulation; Multi-modality; Multi-scale; Multi-source; Rough set"
"Deep learning analysis of mobile physiological, environmental and location sensor data for emotion detection","2019","Information Fusion","10.1016/j.inffus.2018.09.001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054071151&doi=10.1016%2fj.inffus.2018.09.001&partnerID=40&md5=93acded0ef3bb87db4e62e27f7d04492","The detection and monitoring of emotions are important in various applications, e.g., to enable naturalistic and personalised human-robot interaction. Emotion detection often require modelling of various data inputs from multiple modalities, including physiological signals (e.g., EEG and GSR), environmental data (e.g., audio and weather), videos (e.g., for capturing facial expressions and gestures) and more recently motion and location data. Many traditional machine learning algorithms have been utilised to capture the diversity of multimodal data at the sensors and features levels for human emotion classification. While the feature engineering processes often embedded in these algorithms are beneficial for emotion modelling, they inherit some critical limitations which may hinder the development of reliable and accurate models. In this work, we adopt a deep learning approach for emotion classification through an iterative process by adding and removing large number of sensor signals from different modalities. Our dataset was collected in a real-world study from smart-phones and wearable devices. It merges local interaction of three sensor modalities: on-body, environmental and location into global model that represents signal dynamics along with the temporal relationships of each modality. Our approach employs a series of learning algorithms including a hybrid approach using Convolutional Neural Network and Long Short-term Memory Recurrent Neural Network (CNN-LSTM) on the raw sensor data, eliminating the needs for manual feature extraction and engineering. The results show that the adoption of deep-learning approaches is effective in human emotion classification when large number of sensors input is utilised (average accuracy 95% and F-Measure=%95) and the hybrid models outperform traditional fully connected deep neural network (average accuracy 73% and F-Measure=73%). Furthermore, the hybrid models outperform previously developed Ensemble algorithms that utilise feature engineering to train the model average accuracy 83% and F-Measure=82%) © 2018 The Authors","Convoltutional neural network; Deep learning; Emotion recognition; Long short-term memory mobile sensing"
"Multimodal image registration using Laplacian commutators","2019","Information Fusion","10.1016/j.inffus.2018.09.009","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054171415&doi=10.1016%2fj.inffus.2018.09.009&partnerID=40&md5=7d562bfe00752d8f7ed349d7e8a80c22","The fusion and combination of images from multiple modalities is important in many applications. Typically, this process consists of the alignment of the images and the combination of the complementary information. In this work, we focused on the former part and propose a multimodal image distance measure based on the commutativity of graph Laplacians. The eigenvectors of the image graph Laplacian, and thus the graph Laplacian itself, capture the intrinsic structure of the image's modality. Using Laplacian commutativity as a criterion of image structure preservation, we adapt the problem of finding the closest commuting operators to multimodal image registration. Hence, by using the relation between simultaneous diagonalization and commutativity of matrices, we compare multimodal image structures by means of the commutativity of their graph Laplacians. In this way, we avoid spectrum reordering schemes or additional manifold alignment steps which are necessary to ensure the comparability of eigenspaces across modalities. We show on synthetic and real datasets that this approach is applicable to dense rigid and non-rigid image registration. Results demonstrated that the proposed measure is able to deal with very challenging multimodal datasets and compares favorably to normalized mutual information, a de facto similarity measure for multimodal image registration. © 2018 Elsevier B.V.","Image registration; Laplacian commutator; Simultaneous diagonalization; Spectral methods"
"Dynamic emotion modelling and anomaly detection in conversation based on emotional transition tensor","2019","Information Fusion","10.1016/j.inffus.2018.04.001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046730150&doi=10.1016%2fj.inffus.2018.04.001&partnerID=40&md5=23ef6dde461676fbb0fbe45fb8d33e66","Conversational data in social media contain a great deal of useful information, and conversation anomaly detection is an important research direction in the field of sentiment analysis. Each user has his or her own specific emotional characteristic, and by studying the distribution and sampling the users’ emotional transitions, we can simulate specific emotional transitions in the conversations. Anomaly detection in conversation data refers to detecting users’ abnormal opinions and sentiment patterns as well as special temporal aspects of such patterns. This paper proposes a hybrid model that combines the convolutional neural network long short-term memory (CNN-LSTM) with a Markov chain Monte Carlo (MCMC) method to identify users’ emotions, sample users’ emotional transition and detect anomalies according to the transition tensor. The emotional transition sampling is implemented by improving the MCMC algorithm and the anomalies are detected by calculating the similarity between the normal transition tensor and the current transition tensor of the user. The experiment was carried on four corpora, and the results show that emotions can be well sampled to conform to user's characteristics and anomaly can be detected by the proposed method. The model proposed can be used in intelligent conversation systems, such as simulating the emotional transition and detecting the abnormal emotions. © 2018 Elsevier B.V.","Anomaly detection; Emotional transition; Hybrid deep learning model; Social conversation"
"Distributed joint sensor registration and target tracking via sensor network","2019","Information Fusion","10.1016/j.inffus.2018.05.003","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054008754&doi=10.1016%2fj.inffus.2018.05.003&partnerID=40&md5=f8daca7b3f9eafef5e62cdc6e017da93","This paper deals with distributed registration of a sensor network for target tracking in the presence of false and/or missed measurements. Each sensor acquires measurements of the target position in local coordinates, having no knowledge about the relative positions (referred to as drift parameters) of its neighboring nodes. A distributed Bernoulli filter is run over the network to compute in each node a local posterior target density. Then a suitable cost function, expressing the discrepancy between the local posteriors in terms of averaged Kullback–Leibler divergence, is minimized with respect to the drift parameters for sensor registration purposes. In this way, a computationally feasible optimization approach for joint sensor registration and target tracking is devised. Finally, the effectiveness of the proposed approach is demonstrated through simulation experiments on both tree networks and networks with cycles, as well as with both linear and nonlinear sensors. © 2018 Elsevier B.V.","Bernoulli filtering; Distributed detection and tracking; Multisensor fusion; Random finite sets; Sensor networks; Sensor registration"
"An iterative boosting-based ensemble for streaming data classification","2019","Information Fusion","10.1016/j.inffus.2018.01.003","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041473184&doi=10.1016%2fj.inffus.2018.01.003&partnerID=40&md5=e22a4b5866f6eb2830d088101d4f7afa","Among the many issues related to data stream applications, those involved in predictive tasks such as classification and regression, play a significant role in Machine Learning (ML). The so-called ensemble-based approaches have characteristics that can be appealing to data stream applications, such as easy updating and high flexibility. In spite of that, some of the current approaches consider unsuitable ways of updating the ensemble along with the continuous stream processing, such as growing it indefinitely or deleting all its base learners when trying to overcome a concept drift. Such inadequate actions interfere with two inherent characteristics of data streams namely, its possible infinite length and its need for prompt responses. In this paper, a new ensemble-based algorithm, suitable for classification tasks, is proposed. It relies on applying boosting to new batches of data aiming at maintaining the ensemble by adding a certain number of base learners, which is established as a function of the current ensemble accuracy rate. The updating mechanism enhances the model flexibility, allowing the ensemble to gather knowledge fast to quickly overcome high error rates, due to concept drift, while maintaining satisfactory results by slowing down the updating rate in stable concepts. Results comparing the proposed ensemble-based algorithm against eight other ensembles found in the literature show that the proposed algorithm is very competitive when dealing with data stream classification. © 2018 Elsevier B.V.","Boosting algorithms; Data stream classification; Ensemble learning; Incremental learning"
"Non-linear adaptive closed-loop control system for improved efficiency in IoT-blockchain management","2019","Information Fusion","10.1016/j.inffus.2018.12.007","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061176639&doi=10.1016%2fj.inffus.2018.12.007&partnerID=40&md5=1260fbfac59578e124ee037d4b7207e1","IoT network generates a large amount of data. This means that the monitoring and control of these networks and the transfer of packets from the IoT network to the server can cause communications to collapse. On the other hand, due to the large volume of data stored in the databases the monitoring of the IoT network needs very powerful servers to have a high degree of efficiency. This paper presents a novel adaptive closed-loop control system and speed up searches model to improve the monitor and control efficiency in IoT networks, specially those which are based in blockchain. The non linear control model under consideration includes a new way to evaluate the optimal number of blocks that should be at the queue of the miners’ network in order to make the process efficient through the use of queuing theory. Also, a new system to speed up searches is presented by using hashmaps, which makes the monitoring process faster, reliable and efficient. The efficiency of the presented approach is illustrated by a numerical case study. © 2019 Elsevier B.V.","Adaptive closed-loop; Algorithm design and analysis; Control system; IoT; Non-linear control; Queuing theory"
"Machine learning algorithms for wireless sensor networks: A survey","2019","Information Fusion","10.1016/j.inffus.2018.09.013","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054085311&doi=10.1016%2fj.inffus.2018.09.013&partnerID=40&md5=04fc87559041968e5ec38655de2c915c","Wireless sensor network (WSN) is one of the most promising technologies for some real-time applications because of its size, cost-effective and easily deployable nature. Due to some external or internal factors, WSN may change dynamically and therefore it requires depreciating dispensable redesign of the network. The traditional WSN approaches have been explicitly programmed which make the networks hard to respond dynamically. To overcome such scenarios, machine learning (ML) techniques can be applied to react accordingly. ML is the process of self-learning from the experiences and acts without human intervention or re-program. The survey of the ML techniques for WSNs is presented in [1], covering period of 2002–2013. In this survey, we present various ML-based algorithms for WSNs with their advantages, drawbacks, and parameters effecting the network lifetime, covering the period from 2014–March 2018. In addition, we also discuss ML algorithms for synchronization, congestion control, mobile sink scheduling and energy harvesting. Finally, we present a statistical analysis of the survey, the reasons for selection of a particular ML techniques to address an issue in WSNs followed by some discussion on the open issues. © 2018 Elsevier B.V.","Data aggregation; Energy efficiency; Machine learning; Network lifetime; Wireless sensor networks"
"Generative multi-view and multi-feature learning for classification","2019","Information Fusion","10.1016/j.inffus.2018.02.005","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85043278807&doi=10.1016%2fj.inffus.2018.02.005&partnerID=40&md5=8281e26d6278810137e51dc467311055","Multi-view based classification has attracted much attention in recent years. In general, an object can be represented with various views or modalities, and the exploitation of correlation across different views would contribute to improving the classification performance. However, each view can also be described with multiple features and this types of data is called multi-view and multi-feature data. Different from many existing multi-view methods which only model multiple views but ignore intrinsic information among the various features in each view, a generative bayesian model is proposed in this paper to not only jointly take the features and views into account, but also learn a discriminant representation across distinctive categories. A latent variable corresponding to each feature in each view is assumed and the raw feature is a projection of the latent variable from a more discriminant space. Particularly, the extracted variables in each view belonging to the same class are encouraged to follow the same gaussian distribution and those belonging to different classes are conducted to follow different distributions, greatly exploiting the label information. To optimize the presented approach, the proposed method is transformed into a class-conditional model and an effective algorithm is designed to alternatively estimate the parameters and variables. The experimental results on the extensive synthetic and four real-world datasets illustrate the effectiveness and superiority of our method compared with the state-of-the-art. © 2018 Elsevier B.V.","Bayesian model; Classification; Generative model; Multi-feature; Multi-view(modal)"
"A novel image decomposition-based hybrid technique with super-resolution method for multi-focus image fusion","2019","Information Fusion","10.1016/j.inffus.2018.01.015","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041482951&doi=10.1016%2fj.inffus.2018.01.015&partnerID=40&md5=79485ac618226022a871fcc778aee432","Multi-focus image fusion combines two or more images which have different focus values of the same scene using fusion rules. The meaningful image is named all-in-focus image which is more informative and useful for visual perception. In this paper, a novel approach for multi-focus image fusion is proposed. The method is a hybrid method with super-resolution. Firstly, super-resolution method is applied to all source images to enhance information like contrast. Thus, low-resolution source images are converted to high-resolution source images. Secondly, due to decomposing these source images, Stationary Wavelet Transform (SWT) is implemented and images are divided into four sub-bands. These sub-bands are LL (low–low), LH (low–high), HL (high–low) and HH (high–high). LL is the approximation coefficient of source images and others are the detail coefficients of source images. For all these sub-bands, Principal Component Analysis (PCA) is implemented and maximum eigenvector of each sub-band of source images is selected separately to fuse images. Then, Inverse Stationary Wavelet Transform (ISWT) is used to reconstruct the fused sub-bands. Finally, to measure quality of the proposed method objectively, fused image is resized to original source image's size using interpolation based resizing method. To measure the success of method, different metrics without reference image and with reference image, are selected. Results show that the proposed method produce clear edges, good visual perception, good clarity and very few distortion. The proposed hybrid method is applied to produce better quality fused images. Results prove success of the approach in this area. Also visual and quantitative results are very impressive. © 2018 Elsevier B.V.","Image fusion; Interpolation; Multi-focus; PCA; Super-resolution; SWT"
"Deriving decision makers’ weights in group decision making: An overview of objective methods","2019","Information Fusion","10.1016/j.inffus.2018.11.009","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061009930&doi=10.1016%2fj.inffus.2018.11.009&partnerID=40&md5=7461d830194a1102cad242adadb628f6","In group decision making problems, it is almost impossible to have a homogeneous group of decision makers whose experiences, attitudes, knowledge are the same or similar. Therefore, it is required to determine the weights of decision makers to reflect their relative importance or contribution to the problem. Decision maker weights show the importance or reliability of decision makers in solving the particular problem. The studies on determining the weights of the decision makers are limited. Besides, there is no comprehensive literature review or survey related to the determination of decision makers’ weight among the limited numbers of studies. Therefore, in this study, the literature on deriving decision makers’ weights is reviewed to present the state-of-the-art in the group decision making environment. Subsequently, a new classification system is proposed. Objective methods for deriving decision makers’ weights are classified into five categories: Similarity-based approaches, index-based approaches, clustering-based approaches, integrated approaches, and other approaches. The literature review and analysis of the studies are conducted based on these categories; moreover, challenges and potential research directions are identified. According to the analysis of fifty-five papers, the interest in the topic increases dramatically after 2011. The highest percentage of the studies fell into the similarity-based approaches. © 2018 Elsevier B.V.","Decision makers’ weights; Group decision making; Literature survey; Objective weights"
"Seamless navigation and mapping using an INS/GNSS/grid-based SLAM semi-tightly coupled integration scheme","2019","Information Fusion","10.1016/j.inffus.2019.01.004","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061648392&doi=10.1016%2fj.inffus.2019.01.004&partnerID=40&md5=a21585da9c9c40e399b79ab48ca9bdc9","Mobile Mapping Systems (MMS) with Inertial Navigation System / Global Navigation Satellite System (INS/GNSS) and mapping sensors have been widely developed in recent years. However current systems and results are still prone to errors, especially in GNSS-denied or multipath environments. To provide robust and stable navigation information, particularly for mapping in long-term GNSS-denied environments, we propose a semi-tightly coupled integration scheme which integrates INS/GNSS with grid-based Simultaneous Localization and Mapping (SLAM). Although traditional SLAM using LiDAR can map the GNSS-denied environment efficiently, it is only in local localization. The proposed integration scheme is based on the Extended Kalman Filter (EKF) with motion constraints. In this scheme, a measurement model for grid-based SLAM is aided by the heading and velocity information. A special innovation of this scheme is the improved fusion of GNSS/INS with the use of grid-based SLAM serves like virtual odometer and virtual compass, thus gaining reliable measurements and error models to maintain good performance during INS-only mode. In addition, the initial values for example position and heading, are given to solve global localization and loop closure problems in SLAM. Finally, a smoothing and multi-resolution map strategy are applied offline to increase the robustness and performance of the proposed grid-based SLAM. Evaluation based on experimental data shows the significant improvement by the proposed semi-tightly coupled integration scheme with low-cost INS/GNSS and LiDAR, which is able to achieve 1–2 m’ accuracy in terms of positioning and mapping. An approximately 60% improvement was achieved during long-term GNSS-denied environments using the proposed integration scheme. © 2019","GNSS-denied environments; INS/GNSS; LiDAR; Mobile Mapping Systems; SLAM"
"Postpartum depression prediction through pregnancy data analysis for emotion-aware smart systems","2019","Information Fusion","10.1016/j.inffus.2018.07.001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050005561&doi=10.1016%2fj.inffus.2018.07.001&partnerID=40&md5=317574cc93c3577bd3837e2208a9a517","Emotion-aware computing represents an evolution in machine learning enabling systems and devices process to interpret emotional data to recognize human behavior changes. As emotion-aware smart systems evolve, there is an enormous potential for increasing the use of specialized devices that can anticipate life-threatening conditions facilitating an early response model for health complications. At the same time, applications developed for diagnostic and therapy services can support conditions recognition (as depression, for instance). Hence, this paper proposes an improved algorithm for emotion-aware smart systems, capable for predicting the risk of postpartum depression in women suffering from hypertensive disorders during pregnancy through biomedical and sociodemographic data analysis. Results show that ensemble classifiers represent a leading solution concerning predicting psychological disorders related to pregnancy. Merging novel technologies based on IoT, cloud computing, and big data analytics represent a considerable advance in monitoring complex diseases for emotion-aware computing, such as postpartum depression. © 2018","Cognitive computing; Emotion-aware smart systems; Information fusion; Maternal care quality improvement; Mental health solutions"
"Integrating heterogeneous sources for predicting question temporal anchors across Yahoo! Answers","2019","Information Fusion","10.1016/j.inffus.2018.10.006","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055179488&doi=10.1016%2fj.inffus.2018.10.006&partnerID=40&md5=a033701339ed522f3bba9ba48f5aeb7d","Modern Community Question Answering (CQA) web forums provide the possibility to browse their archives using question-like search queries as in Information Retrieval (IR) systems. Although these traditional IR methods have become very successful at fetching semantically related questions, they typically leave unconsidered their temporal relations. That is to say, a group of questions may be asked more often during specific recurring time lines despite being semantically unrelated. In fact, predicting temporal aspects would not only assist these platforms in widening the semantic diversity of their search results, but also in re-stating questions that need to refresh their answers and in producing more dynamic, especially temporally-anchored, displays. In this paper, we devised a new set of time-frame specific categories for CQA questions, which is obtained by fusing two distinct earlier taxonomies (i.e., [29] and [50]). These new categories are then utilized in a large crowd-sourcing based human annotation effort. Accordingly, we present a systematical analysis of its results in terms of complexity and degree of difficulty as it relates to the different question topics1 Incidentally, through a large number of experiments, we investigate the effectiveness of a wider variety of linguistic features compared to what has been done in previous works. We additionally mix evidence/features distilled directly and indirectly from questions by capitalizing on their related web search results. We finally investigate the impact and effectiveness of multi-view learning to boost a large variety of multi-class supervised learners by optimizing a latent layer build on top of two views: one composed of features harvested from questions, and the other from CQA meta data and evidence extracted from web resources (i.e., snippets and Internet archives). © 2018 Elsevier B.V.","Intelligent information retrieval; Multi-view learning; Natural language processing; Question classification; Transfer learning; Web mining"
"A social network based approach for consensus achievement in multiperson decision making","2019","Information Fusion","10.1016/j.inffus.2018.07.006","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050865605&doi=10.1016%2fj.inffus.2018.07.006&partnerID=40&md5=669a6c20748abdeb48a342663c67b982","Nowadays we are living the apogee of the Internet based technologies and consequently web 2.0 communities, where a large number of users interact in real time and share opinions and knowledge, is a generalized phenomenon. This type of social networks communities constitute a challenge scenario from the point of view of Group Decision Making approaches, because it involves a large number of agents coming from different backgrounds and/or with different level of knowledge and influence. In these type of scenarios there exists two main key issues that requires attention. Firstly, the large number of agents and their diverse background may lead to uncertainty and or inconsistency and so, it makes difficult to assess the quality of the information provided as well as to merge this information. Secondly, it is desirable, or even indispensable depending on the situation, to obtain a solution accepted by the majority of the members or at least to asses the existing level of agreement. In this contribution we address these two main issues by bringing together both decision Making approaches and opinion dynamics to develop a similarity-confidence-consistency based Social network that enables the agents to provide their opinions with the possibility of allocating uncertainty by means of the Intuitionistic fuzzy preference relations and at the same time interact with like-minded agents in order to achieve an agreement. © 2018 Elsevier B.V.","Consensus; E-democracy; Group decision making; Intuitionistic fuzzy preference relations; Opinion dynamics; Social network; Uncertainty"
"FusionGAN: A generative adversarial network for infrared and visible image fusion","2019","Information Fusion","10.1016/j.inffus.2018.09.004","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053147465&doi=10.1016%2fj.inffus.2018.09.004&partnerID=40&md5=e0713ed6e69bd8979031fe5db6da471a","Infrared images can distinguish targets from their backgrounds on the basis of difference in thermal radiation, which works well at all day/night time and under all weather conditions. By contrast, visible images can provide texture details with high spatial resolution and definition in a manner consistent with the human visual system. This paper proposes a novel method to fuse these two types of information using a generative adversarial network, termed as FusionGAN. Our method establishes an adversarial game between a generator and a discriminator, where the generator aims to generate a fused image with major infrared intensities together with additional visible gradients, and the discriminator aims to force the fused image to have more details existing in visible images. This enables that the final fused image simultaneously keeps the thermal radiation in an infrared image and the textures in a visible image. In addition, our FusionGAN is an end-to-end model, avoiding manually designing complicated activity level measurements and fusion rules as in traditional methods. Experiments on public datasets demonstrate the superiority of our strategy over state-of-the-arts, where our results look like sharpened infrared images with clear highlighted targets and abundant details. Moreover, we also generalize our FusionGAN to fuse images with different resolutions, say a low-resolution infrared image and a high-resolution visible image. Extensive results demonstrate that our strategy can generate clear and clean fused images which do not suffer from noise caused by upsampling of infrared information. © 2018 Elsevier B.V.","Deep learning; Generative adversarial network; Image fusion; Infrared image; Visible image"
"An efficient key distribution system for data fusion in V2X heterogeneous networks","2019","Information Fusion","10.1016/j.inffus.2019.02.002","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061636172&doi=10.1016%2fj.inffus.2019.02.002&partnerID=40&md5=54ed96fb5dafe57987e2c290cf5ef175","Data fusion in Vehicle-to-Everything (V2X) networks for different data types coming from different sources is the foundation for decision making in the smart vehicle driving systems. Different communication technologies have been combined to form a heterogeneous V2X network to support the data exchange. However, data fusion trust models are still designed for single use cases which cannot meet the general needs of Cooperative Intelligent Transport Systems (C-ITS). In this paper, we first define a data fusion trust architecture with different trust levels. Then, we propose an efficient and practical data fusion trust system for the multi-source and multi-formats of data exchange in the V2X heterogeneous networks. In particular, a location-based PKI system with acceleration brought by General Purpose Graphic Processing Unit (GPGPU) is presented for efficient key distribution with a high level of trust achieved. A performance evaluation is given to verify our data fusion trust system can meet the strict latency requirements in V2X networks. © 2019 Elsevier B.V.","Data fusion; Data processing; Data trust; Heterogeneous network; Security; V2X communication"
"Distributed fusion filter for multi-sensor systems with finite-step correlated noises","2019","Information Fusion","10.1016/j.inffus.2018.05.002","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048709389&doi=10.1016%2fj.inffus.2018.05.002&partnerID=40&md5=b65c3944dbb4da23d7e3a12a45d144d6","This paper addresses the distributed fusion filtering problem for multi-sensor systems with finite-step correlated noises. The process noise and observation noises of different sensors are finite-step auto- and cross-correlated, respectively. Based on the optimal local filtering algorithms that we presented before, the filtering error cross-covariance matrices between any two local filters are derived based on an innovation analysis approach. A distributed fusion filter is put forward by using matrix-weighted fusion estimation algorithm in the linear unbiased minimum variance sense. Finally, the proposed algorithms are extended to systems with random parameter matrices. Two simulation examples are given to show the effectiveness of the proposed algorithms. © 2018","Cross-covariance matrix; Distributed fusion filter; Finite-step correlated noises; Innovation analysis approach; Multi-sensor system; Random parameter matrix"
"Consensus vote models for detecting and filtering neutrality in sentiment analysis","2018","Information Fusion","10.1016/j.inffus.2018.03.007","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044926430&doi=10.1016%2fj.inffus.2018.03.007&partnerID=40&md5=772ab6c55485314c0e1225d8e59b0c69","Recently, interest in sentiment analysis has grown exponentially. Many studies have developed a wide variety of algorithms capable of classifying texts according to the sentiment conveyed in them. Such sentiment is usually expressed as positive, neutral or negative. However, neutral reviews are often ignored in many sentiment analysis problems because of their ambiguity and lack of information. In this paper, we propose to empower neutrality by characterizing the boundary between positive and negative reviews, with the goal of improving the model's performance. We apply different sentiment analysis methods to different corpora extracting their sentiment and, hence, detecting neutral reviews by consensus to filter them, i.e., taking into account different models based on weighted aggregation. We finally compare classification performance on single and aggregated models. The results clearly show that aggregation methods outperform single models in most cases, which led us to conclude that neutrality is key for distinguishing between positive and negative and, then, for improving sentiment classification. © 2018 Elsevier B.V.","Aggregation; Consensus; Filtering; Neutrality; Sentiment analysis"
"Geometrical kinematic modeling on human motion using method of multi-sensor fusion","2018","Information Fusion","10.1016/j.inffus.2017.09.014","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029681041&doi=10.1016%2fj.inffus.2017.09.014&partnerID=40&md5=b1f870cfead8aef024dcb730d9afa131","Human motion sensing based on wearable sensors could be viewed as a multi-objects tracking issue of human body joints. Sensor drift errors and distortion are the main challenges of the tracking accuracy of human motion. Traditional filtering and fusion methods, such as Kalman filter, can to some extent reduce the instantaneous error but cannot avoid sensor drift fundamentally. Physical characteristics of human body should be considered and human motion models should be exhibited to describe human motions. The existing models such as skeleton model and cylinder model are either too simple or too complicated for practical applications. In this study, we put forward a geometrical kinematic characteristics based human motion model. The whole human body is viewed as an articulated skeleton and Denavit–Hartenberg convention is adopted to describe the forward kinematics structure. Theoretical analysis is conducted with the derivation of Posterior Cramer–Rao Lower Bound (PCRLB) in human movement scenes based on proposed model. Significant superiority is shown in simulation results. An experiment on human lower limb motions is carried out to verify the validity of the proposed human motion model in practice applications, from the angles of both capturing accuracy and energy consumption. The capturing accuracy has an obvious increase in the testing results, with acceptable energy consumption. It is far more efficient than traditional methods. © 2017","Denavit–Hartenberg convention; Geometrical characteristics; Human motion; PCRLB; Wearable sensors"
"Ensemble learning for data stream analysis: A survey","2017","Information Fusion","10.1016/j.inffus.2017.02.004","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85011884671&doi=10.1016%2fj.inffus.2017.02.004&partnerID=40&md5=7fbd60b614cf5ec63ae0fd16bda28573","In many applications of information systems learning algorithms have to act in dynamic environments where data are collected in the form of transient data streams. Compared to static data mining, processing streams imposes new computational requirements for algorithms to incrementally process incoming examples while using limited memory and time. Furthermore, due to the non-stationary characteristics of streaming data, prediction models are often also required to adapt to concept drifts. Out of several new proposed stream algorithms, ensembles play an important role, in particular for non-stationary environments. This paper surveys research on ensembles for data stream classification as well as regression tasks. Besides presenting a comprehensive spectrum of ensemble approaches for data streams, we also discuss advanced learning concepts such as imbalanced data streams, novelty detection, active and semi-supervised learning, complex data representations and structured outputs. The paper concludes with a discussion of open research problems and lines of future research. © 2017","Concept drift; Data streams; Ensemble learning; Non-stationary environments; Online learning"
"Dynamic classifier selection: Recent advances and perspectives","2018","Information Fusion","10.1016/j.inffus.2017.09.010","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029576522&doi=10.1016%2fj.inffus.2017.09.010&partnerID=40&md5=b03d0e2f00d7e760556d622136ac4b5f","Multiple Classifier Systems (MCS) have been widely studied as an alternative for increasing accuracy in pattern recognition. One of the most promising MCS approaches is Dynamic Selection (DS), in which the base classifiers are selected on the fly, according to each new sample to be classified. This paper provides a review of the DS techniques proposed in the literature from a theoretical and empirical point of view. We propose an updated taxonomy based on the main characteristics found in a dynamic selection system: (1) The methodology used to define a local region for the estimation of the local competence of the base classifiers; (2) The source of information used to estimate the level of competence of the base classifiers, such as local accuracy, oracle, ranking and probabilistic models, and (3) The selection approach, which determines whether a single or an ensemble of classifiers is selected. We categorize the main dynamic selection techniques in the DS literature based on the proposed taxonomy. We also conduct an extensive experimental analysis, considering a total of 18 state-of-the-art dynamic selection techniques, as well as static ensemble combination and single classification models. To date, this is the first analysis comparing all the key DS techniques under the same experimental protocol. Furthermore, we also present several perspectives and open research questions that can be used as a guide for future works in this domain. © 2017 Elsevier B.V.","Classifier competence; Dynamic classifier selection; Dynamic ensemble selection; Ensemble of classifiers; Multiple classifier systems; Survey"
"Multi-view learning overview: Recent progress and new challenges","2017","Information Fusion","10.1016/j.inffus.2017.02.007","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85015035411&doi=10.1016%2fj.inffus.2017.02.007&partnerID=40&md5=5cb558b0ac8b45730fa7c987d9060670","Multi-view learning is an emerging direction in machine learning which considers learning with multiple views to improve the generalization performance. Multi-view learning is also known as data fusion or data integration from multiple feature sets. Since the last survey of multi-view machine learning in early 2013, multi-view learning has made great progress and developments in recent years, and is facing new challenges. This overview first reviews theoretical underpinnings to understand the properties and behaviors of multi-view learning. Then multi-view learning methods are described in terms of three classes to offer a neat categorization and organization. For each category, representative algorithms and newly proposed algorithms are presented. The main feature of this survey is that we provide comprehensive introduction for the recent developments of multi-view learning methods on the basis of coherence with early methods. We also attempt to identify promising venues and point out some specific challenges which can hopefully promote further research in this rapidly developing field. © 2017 Elsevier B.V.","Co-regularization; Co-training; Margin consistency; Multi-view learning; Statistical learning theory"
"Multiple classifiers in biometrics. part 1: Fundamentals and review","2018","Information Fusion","10.1016/j.inffus.2017.12.003","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85039755274&doi=10.1016%2fj.inffus.2017.12.003&partnerID=40&md5=2bba3600ad5c9d0ebe2466dd9de8a585","We provide an introduction to Multiple Classifier Systems (MCS) including basic nomenclature and describing key elements: classifier dependencies, type of classifier outputs, aggregation procedures, architecture, and types of methods. This introduction complements other existing overviews of MCS, as here we also review the most prevalent theoretical framework for MCS and discuss theoretical developments related to MCS. The introduction to MCS is then followed by a review of the application of MCS to the particular field of multimodal biometric person authentication in the last 25 years, as a prototypical area in which MCS has resulted in important achievements. This review includes general descriptions of successful MCS methods and architectures in order to facilitate the export of them to other information fusion problems. Based on the theory and framework introduced here, in the companion paper we then develop in more technical detail recent trends and developments in MCS from multimodal biometrics that incorporate context information in an adaptive way. These new MCS architectures exploit input quality measures and pattern-specific particularities that move apart from general population statistics, resulting in robust multimodal biometric systems. Similarly as in the present paper, methods in the companion paper are introduced in a general way so they can be applied to other information fusion problems as well. Finally, also in the companion paper, we discuss open challenges in biometrics and the role of MCS to advance them. © 2017 Elsevier B.V.","Adaptive; Biometrics; Classifier; Context; Fusion; Multimodal"
"Information fusion for efficient target detection in large-scale surveillance Wireless Sensor Networks","2017","Information Fusion","10.1016/j.inffus.2017.02.002","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85015031577&doi=10.1016%2fj.inffus.2017.02.002&partnerID=40&md5=dba52d580be8eb586179c9806084b5e2","In this paper, we consider a surveillance scenario, where nodes of a Wireless Sensor Network (WSN) cooperate to detect an event of interest, e.g., the presence of a mobile target in a monitored region. The considered scenario refers, for example, to ELectronic-signals INTelligence (ELINT), since detection is based on sensing the presence of anomalous electromagnetic signals in the monitored area. Leveraging previous results in the field of cognitive wireless networking, we derive proper decision and fusion strategies. We investigate both clustered (where no direct communication between sensors and the Communication and Control center, C2, is allowed and intermediate data fusion is performed at Cluster Heads, CHs) and unclustered (with direct communications between sensor nodes and the C2). System performance is analyzed in terms of False Alarm (FA)/Correct Detection (CD) probabilities and energy consumption, quantifying inherent tradeoffs between these performance indicators. © 2017 Elsevier B.V.","Clustering; Correct Detection (CD); ELectronic-signals INTelligence (ELINT); Energy consumption; False Alarm (FA); Wireless Sensor Network (WSN)"
"A practical tutorial on autoencoders for nonlinear feature fusion: Taxonomy, models, software and guidelines","2018","Information Fusion","10.1016/j.inffus.2017.12.007","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85039759479&doi=10.1016%2fj.inffus.2017.12.007&partnerID=40&md5=c0683611809e324daa4fe09f14bb67df","Many of the existing machine learning algorithms, both supervised and unsupervised, depend on the quality of the input characteristics to generate a good model. The amount of these variables is also important, since performance tends to decline as the input dimensionality increases, hence the interest in using feature fusion techniques, able to produce feature sets that are more compact and higher level. A plethora of procedures to fuse original variables for producing new ones has been developed in the past decades. The most basic ones use linear combinations of the original variables, such as PCA (Principal Component Analysis) and LDA (Linear Discriminant Analysis), while others find manifold embeddings of lower dimensionality based on non-linear combinations, such as Isomap or LLE (Linear Locally Embedding) techniques. More recently, autoencoders (AEs) have emerged as an alternative to manifold learning for conducting nonlinear feature fusion. Dozens of AE models have been proposed lately, each with its own specific traits. Although many of them can be used to generate reduced feature sets through the fusion of the original ones, there also AEs designed with other applications in mind. The goal of this paper is to provide the reader with a broad view of what an AE is, how they are used for feature fusion, a taxonomy gathering a broad range of models, and how they relate to other classical techniques. In addition, a set of didactic guidelines on how to choose the proper AE for a given task is supplied, together with a discussion of the software tools available. Finally, two case studies illustrate the usage of AEs with datasets of handwritten digits and breast cancer. © 2017 Elsevier B.V.","Autoencoders; Deep learning; Feature extraction; Feature fusion; Machine learning; Representation learning"
"CSF: Crowdsourcing semantic fusion for heterogeneous media big data in the internet of things","2017","Information Fusion","10.1016/j.inffus.2017.01.008","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85012245087&doi=10.1016%2fj.inffus.2017.01.008&partnerID=40&md5=6b6846b6e95762daa797b3e793b3bf18","With the rising popularity of social media in the context of environments based on the Internet of things (IoT), semantic information has emerged as an important bridge to connect human intelligence with heterogeneous media big data. As a critical tool to improve media big data retrieval, semantic fusion encounters a number of challenges: the manual method is inefficient, and the automatic approach is inaccurate. To address these challenges, this paper proposes a solution called CSF (Crowdsourcing Semantic Fusion) that makes full use of the collective wisdom of social users and introduces crowdsourcing computing to semantic fusion. First, the correlation of cross-modal semantics is mined and the semantic objects are normalized for fusion. Second, we employ the dimension reduction and relevance feedback approaches to reduce non-principal components and noise. Finally, we research the storage and distribution mechanism. Experiment results highlight the efficiency and accuracy of the proposed approach. The proposed method is an effective and practical cross-modal semantic fusion and distribution mechanism for heterogeneous social media, provides a novel idea for social media semantic processing, and uses an interactive visualization framework for social media knowledge mining and retrieval to improve semantic knowledge and the effect of representation. © 2017 Elsevier B.V.","Big data; Crowdsourcing computing; Internet of things; Semantic fusion; Social media"
"Inertial/magnetic sensors based pedestrian dead reckoning by means of multi-sensor fusion","2018","Information Fusion","10.1016/j.inffus.2017.04.006","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018906357&doi=10.1016%2fj.inffus.2017.04.006&partnerID=40&md5=ba5b8e3b469bb5829cab4abc14ea18e8","The challenges of self-contained sensor based pedestrian dead reckoning (PDR) are mainly sensor installation errors and path integral errors caused by sensor variance, and both may dramatically decrease the accuracy of PDR. To address these challenges, this paper presents a multi-sensor fusion based method in which subjects perform specified walking trials at self-administered speeds in both indoor and outdoor scenarios. After an initial calibration with the reduced installation error, quaternion notation is used to represent three-dimensional orientation and an extend Kalman filter (EKF) is deployed to fuse different types of data. A clustering algorithm is proposed to accurately distinguish stance phases, during which integral error can be minimized using Zero Velocity Updates (ZVU) method. The performance of proposed PDR method is evaluated and validated by an optical motion tracking system on healthy subjects. The position estimation accuracy, stride length and foot angle estimation error are studied. Experimental results demonstrate that the proposed self-contained inertial/magnetic sensor based method is capable of providing consistent beacon-free PDR in different scenarios, achieving less than 1% distance error and end-to-end position error. © 2017 Elsevier B.V.","Body sensor network; Inertial/magnetic sensors; Multi-sensor fusion; Pedestrian dead-reckoning"
"Multi-View Kernel Spectral Clustering","2018","Information Fusion","10.1016/j.inffus.2017.12.002","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85039163095&doi=10.1016%2fj.inffus.2017.12.002&partnerID=40&md5=fa94a30d6dd761fa1fece6dbd7e25279","In multi-view clustering, datasets are comprised of different representations of the data, or views. Although each view could individually be used, exploiting information from all views together could improve the cluster quality. In this paper a new model Multi-View Kernel Spectral Clustering (MVKSC) is proposed that performs clustering when two or more views are available. This model is formulated as a weighted kernel canonical correlation analysis in a primal-dual optimization setting typical of Least Squares Support Vector Machines (LS-SVM). The primal model includes, in particular, a coupling term, which enforces the clustering scores corresponding to the different views to align. Because of the out-of-sample extension, this model is easily applied to large-scale datasets. The performance of the proposed model is shown on synthetic and real-world datasets, as well as on some large-scale datasets. Experimental comparisons with a number of other methods show that using multiple views improves the clustering results and that the proposed method is competitive with other state-of-the-art algorithms in terms of clustering accuracy and runtime. Especially on the large-scale datasets the advantage of the proposed method is clearly shown, as it is able to handle larger datasets than the other state-of-the-art algorithms. © 2017 Elsevier B.V.","Clustering; Kernel CCA; Multi-view learning; Out-of-sample extension"
"Hesitant fuzzy linguistic term sets for linguistic decision making: Current developments, issues and challenges","2018","Information Fusion","10.1016/j.inffus.2017.11.010","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85034786573&doi=10.1016%2fj.inffus.2017.11.010&partnerID=40&md5=6717050560680a9d6e266fe46f0b4a54","The fuzzy linguistic approach is frequently considered as a solution for qualitative decision making. In the traditional framework of linguistic decision making, the representation of linguistic information is quite limited because the information has to be expressed by one predefined term. Hesitant fuzzy linguistic term sets (HFLTSs), which can be elicited by comparative linguistic expressions, have been proposed recently for the convenience of utilizing several consecutive terms at the same time and accommodating uncertainties and hesitations in human linguistic assessments. Since it was introduced, a large number of publications have been devoted to developing the theories, methods and applications of HFLTSs. In this paper, the concept and characteristics of HFLTSs are revisited at first and then the recent developments are reviewed and classified according to their computational strategies. Based on which, a comparative analysis of some similar techniques is presented to recognize the role of HFLTSs in linguistic decision making. Finally, some existing issues and current challenges are summarized to guide the prospective research of HFLTSs towards a high-quality progress. © 2017","Complex linguistic expression; Fuzzy linguistic approach; Hesitant fuzzy linguistic term set; Linguistic term set; Uncertain linguistic term"
"Towards unravelling the relationship between on-body, environmental and emotion data using sensor information fusion approach","2018","Information Fusion","10.1016/j.inffus.2017.05.005","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020287020&doi=10.1016%2fj.inffus.2017.05.005&partnerID=40&md5=65ed81144999b5d5481a5f738520b854","Over the past few years, there has been a noticeable advancement in environmental models and information fusion systems taking advantage of the recent developments in sensor and mobile technologies. However, little attention has been paid so far to quantifying the relationship between environment changes and their impact on our bodies in real-life settings. In this paper, we identify a data driven approach based on direct and continuous sensor data to assess the impact of the surrounding environment and physiological changes and emotion. We aim at investigating the potential of fusing on-body physiological signals, environmental sensory data and on-line self-report emotion measures in order to achieve the following objectives: (1) model the short term impact of the ambient environment on human body, (2) predict emotions based on-body sensors and environmental data. To achieve this, we have conducted a real-world study ‘in the wild’ with on-body and mobile sensors. Data was collected from participants walking around Nottingham city centre, in order to develop analytical and predictive models. Multiple regression, after allowing for possible confounders, showed a noticeable correlation between noise exposure and heart rate. Similarly, UV and environmental noise have been shown to have a noticeable effect on changes in ElectroDermal Activity (EDA). Air pressure demonstrated the greatest contribution towards the detected changes in body temperature and motion. Also, significant correlation was found between air pressure and heart rate. Finally, decision fusion of the classification results from different modalities is performed. To the best of our knowledge this work presents the first attempt at fusing and modelling data from environmental and physiological sources collected from sensors in a real-world setting. © 2017 The Authors","Affective computing; Machine learning; Multi sensor data fusion; Multivariable regression; Physiological signals; Regression analysis sensor data"
"Double hierarchy hesitant fuzzy linguistic term set and MULTIMOORA method: A case of study to evaluate the implementation status of haze controlling measures","2017","Information Fusion","10.1016/j.inffus.2017.02.008","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85015061252&doi=10.1016%2fj.inffus.2017.02.008&partnerID=40&md5=8b51afa0c4fa35d60608a2c33c7433d1","In recent years, hesitant fuzzy linguistic term sets (HFLTSs) have been studied by many scholars and are becoming gradually mature. However, some shortcomings of HFLTS also emerged. To describe the complex linguistic terms or linguistic term sets more accurately and reasonably, in this paper, we introduce the novel concepts named double hierarchy linguistic term set (DHLTS) and double hierarchy hesitant fuzzy linguistic term set (DHHFLTS). The operational laws and properties of the DHHFLTSs are developed as well. Afterwards, we investigate the multiple criteria decision making model with double hierarchy hesitant fuzzy linguistic information. We develop a double hierarchy hesitant fuzzy linguistic MULTIMOORA (DHHFL-MULTIMOORA) method to solve it. Furthermore, we apply the DHHFL-MULTIMOORA method to deal with a practical case about selecting the optimal city in China by evaluating the implementation status of haze controlling measures. Some comparisons between the DHHFL-MULTIMOORA method and the hesitant fuzzy linguistic TOPSIS method are provided to show the advantages of the proposed method. © 2017 Elsevier B.V.","Double hierarchy hesitant fuzzy linguistic term sets; Double hierarchy linguistic term sets; Haze controlling measures; MULTIMOORA method; Multiple criteria decision making"
"EFA-BMFM: A multi-criteria framework for the fusion of colour image segmentation","2017","Information Fusion","10.1016/j.inffus.2017.03.001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85016002313&doi=10.1016%2fj.inffus.2017.03.001&partnerID=40&md5=6a6d0b95c2aeb2d71639d2c249959c1e","Considering the recent progress in the development of practical applications in the field of image processing, it is increasingly important to develop new, efficient and more reliable algorithms to solve an image segmentation problem. To this end, various fusion-based segmentation approaches which use consensus clustering, and which are based on the optimization of a single criterion, have been proposed. One of the greatest challenges with these approaches is to select the best fusion criterion, which gives the best performance for the image segmentation model. In this paper, we propose a new fusion model of image segmentation based on multi-objective optimization, which aims to overcome the limitation and bias caused by a single criterion, and to provide a final improved segmentation. To address the ill-posedness for the search of the best criterion, the proposed fusion model combines two conflicting and complementary criteria for segmentation fusion, namely, the region-based variation of information (VoI) criterion and the contour-based F-measure (precision-recall) criterion using an entropy-based confidence weighting factor. To optimize our energy-based model, we propose an extended local optimization procedure based on superpixels and derived from the iterative conditional mode (ICM) algorithm. This new multi-objective median partition-based approach, which relies on the fusion of inaccurate, quick and spatial clustering results, has emerged as an appealing alternative to the use of traditional segmentation fusion models which exist in the literature. We perform experiments using the Berkeley database with manual ground truth segmentations, and the results clearly show the feasibility and efficiency of the proposed methodology. © 2017 Elsevier B.V.","Berkeley image database; Colour textured image segmentation; Combination of multiple segmentations; Entropy; Multi-objective optimization"
"Multimodal sparse and low-rank subspace clustering","2018","Information Fusion","10.1016/j.inffus.2017.05.002","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019365201&doi=10.1016%2fj.inffus.2017.05.002&partnerID=40&md5=0900ce0c0cccf83fe4839b6596c83f7e","In this paper, we propose multimodal extensions of the recently introduced sparse subspace clustering (SSC) and low-rank representation (LRR) based subspace clustering algorithms for clustering data lying in a union of subspaces. Given multimodal data, our method simultaneously clusters data in the individual modalities according to their subspaces. In our formulation, we exploit the self expressiveness property of each sample in its respective modality and enforce the common representation across the modalities. We modify our model so that it is robust to noise. Furthermore, we kernelize the proposed algorithms to handle nonlinearities in data. The optimization problems are solved efficiently using the alternative direction method of multiplier (ADMM). Experiments on face clustering indicate the proposed method performs favorably compared to state-of-the-art subspace clustering methods. © 2017 Elsevier B.V.","Biometrics; Face clustering; Low-rank representation-based subspace clustering; Multimodal subspace clustering; Sparse subspace clustering; Subspace clustering"
"Multi-biometric template protection based on bloom filters","2018","Information Fusion","10.1016/j.inffus.2017.10.003","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031091963&doi=10.1016%2fj.inffus.2017.10.003&partnerID=40&md5=72644bcbd88823a24b3ca3a4d4fa2974","Biometric verification systems are currently being deployed in numerous large-scale and everyday applications. It is hence of the utmost importance to protect the privacy of the enrolled subjects. Biometric template protection schemes are designed to protect biometric reference data in an irreversible and unlinkable manner, while maintaining key system properties like the accuracy or the speed. In past years, template protection schemes based on Bloom filters have been introduced and applied to various biometric characteristics. While the irreversibility and unlinkability of Bloom filter-based protection schemes have been shown, their application to any given unprotected template is not straightforward. In this article we present a methodology for the estimation of the main parameters of such schemes, based on a statistical analysis of the unprotected templates. Furthermore, in order to increase verification accuracy and privacy protection, a general approach for a protected weighted feature level fusion is proposed. In order to avoid biased results, the soundness of the estimation methodologies is confirmed for face, iris, fingerprint and fingervein over two totally different sets of publicly available databases. In addition, we show how the weighted feature level fusion preserves the accuracy of the unprotected score level fusion, while it adds privacy protection to the system. © 2017 Elsevier B.V.","Biometrics; Irreversibility; Multi-biometrics; Privacy; Template protection; Unlinkability"
"Fusing time, frequency and shape-related information: Introduction to the Discrete Shapelet Transform's second generation (DST-II)","2018","Information Fusion","10.1016/j.inffus.2017.07.004","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026629929&doi=10.1016%2fj.inffus.2017.07.004&partnerID=40&md5=1ad11b8bf623a5c2ac19cb86868d050e","This article introduces the second generation of the Discrete Shapelet Transform (DST-II), a tool created for fusing three types of information: time, frequency and shape-related. Considered a particular Discrete Wavelet Transform (DWT), it allows a productive time-frequency-shape (TFS) joint analysis. In the proposed approach, both the procedure to attain the corresponding filters coefficients and the interpretation of the transformed signal are simplified in relation to the usage of its predecessor, i.e., the DST. Throughout the article, the DST-II formulation is described in detail, including a numerical example, a prototype for use in a diversity of fields and an application on spike and overlap sorting, reassuring the efficacy of the new transform. © 2017 Elsevier B.V.","Discrete shapelet transform (DST); Discrete wavelet transform (DWT); Information fusion; Pattern analysis; Signal processing; Time-frequency-shape (TFS) joint analysis"
"Remoteness index-based Pythagorean fuzzy VIKOR methods with a generalized distance measure for multiple criteria decision analysis","2018","Information Fusion","10.1016/j.inffus.2017.09.003","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028982282&doi=10.1016%2fj.inffus.2017.09.003&partnerID=40&md5=6d71a7bfa08b8ffd77b3cfee328d0045","The aim of this paper is to develop novel VIKOR-based methods for multiple criteria decision analysis involving Pythagorean fuzzy information. The concept of Pythagorean fuzzy sets possesses definite advantages in handling vagueness and complex uncertainty over well-known nonstandard fuzzy sets, such as intuitionistic fuzzy sets and interval-valued fuzzy sets. Taking the powerfulness of Pythagorean fuzzy sets into account when tackling imprecise and ambiguous information in multiple criteria decision-making problems, this paper proposes remoteness index-based Pythagorean fuzzy VIKOR methods, which are significantly different from the existing VIKOR techniques. The uniqueness of the proposed VIKOR methodology is the consideration of uncertain information represented by Pythagorean fuzzy values and the construction of certain valuable concepts of a generalized distance measure and displaced and fixed remoteness indices. A flexible and multipurpose definition of a distance measure for Pythagorean fuzzy information is presented based on the Minkowski distance model. The generalized Pythagorean fuzzy distance measure presented in this paper is then applied to establish useful concepts of remoteness indices, consisting of displaced positive- and negative-ideal remoteness indices as well as fixed positive- and negative-ideal remoteness indices. Unlike the canonical VIKOR ranking procedure, this paper provides a new way to rank candidate alternatives and determine the compromise solution depending on distinct preference structures for adapting to the particularities within the Pythagorean fuzzy environment. Several useful multiple criteria ranking indices, consisting of remoteness-based group utility, individual regret, and compromise indices, are developed to facilitate compromise ranking among alternatives. Four algorithmic procedures of the presented remoteness index-based Pythagorean fuzzy VIKOR methods are also provided in detail. Furthermore, some real-world applications and comparative analyses concerning a criteria satisfaction problem, two service quality and Internet stock performance evaluation problems, and two Internet stock and R&D project investment problems are conducted to demonstrate the effectiveness and advantages of the proposed methods in practice. © 2017 Elsevier B.V.","Comparative analysis; Generalized distance measure; Multiple criteria decision analysis; Pythagorean fuzzy set; Remoteness index; VIKOR"
"Real-time foreground detection approach based on adaptive ensemble learning with arbitrary algorithms for changing environments","2018","Information Fusion","10.1016/j.inffus.2017.05.001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019469784&doi=10.1016%2fj.inffus.2017.05.001&partnerID=40&md5=0698cbd6b4e377528cb002779a32d56d","Foreground detection technologies have emerged as an important research area with increasing popularity of computer vision and camera devices. Even though several foreground detection approaches have been proposed, they cannot address various challenges in actual complex scenes owing to their applicability and restrictions. This study proposes a method that can integrate arbitrary detection technologies to detect foregrounds in real time, thereby improving overall detection performance of video-based systems. Moreover, the proposed approach can be fully initialized with initial foreground results, requires no training, and performs dynamic adjustments online, for every new frame. In this approach, critical weighted values are automatically calculated over time based on observed scenes for optimal flexibility and parameterization. Thus, the proposed method has the flexibility to accommodate any new technology to overcome the challenging problems of foreground detection in changing environments. Experimental results demonstrate that the performance of the proposed method is comparable to that of state-of-the-art methods and satisfies the requirements of real-time practical applications. © 2017 Elsevier B.V.","Arbitrary algorithm; Change detection; Ensemble learning; Foreground segmentation; Real-time applications; Stopped object detection"
"A tutorial review on entropy-based handcrafted feature extraction for information fusion","2018","Information Fusion","10.1016/j.inffus.2017.09.006","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029359276&doi=10.1016%2fj.inffus.2017.09.006&partnerID=40&md5=28f24a1a0908162013b72bee742c7173","Entropy (H) is the main subject of this article, concisely written to serve as a tutorial introducing two feature extraction (FE) methods for usage in digital signal processing (DSP) and pattern recognition (PR). The theory, carefully exposed, is supplemented with numerical cases, augmented with C/C++ source-codes and enriched with example applications on restricted-vocabulary speech recognition and image synthesis. Complementarily and as innovatively shown, the ordinary calculation of H corresponds to the outcome of a partially pre-tuned deep neural network architecture which fuses important information, bringing a cutting-edge point-of-view for both DSP and PR communities. © 2017 Elsevier B.V.","Deep networks; Entropy; Handcrafted feature extraction; Image synthesis; Information fusion; Restricted-vocabulary speech recognition"
"Collaborative clustering: Why, when, what and how","2018","Information Fusion","10.1016/j.inffus.2017.04.008","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018638429&doi=10.1016%2fj.inffus.2017.04.008&partnerID=40&md5=6e0a838c6626677029a9327649ba796a","Clustering is one type of unsupervised learning where the goal is to partition the set of objects into groups called clusters. Faced to the difficulty to design a general purpose clustering algorithm and to choose a good, let alone perfect, set of criteria for clustering a data set, one solution is to resort to a variety of clustering procedures based on different techniques, parameters and/or initializations, in order to construct one (or several) final clustering(s). The hope is that by combining several clustering solutions, each one with its own bias and imperfections, one will get a better overall solution. In the cooperative clustering model, as Ensemble Clustering, a set of clustering algorithms are used in parallel on a given data set: the local results are combined to get a hopefully better overall clustering. In the collaborative framework, the goal is that each local computation, quite possibly applied to distinct data sets, benefit from the work done by the other collaborators. This paper is dedicated to collaborative clustering. In particular, after a brief overview of clustering and the major issues linked to, it presents main challenges related to organize and control the collaborative process. © 2017 Elsevier B.V.","Clustering combining; Collaborative clustering; Cooperative clustering"
"A group decision making method with interval valued fuzzy preference relations based on the geometric consistency","2018","Information Fusion","10.1016/j.inffus.2017.06.003","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021183634&doi=10.1016%2fj.inffus.2017.06.003&partnerID=40&md5=fd8322eba8d2151d92b513a2932edc15","This paper investigates a group decision making (GDM) method with interval valued fuzzy preference relations (IVFPRs). According to the geometric consistency of IVFPR, the max-consistency index and min-consistency index of an IVFPR are developed respectively. Combining the max-consistency index with min-consistency index, the geometric consistent index of an IVFPR is defined to measure the consistency level of the IVFPR by considering decision maker's (DM's) risk attitude. For improving the unacceptable geometric consistency of an IVFPR, a goal programming model is constructed to derive an acceptable geometric consistent IVFPR. By regarding the geometric consistent conditions of an IVFPR as fuzzy constraints, a fuzzy logarithmic program is established to generate the interval priority weights. In GDM problems, the individual interval priority weights are obtained by solving the corresponding fuzzy logarithmic programs. The similarities between DMs are calculated based on their individual interval priority weights. Subsequently the confidence degrees of DMs are defined to determine DMs' weights. To obtain the collective interval priority weights, a parametric linear program is constructed and transformed into a linear program to resolve. The order of alternatives is generated by the collective interval priority weights. Some examples are analyzed to verify the effectiveness of the proposed method. © 2017 Elsevier B.V.","Fuzzy logarithmic programming model; Geometric consistent index; Group decision making; Interval valued fuzzy preference relation; Parametric linear programming model"
"High-order possibilistic c-means algorithms based on tensor decompositions for big data in IoT","2018","Information Fusion","10.1016/j.inffus.2017.04.002","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85017458048&doi=10.1016%2fj.inffus.2017.04.002&partnerID=40&md5=569110bcdcbdd58580addf105afe097a","Internet of Things (IoT) connects the physical world and the cyber world to offer intelligent services by data mining for big data. Each big data sample typically involves a large number of attributes, posing a remarkable challenge on the high-order possibilistic c-means algorithm (HOPCM). Specially, HOPCM requires high-performance servers with a large-scale memory and a powerful computing unit, to cluster big samples, limiting its applicability in IoT systems with low-end devices such as portable computing units and embedded devises which have only limited memory space and computing power. In this paper, we propose two high-order possibilistic c-means algorithms based on the canonical polyadic decomposition (CP-HOPCM) and the tensor-train network (TT-HOPCM) for clustering big data. In detail, we use the canonical polyadic decomposition and the tensor-train network to compress the attributes of each big data sample. To evaluate the performance of our algorithms, we conduct the experiments on two representative big data datasets, i.e., NUS-WIDE-14 and SNAE2, by comparison with the conventional high-order possibilistic c-means algorithm in terms of attributes reduction, execution time, memory usage and clustering accuracy. Results imply that CP-HOPCM and TT-HOPCM are potential for big data clustering in IoT systems with low-end devices since they can achieve a high compression rate for heterogeneous samples to save the memory space significantly without a significant clustering accuracy drop. © 2017","Big data; Canonical polyadic decomposition; IoT; Possibilistic c-means clustering; Tensor-train network"
"Fusion-based methods for result diversification in web search","2019","Information Fusion","10.1016/j.inffus.2018.01.006","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041398947&doi=10.1016%2fj.inffus.2018.01.006&partnerID=40&md5=d298012c7a09bcb5ff46a888c81dd667","Search result diversification of text documents is especially necessary when a user issues a faceted or ambiguous query to the search engine. A variety of approaches have been proposed to deal with this issue in recent years. In this article, we propose a group of fusion-based result diversification methods with the aim to improve performance that considers both relevance and diversity. They are linear combinations of scores that are obtained from different component search systems. The weight of each search system is determined by considering three factors: performance, dissimilarity, and complementarity. There are two major contributions. Firstly, we find that all the three factors of performance and complementarity and dissimilarity are useful for effective weighting of linear combination. Secondly, we present the logarithmic function-based model for converting ranking information into scores. Experiments are carried out with four groups of results submitted to the TREC web diversity task. Experimental results show that some of the fusion methods that use the aforementioned techniques perform more effectively than the state-of-the-art fusion methods for result diversification. © 2018 Elsevier B.V.","Data fusion; Linear combination; Linear score normalization; Result diversification; Web search; Weight assignment"
"Revealing community structures by ensemble clustering using group diffusion","2018","Information Fusion","10.1016/j.inffus.2017.09.013","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030688626&doi=10.1016%2fj.inffus.2017.09.013&partnerID=40&md5=9cb830381b9ce0bb7de884a461030e66","We propose an ensemble clustering approach using group diffusion to reveal community structures in data. We represent data points as a directed graph and assume each data point belong to single cluster membership instead of multiple memberships. The method is based on the concept of ensemble group diffusion with a parameter to represent diffusion depth in clustering. The ability to modulate the diffusion-depth parameter by varying it within a certain interval allows for more accurate construction of clusters. Depending on the value of the diffusion-depth parameter, the presented approach can determine very well both local clusters and global structure of data. At the same time, the ability to combine single outcomes of the method results in better cluster segmentation. Due to this property, the proposed method performs well on data sets where other conventional clustering methods fail. We test the method with both simulated and real-world data sets. The results support our theoretical conjectures on improved accuracy compared to other selected methods. © 2017 Elsevier B.V.","Clustering; Community structure; Diffusion; Markov chain; Social network"
"Adaptive multi-objective swarm fusion for imbalanced data classification","2018","Information Fusion","10.1016/j.inffus.2017.03.007","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85016392535&doi=10.1016%2fj.inffus.2017.03.007&partnerID=40&md5=6b582a17fdabebe7881a6f2f7424cbf8","Learning a classifier from an imbalanced dataset is an important problem in data mining and machine learning. Since there is more information from the majority classes than the minorities in an imbalanced dataset, the classifier would become over-fitted to the former and under-fitted to the latter classes. Previous attempts to address the problem have been focusing on increasing the learning sensitivity to the minorities and/or rebalancing sample sizes among classes before learning. However, how to efficiently identify their optimal mix in rebalancing is still an unresolved problem. Due to non-linear relationships between attributes and class labels, merely to rebalance sample sizes rarely comes up with optimal results. Moreover, brute-force search for the perfect combination is known to be NP-hard and hence a smarter heuristic is required. In this paper, we propose a notion of swarm fusion to address the problem – using stochastic swarm heuristics to cooperatively optimize the mixtures. Comparing with conventional rebalancing methods, e.g., linear search, our novel fusion approach is able to find a close to optimal mix with improved accuracy and reliability. Most importantly, it has found to be with higher computational speed than other coupled swarm optimization techniques and iteration methods. In our experiments, we first compared our proposed solution with traditional methods on thirty publicly available imbalanced datasets. Using neural network as base learner, our proposed method is found to outperform other traditional methods by up to 69% in terms of the credibility of the learned classifiers. Secondly, we wrapped our proposed swarm fusion method with decision tree. Notably, it defeated six state-of-the-art methods on ten imbalanced datasets in all evolution metrics that we considered. © 2017 Elsevier B.V.","Crossover rebalancing; Imbalanced data classification; Multi-objective; Swarm fusion; Swarm intelligence algorithm"
"Distinguishing between facts and opinions for sentiment analysis: Survey and challenges","2018","Information Fusion","10.1016/j.inffus.2017.12.006","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85039787449&doi=10.1016%2fj.inffus.2017.12.006&partnerID=40&md5=cf537a4f48073c6fc4a7b516ec3bad2f","Sentiment analysis requires a lot of information coming from different sources and about different topics to be retrieved and fused. For this reason, one of the most important subtasks of sentiment analysis is subjectivity detection, i.e., the removal of ‘factual’ or ‘neutral’ comments that lack sentiment. It is possibly the most essential subtask of sentiment analysis as sentiment classifiers are often optimized to categorize text as either negative or positive and, hence, forcefully fit unopinionated sentences into one of these two categories. This article reviews hand-crafted and automatic models for subjectivity detection in the literature. It highlights the key assumptions these models make, the results they obtain, and the issues that still need to be explored to further our understanding of subjective sentences. Lastly, the advantages and limitations of each approach are compared. The methods can be broadly categorized as hand-crafted, automatic, and multi-modal. Hand-crafted templates work well on strong sentiments, however they are unable to identify weakly subjective sentences. Automatic methods such as deep learning provide a meta-level feature representation that generalizes well on new domains and languages. Multi-modal methods can combine the abundant audio and video forms of social data with text using multiple kernels. We conclude that the high-dimensionality of n-gram features and temporal nature of sentiments in long product reviews are the major challenges in sentiment mining from text. © 2017 Elsevier B.V.","Convolutional neural network; Multi-lingual analysis; Subjectivity detection; Twitter; Word vector model"
"Joint consensus evaluation of multiple objects on an ordinal scale: An approach driven by monotonicity","2018","Information Fusion","10.1016/j.inffus.2017.09.009","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032230518&doi=10.1016%2fj.inffus.2017.09.009&partnerID=40&md5=d065031bd465c006e341d60f08bde92e","In this paper, we consider the problem of obtaining the consensus evaluation of multiple objects based on the evaluations expressed by several experts. This problem is of relevance to several fields, in particular to the field of sensory evaluation, such as in food quality appraisal, and to the field of recommender systems, such as in movie recommendation and online dating systems. Unlike existing methods for obtaining a consensus evaluation, which strongly rely on a chosen distance function, we adhere to the natural property of monotonicity, resulting in an intuitively appealing consensus evaluation method in which the labels expressed for all objects are considered simultaneously. Three real-life and three synthetic examples illustrate the search for such consensus evaluation. © 2017 Elsevier B.V.","Consensus evaluation; Monometric; Monotonicity; Ordinal scale"
"Fusing texture, shape and deep model-learned information at decision level for automated classification of lung nodules on chest CT","2018","Information Fusion","10.1016/j.inffus.2017.10.005","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032367648&doi=10.1016%2fj.inffus.2017.10.005&partnerID=40&md5=ba1b9dbb6b5dff54e9335ae8e4f0c90e","The separation of malignant from benign lung nodules on chest computed tomography (CT) is important for the early detection of lung cancer, since early detection and management offer the best chance for cure. Although deep learning methods have recently produced a marked improvement in image classification there are still challenges as these methods contain myriad parameters and require large-scale training sets that are not usually available for most routine medical imaging studies. In this paper, we propose an algorithm for lung nodule classification that fuses the texture, shape and deep model-learned information (Fuse-TSD) at the decision level. This algorithm employs a gray level co-occurrence matrix (GLCM)-based texture descriptor, a Fourier shape descriptor to characterize the heterogeneity of nodules and a deep convolutional neural network (DCNN) to automatically learn the feature representation of nodules on a slice-by-slice basis. It trains an AdaBoosted back propagation neural network (BPNN) using each feature type and fuses the decisions made by three classifiers to differentiate nodules. We evaluated this algorithm against three approaches on the LIDC-IDRI dataset. When the nodules with a composite malignancy rate 3 were discarded, regarded as benign or regarded as malignant, our Fuse-TSD algorithm achieved an AUC of 96.65%, 94.45% and 81.24%, respectively, which was substantially higher than the AUC obtained by other approaches. © 2017 Elsevier B.V.","AdaBoost, information fusion; Back propagation neural network (BPNN); Chest CT; Deep convolutional neural network (DCNN); Lung nodule classification"
"Bias estimation for asynchronous multi-rate multi-sensor fusion with unknown inputs","2018","Information Fusion","10.1016/j.inffus.2017.03.002","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019498090&doi=10.1016%2fj.inffus.2017.03.002&partnerID=40&md5=2c0c7ffae7451c301e77c695a3ebe7fa","In asynchronous multi-sensor fusion, it is hard to guarantee that all sensors work at the single sampling rate, especially in the distributive and heterogeneous case. Meanwhile, the time-varying sensor bias driven by unknown inputs (UIs) are likely to occur in complex environments when conducting the sensor registration. In this paper, a two-stage fusion scheme is proposed to estimate the state, the UI and the UI-driven bias for asynchronous multi-sensor fusion. By establishing the dynamic system model at each scale and deriving its corresponding equivalent UI-decoupled bias dynamic model, the proposed scheme is implemented in two stages. At the first stage, each sensor collects its own measurements and generates the local optimal estimates of the state and the bias which are later used to compute the local estimate of the UI via the least squares method. At the second stage, local estimates of the state and the UI are distributively fused via network consensus to obtain the consensus state and UI estimates which are fed back to refine the local bias estimate. Local estimators are designed via the orthogonal projection principle and the least squares method, and the fusion estimators are designed via the average consensus fusion rule weighted by matrices. Simulation experiments are given to show the effectiveness of the developed method. © 2017","Asynchronous multi-rate sensor fusion; Bias estimation; Network consensus; Unknown input decoupling"
"Operations and integrations of probabilistic hesitant fuzzy information in decision making","2017","Information Fusion","10.1016/j.inffus.2017.02.001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85013287629&doi=10.1016%2fj.inffus.2017.02.001&partnerID=40&md5=b3a93fb6f56af213625e726d0d413aba","In recent years, the hesitant fuzzy set (HFS) has been widely applied in practical decision making processes. As a matter of fact, it indeed describes the thoughts of experts better because of a better tolerance. But there is a big defect in its applications—the serious loss of information. To improve the HFS, the probabilistic hesitant fuzzy set (P-HFS) has been put forward. It adds the probability to the HFS and can retain more information than the HFS. However, the P-HFS is still not perfect. In this paper, the definitions of the P-HFS and the probabilistic hesitant fuzzy element (P-HFE) are improved at first. After that, the properties and operations of the improved P-HFEs are studied, and some corresponding aggregation operators are given. Furthermore, the concept of P-HFEs with the continuous form is proposed, some operations and distance measures for them are given. Finally, the integrations of the improved P-HFEs are used to deal with a practical case concerning the automotive industry safety evaluation. © 2017 Elsevier B.V.","Continuous form; Hesitant fuzzy information; Integration; Multiple attribute decision making; Probabilistic hesitant fuzzy set"
"Decomposition theorems and extension principles for hesitant fuzzy sets","2018","Information Fusion","10.1016/j.inffus.2017.08.005","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027534671&doi=10.1016%2fj.inffus.2017.08.005&partnerID=40&md5=a2aeba15b5781d45edea6acee71a4cc3","We prove a decomposition theorem for hesitant fuzzy sets, which states that every typical hesitant fuzzy set on a set can be represented by a well-structured family of fuzzy sets on that set. This decomposition is expressed by the novel concept of hesitant fuzzy set associated with a family of hesitant fuzzy sets, in terms of newly defined families of their cuts. Our result supposes the first representation theorem of hesitant fuzzy sets in the literature. Other related representation results are proven. We also define two novel extension principles that extend crisp functions to functions that map hesitant fuzzy sets into hesitant fuzzy sets. © 2017 Elsevier B.V.","Cut set; Decomposition theorem; Extension principle; Hesitant fuzzy set; Representation theorem"
"A message passing approach for decision fusion in adversarial multi-sensor networks","2018","Information Fusion","10.1016/j.inffus.2017.06.006","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021413999&doi=10.1016%2fj.inffus.2017.06.006&partnerID=40&md5=a5fe59ab0a7fb5bad58aba13ed1bd094","We consider a simple, yet widely studied, set-up in which a Fusion Center (FC) is asked to make a binary decision about a sequence of system states by relying on the possibly corrupted decisions provided by byzantine nodes, i.e. nodes which deliberately alter the result of the local decision to induce an error at the fusion center. When independent states are considered, the optimum fusion rule over a batch of observations has already been derived, however its complexity prevents its use in conjunction with large observation windows. In this paper, we propose a near-optimal algorithm based on message passing that greatly reduces the computational burden of the optimum fusion rule. In addition, the proposed algorithm retains very good performance also in the case of dependent system states. By first focusing on the case of small observation windows, we use numerical simulations to show that the proposed scheme introduces a negligible increase of the decision error probability compared to the optimum fusion rule. We then analyse the performance of the new scheme when the FC makes its decision by relying on long observation windows. We do so by considering both the case of independent and Markovian system states and show that the obtained performance are superior to those obtained with prior suboptimal schemes. As an additional result, we confirm the previous finding that, in some cases, it is preferable for the byzantine nodes to minimise the mutual information between the sequence system states and the reports submitted to the FC, rather than always flipping the local decision. © 2017 Elsevier B.V.","Adversarial signal processing; Decision fusion in adversarial setting; Decision fusion in the presence of Byzantines; Factor graph; Message passing algorithm"
"Fusion estimation for multi-sensor networked systems with packet loss compensation","2019","Information Fusion","10.1016/j.inffus.2018.01.008","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041408946&doi=10.1016%2fj.inffus.2018.01.008&partnerID=40&md5=06584cdf49e954be35c4b52dfa68d830","This paper is concerned with information fusion estimation problems for multi-sensor networked systems with random packet losses. Based on a recent developed compensation strategy of packet losses that the predictor of lost observation is used as the observation when a packet is lost, centralized fusion estimators (CFEs), including the filter, predictor and smoother, in the linear unbiased minimum variance (LUMV) sense are first designed by completing square method. Then, local optimal estimators are designed for each sensor subsystem. Estimation error cross-covariance matrices between any two local estimators are derived. Based on local estimators and cross-covariance matrices, distributed fusion estimators (DFEs) are presented by using the matrix-weighted fusion estimation algorithm in the LUMV sense. Compared with the existing results with zero-input and hold-input compensations, the proposed algorithms with prediction compensations can obviously improve the estimation accuracy. Two simulation examples show their effectiveness. © 2018 Elsevier B.V.","Completing square method; Cross-covariance matrix; Fusion estimation; Multi-sensor networked system; Packet loss compensation"
"On building ensembles of stacked denoising auto-encoding classifiers and their further improvement","2018","Information Fusion","10.1016/j.inffus.2017.03.008","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85017032718&doi=10.1016%2fj.inffus.2017.03.008&partnerID=40&md5=e56b17e85abb084e3fb5b19746cc1cd6","To aggregate diverse learners and to train deep architectures are the two principal avenues towards increasing the expressive capabilities of neural networks. Therefore, their combinations merit attention. In this contribution, we study how to apply some conventional diversity methods –bagging and label switching– to a general deep machine, the stacked denoising auto-encoding classifier, in order to solve a number of appropriately selected image recognition problems. The main conclusion of our work is that binarizing multi-class problems is the key to obtain benefit from those diversity methods. Additionally, we check that adding other kinds of performance improvement procedures, such as pre-emphasizing training samples and elastic distortion mechanisms, further increases the quality of the results. In particular, an appropriate combination of all the above methods leads us to reach a new absolute record in classifying MNIST handwritten digits. These facts reveal that there are clear opportunities for designing more powerful classifiers by means of combining different improvement techniques. © 2017 Elsevier B.V.","Augmentation; Classification; Deep; Diversity; Learning; Pre-emphasis"
"Multi-sensor distributed fusion estimation with applications in networked systems: A review paper","2017","Information Fusion","10.1016/j.inffus.2017.03.006","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85017025985&doi=10.1016%2fj.inffus.2017.03.006&partnerID=40&md5=7493c659a31cbbdc278b05379f90270a","In this paper, the advances of distributed fusion estimation (DFE) algorithms for multi-sensor networked systems (NSs) are reviewed. First, several general DFE algorithms are reviewed. Then, some random phenomena in NSs are discussed, including data quantization, random transmission delays, packet dropouts, fading measurements and communication disturbances. Finally, the advances of DFE algorithms for NSs are summarized. © 2017 Elsevier B.V.","Distributed fusion estimation; Multisensor; Network-induced phenomenon; Networked system; Random uncertainty"
"Multi-view stacking for activity recognition with sound and accelerometer data","2018","Information Fusion","10.1016/j.inffus.2017.06.004","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020796726&doi=10.1016%2fj.inffus.2017.06.004&partnerID=40&md5=0a07b135692f48845dad1bab2168f739","Many Ambient Intelligence (AmI) systems rely on automatic human activity recognition for getting crucial context information, so that they can provide personalized services based on the current users’ state. Activity recognition provides core functionality to many types of systems including: Ambient Assisted Living, fitness trackers, behavior monitoring, security, and so on. The advent of wearable devices along with their diverse set of embedded sensors opens new opportunities for ubiquitous context sensing. Recently, wearable devices such as smartphones and smart-watches have been used for activity recognition and monitoring. Most of the previous works use inertial sensors (accelerometers, gyroscopes) for activity recognition and combine them using an aggregation approach, i.e., extract features from each sensor and aggregate them to build the final classification model. This is not optimal since each sensor data source has its own statistical properties. In this work, we propose the use of a multi-view stacking method to fuse the data from heterogeneous types of sensors for activity recognition. Specifically, we used sound and accelerometer data collected with a smartphone and a wrist-band while performing home task activities. The proposed method is based on multi-view learning and stacked generalization, and consists of training a model for each of the sensor views and combining them with stacking. Our experimental results showed that the multi-view stacking method outperformed the aggregation approach in terms of accuracy, recall and specificity. © 2017 Elsevier B.V.","Accelerometer; Activity recognition; Multi-view learning; Sound; Stacked generalization"
"An event based multi-sensor fusion algorithm with deadzone like measurements","2018","Information Fusion","10.1016/j.inffus.2017.10.004","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032816052&doi=10.1016%2fj.inffus.2017.10.004&partnerID=40&md5=8fc1c5aac27ede4bc657e86b68efeb83","Event based strategy has received increasing attention recent years since it can provide a useful compromise between estimation performance and constrained energy or communication resources. In this paper, we propose an event based multi-sensor fusion algorithm with deadzone like measurements, where every sensor compares its measurements with an interval, and only elements beyond the thresholds, i.e., outside the deadzone, are sent to the fusion centre. To fuse this kind of deadzone like measurement, we firstly derive a modified Kalman filter (KF), which is based on the statistical properties of measurements. Then we obtain its information form, which is utilised in our event based information fusion algorithm to further release the computation burden caused by multi-sensor. Existing standard Tobit KF and KF are special cases of our modified KF, and simulation results demonstrate the advantages of the proposed event based algorithm as compared with several existing methods. © 2017 Elsevier B.V.","Deadzone; Event based; Information fusion; Kalman filter; Sensor networks"
"Deep learning for pixel-level image fusion: Recent advances and future prospects","2018","Information Fusion","10.1016/j.inffus.2017.10.007","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85033460261&doi=10.1016%2fj.inffus.2017.10.007&partnerID=40&md5=93e443cfd5eb69f4c88913c9acec15c7","By integrating the information contained in multiple images of the same scene into one composite image, pixel-level image fusion is recognized as having high significance in a variety of fields including medical imaging, digital photography, remote sensing, video surveillance, etc. In recent years, deep learning (DL) has achieved great success in a number of computer vision and image processing problems. The application of DL techniques in the field of pixel-level image fusion has also emerged as an active topic in the last three years. This survey paper presents a systematic review of the DL-based pixel-level image fusion literature. Specifically, we first summarize the main difficulties that exist in conventional image fusion research and discuss the advantages that DL can offer to address each of these problems. Then, the recent achievements in DL-based image fusion are reviewed in detail. More than a dozen recently proposed image fusion methods based on DL techniques including convolutional neural networks (CNNs), convolutional sparse representation (CSR) and stacked autoencoders (SAEs) are introduced. At last, by summarizing the existing DL-based image fusion methods into several generic frameworks and presenting a potential DL-based framework for developing objective evaluation metrics, we put forward some prospects for the future study on this topic. The key issues and challenges that exist in each framework are discussed. © 2017 Elsevier B.V.","Convolutional neural network; Convolutional sparse representation; Deep learning; Image fusion; Stacked autoencoder"
"A novel hybrid approach based-SRG model for vehicle position prediction in multi-GPS outage conditions","2018","Information Fusion","10.1016/j.inffus.2017.07.002","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85025653447&doi=10.1016%2fj.inffus.2017.07.002&partnerID=40&md5=f1517ba969fc01eb357c18b1e844069a","Trajectory prediction in autonomous driving system is an important aspect for preventing for instance the multi-vehicle collision. However, predicting accurately the future location of a vehicle is still a delicate task especially in intelligent transport systems. This paper proposes a hybrid approach of solving the position prediction problem of vehicle in multi-GPS outage conditions such as free and partial as well as short and long complete GPS outages. The proposed approach aggregates the advantages of both fuzzy inference system (FIS) and sparse random Gaussian (SRG) models, consequently named FIS-SRG, leading to a significant decrease in position prediction error of vehicle. The aforementioned outages are defined by adjusting the GPS propagation weight monitored by the Gaussian model and updated by fuzzy logic system. Experimental results based on data from GPS and INS and the comparison study with the existing prediction methods illustrate the good performance of the proposed approach, in all considered GPS outage conditions. © 2017 Elsevier B.V.","Fuzzy estimation; GPS outages; Inertial sensors; Prediction method; Vehicle position errors"
"Refined expected value decision rules","2018","Information Fusion","10.1016/j.inffus.2017.10.008","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85033598266&doi=10.1016%2fj.inffus.2017.10.008&partnerID=40&md5=1c31652922733c3435b84b069485941c","We consider the difficult problem of choosing between alternatives where the payoffs for the alternatives are uncertain and modeled via discrete probability distributions. One popular approach for making a choice in this complex environment is to use the idea of expected value; we prefer alternatives with larger expected value. Here we suggest an approach for refining the calculation of the expected value to allow for the inclusion of a requirement that we prefer an alternative with payoff probability distribution P1 to an alternative with payoff probability distribution P2 by assuring that expected value of P1 is larger then the expected value of P2. © 2017 Elsevier B.V.","Decision making; Expected value; Probabilistic uncertainty; Stochastic dominance"
"Entrotaxis as a strategy for autonomous search and source reconstruction in turbulent conditions","2018","Information Fusion","10.1016/j.inffus.2017.10.009","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85037145634&doi=10.1016%2fj.inffus.2017.10.009&partnerID=40&md5=f43440799624bc6abc5a2d13aff79432","This paper proposes a strategy for performing an efficient autonomous search to find an emitting source of sporadic cues of noisy information. We focus on the search for a source of unknown strength, releasing particles into the atmosphere where turbulence can cause irregular gradients and intermittent patches of sensory cues. Bayesian inference, implemented via the sequential Monte Carlo method, is used to update posterior probability distributions of the source location and strength in response to sensor measurements. Posterior sampling is then used to approximate a reward function, leading to the manoeuvre to where the entropy of the predictive distribution is the greatest. As it is developed based on the maximum entropy sampling principle, the proposed framework is termed as Entrotaxis. We compare the performance and search behaviour of Entrotaxis with the popular Infotaxis algorithm, for searching in sparse and turbulent conditions where typical gradient-based approaches become inefficient or fail. The algorithms are assessed via Monte Carlo simulations with simulated data and an experimental dataset. Whilst outperforming the Infotaxis algorithm in most of our simulated scenarios, by achieving a faster mean search time, the proposed strategy is also more computationally efficient during the decision making process. © 2017 The Authors","Autonomous search; Bayesian inference; Dispersion modelling; Sensor management; Sequential Monte Carlo; Turbulent flow"
"Visual and textual information fusion using Kernel method for content based image retrieval","2018","Information Fusion","10.1016/j.inffus.2018.03.006","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046121995&doi=10.1016%2fj.inffus.2018.03.006&partnerID=40&md5=81342e2a629ea6848ba9b2ffc12b131b","In computer vision, each region of an image has an equal and important value that is either an object in an image or the text. The appearance of text within images is certainly a rich information for humans as well as for machines. So far, the art methods have explored either visual features or the social tags to retrieve similar images. Another possibility for image retrieval is to generate fully automatic tags/keywords by extracting embedded and scene text in images along with low-level visual features and fuse them together. Considering this, we have investigated a novel approach to retrieve similar textual images by exploiting visual and textual characteristics of the image. The method extracts visual salient features in first step, and the text is detected and recognized in next step. The method allocates two feature vectors each for visual and textual, and fused them together using Kernel method. The method supports three modes of search: Image query, Keywords, and Combination of both. The experimental results on benchmark datasets shows the textual features can be as effective as visual features for CBIR applications. © 2018 Elsevier B.V.","CBIR; Image retrieval; Information fusion; Textual contents; Visual contents"
"Real-time activity monitoring with a wristband and a smartphone","2018","Information Fusion","10.1016/j.inffus.2017.05.004","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020177947&doi=10.1016%2fj.inffus.2017.05.004&partnerID=40&md5=e8c82df91b61fb3e5f74994284102312","Activity monitoring is a very important task in lifestyle and health domains where physical activity of a person plays an important role in further reasoning or for providing personalized recommendations. To make such services available to a broader population, one should use devices that most users already have, such as smartphones. Since trends show an increasing popularity of wrist-worn wearables we also consider a sensor-rich wristband as an optional device in this research. We present a real-time activity monitoring algorithm which utilizes data from the smartphone sensors, wristband sensors or their fusion for activity recognition and estimation of energy expenditure of the user. The algorithm detects which devices are present and uses an interval of walking for gravity detection and normalization of the orientation of the devices. The normalized data is afterwards used for the detection of the location of the smartphone on the body, which serves as a context for the selection of location-specific classification model for activity recognition. The recognized activity is finally used for the selection of one or multiple regression models for the estimation of the user's energy expenditure. To develop the machine-learning models, which can be deployed on the smartphone, we optimized the number and type of extracted features via automatic feature selection. We evaluated each step of the algorithm and each device configuration, and compared the human energy expenditure estimation results against the Bodymedia armband and Microsoft Band 2. We also evaluated the benefit of decision fusion where appropriate. The results show that we achieve a 87% ± 5% average accuracy for activity recognition and that we outperformed both competing devices in the estimation of human energy expenditure by achieving the mean absolute error of 0.6 ± 0.1 MET on average. © 2017 Elsevier B.V.","Activity recognition; Estimation of energy expenditure; Machine learning; Smartphone sensors; Wristband sensors"
"Consensus, dissension and precision in group decision making by means of an algebraic extension of hesitant fuzzy linguistic term sets","2018","Information Fusion","10.1016/j.inffus.2017.09.004","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030723350&doi=10.1016%2fj.inffus.2017.09.004&partnerID=40&md5=19e1bd07e30c4700e0f40c458761cfa6","Present measures of the degree of agreement in group decision-making using hesitant fuzzy linguistic term sets allow consensus or agreement measurement when decision makers’ assessments involve hesitance. Yet they do not discriminate with different degrees of consensus among situations with discordant or polarized assessments. The visualization of differences among groups for which there is no agreement but different possible levels of disagreement is an important issue in collective decision-making situations. In this paper, we propose new collective and individual consensus measures that explicitly consider the hesitance of the decision makers’ hesitance in giving an opinion and also the gap between non-overlapping assessments, thus allowing the measurement of the polarization present within the group's opinions. In addition, an expert's profile is defined by considering the expert's behavior in previous assessments in group decision-making processes in terms of precision and dissension. © 2017 Elsevier B.V.","Consensus measures; Decision maker's profile; Group decision making; Hesitant fuzzy linguistic term sets"
"Design of an accurate end-of-arm force display system based on wearable arm gesture sensors and EMG sensors","2018","Information Fusion","10.1016/j.inffus.2017.04.009","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019559267&doi=10.1016%2fj.inffus.2017.04.009&partnerID=40&md5=6223aecf2c40daf3b9bfcff68b68da32","Most upper limb rehabilitation patients are still hard to feel the accuracy force they have imposed in the end of arm after a systematic upper limb rehabilitation. In order to provide an accurate end-of-arm force for those disabled people, a force display system based on wearable arm gesture sensors and Electromyographic (EMG) sensors is designed and given in this paper. The wearable arm gesture sensors and EMG sensors are specially placed to detect the arm gesture and the EMG signal of the arm, and a force sensor is used to measure the force and verify the force display effect. In order to control the rehabilitation arm move slowly at a constant speed, the kinematic model of the upper arm is analyzed. A special experiment platform is established so as to get the simultaneous data of end-of-arm force and the arm gesture and EMG signal, then the Generalized Regression Neural Network (GRNN) is brought in to catch the relationship between them. A group of horizontal movement experiment and vertical movement experiment are designed specially and verify the feasibility and effectiveness of the system. The result shows that the information fusion based on GRNN for this system could accurately display the end-of-arm force. © 2017 Elsevier B.V.","Force display; GRNN; Information fusion; Upper limb rehabilitation"
"Event-based filtering for time-varying nonlinear systems subject to multiple missing measurements with uncertain missing probabilities","2017","Information Fusion","10.1016/j.inffus.2017.03.003","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85015660333&doi=10.1016%2fj.inffus.2017.03.003&partnerID=40&md5=e9899be4352d94c29e5e013875b036b4","This paper is concerned with the recursive filtering problem for a class of time-varying nonlinear stochastic systems in the presence of event-triggered transmissions and multiple missing measurements with uncertain missing probabilities. The measurements from different sensors may undergo the missing phenomena, which are characterized by a set of mutually independent Bernoulli random variables and the missing probabilities could be uncertain. In addition, the event-triggered transmission mechanism is introduced to reduce the network communication burden, where the current measurement is transmitted to the remote filter only when it changes greatly compared with the previous one. The aim of this paper is to design a time-varying filter such that, in the presence of the multiple missing measurements, event-triggered transmission mechanism and stochastic nonlinearities, an upper bound of the filtering error covariance is obtained and then minimized by properly designing the filter gain. The explicit form of the filter gain is given in terms of the solutions to two recursive matrix equations. It is shown that the developed filtering scheme is of a recursive form applicable for the online computations. Finally, we provide two illustrative examples to demonstrate the feasibility and applicability of the developed event-triggered filtering scheme. © 2017 Elsevier B.V.","Event-triggered mechanism; Multiple missing measurements; Recursive filtering; Time-varying nonlinear systems; Uncertain missing probabilities"
"I sense overeating: Motif-based machine learning framework to detect overeating using wrist-worn sensing","2018","Information Fusion","10.1016/j.inffus.2017.08.003","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85034581732&doi=10.1016%2fj.inffus.2017.08.003&partnerID=40&md5=8e570065582a3efb6a122e1fe3ca15b9","Obesity, caused primarily by overeating, is a preventable chronic disease yielding staggering healthcare costs. To detect overeating passively, a machine learning framework was designed to detect and accurately count the number of feeding gestures during an eating episode to characterize each eating episode with a feeding gesture count using a 6-axis inertial wrist-worn sensor. Moreover, detecting feeding gestures is useful to aid in end-of-day dietary recalls. It has been shown that feeding gesture count correlates with caloric intake; the more one eats, the more calories one is likely consuming. Recent research has shown promise in passively detecting feeding gestures, but this effort focuses on bridging detection of feeding gesture count and identifying overeating episodes. This paper presents results on three experiments: highly structured (participants pretending to eat), in-lab structured with confounding activities (participants eating while performing other scripted activities), and unstructured overeating (participants induced to overeat while watching television and eating their favorite foods). Our experiment successfully induced overeating in 50% of the participants, showing a correlation between feeding gesture count and caloric intake in unstructured eating (r=.79, p-value=.007). Results provide an approximate upper bound on feeding gesture classification using exact segmentation techniques, and show improvement when compared to prior sliding window techniques. Results also suggest the importance of stressing the challenge of accurate segmentation over identifying the accurate classification technique in detection of feeding gestures. Since participant-dependent models provide optimal results, a motif-based time-point fusion classification (MTFC) framework is proposed using spectral energy density, K-Spectral Centroid Clustering, symbolic aggregate approximation (SAX), a Random Forest classifier (trained on segmented motifs) and a time-point classifier fusion technique to show reliable classification of feeding gestures (75% F-measure), and a 94% accuracy of feeding gesture count in the unstructured eating experiment, resulting in a root mean square error of 2.9 feeding gestures. Mapping feeding gesture count to caloric intake, we obtain a rough estimate of whether participants overate while watching television. © 2017 Elsevier B.V.","Classification; Feeding gesture; Fusion; Hand-to-mouth gestures; Inertial sensors; K-Spectral Centroid Clustering; Motif-based segmentation; Overeating; Wearables; Wrist-worn sensors"
"Event-based distributed recursive filtering for state-saturated systems with redundant channels","2018","Information Fusion","10.1016/j.inffus.2017.04.004","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018780064&doi=10.1016%2fj.inffus.2017.04.004&partnerID=40&md5=00fc888438c8f885a50c1e975bfe40c9","In this paper, the event-based distributed recursive filtering problem is investigated for a class of discrete-time state-saturated systems subject to random occurring nonlinearities and measurement losses over the wireless sensor network. In the addressed measurement model, the sensors are assumed to have redundant communication channels that are helpful in increasing the probability of successfully delivering the measurements. At each intelligent node, the local estimation is obtained based on its own measurement and those transmitted from its neighbors according to the sensor topology. In order to reduce the bandwidth consumption and estimator update frequencies, an event-based signal transmission strategy is employed as opposed to the traditional time-based one. An upper bound for the estimation error covariance is constructed at each time step, which is shown to be the solution of a Riccati-like difference equation. Subsequently, the estimator parameter is designed to minimize such an upper bound. Moreover, the performance of the proposed estimator is analyzed by discussing how the packet losses of the measurements affect the obtained upper bound of the error covariance. Finally, a numerical simulation is exploited to show the effectiveness of the proposed distributed filter design algorithm. © 2017","Distributed filters; Event-based strategy; Redundant channels; State-saturated systems; Wireless sensor networks"
"A Social-aware online short-text feature selection technique for social media","2018","Information Fusion","10.1016/j.inffus.2017.05.003","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019594702&doi=10.1016%2fj.inffus.2017.05.003&partnerID=40&md5=7314a51a50b4631b275c9e90879de89a","Large-scale text categorisation in social environments, characterised by the high dimensionality of feature spaces, is one of the most relevant problems in machine learning and data mining nowadays. Short-texts, which are posted at unprecedented rates, accentuate both the importance of learning tasks and the challenges posed by such large feature space. A collection of social media short-texts does not only provide textual information but also topological information given by the relationships between posts and their authors. The linked nature of social data causes new complementary data dimensions to be added to the feature space, which, at the same time, becomes sparser. Additionally, in the context of social media, posts usually arrive simultaneously in streams, which hinders the deployment of efficient traditional feature selection techniques that assume a feature space fully known in advance. Hence, efficient and scalable online feature selection becomes an important requirement in numerous large-scale social applications. This work presents an online feature selection technique for high-dimensional data based on the integration of two information sources, social and content-based, for the real-time classification of short-text streams coming from social media. It focuses on discovering implicit relations amongst new posts, already known ones and their corresponding authors to identify groups of socially related posts. Then, each discovered group is represented by a set of non-redundant and relevant textual features. Finally, such features are used to train different learning models for classifying newly arriving posts. Extensive experiments conducted on real-world short-texts demonstrate that the proposed approach helps to improve classification results when compared to state-of-the-art and traditional online feature selection techniques. © 2017 Elsevier B.V.","Classification; Micro-blogging communities; Online feature selection"
"Approximate reasoning with generalized orthopair fuzzy sets","2017","Information Fusion","10.1016/j.inffus.2017.02.005","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85015356615&doi=10.1016%2fj.inffus.2017.02.005&partnerID=40&md5=47015c4f15eb3440fc1354641c8b2f2d","We introduce the idea of generalized orthopair fuzzy sets, which provide an extension of intuitionistic fuzzy sets. The basic properties of these generalized orthopair fuzzy sets are discussed. We discuss the use of these sets in knowledge representation. We consider the use of these types of orthopair fuzzy sets as a basis for the system of approximate reasoning introduced by Zadeh. This is referred to as OPAR. The basic operations of OPAR are introduced. A reasoning mechanism in OPAR, based on the idea of entailment, is provided. We look at the formulation of the ideas of possibility and certainty using these orthopair fuzzy sets. © 2017 Elsevier B.V.","Approximate reasoning; Computing with words; Fuzzy logic; Generalized intuitionistic fuzzy sets"
"Big Data: Tutorial and guidelines on information and process fusion for analytics algorithms with MapReduce","2018","Information Fusion","10.1016/j.inffus.2017.10.001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031496391&doi=10.1016%2fj.inffus.2017.10.001&partnerID=40&md5=6a693a569a782eb3fac76e4ac7be22f1","We live in a world were data are generated from a myriad of sources, and it is really cheap to collect and storage such data. However, the real benefit is not related to the data itself, but with the algorithms that are capable of processing such data in a tolerable elapse time, and to extract valuable knowledge from it. Therefore, the use of Big Data Analytics tools provide very significant advantages to both industry and academia. The MapReduce programming framework can be stressed as the main paradigm related with such tools. It is mainly identified by carrying out a distributed execution for the sake of providing a high degree of scalability, together with a fault-tolerant scheme. In every MapReduce algorithm, first local models are learned with a subset of the original data within the so-called Map tasks. Then, the Reduce task is devoted to fuse the partial outputs generated by each Map. The ways of designing such fusion of information/models may have a strong impact in the quality of the final system. In this work, we will enumerate and analyze two alternative methodologies that may be found both in the specialized literature and in standard Machine Learning libraries for Big Data. Our main objective is to provide an introduction of the characteristics of these methodologies, as well as giving some guidelines for the design of novel algorithms in this field of research. Finally, a short experimental study will allow us to contrast the scalability issues for each type of process fusion in MapReduce for Big Data Analytics. © 2017 Elsevier B.V.","Big Data Analytics; Information fusion; Machine learning; MapReduce; Spark"
"Hierarchical ELM ensembles for visual descriptor fusion","2018","Information Fusion","10.1016/j.inffus.2017.07.003","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026740026&doi=10.1016%2fj.inffus.2017.07.003&partnerID=40&md5=6c9a353b60e104a399e7fcec7c224b03","Extreme Learning Machines (ELM) have been successfully applied to variety of classification problems by utilizing a single descriptor type. However, a single descriptor may be insufficient for the visual classification task, due to the high level of intra-class variability coupled with low inter-class distance. Although several studies have investigated methods for combining multiple descriptors by ELM, they predominantly apply a simple concatenation of descriptors before classifying them. This type of descriptor fusion may impose problems of descriptor compatibility, high dimensionality and restricted accuracy. In this paper, we propose a hierarchical descriptors fusion strategy at the decision level (“late-fusion”), which relies on ELM ensembles (ELM-E). The proposed method, denoted as H-ELM-E, effectively combines multiple complementary descriptors by a two-level ELM-E based architecture, which ensures that a more informative descriptors will gain more impact on the final decision. In the first level, a separate ELM-E classifier is trained for every image descriptor. In the second level, the output scores from the previous level are aggregated into the mid-level representation which is conducted to an additional ELM-E classifier. The exhaustive experimental evaluation confirmed that the proposed hierarchical ELM-E based strategy is superior to the single-descriptor methods as well as “early fusion” of multiple descriptors, for the visual classification task. Additionally, it was shown that significant accuracy improvement is achieved by integrating ensembles of ELM as a basic classifier, instead of using a single ELM. © 2017 Elsevier B.V.","Extreme Learning Machine; Feature fusion; Hierarchical classifiers; Scene classification"
"Consensus of fractional nonlinear dynamics stochastic operators for multi-agent systems","2018","Information Fusion","10.1016/j.inffus.2017.11.003","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85036475863&doi=10.1016%2fj.inffus.2017.11.003&partnerID=40&md5=fcd923545456e12710422d1c1c14410e","In this paper, we consider nonlinear models of DeGroot, quadratic stochastic operators (QSO) and doubly stochastic quadratic operators (DSQO) with fractional degree for consensus problem in multi-agent systems (MAS). By the limit behaviour of nonlinear approach, we discuss the convergence of the solutions of the models considered. The findings from the results of the carried out investigation demonstrates an efficient approach to convergence for consensus problem in MAS. The main advantages of the proposed work are i) fast convergence to consensus ii) flexible and low complexity in computation iii) ability to achieve optimal consensus. The study is built on fractional representation of [Formula presented] where n → ∞. Further, the simulation results on the related protocols are also presented. © 2017 Elsevier B.V.","Consensus problem; Fractional consensus; Multi-agent systems; Nonlinear stochastic operators"
"A sensor fusion approach for drowsiness detection in wearable ultra-low-power systems","2018","Information Fusion","10.1016/j.inffus.2017.11.005","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85035782009&doi=10.1016%2fj.inffus.2017.11.005&partnerID=40&md5=9609e3a7309a5d0f543d85b95fb84cc3","Drowsiness detection mechanisms have been extensively studied in the last years since they are one of the prevalent causes of accidents within the mining, driving and industrial activities. Many research efforts were done to quantify the drowsiness levels using behavioral analyses based on camera eye tracking systems as well as by analyzing physiological features contained in EEG signals. Detection systems typically use specific drowsiness indicators from only one of these methods, leaving a risk of missed detection since not all the population presents same symptoms of drowsiness. Thus, multi-feature systems are preferable even though most of the current State-of-the-Art (SoA) solutions are based on power-hungry platforms and they have meager chance to be used in embedded wearable applications with long battery lifetime. This work presents a drowsiness detection scheme fusing behavioral information coming from user motion through an IMU sensor and physiological information coming from brain activity through a single EEG electrode. The solution is implemented and tested on a low power programmable platform based on an ARM Cortex-M4 microcontroller, resulting in a wearable device capable to detect 5 different levels of drowsiness with an average accuracy of 95.2% and a battery life of 6 hours, using a 200 mAh battery. We also study the energy optimization achievable by accelerating the sensor fusion-based drowsiness detector on a parallel ultra-low power (PULP) platform. Results show that the use of PULP as efficient processing platform provides an energy improvement of 63x with respect to a solution based on a commercial microcontroller. This may extend the battery life of the complete system up to 46 h with a 7x improvement, paving the way for a completely wearable, always-on system. © 2017 Elsevier B.V.","Drowsiness detection; EEG; Fatigue monitoring; Sensor fusion; Wearable"
"Hierarchical information fusion for decision making in craniofacial superimposition","2018","Information Fusion","10.1016/j.inffus.2017.03.004","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85016581991&doi=10.1016%2fj.inffus.2017.03.004&partnerID=40&md5=19a474a34f20d721fedf02e10163b157","Craniofacial superimposition is one of the most important skeleton-based identification methods. The process studies the possible correspondence between a found skull and a candidate (missing person) through the superimposition of the former over a variable number of images of the face of the latter. Within craniofacial superimposition we identified three different stages, namely: (1) image acquisition-processing and landmark location; (2) skull-face overlay; and (3) decision making. While we have already proposed and validated an automatic skull-face overlay technique in previous works, the final identification stage, decision making, is still performed manually by the expert. This consists of the determination of the degree of support for the assertion that the skull and the ante-mortem image belong to the same person. This decision is made through the analysis of several criteria assessing the skull-face anatomical correspondence based on the resulting skull-face overlay. In this contribution, we present a hierarchical framework for information fusion to support the anthropologist expert in the decision making stage. The main goal is the automation of this stage based on the use of several skull-face anatomical criteria combined at different levels by means of fuzzy aggregation functions. We have implemented two different experiments for our framework. The first aims to obtain the most suitable aggregation functions for the system and the second validates the proposed framework as an identification system. We tested the framework with a dataset of 33 positive and 411 negative identification instances. The present proposal is the first automatic craniofacial superimposition decision support system evaluated in an objective and statistically meaningful way. © 2017 Elsevier B.V.","Computer vision; Craniofacial superimposition; Decision making; Forensic anthropology; Fuzzy aggregation operators; Information fusion"
"Biometric information fusion for web user navigation and preferences analysis: An overview","2017","Information Fusion","10.1016/j.inffus.2017.02.006","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019897318&doi=10.1016%2fj.inffus.2017.02.006&partnerID=40&md5=1654666619dc450c1155407d740d9c53","Throughout the years having knowledge of Web users’ interests, navigational actions and preferences has gained importance due to the objectives of organizations and companies. Traditionally this field has been studied from the Web Mining perspective, particularly through the Web Usage Mining (WUM) concept, which consists of the application of machine learning techniques over data originated in the Web (Web data) for automatic extraction of behavioral patterns from Web users. WUM makes use of data sources that approximate users’ behavior, such as weblogs or clickstreams among others; however these sources imply a considerable degree of subjectivity to interpret. For that reason, the application of biometric tools with the possibility of measuring actual responses to the stimuli presented via websites has become of interest in this field. Instead of doing separate analyses, information fusion (IF) tries to improve results by developing efficient methods for transforming information from different sources into a single representation, which then could be used to guide biometric data fusion to complement the traditional WUM studies and obtain better results. This paper presents a survey of Biometric IF applied to the WUM field, by first defining WUM and its main applications, later explaining how the Biometric IF could be applied and finally reviewing several studies that apply this concept to WUM. © 2017 Elsevier B.V.","Biometric data; Information fusion; Web usage mining"
"Reaching a consensus with minimum adjustment in MAGDM with hesitant fuzzy linguistic term sets","2018","Information Fusion","10.1016/j.inffus.2017.08.006","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030702840&doi=10.1016%2fj.inffus.2017.08.006&partnerID=40&md5=48f87c8eab0d6153a70256cbefef66d0","In real decision making, decision makers tend to express their opinions with uncertainty when facing complicated decision problem and environment. This paper develops a novel consensus reaching process for multiple attribute group decision making (MAGDM) with hesitant fuzzy linguistic term sets (HFLTSs). Firstly, we define a new distance measure for two HFLTSs and propose a distance-based consensus measure for the MAGDM with HFLTSs. Then, based on this consensus measure, we develop a minimum adjustment distance consensus rule for the MAGDM with HFLTSs, which can minimize the adjustment distance between the original and adjusted opinions in the process of reaching consensus. Moreover, to obtain the collective opinion with maximum consensus, we develop a minimum distance aggregation model, which is to minimize the maximum of the distance between each decision maker's individual opinion and the collective opinion. Furthermore, based on the proposed consensus rule and aggregation model, we present a consensus reaching process for MAGDM with HFLTSs. Finally, we provide the convergence proof of the consensus reaching process, and a numerical example is used to demonstrate the validity of the consensus reaching process. © 2017 Elsevier B.V.","Consensus reaching process; Hesitant fuzzy linguistic term sets; Minimum adjustment distance; Multiple attribute group decision making"
"A general framework for boosting feature subset selection algorithms","2018","Information Fusion","10.1016/j.inffus.2018.03.003","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046364680&doi=10.1016%2fj.inffus.2018.03.003&partnerID=40&md5=0bac04ca15cbc558f59901f81b187a1c","Feature selection is one of the most important tasks in many machine learning and data mining problems. Due to the increasing size of the problems, removing useless, erroneous or noisy features is frequently an initial step that is performed before other data mining algorithms are applied. The aim is to reproduce, or even improve, the performance of the data mining algorithm when all the features are used. Furthermore, the selection of the most relevant features may offer the expert valuable information about the problem to be solved. Over the past few decades, many different feature selection algorithms have been proposed, each with its own strengths and weaknesses. However, as in the case of classification, it is unlikely that a single feature selection algorithm would be able to achieve good results across many different datasets and application fields. Furthermore, when we are dealing with thousands of features, the most powerful feature selection methods are frequently too time consuming to be applied. In classification, one of the most successful ways of consistently improving the performance of a single weak learner is to construct ensembles using boosting methods. In this paper, we propose a general framework for feature selection boosting in the same way boosting is applied to classification. The proposed approach opens a new field of research in which to apply the many techniques developed for boosting classifiers. Using 120 datasets, the experiments reported show a clear improvement in several state-of-the-art feature selection algorithms using the proposed methodology. © 2018 Elsevier B.V.","Boosting; Classifier ensembles; Feature selection"
"A comprehensive survey on the reliability of mobile wireless sensor networks: Taxonomy, challenges, and future directions","2018","Information Fusion","10.1016/j.inffus.2018.03.005","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046348873&doi=10.1016%2fj.inffus.2018.03.005&partnerID=40&md5=371b9359ed7668945b6c5304ebdcf930","With the development and popularization of mobile terminal technology, mobile wireless sensor networks (MWSNs) have become a new evolution trend in wireless sensor networks (WSNs) technology. The mobility of nodes introduced by MWSNs greatly expands the application range of WSNs. However, the mobility of the sink node also induces changes of the network topology, time delays, and packet loss rates, which can greatly affect the routing performance of the networks. In addition, the reliability and robustness of the networks are also greatly affected and challenged. The theories and methods applied to WSNs previously, such as data collection, reliable data transmission, network reliability, network topologies, and routing protocols are not currently available for MWSNs. The introduction of mobility features into traditional static WSNs brings new challenges for the stability, security, and reliability of WSNs. Reliability is an important index for evaluating the performance of MWSNs. Moreover, the reliability of the data transmission determines the practical value of MWSNs. The stable and reliable operation of MWSNs requires ongoing and important work. Therefore, in this article, we present a comprehensive and meticulous investigation of the reliability theory of MWSNs which was developed in recent years. This article outlines the classification and features of MWSNs. Specifically, we systematically analyze the research direction and recent progress made in the field of MWSNs. The existing methods are systematically compared and the advantages and disadvantages of the methods are presented. The main parameters of comparison include time delays, network size, energy efficiency, scalability, and reliability. Finally, some open questions and future research directions are presented at the end of this article. © 2018 Elsevier B.V.","Internet of things; Mobile wireless sensor networks; Network performance; Reliability; Routing protocol"
"Unconstrained Kinect video face database","2018","Information Fusion","10.1016/j.inffus.2017.09.002","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042702736&doi=10.1016%2fj.inffus.2017.09.002&partnerID=40&md5=144a2f366e133b75d90147ee735a85b3","Unconstrained face recognition poses several challenges to existing algorithms and to address these variations, different methodologies are proposed, including utilizing video and 3D (depth) information. With the introduction of consumer level depth capturing devices such as Microsoft Kinect, research has been performed in utilizing low cost RGB-D depth data for characterizing and matching faces. Next generation of Kinect device, the Kinect version 2, has also been released which provides higher resolution color, depth and near infrared images at a comparable sensor cost. Such multiple information obtained from a single sensor can be extremely helpful in designing novel algorithms and systems for object and face recognition. This paper introduces the KaspAROV RGB-D video face database which contains face videos and images from both versions of the Kinect device for over 100 subjects which will be made available to the research community. The database captured in visible and NIR spectrum (along with depth) encompasses face images and videos with challenges such as pose, distance, and illumination. The database can be used to evaluate the performance of face recognition algorithms which utilize either uni-spectrum or multi-spectrum information. We provide standard experimental protocols for ease of comparative evaluation on the database and also include baseline results using several existing algorithms including a commercial face recognition system and deep learning algorithm. © 2017 Elsevier B.V.","Biometrics; Database; Face detection; Face recognition; Multi-modal biometrics; Video"
"A consensus model for large-scale group decision making with hesitant fuzzy information and changeable clusters","2018","Information Fusion","10.1016/j.inffus.2017.09.011","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029584866&doi=10.1016%2fj.inffus.2017.09.011&partnerID=40&md5=da0ed044efc2c5e52fa78a319ec299a5","In the large-scale group decision making (LGDM) consensus process, it is usually assumed that the obtained clusters do not change. However, as the individual preferences change as part of the decision process, this is generally not the case. The aim of this paper, therefore, is to propose a LGDM consensus model in which the clusters are allowed to change and the decision makers provide preferences using fuzzy preference relations. The most commonly used clustering method, k-means, is introduced to identify the subgroups and a possibility distribution based hesitant fuzzy element (PDHFE) is employed to represent each cluster preference. A novel distance measure over the PDHFEs is given to compute the various consensus measures, after which a local feedback strategy with four identification rules and two direction rules is designed to guide the consensus reaching process. The proposed model is distinguished from previous studies where the changes occur on the obtained clusters that the feedback mechanism is directly based on the decision makers in the identified clusters. Further, as the clusters (virtual or nominal) change in every interactive consensus round, the consensus process evolution can be captured. Finally, an emergency decision to choose a rescue plan is illustrated to validate the proposed method and demonstrate distinctive characteristics compared with the existing approaches. © 2017 Elsevier B.V.","Consensus; Hesitant fuzzy element; Large-scale group decision making (LGDM); Local feedback strategy; Possibility distribution"
"A new approach to map-assisted Bayesian tracking filtering","2019","Information Fusion","10.1016/j.inffus.2018.01.002","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041454466&doi=10.1016%2fj.inffus.2018.01.002&partnerID=40&md5=7eb1b8fce81991633bda33054ee8c2b4","This paper presents a new non-linear filter designed to track targets following a road network, taking advantage of the road map information. The algorithm is based on a Bayesian Multiple Hypotheses modelling of movement process, postulating and evaluating different hypotheses on the segments being followed by the target after road junctions. Then, the along-road tracking is carried out, for each hypothesis, by a longitudinal IMM filter capable of tracking target movements along straight roads, circular segments, and generic curvilinear segments defined through Bézier curves. The algorithm also includes a lateral drift estimator, which tracks the lateral motion of the target with respect to road axis, to be able to estimate target piloting error and especially to track targets in wide roads. The paper completely describes the filter and associated measurement preprocessing procedures, and also includes a comparative evaluation of the proposed filter with other filtering methods in the literature. © 2018 Elsevier B.V.","Context based tracking; Ground target tracking; IMM; MHT; Non-linear tracking"
"An approach to quality function deployment based on probabilistic linguistic term sets and ORESTE method for multi-expert multi-criteria decision making","2018","Information Fusion","10.1016/j.inffus.2017.11.008","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85034749848&doi=10.1016%2fj.inffus.2017.11.008&partnerID=40&md5=9dc6c9ef679a855eeba4f614c0a607cb","The quality function deployment (QFD) is an effective tool to translate the customer requirements (CRs) to the design requirements (DRs) of a product. The process of selecting the optimal innovative product design to maximize customer satisfaction is full of uncertainty and fuzziness regarding to the users’ preferences, the relationships between CRs and DRs and the merits of product designs. This study proposes a multi-expert multi-criteria decision making method to solve the innovative product design selection problem by developing an enhanced QFD method combined with the complicated fuzzy linguistic representation model, the probabilistic linguistic term set (PLTS), and the ranking method, ORESTE. Firstly, we propose a probability aggregation method to integrate the individuals’ subjective evaluations into group ones expressed as PLTSs. On this basis, we extend the QFD into the probabilistic linguistic context to get the DRs’ fuzzy weights. Then, based on a new distance measure between PLTSs, a probabilistic linguistic global preference score function and three kinds of probabilistic linguistic preference intensity formulas are proposed. Furthermore, we develop a PL-ORESTE method to obtain the preference, indifference and incomparability relations between the alternatives. For the facility of application, we develop the procedure of the QFD-based PL-ORESTE method. Given that the “shared cars” is a new industry appeared in Chinese market, we finally illustrate the applicability of the proposed method by a case study concerning the selection of innovative designs of Panda shared cars. © 2017 Elsevier B.V.","Innovative product design selection; Multi-expert multi-criteria decision making; ORESTE; Probabilistic linguistic term set; Quality function deployment; Shared cars"
"Multistage fusion approaches based on a generative model and multivariate exponentially weighted moving average for diagnosis of cardiovascular autonomic nerve dysfunction","2018","Information Fusion","10.1016/j.inffus.2017.08.004","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028998217&doi=10.1016%2fj.inffus.2017.08.004&partnerID=40&md5=99262c3acd2b27e264e8df98d507832c","Like many medical diagnoses, clinical decision support system (CDSS) is essential to diagnose the cardiovascular autonomic neuropathy (CAN). However, diagnosis of CAN using the traditional ‘Ewing battery test’ becomes very difficult due to the inherent imbalanced and incompleteness condition in the collected clinical data. This influences the health professionals to investigate other related diagnostic reports of patients, including Electrocardiogram (ECG) data from ECG sensors, blood chemistry, podiatry and endocrinology features. However, additional components increase the dimensionality of the feature set as well as its heterogeneity and modality in the clinical data which may limit the applications of traditional data mining approaches for an accurate diagnosis of CAN in the CDSS. To address the aforementioned problem, in this paper, we have proposed, a novel multistage fusion approach based on a generative model and a statistical process control (SPC) technique to diagnose CAN more accurately. The proposed approach develops two different generative models by using a shared and a separated Independent Component Analysis (ICA) to overcome the incompleteness and modality of the data. Due to the heterogeneous and non-normality features, statistical correlations and multivariate control limits in relation to the CAN diagnosis parameters are determined by fusioning of a series of exponentially weighted moving average (MEWMA) control processes. Fusioned features from both component analyses and SPC are applied in an ensemble classification system. The proposed multistage fusion approach is experimentally verified to justify its performance by using a large dataset collected from the diabetes screening research initiative (DiScRi) project at Charles Sturt University, NSW, Australia. Our comprehensive experimental results show that the proposed fusion approach performs better than the standard classifier for both ‘Ewing’ feature set and ‘Ewing and additional feature set’ with significant improvement in accuracy. © 2017 Elsevier B.V.","Autonomic nerve dysfunction classification; Blind source separation; Fusion of features and decisions; Fusion of multiple statistical process control techniques; Multivariate exponentially weighted moving average"
"SCARFF: A scalable framework for streaming credit card fraud detection with spark","2018","Information Fusion","10.1016/j.inffus.2017.09.005","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029580394&doi=10.1016%2fj.inffus.2017.09.005&partnerID=40&md5=f4bd2ce7959cf01ffd4a285eb36b10d0","The expansion of the electronic commerce, together with an increasing confidence of customers in electronic payments, makes of fraud detection a critical factor. Detecting frauds in (nearly) real time setting demands the design and the implementation of scalable learning techniques able to ingest and analyse massive amounts of streaming data. Recent advances in analytics and the availability of open source solutions for Big Data storage and processing open new perspectives to the fraud detection field. In this paper we present a Scalable Real-time Fraud Finder (SCARFF) which integrates Big Data tools (Kafka, Spark and Cassandra) with a machine learning approach which deals with imbalance, nonstationarity and feedback latency. Experimental results on a massive dataset of real credit card transactions show that this framework is scalable, efficient and accurate over a big stream of transactions. © 2017 Elsevier B.V.","Big data; Cassandra; Fraud detection; Kafka; Machine learning; Scalable software; Spark; Streaming analytics"
"Continuous m-dimensional distorted probabilities","2018","Information Fusion","10.1016/j.inffus.2017.12.004","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85039798077&doi=10.1016%2fj.inffus.2017.12.004&partnerID=40&md5=91be20cdc897b861539e6e19171d2de7","Fuzzy measures, also known as non-additive measures, monotonic games, and capacities, have been used in many contexts. For example, in economics, risk analysis, in computer science, computer vision and machine learning and, in general, in mathematics. However, when looking at applications, one of the problems that still needs to be solved is how the measure should be defined in an easy and intuitive way. When the reference set is finite, a few families of measures have been established, e.g. distorted probabilities, k-additive and decomposable measures. But, when the reference set is infinite, the only family is distorted probabilities. In this paper we give a definition for m-dimensional distorted probabilities in the case that the reference set is not finite, and we study some properties of this family. We also give a definition for hierarchically decomposable m-dimensional distorted probabilities that relates to another family of measures defined for the finite case. © 2017 Elsevier B.V.","Fuzzy measure; m-dimensional distorted probabilities; Non-additive measures"
"A rank fusion approach based on score distributions for prioritizing relevance assessments in information retrieval evaluation","2018","Information Fusion","10.1016/j.inffus.2017.04.001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85017248175&doi=10.1016%2fj.inffus.2017.04.001&partnerID=40&md5=07a26004e942ab741f82d3df20cdead6","In this paper we study how to prioritize relevance assessments in the process of creating an Information Retrieval test collection. A test collection consists of a set of queries, a document collection, and a set of relevance assessments. For each query, only a sample of documents from the collection can be manually assessed for relevance. Multiple retrieval strategies are typically used to obtain such sample of documents. And rank fusion plays a fundamental role in creating the sample by combining multiple search results. We propose effective rank fusion models that are adapted to the characteristics of this evaluation task. Our models are based on the distribution of retrieval scores supplied by the search systems and our experiments show that this formal approach leads to natural and competitive solutions when compared to state of the art methods. We also demonstrate the benefits of including pseudo-relevance evidence into the estimation of the score distribution models. © 2017 Elsevier B.V.","Evaluation; Information retrieval; Pooling; Pseudo-relevance; Rank fusion; Score distributions"
"BFSI-B: An improved K-hop graph reachability queries for cyber-physical systems","2017","Information Fusion","10.1016/j.inffus.2017.02.009","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85015057756&doi=10.1016%2fj.inffus.2017.02.009&partnerID=40&md5=9529b81835fda21659fa0c18a6366dd5","Cyber-physical systems, encompass the real physical space and virtual cyber space for providing advanced service for humans, which together, are also namely Internet of Things. The complex and large scale relationships among nodes contain the potential information of user, which is required and essential for providing high quality personalized service. Graph is used to represent, make fusion and process the relationships data, which has been used in many domains with traditional small data sets. K-hop reachability query answering in graphs is seeing a growing number of applications, such as ranked keyword search in databases, social networking, ontology reasoning and bioinformatics. Currently, techniques for efficient evaluation of such queries are based on vertex-cover technology. These methods suffer from a lack of scalability; that is, they cannot be applied to very large graphs. To solve these problems, we propose the compound-index method, namely BFSI-B, which uses the special index to decrease the k-hop reachability query time and improve pruning efficiency. The theoretical analysis and experiment results demonstrate that our method has a smaller index size and a faster query time than the k-reach method, in both dense graphs and very large graphs. © 2017","BFSI-B; K-hop reachability queries; Large graph; Online search"
"Review of ensembles of multi-label classifiers: Models, experimental study and prospects","2018","Information Fusion","10.1016/j.inffus.2017.12.001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85039714911&doi=10.1016%2fj.inffus.2017.12.001&partnerID=40&md5=ba73ae68f805dff91b330817f60c4a1c","The great attention given by the scientific community to multi-label learning in recent years has led to the development of a large number of methods, many of them based on ensembles. A comparison of the state-of-the-art in ensembles of multi-label classifiers over a wide set of 20 datasets have been carried out in this paper, evaluating their performance based on the characteristics of the datasets such as imbalance, dependence among labels and dimensionality. In each case, suggestions are given to choose the algorithm that fits best. Further, given the absence of taxonomies of ensembles of multi-label classifiers, a novel taxonomy for these methods is proposed. © 2017 Elsevier B.V.","Ensemble methods; Multi-label classification"
"Dynamic ensemble selection for quantification tasks","2019","Information Fusion","10.1016/j.inffus.2018.01.001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041416252&doi=10.1016%2fj.inffus.2018.01.001&partnerID=40&md5=5d0edd603bc926500bc6a3f9b88ae366","Ensembles are among the most effective and successful methods for almost all supervised tasks. Not long ago, an ensemble approach has been proposed for quantification learning. The idea of such method is to exploit the prior knowledge about quantification tasks, building ensembles in which diversity is achieved by training each model with a different distribution. These training samples are generated taking into account the expected drift in class distribution. This paper extends this method proposing three new quantifier selection criteria particularly devised for quantification problems, where two of them are defined for dynamic ensemble selection. The experiments demonstrate that, in many cases, these selection functions outperform straightforward approaches, like averaging all models and using quantification accuracy to prune the ensemble. Moreover, the results show that performance heavily depends on the combination of the base quantification algorithm and the selection measure. © 2018 Elsevier B.V.","Dynamic ensemble selection; Ensembles; Quantification"
"A new proposal to deal with hesitant linguistic expressions on preference assessments","2018","Information Fusion","10.1016/j.inffus.2017.09.007","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029502651&doi=10.1016%2fj.inffus.2017.09.007&partnerID=40&md5=7ccb007d7ea536f0883fa142902b8ac8","Information fusion and hesitant information fusion represent an important part of decision making processes. This paper focuses on hesitant expressions and the way to take them into account in the computations, using weights served by a simple but efficient process. In a previous paper we have proposed to use an operator called the symbolic weighted median to express hesitant linguistic assessments such as “I hesitate between this and that but I tend to lean toward that alternative”. Now we go further in explaining in detail how to transform such expressions into our hesitant operators. Inspired by language science research, several hesitant linguistic expressions are discussed, including linguistic modifiers and qualifiers, then they are transformed into weight vectors before being aggregated to complete information fusion. © 2017 Elsevier B.V.",""
"Naïve Bayes switching linear dynamical system: A model for dynamic system modelling, classification, and information fusion","2018","Information Fusion","10.1016/j.inffus.2017.10.002","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032181819&doi=10.1016%2fj.inffus.2017.10.002&partnerID=40&md5=bec9b8d5bc7ccab1fdd8c9e3369f17c5","The Naïve Bayes Switching Linear Dynamical System (NB-SLDS) is proposed as a novel variant of the switching linear dynamical system (SLDS). The variant models multi-variable systems that undergo regime changes in their dynamics. The model may be applied to identify regime changes or classify systems according to their dynamics. The NB-SLDS provides the means to fuse multiple sequential data sources into a single model. A key feature of the model is that it is able to handle missing and unsynchronised data. Filtering and smoothing algorithms for inference and an expectation maximisation algorithm for parameter learning in the NB-SLDS are presented. The model is demonstrated and compared to the SLDS and hidden Markov model (HMM) in a human action recognition problem. © 2017","Classification; Dynamic Bayesian network; Missing data; Regime model; Time series"
"Semi-supervised clue fusion for spammer detection in Sina Weibo","2018","Information Fusion","10.1016/j.inffus.2017.11.002","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85036462577&doi=10.1016%2fj.inffus.2017.11.002&partnerID=40&md5=6555dda4594d614c7e4ba6b79cec08a0","Microblog is a popular social network platform that facilitates users to collect and spread information on the Internet, but on the other side it stimulates new forms of spammers, who can hinder effective information dissemination. Spammers in Sina Weibo use various spamming strategies to evade protection mechanisms, which presents practical challenges in spammer detection. First, clues to identify spammers are usually hidden in multiple aspects, such as content, behavior, relationship, and interaction. Second, labeled training instances are lacking for learning. In this paper, a novel approach called Semi-Supervised Clue Fusion (SSCF) is proposed to conduct effective spammer detection in Sina Weibo. SSCF acquires a linear weighted function to fuse the comprehensive clues explored from multiple aspects to obtain final results. SSCF iteratively predicts the unlabeled instances based on a small size of primarily labeled instances in a semi-supervised fashion. SSCF is empirically validated on the real-world data from Sina Weibo. Results show that this approach significantly outperforms state-of-the-art baselines. © 2017 Elsevier B.V.","Fusion; Multiple views; Sina Weibo; Spammer"
"Collaborative fusion estimation over wireless sensor networks for monitoring CO2 concentration in a greenhouse","2018","Information Fusion","10.1016/j.inffus.2017.11.001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032944136&doi=10.1016%2fj.inffus.2017.11.001&partnerID=40&md5=d0271b18fcc74e119656de210bfed3cc","This paper investigates the data fusion problem over wireless sensor networks (WSNs) for monitoring the carbon dioxide (CO2) concentration in a greenhouse. CO2 concentration is an important environmental parameter in the greenhouse, and adequate regulation of CO2 concentration is certainly beneficial to the improvement of the crop growth efficiency in the greenhouse. Since the measurement of CO2 concentration is unavoidably subject to environmental interferences (e.g. noises), it is vitally important to estimate the true CO2 concentration through available sensor measurements over a WSN with given topology. In this paper, based on the Consensus–Kalman filter, the distributed estimation scheme is presented to improve the state estimation accuracy. After the distributed consensus estimation, the head node can conduct the fusion estimation on the data from the available sensor nodes. The packet loss phenomenon brought by unreliable communication links is reflected by the proportion of the faulty sensors. To further alleviate the effects from the packet losses, we propose a modified estimation scheme for the head node that combines the estimates from sensor node at both the previous and current time points, thereby enhancing the accuracy of data fusion. Simulation analysis is carried out on the collected information of CO2 concentration in the greenhouse in order to demonstrate the effectiveness of the proposed scheme. © 2017 Elsevier B.V.","CO<sub>2</sub> concentration; Consensus–Kalman filter; Data fusion; Greenhouse monitor"
"Mode tracking using multiple data streams","2018","Information Fusion","10.1016/j.inffus.2017.11.011","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85037072003&doi=10.1016%2fj.inffus.2017.11.011&partnerID=40&md5=bd0f1e3e41b978a37733e5c1c08c5347","Most existing work in information fusion focuses on combining information with well-defined meaning towards a concrete, pre-specified goal. In contradistinction, we instead aim for autonomous discovery of high-level knowledge from ubiquitous data streams. This paper introduces a method for recognition and tracking of hidden conceptual modes, which are essential to fully understand the operation of complex environments, and an important step towards building truly intelligent aware systems. We consider a scenario of analyzing usage of a fleet of city buses, where the objective is to automatically discover and track modes such as highway route, heavy traffic, or aggressive driver, based on available on-board signals. The method we propose is based on aggregating the data over time, since the high-level modes are only apparent in the longer perspective. We search through different features and subsets of the data, and identify those that lead to good clusterings, interpreting those clusters as initial, rough models of the prospective modes. We utilize Bayesian tracking in order to continuously improve the parameters of those models, based on the new data, while at the same time following how the modes evolve over time. Experiments with artificial data of varying degrees of complexity, as well as on real-world datasets, prove the effectiveness of the proposed method in accurately discovering the modes and in identifying which one best explains the current observations from multiple data streams. © 2017 Elsevier B.V.","Clustering; Data streams; Knowledge discovery; Mode tracking; Time series"
"Smart system for children's chronic illness monitoring","2018","Information Fusion","10.1016/j.inffus.2017.06.002","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020911988&doi=10.1016%2fj.inffus.2017.06.002&partnerID=40&md5=f4167afb7989e8ec1143ca1613990301","Sick children need a continuous monitoring, but this involves high costs for the government and for the parents. The use of information and communication technologies (ICT) jointly with artificial intelligence and smart devices can reduce these costs, help the children and assist their parents. This paper presents a smart architecture for children's chronic illness monitoring that will let the caregivers (parents, teachers and doctors) to remotely monitor the health of the children based on the sensors embedded in the smartphones and smart wearable devices. The proposed architecture includes a smart algorithm developed to intelligently detect if a parameter has exceeded a threshold, thus it may imply an emergency or not. To check the correct operation of this system, we have developed a small wearable device that is able to measure the heart rate and the body temperature. We have designed a secure mechanism to stablish a Bluetooth connection with the smartphone. In addition, the system is able to perform the data fusion in both the information packetizing process, which contributes to improve the protocol performance, and in the measured values combination, where it is used a stochastic approach. As a result, our system can fusion data from different sensors in real-time and detect automatically strange situations for sending a warning to the caregivers. Finally, the consumed bandwidth and battery autonomy of the developed device have been measured. © 2017 Elsevier B.V.","Child monitoring; Chronic diseases; eHealth; Smart algorithm; Wearable devices"
"Sparse representation based multi-sensor image fusion for multi-focus and multi-modality images: A review","2018","Information Fusion","10.1016/j.inffus.2017.05.006","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020791523&doi=10.1016%2fj.inffus.2017.05.006&partnerID=40&md5=5dd1b321fcf04fd5d5400aed07d9726a","As a result of several successful applications in computer vision and image processing, sparse representation (SR) has attracted significant attention in multi-sensor image fusion. Unlike the traditional multiscale transforms (MSTs) that presume the basis functions, SR learns an over-complete dictionary from a set of training images for image fusion, and it achieves more stable and meaningful representations of the source images. By doing so, the SR-based fusion methods generally outperform the traditional MST image fusion methods in both subjective and objective tests. In addition, they are less susceptible to mis-registration among the source images, thus facilitating the practical applications. This survey paper proposes a systematic review of the SR-based multi-sensor image fusion literature, highlighting the pros and cons of each category of approaches. Specifically, we start by performing a theoretical investigation of the entire system from three key algorithmic aspects, (1) sparse representation models; (2) dictionary learning methods; and (3) activity levels and fusion rules. Subsequently, we show how the existing works address these scientific problems and design the appropriate fusion rules for each application such as multi-focus image fusion and multi-modality (e.g., infrared and visible) image fusion. At last, we carry out some experiments to evaluate the impact of these three algorithmic components on the fusion performance when dealing with different applications. This article is expected to serve as a tutorial and source of reference for researchers preparing to enter the field or who desire to employ the sparse representation theory in other fields. © 2017 Elsevier B.V.","Activity level; Dictionary learning; Image fusion; Sparse representation"
"Preference rules for label ranking: Mining patterns in multi-target relations","2018","Information Fusion","10.1016/j.inffus.2017.07.001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85024868885&doi=10.1016%2fj.inffus.2017.07.001&partnerID=40&md5=e208f5bf1b21fcce7224097fa6a2b6fb","In this paper, we investigate two variants of association rules for preference data, Label Ranking Association Rules and Pairwise Association Rules. Label Ranking Association Rules (LRAR) are the equivalent of Class Association Rules (CAR) for the Label Ranking task. In CAR, the consequent is a single class, to which the example is expected to belong to. In LRAR, the consequent is a ranking of the labels. The generation of LRAR requires special support and confidence measures to assess the similarity of rankings. In this work, we carry out a sensitivity analysis of these similarity-based measures. We want to understand which datasets benefit more from such measures and which parameters have more influence in the accuracy of the model. Furthermore, we propose an alternative type of rules, the Pairwise Association Rules (PAR), which are defined as association rules with a set of pairwise preferences in the consequent. While PAR can be used both as descriptive and predictive models, they are essentially descriptive models. Experimental results show the potential of both approaches. © 2017 Elsevier B.V.","Association rules; Label ranking; Pairwise comparisons"
"Multiview dimension reduction via Hessian multiset canonical correlations","2018","Information Fusion","10.1016/j.inffus.2017.09.001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028972232&doi=10.1016%2fj.inffus.2017.09.001&partnerID=40&md5=d0937224860436347425758b6f8fb2f9","Canonical correlation analysis (CCA) is a main technique of linear subspace approach for two-view dimension reduction by finding basis vectors with maximum correlation between the pair of variables. The shortcoming of the traditional CCA lies that it only handles data represented by two-view features and cannot reveal the nonlinear correlation relationship. In recent years, many variant algorithms have been developed to extend the capability of CCA such as discriminative CCA, sparse CCA, kernel CCA, locality preserving CCA and multiset canonical correlation analysis (MCCA). One representative work is Laplacian multiset canonical correlations (LapMCC) that employs graph Laplacian to exploit the nonlinear correlation information for multiview high-dimensional data. However, it possibly leads to poor extrapolating power because Laplacian regularization biases the solution towards a constant function. In this paper, we present Hessian multiset canonical correlations (HesMCC) for multiview dimension reduction. Hessian can properly exploit the intrinsic local geometry of the data manifold in contrast to Laplacian. HesMCC takes the advantage of Hessian and provides superior extrapolating capability and finally leverage the performance. Extensive experiments on several popular datasets for handwritten digits classification, face classification and object classification validate the effectiveness of the proposed HesMCC algorithm by comparing it with baseline algorithms including TCCA, KMUDA, MCCA and LapMCC. © 2017 Elsevier B.V.","Canonical correlation analysis; Dimension reduction; Hessian; Multiview"
"Novel efficient deployment schemes for sensor coverage in mobile wireless sensor networks","2018","Information Fusion","10.1016/j.inffus.2017.08.001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85034055625&doi=10.1016%2fj.inffus.2017.08.001&partnerID=40&md5=5256383fd2ce30d68c85fbd395771a09","In the study of improving the efficiency of mobile wireless sensor networks (MWSNs), an important issue is to maximize the sensor coverage in a given sensing field by proper deployment of sensors. In this paper, two novel sensor deployment schemes are proposed to address the coverage issue in MWSNs. The first scheme is blind-zone centroid-based scheme (BCBS) and the second one is disturbed centroid-based scheme (DCBS). The main ideas both in BCBS and DCBS are the proposed schemes to find the target locations for sensors to heal the coverage holes efficiently. The definition of Voronoi blind-zone polygon is given for introducing the proposed two schemes. In order to clearly illustrating the effect of Voronoi blind-zone polygon, three possible cases of it are studied in detail. In BCBS, Voronoi blind-zone polygon of each sensor is firstly determined by considering the positions with its neighbors. And then the centroid of the Voronoi blind-zone polygon is regarded as the target location of each sensor if the coverage can increase. In DCBS, sensors find coverage holes according to the centroid-based scheme at first in each round. They then move to the target locations under the local perturbation and local reconstruction operators. These two operators are designed by studying two forms of local convergence. Under the guideline of testbed-based multi-metric quality measurement of sensor deployment schemes, simulation results are sufficiently presented to demonstrate the effectiveness of the proposed two deployment schemes. © 2017 Elsevier B.V.","Centroid; Coverage; Mobile wireless sensor networks; Sensor deployment; Voronoi diagram"
"A minimum adjustment cost feedback mechanism based consensus model for group decision making under social network with distributed linguistic trust","2018","Information Fusion","10.1016/j.inffus.2017.09.012","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029590284&doi=10.1016%2fj.inffus.2017.09.012&partnerID=40&md5=a2635a012b4136085323a5c781edf16c","A theoretical feedback mechanism framework to model consensus in social network group decision making (SN-GDM) is proposed with following two main components: (1) the modelling of trust relationship with linguistic information; and (2) the minimum adjustment cost feedback mechanism. To do so, a distributed linguistic trust decision making space is defined, which includes the novel concepts of distributed linguistic trust functions, expectation degree, uncertainty degrees and ranking method. Then, a social network analysis (SNA) methodology is developed to represent and model trust relationship between a networked group, and the trust in-degree centrality indexes are calculated to assign an importance degree to the associated user. To identify the inconsistent users, three levels of consensus degree with distributed linguistic trust functions are calculated. Then, a novel feedback mechanism is activated to generate recommendation advices for the inconsistent users to increase the group consensus degree. Its novelty is that it produces the boundary feedback parameter based on the minimum adjustment cost optimisation model. Therefore, the inconsistent users are able to reach the threshold value of group consensus incurring a minimum modification of their opinions or adjustment cost, which provides the optimum balance between group consensus and individual independence. Finally, after consensus has been achieved, a ranking order relation for distributed linguistic trust functions is constructed to select the most appropriate alternative of consensus. © 2017 Elsevier B.V.","Consensus; Distributed linguistic trust; Feedback mechanism; Group decision making; Minimum adjustment optimization model; Social network analysis"
"Self-adapting weighted operators for multiscale gradient fusion","2018","Information Fusion","10.1016/j.inffus.2018.03.004","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046171583&doi=10.1016%2fj.inffus.2018.03.004&partnerID=40&md5=5343598f806b9610de7ef89ab4374377","Gradient maps are common intermediate representations in image processing, with extensive use in both classical and state-of-the-art algorithms. Most of the research on gradient map extraction has been devoted to the definition of gradient extraction operators or filters, normally by optimizing certain criteria. In this context, we find a rather limited literature in gradient map extraction using multiscale information. In this work, we develop the idea of producing a gradient map by fusing the gradient maps obtained at different scales. We first analyze the Gaussian Scale Space and the behaviour of gradients when images are projected into it; second, we propose two classes of self-adapting vector fusion operators, which are inspired by the focus-selective nature of the human visual system; third, we present a framework for multiscale boundary detection based on the use of such classes of operators for multiscale gradient fusion. We experimentally test our boundary detection framework to illustrate the validity of our vector fusion operators. © 2018 Elsevier B.V.","Gradient fusion; Multiscale image processing; Multivariate data; Ordered weighted operator; Self-adapting operator"
"META-DES.Oracle: Meta-learning and feature selection for dynamic ensemble selection","2017","Information Fusion","10.1016/j.inffus.2017.02.010","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85015884532&doi=10.1016%2fj.inffus.2017.02.010&partnerID=40&md5=452eec4610a40ba76acaa39d60e6d67d","Dynamic ensemble selection (DES) techniques work by estimating the competence level of each classifier from a pool of classifiers, and selecting only the most competent ones for the classification of a specific test sample. The key issue in DES is defining a suitable criterion for calculating the classifiers’ competence. There are several criteria available to measure the level of competence of base classifiers, such as local accuracy estimates and ranking. However, using only one criterion may lead to a poor estimation of the classifier's competence. In order to deal with this issue, we have proposed a novel dynamic ensemble selection framework using meta-learning, called META-DES. A meta-classifier is trained, based on the meta-features extracted from the training data, to estimate the level of competence of a classifier for the classification of a given query sample. An important aspect of the META-DES framework is that multiple criteria can be embedded in the system encoded as different sets of meta-features. However, some DES criteria are not suitable for every classification problem. For instance, local accuracy estimates may produce poor results when there is a high degree of overlap between the classes. Moreover, a higher classification accuracy can be obtained if the performance of the meta-classifier is optimized for the corresponding data. In this paper, we propose a novel version of the META-DES framework based on the formal definition of the Oracle, called META-DES.Oracle. The Oracle is an abstract method that represents an ideal classifier selection scheme. A meta-feature selection scheme using an overfitting cautious Binary Particle Swarm Optimization (BPSO) is proposed for improving the performance of the meta-classifier. The difference between the outputs obtained by the meta-classifier and those presented by the Oracle is minimized. Thus, the meta-classifier is expected to obtain results that are similar to the Oracle. Experiments carried out using 30 classification problems demonstrate that the optimization procedure based on the Oracle definition leads to a significant improvement in classification accuracy when compared to previous versions of the META-DES framework and other state-of-the-art DES techniques. © 2017 Elsevier B.V.","Classifier competence; Dynamic ensemble selection; Ensemble of classifiers; Meta-learning; Particle swarm optimization"
"Validation of synthetic daily Landsat NDVI time series data generated by the improved spatial and temporal data fusion approach","2018","Information Fusion","10.1016/j.inffus.2017.06.005","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020938759&doi=10.1016%2fj.inffus.2017.06.005&partnerID=40&md5=9176128e21ca779d5588d83e34d9c72b","Correlation analysis has been widely used to validate the accuracy of synthetic medium-resolution data generated by spatial and temporal fusion methods. However, as the temporal resolution of Landsat data is 16 days, this method only can be used for the validation of multi-temporal Landsat data. This means that the fusion accuracy of most images in a synthetic daily time series have not been validated. Furthermore, the fusion accuracy of each image in a synthetic Landsat time series is different, because there is a negative correlation with the time interval length between the fusion date and the base image date. Therefore, there is a need for temporal validation of synthetic daily Landsat time series data. We propose a suitable validation method in this paper. The improved spatial and temporal data fusion approach (ISTDFA) was applied to generate synthetic daily Landsat Normalized Difference Vegetation Index (NDVI) time series, which were then validated for both spatial and temporal dimensions using actual MODIS NDVI time series. For temporal validation, the correlation coefficients (R) between the actual and synthetic 500 m NDVI time series were calculated by pixel-by-pixel to generate imagery with an R value for each pixel. For spatial validation, R between MODIS NDVI imagery and synthetic Landsat NDVI imagery was calculated day by day to generate an R time series. This method was tested and validated in two locations (Bole and Luntai) in Xinjiang Province, China. The results show that, for temporal validation, the R values of 86.08% pixels in Bole and 94.71% pixels in Luntai are higher than 0.9, and in spatial validation, R values are higher than 0.8 on most days. Synthetic daily Landsat NDVI data was used to monitor the phenology of vegetation at a spatial resolution of 30 m successfully, while the MODIS product is limited to 500 m. © 2017 Elsevier B.V.","Landsat; MODIS; Remote sensing; Spatial and temporal data fusion; Temporal validation"
"Distributed data association in smart camera network via dual decomposition","2018","Information Fusion","10.1016/j.inffus.2017.04.007","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018403070&doi=10.1016%2fj.inffus.2017.04.007&partnerID=40&md5=816d3ac1e90e522e3c57211edb4642ba","One of the fundamental requirements for pedestrian surveillance using smart camera network is the correct association of each person's observations generated on different camera nodes to the person's track. Recently, distributed data association methods that involve only local information processing on each camera node and mutual information exchanging between neighboring cameras have attracted many research interests due to their superiority in large scale applications. In this paper, we propose a new method that performs global data association in a distributed manner by fusing the appearance and spatio-temporal measurements of objects captured by all camera nodes in the entire network. Specifically, we formulate the data association problem in smart camera networks as an Integer Programming problem by introducing a set of linking variables, and propose two distributed algorithms, namely L-DD and Q-DD, to solve the Integer Programming problem using the dual decomposition technique. In our algorithms, the original Integer Programming problem is decomposed into several subproblems, which can be solved locally on each smart camera. Different subproblems reach consensus on their solutions in a rigorous way by adjusting their parameters iteratively based on the projected subgradient optimization. The proposed method is simple and flexible, in that (i) we can incorporate any feature extraction and matching technique into our framework to calculate the similarity between observations, which corresponds to the costs of links in our model, and (ii) we can decompose the original problem in any way as long as the resulting subproblem can be solved independently and efficiently. We show the competitiveness of our method in both accuracy and speed by theoretical analysis and experimental comparison with state-of-the-art algorithms. © 2017 Elsevier B.V.","Data association; Distributed algorithm; Dual decomposition; Smart camera network"
"Evaluating virtual image quality using the side-views information fusion and depth maps","2018","Information Fusion","10.1016/j.inffus.2017.11.007","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85035801367&doi=10.1016%2fj.inffus.2017.11.007&partnerID=40&md5=dda83e8e62fa5286c4ff51f671054fa5","Three Dimensional (3D) image quality assessment is a challenging problem as compared to 2D images due to their different nature of acquisition, representation, coding, and display. The additional dimension of depth in multiview video plus depth (MVD) format is exploited to obtain images at novel intermediate viewpoints using depth image based rendering (DIBR) techniques, enabling 3D television and free-viewpoint television (FTV) applications. Depth maps introduce various quality artifacts in the DIBR-synthesized (virtual) images. In this paper, we propose a novel methodology to evaluate the quality of synthesized views in absence of the corresponding original reference views. It computes the statistical characteristics of the side views from whom the virtual view is generated, and fuses this information to estimate the statistical characteristics of the cyclopean image which are compared to those of the synthesized image to evaluate its quality. In addition to texture images, the proposed algorithm also considers the depth maps in evaluating the quality of the synthesized images. The algorithm blends two quality metrics, one estimating the texture distortion in the synthesized texture image induced by compression, transmission, 3D warping, or other causes and the second one determining the distortion of the depth maps. The two metrics are combined to obtain an overall quality assessment of the synthesized image. The proposed Synthesized Image Quality Metric (SIQM) is tested on the challenging MCL-3D and SIAT-3D datasets. The evaluation results show that the proposed metric significantly improves over state-of-the-art 3D image quality assessment algorithms. © 2017 Elsevier B.V.","3D image quality assessment; Depth image based rendering; Free-viewpoint TV; Information fusion; View synthesis"
"Closed-form expressions for some indices of SUOWA operators","2018","Information Fusion","10.1016/j.inffus.2017.08.010","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028018362&doi=10.1016%2fj.inffus.2017.08.010&partnerID=40&md5=9fb40c4a5d1eedd8d0e49d8cb3514df6","Aggregation operators are an important tool in various scientific fields to determine the overall evaluation of an alternative from individual values. So, it seems relevant to know as many features as possible of the operators used in the aggregation processes. For this purpose, several indices have appeared in the literature, among which worth mentioning are the orness degree, the Shapley value, and the veto and favor indices. However, closed-form expressions of these indices are only known for few operators. The aim of this paper is to provide closed-form expressions of the previously said indices for some specific cases of SUOWA operators (which are a special case of Choquet integral), and to show the usefulness of these operators in a classical example given by Grabisch (1995). © 2017 Elsevier B.V.","Choquet integral; Orness degree; Shapley value; SUOWA Operators; Veto and favor indices"
"Classification with class noises through probabilistic sampling","2018","Information Fusion","10.1016/j.inffus.2017.08.007","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027514343&doi=10.1016%2fj.inffus.2017.08.007&partnerID=40&md5=bdd36462059609109d466e63b487beda","Accurately labeling training data plays a critical role in various supervised learning tasks. Now a wide range of algorithms have been developed to identify and remove mislabeled data as labeling in practical applications might be erroneous due to various reasons. In essence, these algorithms adopt the strategy of one-zero sampling (OSAM), wherein a sample will be selected and retained only if it is recognized as clean. There are two types of errors in OSAM: identifying a clean sample as mislabeled and discarding it, or identifying a mislabeled sample as clean and retaining it. These errors could lead to poor classification performance. To improve classification accuracy, this paper proposes a novel probabilistic sampling (PSAM) scheme. In PSAM, a cleaner sample has more chance to be selected. The degree of cleanliness is measured by the confidence on the label. To accurately estimate the confidence value, a probabilistic multiple voting idea is proposed which is able to assign a high confidence value to a clean sample and a low confidence value to a mislabeled sample. Finally, we demonstrate that PSAM could effectively improve the classification accuracy over existing OSAM methods. © 2017","Mislabeled training data; Multiple voting; One-zero sampling; Probabilistic sampling"
"A fusion framework to estimate plantar ground force distributions and ankle dynamics","2018","Information Fusion","10.1016/j.inffus.2017.09.008","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029706732&doi=10.1016%2fj.inffus.2017.09.008&partnerID=40&md5=ed7dd31c64b8959edbb5f1b612412d86","Gait analysis plays an important role in several conditions, including the rehabilitation of patients with orthopaedic problems and the monitoring of neurological conditions, mental health problems and the well-being of elderly subjects. It also constitutes an index of good posture and thus it can be used to prevent injuries in athletes and monitor mental health in typical subjects. Usually, accurate gait analysis is based on the measurement of ankle dynamics and ground reaction forces. Therefore, it requires expensive multi-camera systems and pressure sensors, which cannot be easily employed in a free-living environment. We propose a fusion framework that uses an ear worn activity recognition (e-AR) sensor and a single video camera to estimate foot angle during key gait events. To this end we use canonical correlation analysis with a fused-lasso penalty in a two-steps approach that firstly learns a model of the timing distribution of ground reaction forces based on e-AR signal only and subsequently models the eversion/inversion as well as the dorsiflexion of the ankle based on the combined features of e-AR sensor and the video. The results show that incorporating invariant features of angular ankle information from the video recordings improves the estimation of the foot progression angle, substantially. © 2017","e-AR; Fusion of sensors gait data and video; Gait analysis"
"Measurement variance ignorant target motion analysis","2018","Information Fusion","10.1016/j.inffus.2017.11.006","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85037115647&doi=10.1016%2fj.inffus.2017.11.006&partnerID=40&md5=00583dd25069f4ce2c5a8ce4ac4b1183","The paper is devoted to Bayesian target motion analysis (TMA) for the case when the variance of additive white zero-mean Gaussian measurement noise is unknown. Two Rao–Blackwellised particle filters for TMA are developed, which jointly estimate the target state and the measurement variance. The error performance of the two particle filters is compared against the theoretical Cramer–Rao lower bound. The bound suggests the error in target state estimation is not affected by the ignorance of the measurement noise variance. Both developed TMA algorithms reach this theoretical bound, however, one is significantly faster. © 2017","Bearings-only tracking; Noise adaptive nonlinear filtering; Particle filter; Target motion analysis"
"Evaluation of fused imagery using eye movement-based measures of perceptual processing","2018","Information Fusion","10.1016/j.inffus.2017.04.003","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019626577&doi=10.1016%2fj.inffus.2017.04.003&partnerID=40&md5=2f0f2453728abc9fb8cef10176e05e58","Human performance measures were used to evaluate the perceptual processing efficiency of infrared and fused-infrared images.  In two experiments, eye movements were recorded while subjects searched for and identified human targets in forested scenes presented on a computer monitor.  The scenes were photographed simultaneously using short-wave infrared (SWIR), long-wave infrared (LWIR), and visible (VIS) spectrum cameras. Fused images were created through two-way combinations of these single-band images.  In Experiment 1 the single band sensors were contrasted with a simple average fusion scheme (SWIR/LWIR). Analysis of subjects’ eye movements revealed differences between sensors in measures of central processing (gaze duration, response accuracy) and peripheral selection (detection interval, saccade amplitude). In Experiment 2 this methodology was applied to compare three two-way combinations of sensors (SWIR/LWIR, SWIR/VIS, VIS/LWIR), produced by state-of-the-art fusion methods.  Peripheral selection for fused images tended to exhibit a compromise between the performance levels of component sensor images, while measures of central processing showed evidence that fused images matched or exceeded the performance level of component single-band sensor images. Stimulus analysis was conducted to link measures of central and peripheral processing efficiency to image characteristics (e.g. target contrast, target-background contrast), and these image characteristics were able to account for a moderate amount of the variance in the performance across fusion conditions. These findings demonstrate the utility of eye movement measures for evaluating the perceptual efficiency of fused imagery. © 2017","Eye movements; Infrared; Performance evaluation; Sensor fusion; Visual search"
"Multiple classifiers in biometrics. Part 2: Trends and challenges","2018","Information Fusion","10.1016/j.inffus.2017.12.005","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85039779754&doi=10.1016%2fj.inffus.2017.12.005&partnerID=40&md5=d0004e92f9a1e1990c30dce5df3d5896","The present paper is Part 2 in this series of two papers. In Part 1 we provided an introduction to Multiple Classifier Systems (MCS) with a focus into the fundamentals: basic nomenclature, key elements, architecture, main methods, and prevalent theory and framework. Part 1 then overviewed the application of MCS to the particular field of multimodal biometric person authentication in the last 25 years, as a prototypical area in which MCS has resulted in important achievements. Here in Part 2 we present in more technical detail recent trends and developments in MCS coming from multimodal biometrics that incorporate context information in an adaptive way. These new MCS architectures exploit input quality measures and pattern-specific particularities that move apart from general population statistics, resulting in robust multimodal biometric systems. Similarly as in Part 1, methods here are described in a general way so they can be applied to other information fusion problems as well. Finally, we also discuss here open challenges in biometrics in which MCS can play a key role. © 2017 Elsevier B.V.","Adaptive; Biometrics; Classifier; Context; Fusion; Multimodal"
"Optimizing multi-sensor deployment via ensemble pruning for wearable activity recognition","2018","Information Fusion","10.1016/j.inffus.2017.08.002","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028000152&doi=10.1016%2fj.inffus.2017.08.002&partnerID=40&md5=459d86d95f54a6927d6ee515e94865ca","With the rapid development of sensor types and processers, most wearable activity recognition systems tend to making use of multiple homogeneous or heterogeneous sensors to obtain plethora information. However, in a realistic environment, it is difficult to configure an appropriate multi-sensor deployment to gain a tradeoff among computational complexity, accuracy and subject personality. In this paper, a multi-sensor fusion with ensemble pruning system (MSF-EP) is designed to connect with multi-sensor based wearable activity recognition system. As a result, the multi-sensor configuration problem is transformed to multiple ensemble classifier pruning problem. With respect to ensemble pruning for MSF-EP system, two popular order-based ensemble pruning approaches are utilized firstly: reduce-error pruning (RE) and complementarily pruning (Comp). Then, in light of the proposed MSF-EP system, two new ensemble pruning criteria are proposed: mRMR pruning and discriminative pruning (Disc). The mRMR pruning measure is based on mutual information and is a composite criterion of classifier redundancy and relevance with regard to the selected classifier set. Taking into account the discriminations of misclassified instances and correctly classified instances in classifier subset selected respectively, another ensemble pruning measure Disc, which combining RE pruning and Comp pruning, is presented in the form of mutual information also. Finally, the proposed pruning learner with lower error is selected as final ensemble classifier. Through the algorithm, the number and type of multi-sensor are appropriately decided to optimize the multi-sensor fusion without regrading the accuracy performance. The system conducts experimental studies on two real-world activity recognition data sets and the results show the superiority of system over other ensemble algorithms. © 2017 Elsevier B.V.","Body sensor networks; Ensemble pruning; Human activity recognition; Multi-sensor data fusion"
"A survey on the fusion process in opinion dynamics","2018","Information Fusion","10.1016/j.inffus.2017.11.009","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85036476327&doi=10.1016%2fj.inffus.2017.11.009&partnerID=40&md5=36893844b728ed3cde3937ba5c69d04b","Opinion dynamics is a fusion process of individual opinions, in which a group of interacting agents continuously fuse their opinions on the same issue based on established fusion rules to reach a consensus, polarization, or fragmentation in the final stage. To date, many studies have been conducted on opinion dynamics. To provide a clear perspective on the fusion process in opinion dynamics, this paper presents a review of the framework and formulation of opinion dynamics as well as some basic models, extensions, and applications. Based on the insights gained from prior studies, several open problems are proposed for future research. © 2017 Elsevier B.V.","Consensus; Fusion process; Group decision making; Opinion dynamics"
"Group decision making based on linguistic distributions and hesitant assessments: Maximizing the support degree with an accuracy constraint","2018","Information Fusion","10.1016/j.inffus.2017.08.008","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029165222&doi=10.1016%2fj.inffus.2017.08.008&partnerID=40&md5=4771358497446714fd8f480e57f7d005","The hesitant fuzzy linguistic term set (HFLTS) and the linguistic distribution are becoming popular tools to model linguistic expressions with multiple linguistic terms in decision problems. Compared with HFLTSs, linguistic distributions provide more probabilistic preference information over linguistic terms, and are useful to express decision makers’ preferences accurately. However, in a group decision context a linguistic distribution based group opinion will bring great difficulty for the group to take an accurate action. Meanwhile, the linguistic group opinion should obtain enough support from decision makers in the group. To tackle these issues, based on the use of linguistic distributions and HFLTSs we propose a new linguistic group decision model called the maximum support degree model (MSDM), aiming at maximizing the support degree of the group opinion as well as guarantying the accuracy of the group opinion. A mixed 0–1 linear programming approach is presented to solve the MSDM, and a feedback adjustment is employed to improve the support degree of the group opinion. Finally, the use of the MSDM in multiple attribute group decision making is demonstrated. © 2017 Elsevier B.V.","Computing with words; Group decision making; Hesitant fuzzy linguistic term set; Linguistic distribution"
"Evidential reasoning with discrete belief structures","2018","Information Fusion","10.1016/j.inffus.2017.08.009","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028297091&doi=10.1016%2fj.inffus.2017.08.009&partnerID=40&md5=c2097e9a9d0991030113b18858c03308","In real-world applications, apart from being precise-valued or interval-valued, belief structure measurements can also be discrete-valued. However, problems relating to the combination of discrete-valued belief structures have not been resolved. Therefore, in the research presented in this paper, we explore the counterintuitive behavior associated with the combination of discrete evidence and extend the concept of evidential reasoning (ER) to evidential reasoning with a discrete structure in order to serve as the theoretical basis and as technical support for the fusion of discrete information. This method offers an approach to the normalization of discrete evidence, provides a means of objectively determining the weight of discrete evidence, and optimizes the combination of discrete evidence based on evidential reasoning. The results of various examples show that the method not only offers an effective solution to the combination of non-conflicting discrete evidence, but it also overcomes the counterintuitive results of combining internally or externally conflicting evidence. © 2017 Elsevier B.V.","Decision making; Discrete belief structure; Evidential reasoning"
"Fusing synergistic information from multi-sensor images: An overview from implementation to performance assessment","2018","Information Fusion","10.1016/j.inffus.2017.10.010","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85033468348&doi=10.1016%2fj.inffus.2017.10.010&partnerID=40&md5=573038d0755865f79aeb7f90710f2333","Image fusion is capable of processing multiple heterogeneous images acquired by single or multi-sensor imaging systems for an improved interpretation of the targeted object or scene. A diversity of applications have benefited from the fusion of multi-sensor images through a more reliable and comprehensive fused result. Likewise, numerous approaches to fuse multi-sensor images have been proposed and published in literature. However, due to a lack of benchmark resources and commonly accepted assessment measures, it is hard to identify the significance of new image fusion algorithms and implementations. This paper reviews and categorizes recent algorithms for image fusion and performance assessment based on reported comparative results. We recommend using non-parametric statistical tests to verify the performance of the pixel-level fusion algorithms. Furthermore, a comprehensive evaluation of 40 fusion algorithms from recently published results is conducted to demonstrate the significance of these algorithms in terms of statistical analyses within their respective applications. Although the results of these performance tests are limited by available data sets, baseline algorithms, and selected assessment metrics; it is a critical step for comparative image fusion research. This paper aims to advance image fusion development by creating a complete inventory of state-of-the-art image fusion techniques and advocating statistical comparison tests to avoid unnecessary duplication of development efforts. Establishing a benchmark study for image fusion is critical for performance comparisons of contemporary methods. © 2017 Elsevier B.V.","Fusion implementation; Fusion methods; Image fusion; Performance assessment; Significance test"
"A general packet dropout compensation framework for optimal prior filter of networked multi-sensor systems","2019","Information Fusion","10.1016/j.inffus.2018.01.004","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041410095&doi=10.1016%2fj.inffus.2018.01.004&partnerID=40&md5=a3bb4e02dbda076f70699809c9fc62fd","This paper proposes a new packet dropout compensation framework for networked multi-sensor systems. It is more general, which includes the existing popular mechanisms such as the zero-input and hold-input mechanisms as the special cases. Based on the proposed compensation framework, the centralized fusion linear optimal full-order prior filters with compensators of different weighting factors are presented. However, it is well known that centralized fusion prior filters (CFPFs) have poor reliability. To improve the reliability, the distributed fusion prior filters (DFPFs) are also given based on the well-known matrix-weighted fusion estimation algorithm in the linear unbiased minimum variance (LUMV) sense. Moreover, the stability and steady-state property of the proposed CFPFs and DFPFs are analyzed. A numerical example is used to make the performance comparisons of the proposed and the existing compensation mechanisms. The simulation results verify the effectiveness of the proposed compensation framework and the corresponding fusion filters. © 2018 Elsevier B.V.","Compensation; Multi-sensor system; Networked system; Optimal filter; Packet dropout"
"Multi-sensor fusion in body sensor networks: State-of-the-art and research challenges","2017","Information Fusion","10.1016/j.inffus.2016.09.005","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84988027649&doi=10.1016%2fj.inffus.2016.09.005&partnerID=40&md5=0e05c590b432df690432493f5d0b807e","Body Sensor Networks (BSNs) have emerged as a revolutionary technology in many application domains in health-care, fitness, smart cities, and many other compelling Internet of Things (IoT) applications. Most commercially available systems assume that a single device monitors a plethora of user information. In reality, BSN technology is transitioning to multi-device synchronous measurement environments; fusion of the data from multiple, potentially heterogeneous, sensor sources is therefore becoming a fundamental yet non-trivial task that directly impacts application performance. Nevertheless, only recently researchers have started developing technical solutions for effective fusion of BSN data. To the best of our knowledge, the community is currently lacking a comprehensive review of the state-of-the-art techniques on multi-sensor fusion in the area of BSN. This survey discusses clear motivations and advantages of multi-sensor data fusion and particularly focuses on physical activity recognition, aiming at providing a systematic categorization and common comparison framework of the literature, by identifying distinctive properties and parameters affecting data fusion design choices at different levels (data, feature, and decision). The survey also covers data fusion in the domains of emotion recognition and general-health and introduce relevant directions and challenges of future research on multi-sensor fusion in the BSN domain. © 2016 Elsevier B.V.","Data-level fusion; Decision-level fusion; Feature-level fusion; Human activity recognition; Multi-sensor data fusion"
"Pixel-level image fusion: A survey of the state of the art","2017","Information Fusion","10.1016/j.inffus.2016.05.004","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84970983713&doi=10.1016%2fj.inffus.2016.05.004&partnerID=40&md5=7a233b6567961d39f521b361d4ff1241","Pixel-level image fusion is designed to combine multiple input images into a fused image, which is expected to be more informative for human or machine perception as compared to any of the input images. Due to this advantage, pixel-level image fusion has shown notable achievements in remote sensing, medical imaging, and night vision applications. In this paper, we first provide a comprehensive survey of the state of the art pixel-level image fusion methods. Then, the existing fusion quality measures are summarized. Next, four major applications, i.e.; remote sensing, medical diagnosis, surveillance, photography, and challenges in pixel-level image fusion applications are analyzed. At last, this review concludes that although various image fusion methods have been proposed, there still exist several future directions in different image fusion applications. Therefore, the researches in the image fusion field are still expected to significantly grow in the coming years. ©2016 Published by Elsevier B.V.","Image fusion; Medical imaging; Multiscale decomposition; Remote sensing; Sparse representation"
"Boundary finding based multi-focus image fusion through multi-scale morphological focus-measure","2017","Information Fusion","10.1016/j.inffus.2016.09.006","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84988650908&doi=10.1016%2fj.inffus.2016.09.006&partnerID=40&md5=8e2a4e6fd3566e3cb96104e36bb504d5","Multi-focus image fusion aims to extract the focused regions from multiple partially focused images of the same scene and then combine them together to produce a completely focused image. Detecting the focused regions from multiple images is key for multi-focus image fusion. In this paper, we propose a novel boundary finding based multi-focus image fusion algorithm, in which the task of detecting the focused regions is treated as finding the boundaries between the focused and defocused regions from the source images. According to the found boundaries, the source images could be naturally separated into regions with the same focus conditions, i.e., each region is fully focused or defocused. Then, the focused regions can be found out by selecting the regions with greater focus-measures from each pair of regions. To improve the precision of boundary detection and focused region detection, we also present a multi-scale morphological focus-measure, effectiveness of which has been verified by using some quantitative evaluations. Different from the general multi-focus image fusion algorithms, our algorithm fuses the boundary regions and non-boundary regions of the source images respectively, which helps produce a fusion image with good visual quality. Moreover, the experimental results validate that the proposed algorithm outperforms some state-of-the-art image fusion algorithms in both qualitative and quantitative evaluations. © 2016 Elsevier B.V.","Boundary finding; Multi-focus image fusion; Multi-scale morphological focus-measure"
"Statistical comparison of image fusion algorithms: Recommendations","2017","Information Fusion","10.1016/j.inffus.2016.12.007","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85007082708&doi=10.1016%2fj.inffus.2016.12.007&partnerID=40&md5=7224fdc2b01b471461c805ecac1711c7","Pixel-level image fusion has been applied in a variety of applications, including multi-modal medical imaging, remote sensing, industrial inspection, video surveillance, and night vision etc. Various algorithms are being proposed for numerous applications which requires a comprehensive method of assessment to discern which methods provide decision support. Currently, the validation or assessment of newly proposed algorithms is done either subjectively or objectively. A subjective assessment is costly and affected by a number of factors that are difficult to control. On the other hand, an objective assessment is carried out with a fusion performance metric which is defined to evaluate the effectiveness and/or efficiency of the fusion operation. There are a number of fusion metrics proposed for fusion processes taking different perspectives. Most image fusion research presents a comparison of the proposed and existing fusion algorithms with selected fusion metric(s) over multiple image data sets. The proposed algorithm advantage is justified by the relative difference with the best or better metric values. However, the statistical significance of such difference is unknown leading to a misperception of the quantitative differences between methods. This paper proposes the use of non-parametric statistical analysis for comparisons of fusion algorithms along with the Image fusion Toolbox Employing Significance Testing (ImTEST). Strategies to use different tests in varied scenarios are presented and recommended. Experiments with recently published algorithms demonstrate the necessity to adopt the statistical comparison to establish a baseline for image fusion research. © 2016 Elsevier B.V.","Image fusion; Performance assessment; Pixel-level fusion; Statistical comparison; Statistical significance"
"A survey on joint tracking using expectation-maximization based techniques","2016","Information Fusion","10.1016/j.inffus.2015.11.008","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84949591377&doi=10.1016%2fj.inffus.2015.11.008&partnerID=40&md5=187435ff1531aa13a9cfa6a3300cca24","Many target tracking problems can actually be cast as joint tracking problems where the underlying target state may only be observed via the relationship with a latent variable. In the presence of uncertainties in both observations and latent variable, which encapsulates the target tracking into a variational problem, the expectation-maximization (EM) method provides an iterative procedure under Bayesian inference framework to estimate the state of target in the process which minimizes the latent variable uncertainty. In this paper, we treat the joint tracking problem using a united framework under the EM method and provide a comprehensive overview of various EM approaches in joint tracking context from their necessity, benefits, and challenging viewpoints. Some examples on the EM application idea are presented. In addition, future research directions and open issues for using EM method in the joint tracking are given. © 2015 Elsevier B.V. All rights reserved.","Bayesian inference; Expectation maximization; Information fusion; Joint identification and estimation; Target tracking"
"A delay-aware schedule method for distributed information fusion with elastic and inelastic traffic","2017","Information Fusion","10.1016/j.inffus.2016.11.008","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85006726036&doi=10.1016%2fj.inffus.2016.11.008&partnerID=40&md5=bcc512df108bb722e42c61e243c77478","Information fusion is an efficient way to detect the specified events and extract useful information, especially in the context of big data. As a large-scale data-gathering system, Internet of Things (IoT) has the traffic with the mixed timing characteristics. The real-time observations with various delay constraints and the non-real-time observations are needed in information fusion. In order to guarantee the performance of Distributed Information Fusion (DIF), the paper focuses on the communication mechanism from the perspective of real-time delivery of sensing data. An online scheduling algorithm and its distributed implementation, named Delay-Guaranteed CSMA, are proposed. Both the timing constraints and the historical transmission statistics of sensors are taking into consideration. The simulation results have shown that the proposed policy achieves good delay-guaranteed satisfaction. The goal of real-time data delivery for distributed information fusion is achieved. © 2016 Elsevier B.V.","Big data; Distributed information fusion; Internet of things; Online scheduling; Real-time"
"Composite sketch recognition using saliency and attribute feedback","2017","Information Fusion","10.1016/j.inffus.2016.04.003","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84969945382&doi=10.1016%2fj.inffus.2016.04.003&partnerID=40&md5=f4d0ae72d51e7346f2047fd13c163790","Recent interest and requirement of law enforcement agencies in matching composite sketches with digital images has instigated research in this important face recognition problem. In this paper, we propose feature extraction and matching algorithm using visual saliency and combination of texture features for matching composite sketches with digital photos. The attributes such as gender, ethnicity, and skin color are utilized for re-ordering the ranked list. Further, information from multiple experts such as multiple composite sketch generation tools or artists is combined for improving the matching performance. The results obtained on the extended PRIP database show that the proposed algorithm improves the state-of-art in matching composite sketch and digital face images and yields the rank 50 identification accuracy of 70.3% on a database of 1500 subjects. © 2016 Elsevier B.V. All rights reserved.","Biometrics; Composite sketch; Face recognition; Saliency; Sketch recognition"
"Combining the spectral PCA and spatial PCA fusion methods by an optimal filter","2016","Information Fusion","10.1016/j.inffus.2015.06.006","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84936858181&doi=10.1016%2fj.inffus.2015.06.006&partnerID=40&md5=fa6e3155fab72050b74110a4c411943e","Abstract High correlation among the neighboring pixels, both spectrally and spatially in a multispectral image makes it indispensable to use relevant data transformation approaches, before performing image fusion. The principal component analysis (PCA) method has been a popular choice for the spectral transformation. To propose a new consistent data transformation method in spatial domain, this paper applies the PCA transform to the spatial information of the neighboring pixels. Owing to the fact that the coefficients of PCA are obtained from statistical properties of data, they are adaptive and robust. Then, a new hybrid algorithm is proposed combining the spectral PCA and spatial PCA methods, by an optimal filter to make the synthesized result more similar to what the corresponding multisensors would observe at the high-resolution level. The evaluation of the pan-sharpened images, using global validation indexes, reveals that the proposed approach improves the fusion quality compared with six state of the art fusion methods. © 2015 Elsevier B.V.","Image fusion; Optimal filter; Principal component analysis; Spatial information; Spectral information"
"Cooperative localization for disconnected sensor networks and a mobile robot in friendly environments","2017","Information Fusion","10.1016/j.inffus.2017.01.001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85008930056&doi=10.1016%2fj.inffus.2017.01.001&partnerID=40&md5=6eb8cde93804cb4e4e1f7d527ea2f511","Localization for a disconnected sensor network is highly unlikely to be achieved by its own sensor nodes, since accessibility of the information between any pair of sensor nodes cannot be guaranteed. In this paper, a mobile robot (or a mobile sensor node) is introduced to establish correlations among sparsely distributed sensor nodes which are disconnected, even isolated. The robot and the sensor network operate in a friendly manner, in which they can cooperate to perceive each other for achieving more accurate localization, rather than trying to avoid being detected by each other. The mobility of the robot allows for the stationary and internally disconnected sensor nodes to be dynamically connected and correlated. On one hand, the robot performs simultaneous localization and mapping (SLAM) based on the constrained local submap filter (CLSF). The robot creates a local submap composed of the sensor nodes present in its immediate vicinity. The locations of these nodes and the pose (position and orientation angle) of the robot are estimated within the local submap. On the other hand, the sensor nodes in the submap estimate the pose of the robot. A parallax-based robot pose estimation and tracking (PROPET) algorithm, which uses the relationship between two successive measurements of the robot's range and bearing, is proposed to continuously track the robot's pose with each sensor node. Then, tracking results of the robot's pose from different sensor nodes are fused by the Kalman filter (KF). The multi-node fusion result are further integrated with the robot's SLAM result within the local submap to achieve more accurate localization for the robot and the sensor nodes. Finally, the submap is projected and fused into the global map by the CLSF to generate localization results represented in the global frame of reference. Simulation and experimental results are presented to show the performances of the proposed method for robot-sensor network cooperative localization. Especially, if the robot (or the mobile sensor node) has the same sensing ability as the stationary sensor nodes, the localization accuracy can be significantly enhanced using the proposed method. © 2017 Elsevier B.V.","Cooperative localization; Mobile robot; Sensor information fusion; Sensor network"
"An improved high spatial and temporal data fusion approach for combining Landsat and MODIS data to generate daily synthetic Landsat imagery","2016","Information Fusion","10.1016/j.inffus.2015.12.005","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84953884516&doi=10.1016%2fj.inffus.2015.12.005&partnerID=40&md5=6d7f2dfe2d891041d716629ee775ff28","Because of low temporal resolution and cloud influence, many remote-sensing applications lack high spatial resolution remote-sensing data. To address this problem, this study introduced an improved spatial and temporal data fusion approach (ISTDFA) to generate daily synthetic Landsat imagery. This algorithm was designed to avoid the weaknesses of the spatial and temporal data fusion approach (STDFA) method, including the sensor difference and spatial variability. A weighted linear mixed model was used to adjust the spatial variability of surface reflectance. A linear-regression method was used to remove the influence of differences in sensor systems. This method was tested and validated in three study areas located in Xinjiang and Anhui province, China. The other two methods, the STDFA and the Enhanced Spatial and Temporal Adaptive Reflectance Fusion Model (ESTARFM), were also applied and compared in those three study areas. The results showed that the ISTDFA algorithm can generate daily synthetic Landsat imagery accurately, with correlation coefficient r equal to 0.9857 and root mean square error (RMSE) equal to 0.0195, which is superior to the STDFA method. The ISTDFA method had higher accuracy than ESTARFM in areas greater than 200 × 200 MODIS pixels while the ESTARFM method had higher accuracy than the ISTDFA method in small areas. The correlation coefficient r had a negative power relation with ratio of land-cover change pixels. A land-cover change of 20.25% pixels can lead to a reduced correlation coefficient r of 0.295 in the blue band. The accuracy of the ISTDFA method indicated a logarithmic relationship with the size of the applied area, so it is recommended for use in large-scale areas. © 2015 Elsevier B.V. All rights reserved.","FROM-GLC; Landsat; MODIS; Remote sensing; Spatial and temporal data fusion"
"An integrated index for identification of fatty liver disease using radon transform and discrete cosine transform features in ultrasound images","2016","Information Fusion","10.1016/j.inffus.2015.12.007","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84954357780&doi=10.1016%2fj.inffus.2015.12.007&partnerID=40&md5=89606c14153f0435f369511f5860a971","Alcoholic and non-alcoholic fatty liver disease is one of the leading causes of chronic liver diseases and mortality in Western countries and Asia. Ultrasound image assessment is most commonly and widely used to identify the Non-Alcoholic Fatty Liver Disease (NAFLD). It is one of the faster and safer non-invasive methods of NAFLD diagnosis available in imaging modalities. The diagnosis of NAFLD using biopsies is expensive, invasive, and causes anxiety to the patients. The advent of advanced image processing and data mining techniques have helped to develop faster, efficient, objective, and accurate decision support system for fatty liver disease using ultrasound images. This paper proposes a novel feature extraction models based on Radon Transform (RT) and Discrete Cosine Transform (DCT). First, Radon Transform (RT) is performed on the ultrasound images for every 1 degree to capture the low frequency details. Then 2D-DCT is applied on the Radon transformed image to obtain the frequency features (DCT coefficients). Further the 2D-DCT frequency coefficients (features) obtained are converted to 1D coefficients vector in zigzag fashion. This 1D array of DCT coefficients are subjected to Locality Sensitive Discriminant Analysis (LSDA) to reduce the number of features. Then these features are ranked using minimum Redundancy and Maximum Relevance (mRMR) ranking method. Finally, highly ranked minimum numbers of features are fused using Decision Tree (DT), k-Nearest Neighbour (k-NN), Probabilistic Neural Network (PNN), Support Vector Machine (SVM), Fuzzy Sugeno (FS) and AdaBoost classifiers to get the highest classification performance. In this work, we have obtained an average accuracy, sensitivity and specificity of 100% in the detection of NAFLD using FS classifier. Also, we have devised an integrated index named as Fatty Liver Disease Index (FLDI) by fusing two significant LSDA components to distinguish normal and FLD class with single number. © 2015 Elsevier B.V. All rights reserved.","Discrete cosine transform; Fatty liver disease; Fuzzy classifier; Locality sensitive discriminant analysis; Ultrasound"
"Efficient integration of RSSI for tracking using Wireless Camera Networks","2017","Information Fusion","10.1016/j.inffus.2016.11.001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85008224800&doi=10.1016%2fj.inffus.2016.11.001&partnerID=40&md5=a069b5805335a1c73c36938b87b489b8","This paper proposes a scheme that efficiently exploits synergies between RSSI and camera measurements in cluster-based target tracking using Wireless Camera Networks (WCNs). The scheme is based on the combination of two main components: a training method that accurately trains RSSI-range models adapted to the conditions of the particular local environment; and a sensor activation/deactivation method that decides on the individual activation of sensors balancing the different information contributions and energy consumptions of camera and RSSI measurements involved in sensing. The scheme also includes a distributed Extended Information Filter that integrates all available measurements. The combination of these components originates self-regulated behaviors that drastically reduce power consumption and computational effort with no significant tracking degradation w.r.t. existing schemes based exclusively on cameras. Besides, it shows better robustness to target occlusions. The proposed scheme has been implemented and validated in real experiments. © 2016 Elsevier B.V.","Camera networks; RSSI; Wireless Sensor Networks"
"Adaptive latent fingerprint segmentation using feature selection and random decision forest classification","2017","Information Fusion","10.1016/j.inffus.2016.05.002","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84975257996&doi=10.1016%2fj.inffus.2016.05.002&partnerID=40&md5=fb780df66519ac6bfe4dff7a73516651","Latent fingerprints are important evidences used by law enforcement agencies. However, current state-of-the-art for automatic latent fingerprint recognition is not as reliable as live-scan fingerprints and advancements are required in every step of the recognition pipeline. This research focuses on automatically segmenting latent fingerprints to distinguish between ridge and non-ridge patterns. There are three major contributions of this research: (i) a machine learning algorithm for combining five different categories of features for automatic latent fingerprint segmentation, (ii) a feature selection technique using modified RELIEF formulation for analyzing the influence of multiple category features on latent fingerprint segmentation, and (iii) a novel SIVV based metric to measure the effect of the segmentation algorithm without the requirement to perform the entire matching process. The image is tessellated into local patches and saliency based features along with image, gradient, ridge, and quality based features are extracted. Feature selection is performed to study the contribution of the various category features towards foreground ridge pattern representation. Using these selected features, a trained Random Decision Forest based algorithm classifies the local patches as background or foreground. The results on three publicly available databases demonstrate the efficacy of the proposed algorithm. © 2016 Elsevier B.V. All rights reserved.","Feature selection; Latent fingerprint segmentation; Random decision forest; Saliency"
"The basic principles of uncertain information fusion. An organised review of merging rules in different representation frameworks","2016","Information Fusion","10.1016/j.inffus.2016.02.006","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85009839085&doi=10.1016%2fj.inffus.2016.02.006&partnerID=40&md5=ea938fd043d9e0c7fa158e6fe2970bd6","We propose and advocate basic principles for the fusion of incomplete or uncertain information items, that should apply regardless of the formalism adopted for representing pieces of information coming from several sources. This formalism can be based on sets, logic, partial orders, possibility theory, belief functions or imprecise probabilities. We propose a general notion of information item representing incomplete or uncertain information about the values of an entity of interest. It is supposed to rank such values in terms of relative plausibility, and explicitly point out impossible values. Basic issues affecting the results of the fusion process, such as relative information content and consistency of information items, as well as their mutual consistency, are discussed. For each representation setting, we present fusion rules that obey our principles, and compare them to postulates specific to the representation proposed in the past. In the crudest (Boolean) representation setting (using a set of possible values), we show that the understanding of the set in terms of most plausible values, or in terms of non-impossible ones matters for choosing a relevant fusion rule. Especially, in the latter case our principles justify the method of maximal consistent subsets, while the former is related to the fusion of logical bases. Then we consider several formal settings for incomplete or uncertain information items, where our postulates are instantiated: plausibility orderings, qualitative and quantitative possibility distributions, belief functions and convex sets of probabilities. The aim of this paper is to provide a unified picture of fusion rules across various uncertainty representation settings. © 2016 The Authors","Combination rules; Evidence theory; Imprecise probability; Information fusion; Knowledge-based merging; Plausibility orderings; Possibility theory"
"A review of affective computing: From unimodal analysis to multimodal fusion","2017","Information Fusion","10.1016/j.inffus.2017.02.003","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85011844403&doi=10.1016%2fj.inffus.2017.02.003&partnerID=40&md5=0b9d518723f057d6d0431c5d7b02cdd9","Affective computing is an emerging interdisciplinary research field bringing together researchers and practitioners from various fields, ranging from artificial intelligence, natural language processing, to cognitive and social sciences. With the proliferation of videos posted online (e.g., on YouTube, Facebook, Twitter) for product reviews, movie reviews, political views, and more, affective computing research has increasingly evolved from conventional unimodal analysis to more complex forms of multimodal analysis. This is the primary motivation behind our first of its kind, comprehensive literature review of the diverse field of affective computing. Furthermore, existing literature surveys lack a detailed discussion of state of the art in multimodal affect analysis frameworks, which this review aims to address. Multimodality is defined by the presence of more than one modality or channel, e.g., visual, audio, text, gestures, and eye gage. In this paper, we focus mainly on the use of audio, visual and text information for multimodal affect analysis, since around 90% of the relevant literature appears to cover these three modalities. Following an overview of different techniques for unimodal affect analysis, we outline existing methods for fusing information from different modalities. As part of this review, we carry out an extensive study of different categories of state-of-the-art fusion techniques, followed by a critical analysis of potential performance improvements with multimodal analysis compared to unimodal analysis. A comprehensive overview of these two complementary fields aims to form the building blocks for readers, to better understand this challenging and exciting research field. © 2017 Elsevier B.V.","Affective computing; Audio, visual and text information fusion; Multimodal affect analysis; Multimodal fusion; Sentiment analysis"
"MetricFusion: Generalized metric swarm learning for similarity measure","2016","Information Fusion","10.1016/j.inffus.2015.12.004","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84952326594&doi=10.1016%2fj.inffus.2015.12.004&partnerID=40&md5=3270bc6a1caa3cdab498888c8a0963e0","Learning distance metrics for measuring the similarity between two data points in unsupervised and supervised pattern recognition has been widely studied in unconstrained face verification tasks. Motivated by the fact that enforcing single distance metric learning for verification via an empirical score threshold is not robust in uncontrolled experimental conditions, we therefore propose to obtain a metric swarm by learning local patches alike sub-metrics simultaneously that naturally formulates a generalized metric swarm learning (GMSL) model with a joint similarity score function solved by an efficient alternative optimization algorithm. Further, each sample pair is represented as a similarity vector via the well-learned metric swarm, such that the face verification task becomes a generalized SVM-alike classification problem. Therefore, the verification can be enforced in the represented metric swarm space that can well improve the robustness of verification under irregular data structure. Experiments are preliminarily conducted using several UCI benchmark datasets for solving general classification problem. Further, the face verification experiments on real-world LFW and PubFig datasets demonstrate that our proposed model outperforms several state-of-the-art metric learning methods. © 2015 Elsevier Ltd. All rights reserved.","Classification; Face verification; Metric learning; Similarity"
"An algorithm for group decision making using n-dimensional fuzzy sets, admissible orders and OWA operators","2017","Information Fusion","10.1016/j.inffus.2017.01.007","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85011850889&doi=10.1016%2fj.inffus.2017.01.007&partnerID=40&md5=e7ef79144c1e86cf899518957c19e580","In this paper we propose an algorithm to solve group decision making problems using n-dimensional fuzzy sets, namely, sets in which the membership degree of each element to the set is given by an increasing tuple of n elements. The use of these sets has naturally led us to define admissible orders for n-dimensional fuzzy sets, to present a construction method for those orders and to study OWA operators for aggregating the tuples used to represent the membership degrees of the elements. In these conditions, we present an algorithm and apply it to a case study, in which we show that the exploitation phase which appears in many decision making methods can be omitted by just considering linear orders between tuples. © 2017 Elsevier B.V.","Decision-making; Fuzzy multisets; n-dimensional fuzzy sets; OWA operator"
"Gradient entropy metric and p-Laplace diffusion constraint-based algorithm for noisy multispectral image fusion","2016","Information Fusion","10.1016/j.inffus.2015.06.003","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84933564973&doi=10.1016%2fj.inffus.2015.06.003&partnerID=40&md5=2ca26fe77357c96bc1da1009f59bcb2d","Abstract Noise is easily mistaken as useful features of input images, and therefore, significantly reducing image fusion quality. In this paper, we propose a novel gradient entropy metric and p-Laplace diffusion constraint-based method. Specifically, the method is based on the matrix of structure tensor to fuse the gradient information. To minimize the negative effects of noise on the selections of image features, the gradient entropy metric is proposed to construct the weight for each gradient of input images. Particularly, the local adaptive p-Laplace diffusion constraint is constructed to further suppress noise when rebuilding the fused image from the fused gradient field. Experimental results show that the proposed method effectively preserves edge detail features of multispectral images while suppressing noise, achieving an optimal visual effect and more comprehensive quantitative assessments compared to other existing methods. © 2015 Elsevier B.V.","Gradient entropy metric; Image fusion; Matrix of structure tensor; Noisy multispectral images; p-Laplace diffusion constraint"
"Improved classification with allocation method and multiple classifiers","2016","Information Fusion","10.1016/j.inffus.2015.12.006","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84954187617&doi=10.1016%2fj.inffus.2015.12.006&partnerID=40&md5=443c18a3fe87a81216f2e5a97a76d3be","Classification is the most used supervized machine learning method. As each of the many existing classification algorithms can perform poorly on some data, different attempts have arisen to improve the original algorithms by combining them. Some of the best know results are produced by ensemble methods, like bagging or boosting. We developed a new ensemble method called allocation. Allocation method uses the allocator, an algorithm that separates the data instances based on anomaly detection and allocates them to one of the micro classifiers, built with the existing classification algorithms on a subset of training data. The outputs of micro classifiers are then fused together into one final classification. Our goal was to improve the results of original classifiers with this new allocation method and to compare the classification results with existing ensemble methods. The allocation method was tested on 30 benchmark datasets and was used with six well known basic classification algorithms (J48, NaiveBayes, IBk, SMO, OneR and NBTree). The obtained results were compared to those of the basic classifiers as well as other ensemble methods (bagging, MultiBoost and AdaBoost). Results show that our allocation method is superior to basic classifiers and also to tested ensembles in classification accuracy and f-score. The conducted statistical analysis, when all of the used classification algorithms are considered, confirmed that our allocation method performs significantly better both in classification accuracy and f-score. Although the differences are not significant for each of the used basic classifier alone, the allocation method achieved the biggest improvements on all six basic classification algorithms. In this manner, allocation method proved to be a competitive ensemble method for classification that can be used with various classification algorithms and can possibly outperform other ensembles on different types of data. © 2015 Elsevier B.V. All rights reserved.","Allocation; Anomaly detection; Classification; Ensemble methods"
"An intelligent quality-based approach to fusing multi-source probabilistic information","2016","Information Fusion","10.1016/j.inffus.2016.02.005","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84959462359&doi=10.1016%2fj.inffus.2016.02.005&partnerID=40&md5=0fec28642dab303092b595bdf616791e","Our objective here is to obtain quality-fused values from multiple sources of probabilistic distributions, where quality is related to the lack of uncertainty in the fused value and the use of credible sources. We first introduce a vector representation for a probability distribution. With the aid of the Gini formulation of entropy, we show how the norm of the vector provides a measure of the certainty, i.e., information, associated with a probability distribution. We look at two special cases of fusion for source inputs those that are maximally uncertain and certain. We provide a measure of credibility associated with subsets of sources. We look at the issue of finding the highest quality fused value from the weighted aggregations of source provided probability distributions. © 2016 Elsevier B.V. All rights reserved.","Credibility; Entropy; Fusion; Quality-based"
"Information fusion in content based image retrieval: A comprehensive overview","2017","Information Fusion","10.1016/j.inffus.2017.01.003","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85009063768&doi=10.1016%2fj.inffus.2017.01.003&partnerID=40&md5=d7526626634a6cf15f8d0a4b625b8ad3","An ever increasing part of communication between persons involve the use of pictures, due to the cheap availability of powerful cameras on smartphones, and the cheap availability of storage space. The rising popularity of social networking applications such as Facebook, Twitter, Instagram, and of instant messaging applications, such as WhatsApp, WeChat, is the clear evidence of this phenomenon, due to the opportunity of sharing in real-time a pictorial representation of the context each individual is living in. The media rapidly exploited this phenomenon, using the same channel, either to publish their reports, or to gather additional information on an event through the community of users. While the real-time use of images is managed through metadata associated with the image (i.e., the timestamp, the geolocation, tags, etc.), their retrieval from an archive might be far from trivial, as an image bears a rich semantic content that goes beyond the description provided by its metadata. It turns out that after more than 20 years of research on Content-Based Image Retrieval (CBIR), the giant increase in the number and variety of images available in digital format is challenging the research community. It is quite easy to see that any approach aiming at facing such challenges must rely on different image representations that need to be conveniently fused in order to adapt to the subjectivity of image semantics. This paper offers a journey through the main information fusion ingredients that a recipe for the design of a CBIR system should include to meet the demanding needs of users. © 2017 Elsevier B.V.","Content based image retrieval; Information fusion"
"Numerical integration for the Choquet integral","2016","Information Fusion","10.1016/j.inffus.2016.02.007","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84959336348&doi=10.1016%2fj.inffus.2016.02.007&partnerID=40&md5=72e0a4d753355bccea80095e06f1da50","Choquet integrals with respect to non-additive (or fuzzy measures) have been used in a large number of applications because they permit us to integrate information from different sources when there are interactions. Successful applications use a discrete reference set. In the case of measures on a continuous reference set, as e.g. the real line, few results have been obtained that permit us to have an analytical expression of the integral. However, in most of the cases there is no such analytical expression. In this paper we describe how to perform the numerical integration of a Choquet integral with respect to a non-additive measure. © 2016 Elsevier B.V. All rights reserved.","Choquet integral; Numerical integration"
"Fusing and mining opinions for reputation generation","2017","Information Fusion","10.1016/j.inffus.2016.11.011","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85001033161&doi=10.1016%2fj.inffus.2016.11.011&partnerID=40&md5=3fab320518a66be5aecb4c9a12c8fa96","The Internet provides a convenient platform for people to freely share their opinions on any entities. The opinions expressed in natural languages carry the subjective attitudes and preferences of humans. They represent the public perspectives on any entity, thus impact user decisions and behaviors in some way. Therefore, opinions have been recognized as useful and valuable pieces of information for reputation generation. Fusing and mining opinions offer a promising approach to extract reputation information and track public perspectives. However, the literature lacks studies on this topic. In this paper, we propose a novel reputation generation approach based on opinion fusion and mining. In our approach, opinions are filtered to eliminate unrelated ones, and then grouped into a number of fused principal opinion sets that contain opinions with a similar or the same attitude or preference. By aggregating the ratings attached to the fused opinions, we normalize the reputation of an entity. Meanwhile, various types of recommendations can be generated based on relationships among opinions. To offer sufficient reputation information to users, we also propose a new way of reputation visualization. It shows the details of opinion fusing and mining results, such as the normalized reputation value, principal opinions with popularity and other statistics. Experimental results coming from an analysis of big real-world data collected from several popular commercial websites in both English and Chinese demonstrate the generality and accuracy of the proposed approach, especially the effectiveness of opinion filtering for reputation generation. A small-scale real-world user study further quantifies the user acceptance of the developed reputation visualization method. In the sequel, this implies that the proposed approach can be applied in practice to generate reputation. © 2016 Elsevier B.V.","Opinion fusion; Opinion mining; Recommender system; Reputation generation; Reputation visualization"
"A study of cognitive strategies for an autonomous search","2016","Information Fusion","10.1016/j.inffus.2015.06.008","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84938517769&doi=10.1016%2fj.inffus.2015.06.008&partnerID=40&md5=795258ca419fceb90b4b5baa723aab85","Abstract Cognitive search is a collective term for search strategies based on information theoretic rewards required in sequential decision making under uncertainty. The paper presents a comparative study of cognitive search strategies for finding an emitting source of unknown strength using sparse sensing cues in the form of occasional non-zero sensor measurements. The study is cast in the context of an emitting source of particles transported by turbulent flow. The search algorithm, which sequentially estimates the source parameters and the reward function for motion control, has been implemented using the sequential Monte Carlo method. The distribution of the search time has been explained by the inverse Gaussian distribution. Crown Copyright © 2015 Published by Elsevier B.V. All rights reserved.","Autonomous search; Dispersion modelling; Sensor management; Sequential Monte Carlo method; Turbulent flow"
"Score level fusion of classifiers in off-line signature verification","2016","Information Fusion","10.1016/j.inffus.2016.02.003","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84977855141&doi=10.1016%2fj.inffus.2016.02.003&partnerID=40&md5=6ea1886addba7e08c07cbbbaeee5e5de","Offline signature verification is a task that benefits from matching both the global shape and local details; as such, it is particularly suitable to a fusion approach. We present a system that uses a score-level fusion of complementary classifiers that use different local features (histogram of oriented gradients, local binary patterns and scale invariant feature transform descriptors), where each classifier uses a feature-level fusion to represent local features at coarse-to-fine levels. For classifiers, two different approaches are investigated, namely global and user-dependent classifiers. User-dependent classifiers are trained separately for each user, to learn to differentiate that user's genuine signatures from other signatures; while a single global classifier is trained with difference vectors of query and reference signatures of all users in the training set, to learn the importance of different types of dissimilarities. The fusion of all classifiers achieves a state-of-the-art performance with 6.97% equal error rate in skilled forgery tests using the public GPDS-160 signature database. The proposed system does not require skilled forgeries of the enrolling user, which is essential for real life applications. © 2016 Elsevier B.V. All rights reserved.","Histogram of oriented gradients; Local binary patterns; Offline signature; Scale invariant feature transform; Score-level fusion"
"Motion prediction via online instantaneous frequency estimation for vision-based beating heart tracking","2017","Information Fusion","10.1016/j.inffus.2016.09.004","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84988024362&doi=10.1016%2fj.inffus.2016.09.004&partnerID=40&md5=e2837f4355c8e96a19e7f770da66212a","The beating heart tracking based on stereo endoscope remains challenging due to highly dynamic scenes and poor imaging conditions in minimally invasive surgery. This paper proposes a new prediction method for robust tracking of heart motion. The dual time-varying Fourier series is used for modeling the motion of points of interest (POI) on heart surfaces, which is driven jointly by breathing and heartbeat motion. A dual Kalman filtering scheme is used to estimate the frequencies and Fourier coefficients of the model respectively. A novel orthogonal decomposition algorithm is developed to measure the instantaneous frequencies of breathing and heartbeat motion online from the 3D trajectory of the POI. The difference in direction between breathing and heartbeat motion is exploited by using principal component analysis on the past trajectory, and optimal 1D principal component signals are extracted for measuring the corresponding frequencies. The frequencies calculated from the orthogonal subbands are fused based on an additive noise model for optimal frequency measurement. The proposed method is evaluated and compared with other available prediction methods based on the simulated data and the real-measured signals from the videos recorded by the daVinci® surgical robot. The prediction algorithm is finally incorporated into a well-established visual tracking method to handle long-term occlusions. © 2016 Elsevier B.V.","Beating heart tracking; Instantaneous frequency; Kalman filter; Motion compensation; Motion prediction"
"A review of natural language processing techniques for opinion mining systems","2017","Information Fusion","10.1016/j.inffus.2016.10.004","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84994607116&doi=10.1016%2fj.inffus.2016.10.004&partnerID=40&md5=9222d57d0f33e5bd8092495affd34d15","As the prevalence of social media on the Internet, opinion mining has become an essential approach to analyzing so many data. Various applications appear in a wide range of industrial domains. Meanwhile, opinions have diverse expressions which bring along research challenges. Both of the practical demands and research challenges make opinion mining an active research area in recent years. In this paper, we present a review of Natural Language Processing (NLP) techniques for opinion mining. First, we introduce general NLP techniques which are required for text preprocessing. Second, we investigate the approaches of opinion mining for different levels and situations. Then we introduce comparative opinion mining and deep learning approaches for opinion mining. Opinion summarization and advanced topics are introduced later. Finally, we discuss some challenges and open problems related to opinion mining. © 2016 Elsevier B.V.","Deep learning; Machine learning; Natural language processing; Opinion mining; Sentiment analysis"
"A centralized immune-Voronoi deployment algorithm for coverage maximization and energy conservation in mobile wireless sensor networks","2016","Information Fusion","10.1016/j.inffus.2015.11.005","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84949512842&doi=10.1016%2fj.inffus.2015.11.005&partnerID=40&md5=d2fb24c3197f0be89726ab17fc0f8851","Saving energy is a most important challenge in Mobile Wireless Sensor Networks (MWSNs) to extend the lifetime, and optimal coverage is the key to it. Therefore, this paper proposes a Centralized Immune-Voronoi deployment Algorithm (CIVA) to maximize the coverage based on both binary and probabilistic models. CIVA utilizes the multi-objective immune algorithm that uses the Voronoi diagram properties to provide a better trade-off between the coverage and the energy consumption. The CIVA algorithm consists from two phases to improve the lifetime and the coverage of MWSN. In the first phase, CIVA controls the positions and the sensing ranges of Mobile Sensor Nodes (MSNs) based on maximizing the coverage and minimizing the dissipated energy in mobility and sensing. While the second phase of CIVA adjusts the radio (sleep/active) of MSNs to minimize the number of active sensors based on minimizing the consumption energy in sensing and redundant coverage and preserving the coverage at high level. The performance of the CIVA is compared with the previous algorithms using Matlab simulation for different network configurations with and without obstacles. Simulation results show that the CIVA algorithm outperforms the previous algorithms in terms of the coverage and the dissipated energy for different networks configurations. © 2015 Elsevier B.V. All rights reserved.","Coverage area; Immune algorithm; Mobile wireless sensor networks; Node deployment; Voronoi Diagram"
"Visual feature coding based on heterogeneous structure fusion for image classification","2017","Information Fusion","10.1016/j.inffus.2016.12.010","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85007360120&doi=10.1016%2fj.inffus.2016.12.010&partnerID=40&md5=5701107d1d9b762e425c8329964ba085","The relationship between visual words and local feature (words structure) or the distribution among images (images structure) is important in feature encoding to approximate the intrinsically discriminative structure of images in the Bag-of-Words (BoW) model. However, in recently most methods, the intrinsic invariance in intra-class images is difficultly captured using words structure or images structure for large variability image classification. To overcome this limitation, we propose a local visual feature coding based on heterogeneous structure fusion (LVFC-HSF) that explores the nonlinear relationship between words structure and images structure in feature space, as follows. First, we utilize high-order topology to describe the dependence of the visual words, and use the distance measurement based on the local feature to represent the distribution of images. Then, we construct the unitedly optimal framework according to the relevance between words structure and images structure to solve the projection matrix of local feature and the weight coefficient, which can exploit the nonlinear relationship of heterogeneous structure to balance their interaction. Finally, we adopt the improving fisher kernel(IFK) to fit the distribution of the projected features for obtaining the image feature. The experimental results on ORL, 15 Scenes, Caltech 101 and Caltech 256 demonstrate that heterogeneous structure fusion significantly enhances the intrinsic structure construction, and consequently improves the classification performance in these data sets. © 2016 Elsevier B.V.","Heterogeneous structure fusion; Image classification; Images structure; Words structure"
"An ensemble of patch-based subspaces for makeup-robust face recognition","2016","Information Fusion","10.1016/j.inffus.2015.09.005","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84992299300&doi=10.1016%2fj.inffus.2015.09.005&partnerID=40&md5=4639fcdd2cdd1ff02991a7a293c58707","Recent research has demonstrated the negative impact of makeup on automated face recognition. In this work, we introduce a patch-based ensemble learning method, which uses multiple subspaces generated by sampling patches from before-makeup and after-makeup face images, to address this problem. In the proposed scheme, each face image is tessellated into patches and each patch is represented by a set of feature descriptors, viz., Local Gradient Gabor Pattern (LGGP), Histogram of Gabor Ordinal Ratio Measures (HGORM) and Densely Sampled Local Binary Pattern (DS-LBP). Then, an improved Random Subspace Linear Discriminant Analysis (SRS-LDA) method is used to perform ensemble learning by sampling patches and constructing multiple common subspaces between before-makeup and after-makeup facial images. Finally, Collaborative-based and Sparse-based Representation Classifiers are used to compare feature vectors in this subspace and the resulting scores are combined via the sum-rule. The proposed face matching algorithm is evaluated on the YMU makeup dataset and is shown to achieve very good results. It outperforms other methods designed specifically for the makeup problem. © 2015 Elsevier B.V. All rights reserved.","Cosmetics; Ensemble learning; Face recognition; Makeup; Random subspace"
"A fused deep learning architecture for viewpoint classification of echocardiography","2017","Information Fusion","10.1016/j.inffus.2016.11.007","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84995804182&doi=10.1016%2fj.inffus.2016.11.007&partnerID=40&md5=550421904d7e0d399df8767f5e394946","This study extends the state of the art of deep learning convolutional neural network (CNN) to the classification of video images of echocardiography, aiming at assisting clinicians in diagnosis of heart diseases. Specifically, the architecture of neural networks is established by embracing hand-crafted features within a data-driven learning framework, incorporating both spatial and temporal information sustained by the video images of the moving heart and giving rise to two strands of two-dimensional convolutional neural network (CNN). In particular, the acceleration measurement along the time direction at each point is calculated using dense optical flow technique to represent temporal motion information. Subsequently, the fusion of both networks is conducted via linear integrations of the vectors of class scores obtained from each of the two networks. As a result, this architecture maintains the best classification results for eight viewpoint categories of echo videos with 92.1% accuracy rate whereas 89.5% is achieved using only single spatial CNN network. When concerning only three primary locations, 98% of accuracy rate is realised. In addition, comparisons with a number of well-known hand-engineered approaches are also performed, including 2D KAZE, 2D KAZE with Optical Flow, 3D KAZA, Optical Flow, 2D SIFT and 3D SIFT, which delivers accuracy rate of 89.4%, 84.3%, 87.9%, 79.4%, 83.8% and 73.8% respectively. © 2016 Elsevier B.V.","Classification architecture for echo video images; Convolutional neural network; Deep learning; Echocardiography; KAZE; SIFT; SURF"
"Utility-preserving differentially private data releases via individual ranking microaggregation","2016","Information Fusion","10.1016/j.inffus.2015.11.002","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84947474988&doi=10.1016%2fj.inffus.2015.11.002&partnerID=40&md5=94af327b315e78ce70b4261e1d0e1448","Being able to release and exploit open data gathered in information systems is crucial for researchers, enterprises and the overall society. Yet, these data must be anonymized before release to protect the privacy of the subjects to whom the records relate. Differential privacy is a privacy model for anonymization that offers more robust privacy guarantees than previous models, such as k-anonymity and its extensions. However, it is often disregarded that the utility of differentially private outputs is quite limited, either because of the amount of noise that needs to be added to obtain them or because utility is only preserved for a restricted type and/or a limited number of queries. On the contrary, k-anonymity-like data releases make no assumptions on the uses of the protected data and, thus, do not restrict the number and type of doable analyses. Recently, some authors have proposed mechanisms to offer general-purpose differentially private data releases. This paper extends such works with a specific focus on the preservation of the utility of the protected data. Our proposal builds on microaggregation-based anonymization, which is more flexible and utility-preserving than alternative anonymization methods used in the literature, in order to reduce the amount of noise needed to satisfy differential privacy. In this way, we improve the utility of differentially private data releases. Moreover, the noise reduction we achieve does not depend on the size of the data set, but just on the number of attributes to be protected, which is a more desirable behavior for large data sets. The utility benefits brought by our proposal are empirically evaluated and compared with related works for several data sets and metrics. © 2015 Elsevier Ltd. All rights reserved.","Data utility; Differential privacy; k-Anonymity; Microaggregation; Privacy-preserving data publishing"
"Ranking products through online reviews: A method based on sentiment analysis technique and intuitionistic fuzzy set theory","2017","Information Fusion","10.1016/j.inffus.2016.11.012","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84996939013&doi=10.1016%2fj.inffus.2016.11.012&partnerID=40&md5=bfdb856de093869454a489905685e070","Online product reviews have significant impacts on consumers’ purchase decisions. To support consumers’ purchase decisions, how to rank the products through online reviews is a valuable research topic, while research concerning this issue is still relatively scarce. This paper proposes a method based on the sentiment analysis technique and the intuitionistic fuzzy set theory to rank the products through online reviews. An algorithm based on sentiment dictionaries is developed to identify the positive, neutral or negative sentiment orientation on the alternative product concerning the product feature in each review. According to the identified positive, neutral and negative sentiment orientations, an intuitionistic fuzzy number is constructed for representing the performance of an alternative product concerning a product feature. The ranking of alternative products is determined by intuitionistic fuzzy weighted averaging (IFWA) operator and preference ranking organization methods for enrichment evaluations II (PROMETHEE II). A case study is given to illustrate the use of the proposed method. The comparisons and experiments are further conducted to illustrate the characteristics and advantages of the proposed method. Converting the identified positive, neutral and negative sentiment orientations into intuitionistic fuzzy numbers is a new idea for processing and fusing a large number of sentiment orientations of online reviews. Based on the proposed method, decision support system can be developed to support the consumers’ purchase decisions more conveniently. © 2016 Elsevier B.V.","IFWA operator; Intuitionistic fuzzy number; Online reviews; Product ranking; Sentiment analysis"
"Personalized individual semantics in computing with words for supporting linguistic group decision making. An application on consensus reaching","2017","Information Fusion","10.1016/j.inffus.2016.04.005","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84964743910&doi=10.1016%2fj.inffus.2016.04.005&partnerID=40&md5=73136f0d74d02404362e599fcc7e5f58","In group decision making (GDM) dealing with Computing with Words (CW) has been highlighted the importance of the statement, words mean different things for different people, because of its influence in the final decision. Different proposals that either grouping such different meanings (uncertainty) to provide one representation for all people or use multi-granular linguistic term sets with the semantics of each granularity, have been developed and applied in the specialized literature. Despite these models are quite useful they do not model individually yet the different meanings of each person when he/she elicits linguistic information. Hence, in this paper a personalized individual semantics (PIS) model is proposed to personalize individual semantics by means of an interval numerical scale and the 2-tuple linguistic model. Specifically, a consistency-driven optimization-based model to obtain and represent the PIS is introduced. A new CW framework based on the 2-tuple linguistic model is then defined, such a CW framework allows us to deal with PIS to facilitate CW keeping the idea that words mean different things to different people. In order to justify the feasibility and validity of the PIS model, it is applied to solve linguistic GDM problems with a consensus reaching process. © 2016 Elsevier B.V. All rights reserved.","2-tuple linguistic model; Computing with words; Group decision making; Preference relations; Semantics"
"Quantitative orness for lattice OWA operators","2016","Information Fusion","10.1016/j.inffus.2015.11.007","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84949895052&doi=10.1016%2fj.inffus.2015.11.007&partnerID=40&md5=68f76f31bdb805f0642ec4b85d4b85c8","This paper deals with OWA (ordered weighted average) operators defined on any complete lattice endowed with a t-norm and a t-conorm and satisfying a certain finiteness local condition. A parametrization of these operators is suggested by introducing a quantitative orness measure for each OWA operator, based on its proximity to the OR operator. The meaning of this measure is analyzed for some concrete OWA operators used in color image reduction, as well as for some OWA operators used in a medical decision making process. © 2015 Published by Elsevier B.V.","Decision making; Image processing; Lattice-valued fuzzy sets; Orness; OWA operator"
"Robust centralized and weighted measurement fusion Kalman estimators for uncertain multisensor systems with linearly correlated white noises","2017","Information Fusion","10.1016/j.inffus.2016.08.002","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84983397291&doi=10.1016%2fj.inffus.2016.08.002&partnerID=40&md5=ecf0c5e1ad35bf2c64e697cd25c5a8c1","This paper addresses the design of robust centralized fusion (CF) and weighted measurement fusion (WMF) Kalman estimators for a class of uncertain multisensor systems with linearly correlated white noises. The uncertainties of the systems include multiplicative noises, missing measurements, and uncertain noise variances. By introducing the fictitious noises, the considered system is converted into one with only uncertain noise variances. According to the minimax robust estimation principle, based on the worst-case system with the conservative upper bounds of uncertain noise variances, the robust CF and WMF time-varying Kalman estimators (predictor, filter, and smoother) are presented in a unified framework. Applying the Lyapunov equation approach, their robustness is proved in the sense that their actual estimation error variances are guaranteed to have the corresponding minimal upper bounds for all admissible uncertainties. Using the information filter, their equivalence is proved. Their accuracy relations are proved. The computational complexities of their algorithms are analyzed and compared. Compared with CF algorithm, the WMF algorithm can significantly reduce the computational burden when the number of sensors is larger. A robust weighted least squares (WLS) measurement fusion filter is also presented only based on the measurement equation, and it is proved that the robust accuracy of the robust CF or WMF Kalman filter is higher than that of robust WLS filter. The corresponding robust fused steady-state estimators are also presented, and the convergence in a realization between the time-varying and steady-state robust fused estimators is proved by the dynamic error system analysis (DESA) method. A simulation example shows the effectiveness and correctness of the proposed results. © 2016 Elsevier B.V.","Linearly correlated white noises; Minimax robust Kalman estimators; Missing measurements; Multiplicative noises; Uncertain noise variances; Weighted measurement fusion"
"An efficient ensemble pruning approach based on simple coalitional games","2017","Information Fusion","10.1016/j.inffus.2016.06.003","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84974698175&doi=10.1016%2fj.inffus.2016.06.003&partnerID=40&md5=c1bbbc3acf8e3d446d4f50dd110726df","We propose a novel ensemble pruning methodology using non-monotone Simple Coalitional Games, termed SCG-Pruning. Our main contribution is two-fold: (1) Evaluate the diversity contribution of a classifier based on Banzhaf power index. (2) Define the pruned ensemble as the minimal winning coalition made of the members that together exhibit moderate diversity. We also provide a new formulation of Banzhaf power index for the proposed game using weighted voting games. To demonstrate the validity and the effectiveness of the proposed methodology, we performed extensive statistical comparisons with several ensemble pruning techniques based on 58 UCI benchmark datasets. The results indicate that SCG-Pruning outperforms both the original ensemble and some major state-of-the-art selection approaches. © 2016 Elsevier B.V. All rights reserved.","Banzhaf power index; Diversity; Ensemble pruning; Simple coalitional game; Weighted voting game"
"The analysis of expert opinions’ consensus quality","2017","Information Fusion","10.1016/j.inffus.2016.06.005","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84977672908&doi=10.1016%2fj.inffus.2016.06.005&partnerID=40&md5=ee465609c8cdde43e7e965bfa3bd59c0","In many situations we need to obtain one, common decision (which can be understood as a consistent state of knowledge) out of opinions collected from many experts or any other external sources. This entails a problem concerning the reliability of such decision. We would like to know that decisions based on experts’ opinions are trustworthy. Unfortunately, in many cases the determination of such decision is difficult and expensive, especially when big sets of input data are involved in the process. This paper presents a framework which allows to assess the quality of the aforementioned final decision. Its output is based solely on the analysis of its input (e.g. an assumed representation of experts’ opinions). Moreover, the paper contains an overview of several types of possible approaches to the considered topic. © 2016 Elsevier B.V.","Consensus; Experts’ opinions; Quality"
"Multi-focus image fusion with a deep convolutional neural network","2017","Information Fusion","10.1016/j.inffus.2016.12.001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85002945898&doi=10.1016%2fj.inffus.2016.12.001&partnerID=40&md5=0da3c254784ecafecd2f718e2ae678d4","As is well known, activity level measurement and fusion rule are two crucial factors in image fusion. For most existing fusion methods, either in spatial domain or in a transform domain like wavelet, the activity level measurement is essentially implemented by designing local filters to extract high-frequency details, and the calculated clarity information of different source images are then compared using some elaborately designed rules to obtain a clarity/focus map. Consequently, the focus map contains the integrated clarity information, which is of great significance to various image fusion issues, such as multi-focus image fusion, multi-modal image fusion, etc. However, in order to achieve a satisfactory fusion performance, these two tasks are usually difficult to finish. In this study, we address this problem with a deep learning approach, aiming to learn a direct mapping between source images and focus map. To this end, a deep convolutional neural network (CNN) trained by high-quality image patches and their blurred versions is adopted to encode the mapping. The main novelty of this idea is that the activity level measurement and fusion rule can be jointly generated through learning a CNN model, which overcomes the difficulty faced by the existing fusion methods. Based on the above idea, a new multi-focus image fusion method is primarily proposed in this paper. Experimental results demonstrate that the proposed method can obtain state-of-the-art fusion performance in terms of both visual quality and objective assessment. The computational speed of the proposed method using parallel computing is fast enough for practical usage. The potential of the learned CNN model for some other-type image fusion issues is also briefly exhibited in the experiments. © 2016 Elsevier B.V.","Activity level measurement; Convolutional neural networks; Deep learning; Fusion rule; Image fusion; Multi-focus image fusion"
"Soft likelihood functions in combining evidence","2017","Information Fusion","10.1016/j.inffus.2016.11.013","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85000916488&doi=10.1016%2fj.inffus.2016.11.013&partnerID=40&md5=e17bfa466ef7cc693186d2d99c1e469b","We develop an approach for flexible computation of likelihood functions of probabilistic evidence in the context of forensic crime investigations. An ordered weighted average (OWA) aggregation approach allows a softening of the strong likelihood constraint of requiring all such evidence. Use of the OWA measure known as attitudinal character provides OWA weights allowing optimistic or pessimistic likelihood results. This approach is extended by introducing the reliability of evidence in the computations of likelihood functions. Examples of the basic OWA computation and the likelihood results introducing reliability are provided. © 2016 Elsevier B.V.","Attitudinal character; Evidence aggregation; Likelihood function; Ordered weighted average; Reliability"
"Gaussian-consensus filter for nonlinear systems with randomly delayed measurements in sensor networks","2016","Information Fusion","10.1016/j.inffus.2015.12.003","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84952331555&doi=10.1016%2fj.inffus.2015.12.003&partnerID=40&md5=c535cd961b18f18f35237cd6fbb3d23b","This paper presents the decentralized state estimation problem of discrete-time nonlinear systems with randomly delayed measurements in sensor networks. In this problem, measurement data from the sensor network is sent to a remote processing network via data transmission network, with random measurement delays obeying a Markov chain. Here, we present the Gaussian-consensus filter (GCF) to pursue a tradeoff between estimate accuracy and computing time. It includes a novel Gaussian approximated filter with estimated delay probability (GEDPF) online in the sense of minimizing the estimate error covariance in each local processing unit (PU), and a consensus strategy among PUs in processing network to give a fast decentralized fusion. A numerical example with different measurement delays is simulated to validate the proposed method. © 2015 Elsevier Ltd. All rights reserved.","Consensus filter; Gaussian approximated filter; Markov chain; Randomly delayed measurements; Sensor networks"
"Using multiple models to uncover blood vessel patterns in color images for forensic analysis","2016","Information Fusion","10.1016/j.inffus.2015.08.004","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84940824940&doi=10.1016%2fj.inffus.2015.08.004&partnerID=40&md5=230f831d18b9748c989d4d051aa119ca","With the proliferation of digital cameras, images of crimes, such as child sexual abuse images, are increasing dramatically. Both verification and identification of criminals and victims in these images are highly difficult and often impossible for the current biometric technology because their faces, tattoos, and distinctive skin mark patterns are not always observable. Superficial blood vessels under skin are a potential solution to compensate the weaknesses of the traditional biometric traits. However, blood vessels were neglected by law enforcement agencies because they are generally invisible in color images. To use blood vessel patterns in forensic analysis, this paper proposes three computational models to uncover hidden patterns, two optimization schemes to handle illumination variations and prevent over-relying on biophysical parameters measured in ideal medical conditions, a matching algorithm to automatically extract and compare noisy patterns, and two fusion rules to combine patterns from the three models for performance enhancement. The experimental results on 1900 color images and 1900 infrared images from 490 forearms and 460 thighs show that the matching performance of the blood vessel patterns from the color images is comparable with that from the infrared images. The proposed models are also applied to hands, arms, thighs, chests, breasts, and abdomens of men, women, and children in indoor and outdoor images collected from the Internet. Though these images were taken in uncontrolled environments and the subjects had different poses, the proposed models can uncover blood vessels. These results indicate that the potential of using blood vessel patterns in forensic analysis was underestimated. © 2015 Elsevier B.V. All rights reserved.","Biometrics; Child pornography; Forensics; Skin marks; Tattoos"
"Dynamics of linguistic opinion formation in bounded confidence model","2016","Information Fusion","10.1016/j.inffus.2016.03.001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84962784441&doi=10.1016%2fj.inffus.2016.03.001&partnerID=40&md5=b76711bb529e411ef414de5c56c49f44","Opinion dynamics is a fusion process of individual opinions based on the established fusion rules. The existing opinion dynamics models assume that agents express and receive their opinions in a numerical way. In this paper, we focus on the opinion formation in linguistic environment (i.e., linguistic opinion formation), and propose a linguistic opinion dynamics (LOD) model in the framework of the bounded confidence and the 2-tuples linguistic model with numerical scales. In the LOD model, agents express and receive the opinions by using the simple terms in a linguistic term set with finite granularity at each time. Based on the LOD model, we present some theoretical analyses to reveal the conditions to form a consensus or splits in the linguistic opinion formation. Furthermore, we design some simulations to investigate the effects of the bounded confidence and the uniformities of linguistic term sets on the linguistic opinion formation. The simulation results show that: (i) with the increase in the bounded confidence and the uniformities of linguistic term sets, the opportunity for reaching a consensus will increase, and the time for reaching a consensus will become shorter in the dynamics of linguistic opinion formation; (ii) there exists a critical point in the evolution of linguistic opinions, which is called agreed confidence in this paper, and a consensus among the agents will be reached if the value of the bounded confidence is equal or greater than the agreed confidence. © 2016 Elsevier B.V. All rights reserved.","2-tuples linguistic model; Bounded confidence; Fusion process; Linguistic opinions; Opinion dynamics"
"Towards a multi-source fusion approach for eye movement-driven recognition","2016","Information Fusion","10.1016/j.inffus.2015.08.003","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84940703015&doi=10.1016%2fj.inffus.2015.08.003&partnerID=40&md5=3a28dc7fcd82245916f74f82f6350a50","This paper presents a research for the use of multi-source information fusion in the field of eye movement biometrics. In the current state-of-the-art, there are different techniques developed to extract the physical and the behavioral biometric characteristics of the eye movements. In this work, we explore the effects from the multi-source fusion of the heterogeneous information extracted by different biometric algorithms under the presence of diverse visual stimuli. We propose a two-stage fusion approach with the employment of stimulus-specific and algorithm-specific weights for fusing the information from different matchers based on their identification efficacy. The experimental evaluation performed on a large database of 320 subjects reveals a considerable improvement in biometric recognition accuracy, with minimal equal error rate (EER) of 5.8%, and best case Rank-1 identification rate (Rank-1 IR) of 88.6%. It should be also emphasized that although the concept of multi-stimulus fusion is currently evaluated specifically for the eye movement biometrics, it can be adopted by other biometric modalities too, in cases when an exogenous stimulus affects the extraction of the biometric features. © 2015 Elsevier B.V. All rights reserved.","Eye movement biometrics; Multi-algorithmic fusion; Multi-stimulus fusion"
"PAC-Bayes analysis of multi-view learning","2017","Information Fusion","10.1016/j.inffus.2016.09.008","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84991783981&doi=10.1016%2fj.inffus.2016.09.008&partnerID=40&md5=0f9f67170cc0981ebf5a092882fb7f4c","Multi-view learning is a widely applicable research direction. This paper presents eight PAC-Bayes bounds to analyze the generalization performance of multi-view classifiers. These bounds adopt data dependent Gaussian priors which emphasize classifiers with high view agreements. The center of the prior for the first two bounds is the origin, while the center of the prior for the third and fourth bounds is given by a data dependent vector. An important technique to obtain these bounds is two derived logarithmic determinant inequalities whose difference lies in whether the dimensionality of data is involved. The centers of the fifth and sixth bounds are calculated on a separate subset of the training set. The last two bounds use unlabeled data to represent view agreements and are thus applicable to semi-supervised multi-view learning. We evaluate all the presented multi-view PAC-Bayes bounds on benchmark data and compare them with previous single-view PAC-Bayes bounds. The usefulness and performance of the multi-view bounds are discussed. © 2016 Elsevier B.V.","Multi-view learning; PAC-Bayes bound; Statistical learning theory; Support vector machine"
"Estimation, filtering and fusion for networked systems with network-induced phenomena: New progress and prospects","2016","Information Fusion","10.1016/j.inffus.2016.01.001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84955481474&doi=10.1016%2fj.inffus.2016.01.001&partnerID=40&md5=7eb1fb7e67780404f326c9256a99e433","In this paper, some recent advances on the estimation, filtering and fusion for networked systems are reviewed. Firstly, the network-induced phenomena under consideration are briefly recalled including missing/fading measurements, signal quantization, sensor saturations, communication delays, and randomly occurring incomplete information. Secondly, the developments of the estimation, filtering and fusion for networked systems from four aspects (linear networked systems, nonlinear networked systems, complex networks and sensor networks) are reviewed comprehensively. Subsequently, some recent results on the estimation, filtering and fusion for systems with the network-induced phenomena are reviewed in great detail. In particular, some latest results on the multi-objective filtering problems for time-varying nonlinear networked systems are summarized. Finally, conclusions are given and several possible research directions concerning the estimation, filtering, and fusion for networked systems are highlighted. © 2016 Elsevier B.V. All rights reserved.","Estimation; Filtering; Multi-sensor data fusion; Network-induced phenomena; Networked systems"
"Group sparse representation based classification for multi-feature multimodal biometrics","2016","Information Fusion","10.1016/j.inffus.2015.06.007","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84937047038&doi=10.1016%2fj.inffus.2015.06.007&partnerID=40&md5=cc98feab4a29a4cd7f42a1f0cb810be4","Multimodal biometrics technology consolidates information obtained from multiple sources at sensor level, feature level, match score level, and decision level. It is used to increase robustness and provide broader population coverage for inclusion. Due to the inherent challenges involved with feature-level fusion, combining multiple evidences is attempted at score, rank, or decision level where only a minimal amount of information is preserved. In this paper, we propose the Group Sparse Representation based Classifier (GSRC) which removes the requirement for a separate feature-level fusion mechanism and integrates multi-feature representation seamlessly into classification. The performance of the proposed algorithm is evaluated on two multimodal biometric datasets. Experimental results indicate that the proposed classifier succeeds in efficiently utilizing a multi-feature representation of input data to perform accurate biometric recognition. © 2015 Elsevier B.V. All rights reserved.","Biometrics; Feature-level fusion; Multimodal; Sparse representation"
"A System-of-Systems perspective for information fusion system design and evaluation","2017","Information Fusion","10.1016/j.inffus.2016.10.002","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84995603649&doi=10.1016%2fj.inffus.2016.10.002&partnerID=40&md5=703a3c1efa96d2552b63ee692c0169b7","This paper provides a System-of-Systems (SoS) perspective for integrated design and evaluation of an Information Fusion System (IFS). IFS is comprised of distributed and heterogeneous systems that accomplish low-level and high-level information fusion (LLIF and HLIF) functionality. LLIF and HLIF functions are developed independent from one another but require collaboration to achieve the IFS mission objectives. The distribution and heterogeneity of systems, in addition to the multiplicity of LLIF and HLIF functions, creates an extensively large design space for the IFS. We apply a SoS engineering architecting process to obtain integrated architectures of IFS and propose guidelines to constrain an otherwise infinite design space of Information Fusion System-of-Systems (IF-SoS). Furthermore, we elaborate a multi-agent system modeling approach and pair it with Design of Experiments for objective evaluation of the IF-SoS design space. The statistical analysis, based on analysis of variance (ANOVA) and Tukey Honest Significant Difference (HSD) Range Tests, quantifies the impact of interactions between LLIF and HLIF design considerations on the IF-SoS performance. Furthermore, statistical evidence is provided to demonstrate that the interactions among JDL levels, in particular between LLIF and HLIF, are the most significant design considerations for fusion performance which necessitate an integrated design and evaluation of LLIF and HLIF—a manifestation of the SoS perspective for the IFS. © 2016 Elsevier B.V.","Design of Experiments; Information Fusion System; Model Based Systems Engineering; System-of-Systems"
"MRI segmentation fusion for brain tumor detection","2017","Information Fusion","10.1016/j.inffus.2016.10.003","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85006810960&doi=10.1016%2fj.inffus.2016.10.003&partnerID=40&md5=09224d18c29c59bfa40ba12e6c2ff3b0","The process of manually generating precise segmentations of brain tumors from magnetic resonance images (MRI) is time-consuming and error-prone. We present a new algorithm, Potential Field Segmentation (PFS), and propose the use of ensemble approaches that combine the results generated by PFS and other methods to achieve a fused segmentation. For the PFS method, we build on our recently proposed clustering algorithm, Potential Field Clustering, which is based on an analogy with the concept of potential field in Physics. We view the intensity of a pixel in an MRI as a “mass” that creates a potential field. Specifically, for each pixel in the MRI, the potential field is computed and, if smaller than an adaptive potential threshold, the pixel is associated with the tumor region. This “small potential” segmentation criterion is intuitively valid because tumor pixels have larger “mass” and thus the potential of surrounding regions is also much larger than in other regions of smaller or no “mass”. We evaluate the performance of the different methods, including the ensemble approaches, on the publicly available Brain Tumor Image Segmentation (BRATS) MRI benchmark database. © 2016 Elsevier B.V.","Clustering; Data fusion; Medical imaging; MRI; Segmentation; Tumor"
"Infrared and visible image fusion via gradient transfer and total variation minimization","2016","Information Fusion","10.1016/j.inffus.2016.02.001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84958952372&doi=10.1016%2fj.inffus.2016.02.001&partnerID=40&md5=d8a2ef461b8ebb2f1c21e7f78d528383","In image fusion, the most desirable information is obtained from multiple images of the same scene and merged to generate a composite image. This resulting new image is more appropriate for human visual perception and further image-processing tasks. Existing methods typically use the same representations and extract the similar characteristics for different source images during the fusion process. However, it may not be appropriate for infrared and visible images, as the thermal radiation in infrared images and the appearance in visible images are manifestations of two different phenomena. To keep the thermal radiation and appearance information simultaneously, in this paper we propose a novel fusion algorithm, named Gradient Transfer Fusion (GTF), based on gradient transfer and total variation (TV) minimization. We formulate the fusion problem as an ℓ1-TV minimization problem, where the data fidelity term keeps the main intensity distribution in the infrared image, and the regularization term preserves the gradient variation in the visible image. We also generalize the formulation to fuse image pairs without pre-registration, which greatly enhances its applicability as high-precision registration is very challenging for multi-sensor data. The qualitative and quantitative comparisons with eight state-of-the-art methods on publicly available databases demonstrate the advantages of GTF, where our results look like sharpened infrared images with more appearance details. © 2016 Elsevier B.V.","Gradient transfer; Image fusion; Infrared; Registration; Total variation"
"Gb2sμMOD: A MUltiMODal biometric video database using visible and IR light","2016","Information Fusion","10.1016/j.inffus.2015.09.003","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84956969385&doi=10.1016%2fj.inffus.2015.09.003&partnerID=40&md5=aba7090b6aa21fa9f2a8066b30f0f97c","In spite of recent efforts in gathering multimodal databases containing a big number of traits, a huge amount of users and covering multiple realistic scenarios, there is still a lack of touch-less realistic samples, video recordings for some traits and the use of infrared cameras which allows, among others, to avoid lighting influence and test recently appeared biometric techniques such as hand vein recognition. For this reason, a new realistic multimodal database composed of 8,160 hand, iris and face videos has been captured. To this end, a total of 60 contributors have participated in three separated acquisition sessions in which three different cameras have been used, covering different ranges of the light spectrum: visible light and two different infrared wavelengths. To simulate real-world working conditions, the database has been recorded in an indoor environment with different lightings and backgrounds. In addition, due to the relevance of performing evaluation experiments in such a way that a reliable comparison of the results can be accomplished, an evaluation protocol is provided at the end of this paper. Moreover, performance results are provided for several biometric traits in mono- and multi- modalities that can be used as a baseline. © 2015 Elsevier B.V. All rights reserved.","Biometrics; Database; Multimodal; Multisensor; Realistic Environments; Touch-less; Video"
"Sheaves are the canonical data structure for sensor integration","2017","Information Fusion","10.1016/j.inffus.2016.12.002","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85005990079&doi=10.1016%2fj.inffus.2016.12.002&partnerID=40&md5=19152ff5e8e87af1174eb5da41baf6fb","A sensor integration framework should be sufficiently general to accurately represent many sensor modalities, and also be able to summarize information in a faithful way that emphasizes important, actionable information. Few approaches adequately address these two discordant requirements. The purpose of this expository paper is to explain why sheaves are the canonical data structure for sensor integration and how the mathematics of sheaves satisfies our two requirements. We outline some of the powerful inferential tools that are not available to other representational frameworks. © 2016 Elsevier B.V.","Cohomology; Heterogeneous data source; Mosaic; Semantic fusion; Sensor integration; Sheaf"
"A box-particle implementation of standard PHD filter for extended target tracking","2017","Information Fusion","10.1016/j.inffus.2016.06.007","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976631566&doi=10.1016%2fj.inffus.2016.06.007&partnerID=40&md5=c1d0a7d8c86fe37c47462f4b0ed3ae8b","This paper presents a box-particle implementation of the standard probability hypothesis density (PHD) filter for extended target tracking, called the extended target box-particle PHD (ET-Box-PHD) filter. The proposed filter can dynamically track multiple extended targets and estimate the unknown number of extended targets, in the presence of clutter measurements, false alarms and missed detections, where the extended targets are described as a Poisson model developed by Gilholm et al. To get the PHD recursion of the ET-Box-PHD filter, a suitable cell likelihood function for one given reliable partition is derived, and the main filter steps are presented along with the necessary box manipulations and approximations. The capabilities and limitations of the proposed ET-Box-PHD filter are illustrated both in linear simulation examples and in nonlinear ones. The simulation results show that the proposed ET-Box-PHD filter can effectively avoid the high number of particles and obviously reduce computational burden, compared to a particle implementation of the standard PHD filter for extended target tracking. © 2016 Elsevier B.V.","Bayesian partition; Box-particle implementation; Cell likelihood; Extended target; Standard PHD filter"
"Tackling the supervised label ranking problem by bagging weak learners","2017","Information Fusion","10.1016/j.inffus.2016.09.002","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84989814714&doi=10.1016%2fj.inffus.2016.09.002&partnerID=40&md5=1951d1925d7abaca9b933c85ec59a497","Preference learning is the branch of machine learning in charge of inducing preference models from data. In this paper we focus on the task known as label ranking problem, whose goal is to predict a ranking among the different labels the class variable can take. Our contribution is twofold: (i) taking as basis the tree-based algorithm LRT described in [1], we design weaker tree-based models which can be learnt more efficiently; and (ii) we show that bagging these weak learners improves not only the LRT algorithm, but also the state-of-the-art one (IBLR [1]). Furthermore, the bagging algorithm which takes the weak LRT-based models as base classifiers is competitive in time with respect to LRT and IBLR methods. To check the goodness of our proposal, we conduct a broad experimental study over the standard benchmark used in the label ranking problem literature. © 2016 Elsevier B.V.","Bagging; Decision tree; Ensemble; Label ranking problem; Mallows model; Supervised classification"
"A semantic-grained perspective of latent knowledge modeling","2017","Information Fusion","10.1016/j.inffus.2016.11.003","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84995466207&doi=10.1016%2fj.inffus.2016.11.003&partnerID=40&md5=423a4c985f3ca2d362da7f86998164e6","In the era of Web 2.0, the knowledge is the de-facto social currency in the global network environment. Knowledge is not an accumulation of data, but a relation-based representation of the information content, which needs to be distilled and arranged in a semantic infrastructure to guarantee interoperability and sharable understanding. In the light of this scenario, the paper introduces a semantically enhanced document retrieval system that describes each retrieved document with an ontological multi-grained network of the extracted conceptualization. The system is based on two well-known latent models: Latent Semantic Analysis (LSA) and Latent Dirichlet Allocation (LDA): LSA provides a spatial distribution of the input documents, facilitating their retrieval, thanks to an ontological representation of their relationship network. LDA works instead at deeper level: it drives the ontological structuring of the knowledge inside the individual retrieved documents in terms of words, concepts and topics. The novelty of this approach is a multi-level granulation of the knowledge: from a document matching the query (coarse granularity), to the topics that join documents, until to the words describing a concept into a topic (fine granularity). The final result is a SKOS-based ontology, ad-hoc created for a document corpus; graphically supported for the navigation, it enables the exploration of the concepts at different granularity levels. © 2016 Elsevier B.V.","Concept extraction; Knowledge structuring; Latent Dirichlet Allocation (LDA); Latent Semantic Analysis (LSA); Ontology; SKOS"
"Decision forest: Twenty years of research","2016","Information Fusion","10.1016/j.inffus.2015.06.005","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84933574325&doi=10.1016%2fj.inffus.2015.06.005&partnerID=40&md5=0b63e99f4357b035f1814d55f7878171","A decision tree is a predictive model that recursively partitions the covariate's space into subspaces such that each subspace constitutes a basis for a different prediction function. Decision trees can be used for various learning tasks including classification, regression and survival analysis. Due to their unique benefits, decision trees have become one of the most powerful and popular approaches in data science. Decision forest aims to improve the predictive performance of a single decision tree by training multiple trees and combining their predictions. This paper provides an introduction to the subject by explaining how a decision forest can be created and when it is most valuable. In addition, we are reviewing some popular methods for generating the forest, fusion the individual trees' outputs and thinning large decision forests. © 2015 Elsevier B.V. All rights reserved.","Classification tree; Decision forest; Decision tree; Random forest"
"Optimal sequential fusion for multibiometric cryptosystems","2016","Information Fusion","10.1016/j.inffus.2016.02.002","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84966711329&doi=10.1016%2fj.inffus.2016.02.002&partnerID=40&md5=97c02119d20513441d3ef2fea251dfc7","Biometric cryptosystems have been widely studied in the literature to protect biometric templates. To ensure sufficient security of the biometric cryptosystem against the offline brute-force attack (also called the FAR attack), it is critical to reduce FAR of the system. One of the most effective approaches to improve the accuracy is multibiometric fusion, which can be divided into three categories: feature level fusion, score level fusion, and decision level fusion. Among them, only feature level fusion can be applied to the biometric cryptosystem for security and accuracy reasons. Conventional feature level fusion schemes, however, require a user to input all of the enrolled biometric samples at each time of authentication, and make the system inconvenient. In this paper, we first propose a general framework for feature level sequential fusion, which combines biometric features and makes a decision each time a user inputs a biometric sample. We then propose a feature level sequential fusion algorithm that can minimize the average number of input, and prove its optimality theoretically. We apply the proposed scheme to the fuzzy commitment scheme, and demonstrate its effectiveness through experiments using the finger-vein dataset that contains six fingers from 505 subjects. We also analyze the security of the proposed scheme against various attacks: attacks that exploit the relationship between multiple protected templates, the soft-decoding attack, the statistical attack, and the decodability attack. © 2016 Elsevier B.V. All rights reserved.","Biometric cryptosystems; Multimodal biometrics; Sequential fusion; Sequential probability ratio test"
"Applying Gaussian distributed constraints to Gaussian distributed variables","2016","Information Fusion","10.1016/j.inffus.2016.02.008","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84962308795&doi=10.1016%2fj.inffus.2016.02.008&partnerID=40&md5=f4be61a70717c22f09f3694a01517b05","This paper develops an analytical method of truncating inequality constrained Gaussian distributed variables where the constraints are themselves described by Gaussian distributions. Existing truncation methods either assume hard constraints, or use numerical methods to handle uncertain constraints. The proposed approach introduces moment-based Gaussian approximations of the truncated distribution. This method can be applied to numerous problems, with the motivating problem being Kalman filtering with uncertain constraints. In a simulation example, the developed method is shown to outperform unconstrained Kalman filtering by over 40% and hard-constrained Kalman filtering by over 17%. © 2016 Elsevier B.V. All rights reserved.","Constrained Kalman filter; Uncertain constraints"
"Tweet categorization by combining content and structural knowledge","2016","Information Fusion","10.1016/j.inffus.2016.01.002","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84955466168&doi=10.1016%2fj.inffus.2016.01.002&partnerID=40&md5=049d95f8c2f97144fe2f3e9667e83177","Twitter is a worldwide social media platform where millions of people frequently express ideas and opinions about any topic. This widespread success makes the analysis of tweets an interesting and possibly lucrative task, being those tweets rarely objective and becoming the targeting for large-scale analysis. In this paper, we explore the idea of integrating two fundamental aspects of a tweet, the proper textual content and its underlying structural information, when addressing the tweet categorization task. Thus, not only we analyze textual content of tweets but also analyze the structural information provided by the relationship between tweets and users, and we propose different methods for effectively combining both kinds of feature models extracted from the different knowledge sources. In order to test our approach, we address the specific task of determining the political opinion of Twitter users within their political context, observing that our most refined knowledge integration approach performs remarkably better (about 5 points above) than the textual-based classic model. © 2016 Elsevier B.V. All rights reserved.","Ensemble learning; Knowledge combination; Tweet categorization; Twitter"
"Domain-specific sentiment classification via fusing sentiment knowledge from multiple sources","2017","Information Fusion","10.1016/j.inffus.2016.09.001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84986000584&doi=10.1016%2fj.inffus.2016.09.001&partnerID=40&md5=0824fd9e13538429452ac458cdf30f2a","Analyzing the sentiments in massive user-generated online data, such as product reviews and microblogs, has become a hot research topic. It can help customers, companies and expert systems make more informed decisions. Sentiment analysis is widely known as a domain dependent problem. Different domains usually have different sentiment expressions and a general sentiment classifier is not suitable for all domains. A natural solution to this problem is to train a domain-specific sentiment classifier for each target domain. However, the labeled data in target domain is usually insufficient, and it is costly and time-consuming to annotate enough samples. In order to tackle this problem, we propose a novel approach to train domain-specific sentiment classifiers by fusing the sentiment knowledge from multiple sources. Sentiment information from four sources is extracted and fused in our approach. The first source is sentiment lexicons, which contain sentiment polarities of general sentiment words. The second source is the sentiment classifiers of multiple source domains. The third source is the unlabeled data in target domain, from which we extract domain-specific sentiment relations among words. The fourth source is the labeled data in target domain. We propose a unified framework to fuse these four kinds of sentiment knowledge and train domain-specific sentiment classifier for target domain. In addition, we present an efficient optimization algorithm to solve the model of our approach. Extensive experiments are conducted on both Amazon product review dataset and Twitter dataset. Experimental results show that by fusing the sentiment information extracted from multiple sources, our approach can effectively improve the performance of sentiment classification and reduce the dependence on labeled data. For instance, our approach can achieve an accuracy of 87.22% in Kitchen domain when only 200 samples in target domain are labeled. The performance improvements of our approach compared with purely supervised sentiment classifier are 8.98% and 7.92% on Amazon and Twitter datasets respectively. © 2016 Elsevier B.V.","Domain adaptation; Information fusion; Sentiment classification"
"A review of source term estimation methods for atmospheric dispersion events using static or mobile sensors","2017","Information Fusion","10.1016/j.inffus.2016.11.010","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84996841786&doi=10.1016%2fj.inffus.2016.11.010&partnerID=40&md5=a4efede14fbebde8dbcd569d68493dfa","Understanding atmospheric transport and dispersal events has an important role in a range of scenarios. Of particular importance is aiding in emergency response after an intentional or accidental chemical, biological or radiological (CBR) release. In the event of a CBR release, it is desirable to know the current and future spatial extent of the contaminant as well as its location in order to aid decision makers in emergency response. Many dispersion phenomena may be opaque or clear, thus monitoring them using visual methods will be difficult or impossible. In these scenarios, relevant concentration sensors are required to detect the substance where they can form a static network on the ground or be placed upon mobile platforms. This paper presents a review of techniques used to gain information about atmospheric dispersion events using static or mobile sensors. The review is concluded with a discussion on the current limitations of the state of the art and recommendations for future research. © 2016","Atmospheric dispersion; Bayesian inference; Boundary tracking; Dispersion modelling; Inverse modelling; Optimisation; Source estimation; Source localisation"
"Monometrics and their role in the rationalisation of ranking rules","2017","Information Fusion","10.1016/j.inffus.2016.06.001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84974573971&doi=10.1016%2fj.inffus.2016.06.001&partnerID=40&md5=a9652be1469899e0b64133f76d824d8c","The aggregation of rankings is a long-standing problem that consists of, given a profile of rankings, obtaining the single ranking that best represents the nature of this given profile. Under the name of metric rationalisation of ranking rules, it has been proven that most ranking rules can be characterized as minimizing the distance to a consensus state for some appropriate distance function. In this paper, we propose to consider monometrics instead of distance functions. Although these concepts are closely related, monometrics better capture the nature of the problem, as the purpose of a monometric is to preserve a given betweenness relation. This is obviously only meaningful when an interesting betweenness relation is fixed, for instance, the one based on reversals in rankings proposed by Kemeny. In this way, ranking rules can be characterized in terms of a consensus state and a monometric. © 2016 Elsevier B.V. All rights reserved.","Aggregation of rankings; Consensus state; Monometric; Ranking"
"Adaptive management of multimodal biometrics fusion using ant colony optimization","2016","Information Fusion","10.1016/j.inffus.2015.09.002","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84967146034&doi=10.1016%2fj.inffus.2015.09.002&partnerID=40&md5=9b1553da80174c183b9651f16ba29087","This paper presents a new approach for the adaptive management of multimodal biometrics to meet a wide range of application dependent adaptive security requirements. In this work, ant colony optimization (ACO) is employed for the selection of key parameters like decision threshold and fusion rule, to ensure the optimal performance in meeting varying security requirements during the deployment of multimodal biometrics systems. Particle swarm optimization (PSO) has been widely utilized for the optimal selection of these parameters in the earlier attempts in the literature [Veeramachaneni et al., 2005] and [Kumar et al., 2010]. However, in PSO these parameters are computed in continuous domain while they are assumed to be better represented as discrete variables [Kumar et al., 2010]. This paper therefore proposes the use of ACO, in which discrete biometric verification parameters are computed to ensure the optimal performance from the multimodal biometrics system. The proposed ACO based framework is also extended to the pattern classification approach where fuzzy binary decision tree (FBDT) is utilized for two-class biometrics verification. The experimental results are presented on true multimodal systems from various publicly available databases; IITD databases of palmprint and iris, XM2VTS database of speech and faces, and the NIST BSSR1 databases of faces and fingerprint images. Our experimental results presented in this paper suggest that (i) ACO based approach is capable of operating on significantly small error rates in comparison to the widely employed PSO for automated selection of biometrics fusion rules/parameters, (ii) the score-level fusion yields better performance with lower error rate in comparison to the decision level fusion, and finally (iii) the FBDT based classification approach delivers considerably superior performance for the adaptive biometrics verification. © 2015 Elsevier B.V. All rights reserved.","ACO; Adaptive biometric verification; FBDT; PSO; Score-level fusion"
"Spatial anomaly detection in sensor networks using neighborhood information","2017","Information Fusion","10.1016/j.inffus.2016.04.007","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84966421068&doi=10.1016%2fj.inffus.2016.04.007&partnerID=40&md5=5f14cd1f5135b57b47493722d78b50a0","The field of wireless sensor networks (WSNs), embedded systems with sensing and networking capability, has now matured after a decade-long research effort and technological advances in electronics and networked systems. An important remaining challenge now is to extract meaningful information from the ever-increasing amount of sensor data collected by WSNs. In particular, there is strong interest in algorithms capable of automatic detection of patterns, events or other out-of-the order, anomalous system behavior. Data anomalies may indicate states of the system that require further analysis or prompt actions. Traditionally, anomaly detection techniques are executed in a central processing facility, which requires the collection of all measurement data at a central location, an obvious limitation for WSNs due to the high data communication costs involved. In this paper we explore the extent by which one may depart from this classical centralized paradigm, looking at decentralized anomaly detection based on unsupervised machine learning. Our aim is to detect anomalies at the sensor nodes, as opposed to centrally, to reduce energy and spectrum consumption. We study the information gain coming from aggregate neighborhood data, in comparison to performing simple, in-node anomaly detection. We evaluate the effects of neighborhood size and spatio-temporal correlation on the performance of our new neighborhood-based approach using a range of real-world network deployments and datasets. We find the conditions that make neighborhood data fusion advantageous, identifying also the cases in which this approach does not lead to detectable improvements. Improvements are linked to the diffusive properties of data (spatio-temporal correlations) but also to the type of sensors, anomalies and network topological features. Overall, when a dataset stems from a similar mixture of diffusive processes precision tends to benefit, particularly in terms of recall. Our work paves the way towards understanding how distributed data fusion methods may help managing the complexity of wireless sensor networks, for instance in massive Internet of Things scenarios. © 2016 Published by Elsevier B.V.","Anomaly detection; Collaborative WSN; Sensor fusion; Sensor networks"
"Surface area-based focus criterion for multi-focus image fusion","2017","Information Fusion","10.1016/j.inffus.2016.12.009","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85007485801&doi=10.1016%2fj.inffus.2016.12.009&partnerID=40&md5=c12a4a2a0c4f1a79e2d23d5b0e54fd28","Nowadays image processing and machine vision fields have become important research topics due to numerous applications in almost every field of science. Performance in these fields is critically dependent to the quality of input images. In most of the imaging devices, optical lenses are used to capture images from a particular scene. But due to the limited depth of field of optical lenses, objects in different distances from focal point will be captured with different sharpness and details. Thus, important details of the scene might be lost in some regions. Multi-focus image fusion is an effective technique to cope with this problem. The main challenge in multi-focus fusion is the selection of an appropriate focus measure. In this paper, we propose a novel focus measure based on the surface area of regions surrounded by intersection points of input source images. The potential of this measure to distinguish focused regions from the blurred ones is proved. In our fusion algorithm, intersection points of input images are calculated and then input images are segmented using these intersection points. After that, the surface area of each segment is considered as a measure to determine focused regions. Using this measure we obtain an initial selection map of fusion which is then refined by morphological modifications. To demonstrate the performance of the proposed method, we compare its results with several competing methods. The results show the effectiveness of our proposed method. © 2016 Elsevier B.V.","Focus criterion; Fusion metrics; Multi-focus image fusion; Surface area"
"Exploiting the ensemble paradigm for stable feature selection: A case study on high-dimensional genomic data","2017","Information Fusion","10.1016/j.inffus.2016.10.001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84991777388&doi=10.1016%2fj.inffus.2016.10.001&partnerID=40&md5=525850c216d0006b27960dad58240c0d","Ensemble classification is a well-established approach that involves fusing the decisions of multiple predictive models. A similar “ensemble logic” has been recently applied to challenging feature selection tasks aimed at identifying the most informative variables (or features) for a given domain of interest. In this work, we discuss the rationale of ensemble feature selection and evaluate the effects and the implications of a specific ensemble approach, namely the data perturbation strategy. Basically, it consists in combining multiple selectors that exploit the same core algorithm but are trained on different perturbed versions of the original data. The real potential of this approach, still object of debate in the feature selection literature, is here investigated in conjunction with different kinds of core selection algorithms (both univariate and multivariate). In particular, we evaluate the extent to which the ensemble implementation improves the overall performance of the selection process, in terms of predictive accuracy and stability (i.e., robustness with respect to changes in the training data). Furthermore, we measure the impact of the ensemble approach on the final selection outcome, i.e. on the composition of the selected feature subsets. The results obtained on ten public genomic benchmarks provide useful insight on both the benefits and the limitations of such ensemble approach, paving the way to the exploration of new and wider ensemble schemes. © 2016 Elsevier B.V.","Data perturbation; Ensemble paradigm; Feature selection; High-dimensional genomic data; Selection stability"
"A novel multi-focus image fusion approach based on image decomposition","2017","Information Fusion","10.1016/j.inffus.2016.09.007","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84988521374&doi=10.1016%2fj.inffus.2016.09.007&partnerID=40&md5=6cfa59afdf925924fa8e58605602d420","Multi-focus image fusion is an effective technique to integrate the relevant information from a set of images with the same scene, into a comprehensive image. The fused image would be more informative than any of the source images. In this paper, a novel fusion scheme based on image cartoon-texture decomposition is proposed. Multi-focus source images are decomposed into cartoon content and texture content by an improved iterative re-weighted decomposition algorithm. It can achieve rapid convergence and naturally approximates the morphological structure components. The proper fusion rules are constructed to fuse the cartoon content and the texture content, respectively. Finally, the fused cartoon and texture components are combined to obtain the all-in-focus image. This fusion processing can preserve morphological structure information from source images and performs few artifacts or additional noise. Our experimental results have clearly shown that the proposed algorithm outperforms many state-of-the-art methods, in terms of visual and quantitative evaluations. © 2016 Elsevier B.V.","Cartoon content; Image decomposition; Multi-focus image fusion; Texture content"
"Fusion of instance selection methods in regression tasks","2016","Information Fusion","10.1016/j.inffus.2015.12.002","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84951822313&doi=10.1016%2fj.inffus.2015.12.002&partnerID=40&md5=6e5ef323aeabdeb9e981a408db7f7b34","Data pre-processing is a very important aspect of data mining. In this paper we discuss instance selection used for prediction algorithms, which is one of the pre-processing approaches. The purpose of instance selection is to improve the data quality by data size reduction and noise elimination. Until recently, instance selection has been applied mainly to classification problems. Very few recent papers address instance selection for regression tasks. This paper proposes fusion of instance selection algorithms for regression tasks to improve the selection performance. As the members of the ensemble two different families of instance selection methods are evaluated: one based on distance threshold and the other one on converting the regression task into a multiple class classification task. Extensive experimental evaluation performed on the two regression versions of the Edited Nearest Neighbor (ENN) and Condensed Nearest Neighbor (CNN) methods showed that the best performance measured by the error value and data size reduction are in most cases obtained for the ensemble methods. © 2015 Elsevier B.V. All rights reserved.","Ensemble models; Instance selection; Regression"
"Combining eye tracking, pupil dilation and EEG analysis for predicting web users click intention","2017","Information Fusion","10.1016/j.inffus.2016.09.003","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84987974432&doi=10.1016%2fj.inffus.2016.09.003&partnerID=40&md5=3b261689f085e64a6644626aae687a87","In this paper a novel approach for analyzing web user behavior and preferences on a web site is introduced, consisting of a physiological-based analysis for the assessment of a web users’ click intention, by merging pupil dilation and electroencephalogram (EEG) responses.; First, we conducted an empirical study using five real web sites from which the gaze position, pupil dilation and EEG of 21 human subjects were recorded while performing diverse information foraging tasks. We found the existence of a statistical differentiation between choice and not-choice pupil dilation curves, specifically that fixations corresponding to clicks had greater pupil size than fixations without a click.; Then 7 classification models were proposed using 15 out of 789 pupil dilation and EEG features obtained from a Random Lasso feature selection process. Although good results were obtained for Accuracy (71,09% using Logistic Regression), the results for Precision, Recall and F-Measure remained low, which indicates that the behaviour we were studying was not well classified.; The above results show that it is possible to create a classifier for web user click intention behaviour based on merging features extracted from pupil dilation and EEG responses. However we conclude that it is necessary to use better quality instruments for capturing the data. © 2016 Elsevier B.V.","Decision making; EEG; Eye-tracking; Pupil dilation; Web user"
"Improving positioning accuracy of vehicular navigation system during GPS outages utilizing ensemble learning algorithm","2017","Information Fusion","10.1016/j.inffus.2016.08.001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84983448668&doi=10.1016%2fj.inffus.2016.08.001&partnerID=40&md5=f7217dfc4bbbba206f0840cd6897c554","Recently, methods based on Artificial Intelligence (AI) have been widely used to improve positioning accuracy for land vehicle navigation by integrating the Global Positioning System (GPS) with the Strapdown Inertial Navigation System (SINS). In this paper, we propose the ensemble learning algorithm instead of traditional single neural network to overcome the limitations of complex and dynamic data cased by vehicle irregular movement. The ensemble learning algorithm (LSBoost or Bagging), similar to the neural network, can build the SINS/GPS position model based on current and some past samples of SINS velocity, attitude and IMU output information. The performance of the proposed algorithm has been experimentally verified using GPS and SINS data of different trajectories collected in some land vehicle navigation tests. The comparison results between the proposed model and traditional algorithms indicate that the proposed algorithm can improve the positioning accuracy for cases of SINS and specific GPS outages. © 2016 Elsevier B.V.","Ensemble learning algorithm; Gps outages; Neural network; Sins/gps integration"
"Super- and subadditive constructions of aggregation functions","2017","Information Fusion","10.1016/j.inffus.2016.06.006","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976864811&doi=10.1016%2fj.inffus.2016.06.006&partnerID=40&md5=181ce0c5f47124996ef633444bd6414e","Two construction methods for aggregation functions based on a restricted a priori known decomposition set and decomposition weighing function are introduced and studied. The outgoing aggregation functions are either superadditive or subadditive. Several examples, including illustrative figures, show the potential of the introduced construction methods. Our approach generalizes several known constructions and optimization methods, including decomposition and superdecomposition integrals. We present also an economic applications of the introduced concepts. © 2016 Elsevier B.V.","Aggregation function; Decomposition integral; Subadditive transformation; Superadditive transformation"
"Diffusion Kalman filtering with multi-channel decoupled event-triggered strategy and its application to the optic-electric sensor network","2017","Information Fusion","10.1016/j.inffus.2016.12.004","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85006511356&doi=10.1016%2fj.inffus.2016.12.004&partnerID=40&md5=5b4267594ad3deb3558732c81fa9d1ec","Recently the distributed estimation problem with communication constraints has been widely studied for sensor network application. Our work focus on the diffusion Kalman filter with communication constraints. To satisfy finite communication resources constraints, this paper presents a multi-channel decoupled event-triggered strategy which improves the utilization of the network communication resources. With this strategy, only some entries of sensors’ measurements are transmitted if their triggering criteria are satisfied. We apply this strategy to the step 1 of the diffusion Kalman filter and analyze its performance. The analysis shows that the multi-channel decoupled event-triggered diffusion Kalman filter is unbiased in mean sense and is convergent in mean-square sense. The theoretical steady-state mean-square deviation (MSD) and communication cost are also given in this article. Simulation results demonstrate a good match between the theory analysis and experiment. Finally this algorithm is applied to the optic-electric sensor network, and the results verify the effectiveness of the proposed strategy in terms of the communication resources utilization. © 2016 Elsevier B.V.","Communication constraints; Diffusion Kalman filter algorithm; Multi-channel decoupled event-triggered strategy; Performance analysis"
"Overview of the combination of biometric matchers","2017","Information Fusion","10.1016/j.inffus.2016.05.003","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84969822566&doi=10.1016%2fj.inffus.2016.05.003&partnerID=40&md5=b6a1b486d748767f1c558f3678b4c8a5","Biometric identity verification refers to technologies used to measure human physical or behavioral characteristics, which offer a radical alternative to passports, ID cards, driving licenses or PIN numbers in authentication. Since biometric systems present several limitations in terms of accuracy, universality, distinctiveness, acceptability, methods for combining biometric matchers have attracted increasing attention of researchers with the aim of improving the ability of systems to handle poor quality and incomplete data, achieving scalability to manage huge databases of users, ensuring interoperability, and protecting user privacy against attacks. The combination of biometric systems, also known as ""biometric fusion"", can be classified into unimodal biometric if it is based on a single biometric trait and multimodal biometric if it uses several biometric traits for person authentication. The main goal of this study is to analyze different techniques of information fusion applied in the biometric field. This paper overviews several systems and architectures related to the combination of biometric systems, both unimodal and multimodal, classifying them according to a given taxonomy. Moreover, we deal with the problem of biometric system evaluation, discussing both performance indicators and existing benchmarks. As a case study about the combination of biometric matchers, we present an experimental comparison of many different approaches of fusion of matchers at score level, carried out on three very different benchmark databases of scores. Our experiments show that the most valuable performance is obtained by mixed approaches, based on the fusion of scores. The source code of all the method implemented for this research is freely available for future comparisons1. After a detailed analysis of pros and cons of several existing approaches for the combination of biometric matchers and after an experimental evaluation of some of them, we draw our conclusion and suggest some future directions of research, hoping that this work could be a useful start point for newer research. © 2016 Elsevier B.V. All rights reserved.","Biometric matchers; Fusion at score level; Multimodal biometrics; Unimodal biometrics"
"CAMAS: A cluster-aware multiagent system for attributed graph clustering","2017","Information Fusion","10.1016/j.inffus.2017.01.002","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85009070492&doi=10.1016%2fj.inffus.2017.01.002&partnerID=40&md5=426b32aa3e2801fd6a8490d054c43a47","Attributed graphs describe nodes via attribute vectors and also relationships between different nodes via edges. To partition nodes into clusters with tighter correlations, an effective way is applying clustering techniques on attributed graphs based on various criteria such as node connectivity and/or attribute similarity. Even though clusters typically form around nodes with tight edges and similar attributes, existing methods have only focused on one of these two data modalities. In this paper, we comprehend each node as an autonomous agent and develop an accurate and scalable multiagent system for extracting overlapping clusters in attributed graphs. First, a kernel function with a tunable bandwidth factor δ is introduced to measure the influence of each agent, and those agents with highest local influence can be viewed as the “leader” agents. Then, a novel local expansion strategy is proposed, which can be applied by each leader agent to absorb the most relevant followers in the graph. Finally, we design the cluster-aware multiagent system (CAMAS), in which agents communicate with each other freely under an efficient communication mechanism. Using the proposed multiagent system, we are able to uncover the optimal overlapping cluster configuration, i.e. nodes within one cluster are not only connected closely with each other but also with similar attributes. Our method is highly efficient, and the computational time is shown that nearly linearly dependent on the number of edges when δ ∈ [0.5, 1). Finally, applications of the proposed method on a variety of synthetic benchmark graphs and real-life attributed graphs are demonstrated to verify the systematic performance. © 2017 Elsevier B.V.","Attributed graph clustering; Cluster extraction; Cluster-aware; Leader identification; Multiagent system"
"Event-triggered distributed state estimation for a class of time-varying systems over sensor networks with redundant channels","2017","Information Fusion","10.1016/j.inffus.2016.12.005","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85007107153&doi=10.1016%2fj.inffus.2016.12.005&partnerID=40&md5=652ce9dd29a9f2fff701a3cd2b2b2b8e","This paper is concerned with the distributed state estimation problem for a class of time-varying systems over sensor networks. An event-triggered communication scheme is utilized to save the constrained computation resource and network bandwidth while preserving the desired performance. The measurements on each node are transmitted to the estimators only when a certain triggering condition is satisfied. Moreover, in order to improve the reliability of data transmission services, we exploit redundant communication channels during the transmission process. The purpose of this paper is to design a set of time-varying state estimators such that the dynamics of the state estimation error satisfies the average H∞ performance constraints. The specific gains of the estimator can be obtained by calculating a series of recursive linear matrix inequalities (RLMIs). Finally, a simulation example is presented to show the effectiveness of the state estimation method proposed in this paper. © 2016 Elsevier B.V.","Event-triggered transmission; Redundant channels; Sensor networks; State estimation; Time-varying systems"
"Air quality data clustering using EPLS method","2017","Information Fusion","10.1016/j.inffus.2016.11.015","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85004097337&doi=10.1016%2fj.inffus.2016.11.015&partnerID=40&md5=f99807ba9fe9d65b0a63dadbd36068a2","Nowadays air quality data can be easily accumulated by sensors around the world. Analysis on air quality data is very useful for society decision. Among five major air pollutants which are calculated for AQI (Air Quality Index), PM2.5 data is the most concerned by the people. PM2.5 data is also cross-impacted with the other factors in the air and which has properties of non-linear non-stationary including high noise level and outlier. Traditional methods cannot solve the problem of PM2.5 data clustering very well because of their inherent characteristics. In this paper, a novel model-based feature extraction method is proposed to address this issue. The EPLS model includes: (1) Mode Decomposition, in which EEMD algorithm is applied to the aggregation dataset; (2) Dimension Reduction, which is carried out for a more significant set of vectors; (3) Least Squares Projection, in which all testing data are projected to the obtained vectors. Synthetic dataset and air quality dataset are applied to different clustering methods and similarity measures. Experimental results demonstrate that EPLS is efficient in dealing with high noise level and outlier air quality clustering problems, and which can also be adapted to various clustering techniques and distance measures. © 2016 Elsevier B.V.","Air quality; Clustering; EEMD; PCA; PM<sub>2.5</sub>"
"One versus one multi-class classification fusion using optimizing decision directed acyclic graph for predicting listing status of companies","2017","Information Fusion","10.1016/j.inffus.2016.11.009","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84995752440&doi=10.1016%2fj.inffus.2016.11.009&partnerID=40&md5=ffd6bd486991ca4f43a574576744b628","Most existing research has demonstrated the success of different decomposition and ensemble strategies for solving multi-class classification problems. This study proposes a new ensemble strategy for One-vs-One (OVO) scheme that uses optimizing decision directed acyclic graph (ODDAG) whose structure is determined by maximizing the fitness on the training set instead of by predefined rules. It makes an attempt to reduce the effect of non-competent classifiers in OVO scheme like decision directed acyclic graph (DDAG) but in another way. We test the proposed method on some public data sets and compare it to some other widely used methods to select the proper candidates and related settings for a problem with practical concern from financial industry in China, i.e. the prediction of listing status of companies. The experimental result shows that our model can outperform the benchmarked methods on this real problem. In addition, the ODDAG combined with decision tree is a white box model whose internal rules can be viewed and checked by decision makers. © 2016 Elsevier B.V.","Decision directed acyclic graph; Listing status; Multi-class classification; One versus one; Optimizing; Prediction"
"On the syntax and semantics of virtual linguistic terms for information fusion in decision making","2017","Information Fusion","10.1016/j.inffus.2016.06.002","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84975864672&doi=10.1016%2fj.inffus.2016.06.002&partnerID=40&md5=af3e841b2f73f5609c19aaad495b6c1f","The virtual linguistic model is a good technique for linguistic decision making and has been widely used in applications including linguistic information fusion. The main purpose of this paper is to define and specify the syntax and semantics of virtual linguistic terms (VLTs) in detail, and then to serve as the theoretical foundation of the computational models based on VLTs. The syntactical rule generates VLTs by a symbolic transformation, and then the semantic rule presents the semantics of VLTs by means of linguistic modifiers. Based on the syntax and semantics, VLTs could be a possible alternative for solving some current challenges of qualitative information fusion in decision making. © 2016 Elsevier B.V. All rights reserved.","Computing with words; Semantics; Syntax; Virtual linguistic terms (VLTs)"
"Divide-and-conquer architecture based collaborative sensing for target monitoring in wireless sensor networks","2017","Information Fusion","10.1016/j.inffus.2016.11.014","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84998780424&doi=10.1016%2fj.inffus.2016.11.014&partnerID=40&md5=34b5da48b1c5a312216f67c9c5eb13de","Most surveillance applications in wireless sensor network (WSN) have stringent accuracy requirements in targets surveillance with maximized system lifetime, while large amount of continuous sensing data and limited resource in WSNs pose great challenges. So it is necessary to select appropriate sensors that can collaboratively work with each other in order to obtain balance between accuracy and system lifetime. However, because of sensing diversity and big data from WSN, most existing methods can not select appropriate sensors to cover all critical monitoring locations in large scale real deployments. Accordingly, an AdaBoost based algorithm is first proposed to identify valid sensors with contribution towards accuracy improvement, which can reduce computation and communication overhead by excluding invalid sensors. The valid sensors are combined and work in a collaborative way, which can obtain better performance than other ways. Then, because of independence of each monitoring location, a divide-and-conquer architecture based method (EasiSS) is proposed to select the most informative sensor clusters from the valid sensors for critical monitoring locations. EasiSS can obtain higher classification accuracy at different user requirement. Finally, according to the experiment on real data, we demonstrate that our proposed method can get a better performance of sensor selection, comparing with traditional methods. © 2016 Elsevier B.V.","AdaBoost; Divide-and-conquer; Sensing diversity; Sensor selection; Targets surveillance; Wireless sensor network"
"A novel system for object pose estimation using fused vision and inertial data","2017","Information Fusion","10.1016/j.inffus.2016.04.006","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84966800531&doi=10.1016%2fj.inffus.2016.04.006&partnerID=40&md5=a7eba99f31e803b697b612a5a3ce4900","Six-degree-of-freedom (6-DoF) pose estimation is of fundamental importance to many applications, such as robotics, indoor tracking and Augmented Reality. Although a number of pose estimation solutions have been proposed, it remains a critical challenge to provide a low-cost, real-time, accurate and easy-to-deploy solution. Addressing this issue, this paper describes a multisensor system for accurate pose estimation that relies on low-cost technologies, in particular on a combination of webcams, inertial sensors and a printable colored fiducial. With the aid of inertial sensors, the system can estimate full pose both with monocular and stereo vision. The system error propagation is analyzed and validated by simulations and experimental tests. Our error analysis and experimental data demonstrate that the proposed system has great potential in practical applications, as it achieves high accuracy (in the order of centimeters for the position estimation and few degrees for the orientation estimation) using the mentioned low-cost sensors, while satisfying tight real-time requirements. © 2016 Elsevier Ltd. All rights reserved.","Augmented reality; Error propagation; Inertial systems; Pose estimation; Sensor fusion; Visual sensors"
"A cardinality modified product multi-sensor PHD","2016","Information Fusion","10.1016/j.inffus.2016.01.004","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84958183414&doi=10.1016%2fj.inffus.2016.01.004&partnerID=40&md5=cebb6793d15a407d5ffdf601a3dfd86e","The iterated-corrector PHD (IC-PHD) filter, which is the most commonly used multi-sensor PHD filter, is affected by the sensor order and the probability of detection. To address this problem, the product multi-sensor PHD (PM-PHD) filter, a modified version of the IC-PHD filter, is proposed. The update formulation of the PM-PHD filter consists of a likelihood function and a modified coefficient. Although the coefficient improves the performance of the PM-PHD filter, it still has some drawbacks. In this paper, two improvements on the coefficient are proposed. (1) The coefficient is the quotient of two infinite sums which are computational intractable. We prove that some terms in the infinite sums can be eliminated, and thus the infinite sums can be approximated by the sum of finite terms. (2) Since the coefficient is a scalar quantity, it mainly focuses on maintaining the magnitudes of the posterior PHD and the number of targets. It may lead to an inaccurate state estimation in some situations. In the Gaussian mixture implementation of the PM-PHD filter, a cardinality modified method is proposed to reassign the weight of Gaussian components and modify the posterior PHD. The advantages of these two methods are verified by simulations and experiments. © 2016 Elsevier B.V. All rights reserved.","Multi-sensor fusion; Multi-target tracking; Probability hypothesis density; Random finite set"
"A fusion strategy for reliable vehicle positioning utilizing RFID and in-vehicle sensors","2016","Information Fusion","10.1016/j.inffus.2016.01.003","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84957806960&doi=10.1016%2fj.inffus.2016.01.003&partnerID=40&md5=1aadd8dce73808e7bb09b023d7ab3f79","In recent years, RFID has become a viable solution to provide object's location information. However, the RFID-based positioning algorithms in the literature have disadvantages such as low accuracy, low output frequency and the lack of speed or attitude information. To overcome these problems, this paper proposes a RFID/in-vehicle sensors fusion strategy for vehicle positioning in completely GPS-denied environments such as tunnels. The low-cost in-vehicle sensors including electronic compass and wheel speed sensors are introduced to be fused with RFID. The strategy adopts a two-step approach, i.e., the calculation of the distances between the RFID tags and the reader, and then the global fusion estimation of vehicle position. First, a Least Square Support Vector Machine (LSSVM) algorithm is developed to obtain the distances. Further, a novel LSSVM Multiple Model (LMM) algorithm is designed to fuse the data obtained from RFID and in-vehicle sensors. Contrarily to other multiple model algorithms, the LMM is more suitable for current driving conditions because the model probabilities can be calculated according to the operating state of the vehicle by using the LSSVM decision model. Finally, the proposed strategy is evaluated through experiments. The results validate the feasibility and effectiveness of the proposed strategy. © 2016 Elsevier B.V. All rights reserved.","In-vehicle sensors; Multiple model; RFID; Sensor fusion; Vehicle positioning"
"DPD-DFF: A dual phase distributed scheme with double fingerprint fusion for fast and accurate identification in large databases","2016","Information Fusion","10.1016/j.inffus.2016.03.002","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84962437230&doi=10.1016%2fj.inffus.2016.03.002&partnerID=40&md5=0db82a5911df87f9d165c7e19b59a43e","Nowadays, many companies and institutions need fast and reliable identification systems that are able to deal with very large databases. Fingerprints are among the most used biometric traits for identification. In the current literature there are fingerprint matching algorithms that are focused on efficiency, whilst others are based on accuracy. In this paper we propose a flexible dual phase identification method, called DPD-DFF, that combines two fingers and two matchers within a hybrid fusion scheme to obtain both fast and accurate results. Different alternatives are designed to find a trade-off between runtime and accuracy that can be further tuned with a single parameter. The experiments show that DPD-DFF obtains very competitive results in comparison with the state-of-the-art score fusion techniques, especially when dealing with large databases or impostor fingerprints. © 2016 Elsevier B.V. All rights reserved.","Biometrics; Decision fusion; Fingerprint fusion; Large databases; Minutiae matching; Parallel computing; Real-time identification; Score fusion"
"Machine learning techniques to discover genes with potential prognosis role in Alzheimer's disease using different biological sources","2017","Information Fusion","10.1016/j.inffus.2016.11.005","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84995944907&doi=10.1016%2fj.inffus.2016.11.005&partnerID=40&md5=1e794eec1f783a4754b15d30ec59cb86","Alzheimer's disease is a complex progressive neurodegenerative brain disorder, being its prevalence expected to rise over the next decades. Unconventional strategies for elucidating the genetic mechanisms are necessary due to its polygenic nature. In this work, the input information sources are five: a public DNA microarray that measures expression levels of control and patient samples, repositories of known genes associated to Alzheimer's disease, additional data, Gene Ontology and finally, a literature review or expert knowledge to validate the results. As methodology to identify genes highly related to this disease, we present the integration of three machine learning techniques: particularly, we have used decision trees, quantitative association rules and hierarchical cluster to analyze Alzheimer's disease gene expression profiles to identify genes highly linked to this neurodegenerative disease, through changes in their expression levels between control and patient samples. We propose an ensemble of decision trees and quantitative association rules to find the most suitable configurations of the multi-objective evolutionary algorithm GarNet, in order to overcome the complex parametrization intrinsic to this type of algorithms. To fulfill this goal, GarNet has been executed using multiple configuration settings and the well-known C4.5 has been used to find the minimum accuracy to be satisfied. Then, GarNet is rerun to identify dependencies between genes and their expression levels, so we are able to distinguish between healthy individuals and Alzheimer's patients using the configurations that overcome the minimum threshold of accuracy defined by C4.5 algorithm. Finally, a hierarchical cluster analysis has been used to validate the obtained gene-Alzheimer's Disease associations provided by GarNet. The results have shown that the obtained rules were able to successfully characterize the underlying information, grouping relevant genes for Alzheimer Disease. The genes reported by our approach provided two well defined groups that perfectly divided the samples between healthy and Alzheimer's Disease patients. To prove the relevance of the obtained results, a statistical test and gene expression fold-change were used. Furthermore, this relevance has been summarized in a volcano plot, showing two clearly separated and significant groups of genes that are up or down-regulated in Alzheimer's Disease patients. A biological knowledge integration phase was performed based on the information fusion of systematic literature review, enrichment Gene Ontology terms for the described genes found in the hippocampus of patients. Finally, a validation phase with additional data and a permutation test is carried out, being the results consistent with previous studies. © 2016 Elsevier B.V.","Alzheimer's disease; Association rules; Biological knowledge integration; Ensemble learning; Gene expression profiles; Statistical significant genes"
"An overview of particle methods for random finite set models","2016","Information Fusion","10.1016/j.inffus.2016.02.004","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84961578404&doi=10.1016%2fj.inffus.2016.02.004&partnerID=40&md5=e5e7417fc45134a21670bd8f069329f3","This overview paper describes the particle methods developed for the implementation of the class of Bayes filters formulated using the random finite set formalism. It is primarily intended for the readership already familiar with the particle methods in the context of the standard Bayes filter. The focus in on the Bernoulli particle filter, the probability hypothesis density (PHD) particle filter and the generalised labelled multi-Bernoulli (GLMB) particle filter. The performance of the described filters is demonstrated in the context of bearings-only target tracking application. © 2016 Elsevier B.V. All rights reserved.","Bearings-only measurements; Random set models; Sequential Monte Carlo estimation; Stochastic nonlinear filtering; Target tracking"
"Diversity-aware classifier ensemble selection via f-score","2016","Information Fusion","10.1016/j.inffus.2015.07.003","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84939175565&doi=10.1016%2fj.inffus.2015.07.003&partnerID=40&md5=4d92a742ef67ec764bd8f939b03ed7e7","The primary effect of using a reduced number of classifiers is a reduction in the computational requirements during learning and classification time. In addition to this obvious result, research shows that the fusion of all available classifiers is not a guarantee of best performance but good results on the average. The much researched issue of whether it is more convenient to fuse or to select has become even more of interest in recent years with the development of the Online Boosting theory, where a limited set of classifiers is continuously updated as new inputs are observed and classifications performed. The concept of online classification has recently received significant interest in the computer vision community. Classifiers can be trained on the visual features of a target, casting the tracking problem into a binary classification one: distinguishing the target from the background. Here we discuss how to optimize the performance of a classifier ensemble employed for target tracking in video sequences. In particular, we propose the F-score measure as a novel means to select the members of the ensemble in a dynamic fashion. For each frame, the ensemble is built as a subset of a larger pool of classifiers selecting its members according to their F-score. We observed an overall increase in classification accuracy and a general tendency in redundancy reduction among the members of an f-score optimized ensemble. We carried out our experiments both on benchmark binary datasets and standard video sequences. © 2015 Elsevier B.V. All rights reserved.","Classifiers fusion; Classifiers selection; F-score; Online tracking; Tracking via classification"
"Joint Transceiver Design for Linear MMSE Data Fusion in Coherent MAC Wireless Sensor Networks","2017","Information Fusion","10.1016/j.inffus.2016.12.008","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85009154248&doi=10.1016%2fj.inffus.2016.12.008&partnerID=40&md5=55f1773962f5969e6690c9edd583bfb2","This paper considers the design of minimal mean square error (MMSE) transceivers in a wireless sensor network. The problem is nonconvex and challenging, and previous results (with partial solutions and/or with convergence unproved) left much to be desired. Here we propose several approaches – 2 block coordinate descent (BCD), essentially cyclic multi-block method and its variants and distributive method to solve this problem. The proposed 2-BCD approach formulates the subproblem of joint beamformer optimization as a general second-order cone programming problem, which lends itself to standard numerical solvers and which requires no extra assumptions like previous works do. The proposed essentially cyclic multi-block approach further decomposes the joint beamformer design subproblem into multiple blocks, and rigorously solves each with semi-closed-form solution. The distributive algorithm optimizes transmitters in a decentralized manner and has never been considered in existing literature. The distributive algorithm has time complexity independent of number of sensors and is especially suitable for large-scale networks. All the previous BCD-based approaches left some singularity issue unattended as well as the convergence property unaddressed, our proposals are the first to provide a complete and provably-converging analytical solution. Extensive analysis and simulations demonstrate the merits of the novel approaches relative to existing alternatives. © 2017 Elsevier B.V.","Data fusion; Linear transceiver; Optimization; Signal estimation; Wireless sensor network"
"An improved inertial/wifi/magnetic fusion structure for indoor navigation","2017","Information Fusion","10.1016/j.inffus.2016.06.004","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84979287987&doi=10.1016%2fj.inffus.2016.06.004&partnerID=40&md5=edf826d043650190d49b30aa6af0de09","This paper proposes a dead-reckoning (DR)/WiFi fingerprinting/magnetic matching (MM) integration structure that uses off-the-shelf sensors in consumer portable devices and existing WiFi infrastructures. One key improvement of this structure over previous DR/WiFi/MM fusion structures is the introduction of a three-level quality-control (QC) mechanism based on the interaction between different techniques. On QC Level #1, several criteria are applied to filter out blunders or unreliable measurements in each separate technology. Then, on Level #2, a threshold-based approach is used to set the weight of WiFi results automatically through the investigation of the EKF innovation sequence. Finally, on Level #3, DR/WiFi results are utilized to limit the MM search space and in turn reduce both mismatch rate and computational load. The proposed structure reduced the root mean square (RMS) of position errors in the range of 13.3 to 55.2% in walking experiments with two smartphones, under four motion conditions, and in two indoor environments. Furthermore, the proposed structure reduced the rate of mismatches (i.e., matching to an incorrect point that is geographically located over 15 m away from the true position) rate by over 75.0% when compared with previous DR/WiFi/MM integration structures. © 2016 Elsevier B.V.","Indoor pedestrian navigation; Magnetic feature; Mems sensors; Portable devices; Wireless positioning"
"Fusion of multiple diverse predictors in stock market","2017","Information Fusion","10.1016/j.inffus.2016.11.006","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84995739777&doi=10.1016%2fj.inffus.2016.11.006&partnerID=40&md5=186401054f7ae6bcaea1c6740215f5d8","Forecasting stock returns and their risk represents one of the most important concerns of market decision makers. Although many studies have examined single classifiers of stock returns and risk methods, fusion methods, which have only recently emerged, require further study in this area. The main aim of this paper is to propose a fusion model based on the use of multiple diverse base classifiers that operate on a common input and a Meta classifier that learns from base classifiers’ outputs to obtain more precise stock return and risk predictions. A set of diversity methods, including Bagging, Boosting and AdaBoost, is applied to create diversity in classifier combinations. Moreover, the number and procedure for selecting base classifiers for fusion schemes is determined using a methodology based on dataset clustering and candidate classifiers’ accuracy. The results demonstrate that Bagging exhibited superior performance within the fusion scheme and could achieve a maximum of 83.6% accuracy with Decision Tree, LAD Tree and Rep Tree for return prediction and 88.2% accuracy with BF Tree, DTNB and LAD Tree in risk prediction. For feature selection part, a wrapper-GA algorithm is developed and compared with the fusion model. This paper seeks to help researcher select the best individual classifiers and fuse the proper scheme in stock market prediction. To illustrate the approach, we apply it to Tehran Stock Exchange (TSE) data for the period from 2002 to 2012. © 2016 Elsevier B.V.","Classifier fusion; Diversity creation; Fundamental analysis; Machine learning; Risk prediction; Stock returns prediction"
"Distributed detection of a non-cooperative target via generalized locally-optimum approaches","2017","Information Fusion","10.1016/j.inffus.2016.12.006","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85007417728&doi=10.1016%2fj.inffus.2016.12.006&partnerID=40&md5=94d2e9c15c0ae9007fa74a4dd8230231","In this paper we tackle distributed detection of a non-cooperative target with a Wireless Sensor Network (WSN). When the target is present, sensors observe an unknown random signal with amplitude attenuation depending on the distance between the sensor and the target (unknown) positions, embedded in white Gaussian noise. The Fusion Center (FC) receives sensors decisions through error-prone Binary Symmetric Channels (BSCs) and is in charge of performing a (potentially) more-accurate global decision. The resulting problem is a one-sided testing with nuisance parameters present only under the target-present hypothesis. We first focus on fusion rules based on Generalized Likelihood Ratio Test (GLRT), Bayesian and hybrid approaches. Then, aimed at reducing the computational complexity, we develop fusion rules based on generalizations of the well-known Locally-Optimum Detection (LOD) framework. Finally, all the proposed rules are compared in terms of performance and complexity. © 2016 Elsevier B.V.","Bayesian approach; Decision fusion; Distributed detection; GLRT; LOD; Target detection"
"Using check-in features to partition locations for individual users in location based social network","2017","Information Fusion","10.1016/j.inffus.2017.01.006","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85011826538&doi=10.1016%2fj.inffus.2017.01.006&partnerID=40&md5=4643abfbb32c88827bd85bd160e61687","With location-based social network (LBSN) flourishing, location check-in records offer us sufficient information resource to do relative mining. Among locations visited by a user, those attracting relatively more visits from that user can serve as a support for further mining and improvement for location-based services. Therefore, great significance lies in the partition for visited locations based on a user's visiting frequency. The aim of our paper is to partition locations for individual users by utilizing classification in machine learning, categorizing the location for a user once he or she makes initial check-in there. After feature extraction for each initial check-in record, we evaluate the contribution of three feature categories. The results show the contribution of different feature categories varies in classification, where social features appear to offer the least contribution. At last, we do a final test on the whole sample, comparing the results with two baselines based on majority voting respectively. The results largely outperform the baselines in general, demonstrating the effectiveness of classification. © 2017 Elsevier B.V.","Classification; Location-based social network; Prediction"
"Kernel fusion based extreme learning machine for cross-location activity recognition","2017","Information Fusion","10.1016/j.inffus.2017.01.004","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85008951985&doi=10.1016%2fj.inffus.2017.01.004&partnerID=40&md5=04c6ebedb8e4717c9f96effbcf5087dd","Fixed placements of inertial sensors have been utilized by previous human activity recognition algorithms to train the classifier. However, the distribution of sensor data is seriously affected by the sensor placement. The performance will be degraded when the model trained on one placement is used in others. In order to tackle this problem, a fast and robust human activity recognition model called TransM-RKELM (Transfer learning mixed and reduced kernel Extreme Learning Machine) is proposed in this paper; It uses a kernel fusion method to reduce the influence by the choice of kernel function and the reduced kernel is utilized to reduce the computational cost. After realizing initial activity recognition model by mixed and reduced kernel extreme learning model (M-RKELM), in the online phase M-RKELM is utilized to classify the activity and adapt the model to new locations based on high confident recognition results in real time. Experimental results show that the proposed model can adapt the classifier to new sensor locations quickly and obtain good recognition performance. © 2017","Extreme learning machine; Human activity recognition; Inertial sensors; Machine learning; Mixed kernel"
"Ensemble similarity learning for kinship verification from facial images in the wild","2016","Information Fusion","10.1016/j.inffus.2015.08.006","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84941696056&doi=10.1016%2fj.inffus.2015.08.006&partnerID=40&md5=0858e7f77335a3ef38b7e284111422be","Kin relationship has been well investigated in psychology community over the past decades, while kin verification using facial images is relatively new and challenging problem in biometrics society. Recently, it has attracted substantial attention from biometrics society, mainly motivated by the relative characteristics that children generally resemble their parents more than other persons with respect to facial appearance. Unlike most previous supervised metric learning methods focusing on learning the Mahalanobis distance metric for kin verification, we propose in this paper a new Ensemble similarity learning (ESL) method for this challenging problem. We first introduce a sparse bilinear similarity function to model the relative characteristics encoded in kin data. The similarity function parameterized by a diagonal matrix enjoys the superiority in computational efficiency, making it more practical for real-world high-dimensional kinship verification applications. Then, ESL learns from kin dataset by generating an ensemble of similarity models with the aim of achieving strong generalization ability. Specifically, ESL works by best satisfying the constraints (typically triplet-based) derived from the class labels on each base similarity model, while maximizing the diversity among the base similarity models. Experiments results demonstrate that our method is superior to some state-of-the-art methods in terms of both verification rate and computational efficiency. © 2015 Elsevier B.V. All rights reserved.","Face recognition; Genetic similarity; Kinship verification; Metric learning"
"NMC: nearest matrix classification – A new combination model for pruning One-vs-One ensembles by transforming the aggregation problem","2017","Information Fusion","10.1016/j.inffus.2016.11.004","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84994890364&doi=10.1016%2fj.inffus.2016.11.004&partnerID=40&md5=5dd99eb6ec1980f2fa66a0fee552a281","The One-vs-One strategy is among the most used techniques to deal with multi-class problems in Machine Learning. This way, any binary classifier can be used to address the original problem, since one classifier is learned for each possible pair of classes. As in every ensemble method, classifier combination becomes a vital step in the classification process. Even though many combination models have been developed in the literature, none of them have dealt with the possibility of reducing the number of generated classifiers after the training phase, i.e., ensemble pruning, since every classifier is supposed to be necessary. On this account, our objective in this paper is two-fold: (1) We propose a transformation of the aggregation step, which lead us to a new combination strategy where instances are classified on the basis of the similarities among score-matrices. (2) This fact allows us to introduce the possibility of reducing the number of binary classifiers without affecting the final accuracy. We will show that around 50% of classifiers can be removed (depending on the base learner and the specific problem) and that the confidence degrees obtained by these base classifiers have a strong influence on the improvement in the final accuracy. A thorough experimental study is carried out in order to show the behavior of the proposed approach in comparison with the state-of-the-art combination models in the One-vs-One strategy. Different classifiers from various Machine Learning paradigms are considered as base classifiers and the results obtained are contrasted with the proper statistical analysis. © 2016 Elsevier B.V.","Classifier selection; Decomposition strategies; Ensemble pruning; Multi-class classification; One-vs-One"
"Distributed fusion filters from uncertain measured outputs in sensor networks with random packet losses","2017","Information Fusion","10.1016/j.inffus.2016.06.008","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84979633695&doi=10.1016%2fj.inffus.2016.06.008&partnerID=40&md5=10b5c9019ec3380c908dc8e0a2544c70","This paper addresses the distributed fusion filtering problem for discrete-time random signals from measured outputs perturbed by random parameter matrices and correlated additive noises. These measurements are obtained by a sensor network with a given topology, where random packet dropouts occur during the data transmission through the different network communication channels. The distributed fusion estimation is accomplished in two phases. Firstly, by an innovation approach and using the last observation that successfully arrived if a packet is lost, a preliminary distributed least-squares estimator is designed at each sensor node using its own measurements and those from its neighbors. Secondly, every sensor collects the preliminary filters that are successfully received from its neighbors and fuses this information with its own one to generate the least-squares linear matrix-weighted distributed fusion estimator. The accuracy of the proposed estimators, which is measured by the estimation error covariances, is examined by a numerical simulation example. © 2016 Elsevier B.V.","Correlated noises; Distributed filtering; Random packet dropouts; Random parameter matrices; Sensor networks"
"A finite point process approach to multi-target localization using transient measurements","2016","Information Fusion","10.1016/j.inffus.2016.04.001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84963753112&doi=10.1016%2fj.inffus.2016.04.001&partnerID=40&md5=b2f453a82371753e2d71fcc84de5a5cc","A finite point process approach to multi-target localization from a transient signal is presented. After modeling the measurements as a Poisson point process, we propose a twofold scheme that includes an expectation maximization algorithm to estimate the target locations for a given number of targets and an information theoretic algorithm to select the number of targets. The proposed localization scheme does not require explicitly solving the data association problem and can account for clutter noise as well as missed detections. Although point process theory has been widely utilized for sequential tracking of multiple moving targets, the application of point process theory for multi-target localization from transient measurements has received very little attention. The optimal subpattern assignment metric is used to assess the performance and accuracy of the proposed localization algorithm. Implementation of the proposed algorithm on synthetic data yields desirable results. The proposed algorithm is then applied to the multi-shooter localization problem using acoustic gunfire detection systems.","Acoustic gunfire detection; Expectation maximization; Finite point process; Multi-sensor multi-target localization; Optimal subpattern assignment; Poisson point process"
"Multi-sensor fusion approach with fault detection and exclusion based on the Kullback–Leibler Divergence: Application on collaborative multi-robot system","2017","Information Fusion","10.1016/j.inffus.2017.01.005","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85010471343&doi=10.1016%2fj.inffus.2017.01.005&partnerID=40&md5=40e4f3bdc54beddda85e7e9151631e0c","This paper presents a multi-sensor fusion strategy able to detect the spurious sensors data that must be eliminated from the fusion procedure. The used estimator is the informational form of the Kalman Filter (KF) namely Information Filter (IF). In order to detect the erroneous sensors measurements, the Kullback–Leibler Divergence (KLD) between the a priori and a posteriori distributions of the IF is computed. It is generated from two tests: One acts on the means and the other deals with the covariance matrices. Optimal thresholding method based on a Kullback–Leibler Criterion (KLC) is developed and discussed in order to replace classical approaches that fix heuristically the false alarm probability. Multi-robot systems became one of the major fields of study in the indoor environment where the environmental monitoring and the response to crisis must be ensured. Consequently, the robots required to know precisely their positions and orientations in order to successfully perform their mission. Fault detection and exclusion (FDE) play a crucial role in enhancing the integrity of localization of the multi-robot team. The main contributions of this paper are: - developing a new method of sensors data fusion that tackle the erroneous data issues, - developing a Kullback–Leibler based criterion for the threshold optimization, - Validation with real experimental data from a group of robots. © 2017 Elsevier B.V.","Collaborative Localization; Fault detection and exclusion; Information filter; Kullback–Leibler Divergence; Multi-sensor data fusion; Threshold optimization"
"Event-triggered multi-rate fusion estimation for uncertain system with stochastic nonlinearities and colored measurement noises","2017","Information Fusion","10.1016/j.inffus.2016.12.003","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85008931477&doi=10.1016%2fj.inffus.2016.12.003&partnerID=40&md5=513494ef6fea08bf3027aebdaae0e1b0","This paper is concerned with the event-triggered robust fusion estimation problem for uncertain multi-rate sampled-data systems with stochastic nonlinearities and the colored measurement noises. Due to the effects of stochastic nonlinearities and parameter uncertainties, a new augmentation approach is proposed by which the multi-rate sampled-data system under consideration is transformed into the single-rate system. In order to eliminate the effect of the colored measurement noises, a measurement model with uncorrected noises is established. Based on the measurement model established, a set of local event-triggered filters is constructed and the upper bounds of the local filtering error covariances at each sampling instant are obtained. By using the Lagrange multiplier method, the local filter parameters are designed such that the upper bound obtained is minimum. For the local state estimates, a new fusion estimation scheme is proposed with the help of covariance intersection (CI) method and the consistency of the proposed CI-based fusion estimation scheme is shown. Finally, an illustrative example is presented to verify the effectiveness of the fusion estimation scheme proposed. © 2016 Elsevier B.V.","Colored measurement noises; Fusion estimation; Multi-rate sampled-data; Stochastic nonlinearities; Uncertain systems"
"Using ensembles for problems with characterizable changes in data distribution: A case study on quantification","2017","Information Fusion","10.1016/j.inffus.2016.07.001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84977606052&doi=10.1016%2fj.inffus.2016.07.001&partnerID=40&md5=fbfd885a90b41980978f7787fb590a43","Ensemble methods are widely applied to supervised learning tasks. Based on a simple strategy they often achieve good performance, especially when the single models comprising the ensemble are diverse. Diversity can be introduced into the ensemble by creating different training samples for each model. In that case, each model is trained with a data distribution that may be different from the original training set distribution. Following that idea, this paper analyzes the hypothesis that ensembles can be especially appropriate in problems that: (i) suffer from distribution changes, (ii) it is possible to characterize those changes beforehand. The idea consists in generating different training samples based on the expected distribution changes, and to train one model with each of them. As a case study, we shall focus on binary quantification problems, introducing ensembles versions for two well-known quantification algorithms. Experimental results show that these ensemble adaptations outperform the original counterpart algorithms, even when trivial aggregation rules are used. © 2016","Distribution changes; Ensembles; Quantification"
"Novel intuitionistic fuzzy decision making models in the framework of decision field theory","2017","Information Fusion","10.1016/j.inffus.2016.05.001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84969497829&doi=10.1016%2fj.inffus.2016.05.001&partnerID=40&md5=0045353af99c4a0f976949a5dce776dc","The intuitionistic fuzzy decision making problems have gained great popularity recently. Most of the current methods depend on various aggregation operators that provide collective intuitionistic fuzzy values of alternatives to be ranked. Such collective information only depicts the overall characteristics of the alternatives but ignores the detailed contrasts among them. Most important of all, the current decision making procedure is not in accordance with the way that the decision makers (DMs) think about the decision making problems. In this paper, we develop a novel intuitionistic fuzzy decision making model in the framework of decision field theory. The decision making model emphasizes the contrasts among alternatives with respect to each attribute that competes and influences each other, and thus, the preferences for alternatives can dynamically evolve and provide the final optimal result. After that, we develop an intuitionistic fuzzy group decision making model based on decision field theory, and then make a practical case study on the application of the developed models to the ""one belt, one road"" investment decision making problems. Finally, we point out the characteristics and the limitations of our models in detail. © 2016 Elsevier B.V. All rights reserved.","Decision field theory; Decision making models; Group decision making; Intuitionistic fuzzy set"
"A paired-comparison approach for fusing preference orderings from rank-ordered agents","2015","Information Fusion","10.1016/j.inffus.2015.01.004","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84939981916&doi=10.1016%2fj.inffus.2015.01.004&partnerID=40&md5=0122a1122fa7223fe0b6938424d05946","The problem of aggregating multi-agent preference orderings has received considerable attention in many fields of research, such as multi-criteria decision aiding and social choice theory; nevertheless, the case in which the agents' importance is expressed in the form of a rank-ordering, instead of a set of weights, has not been much debated. The aim of this article is to present a novel algorithm - denominated as ""Ordered Paired-Comparisons Algorithm"" (OPCA), which addresses this decision-making problem in a relatively simple and practical way. The OPCA is organized into three main phases: (i) turning multi-agent preference orderings into sets of paired comparisons, (ii) synthesizing the paired-comparison sets, and (iii) constructing a fused (or consensus) ordering. Particularly interesting is phase two, which introduces a new aggregation process based on a priority sequence, obtained from the agents' importance rank-ordering. A detailed description of the new algorithm is supported by practical examples. © 2015 Elsevier B.V. All rights reserved.","Decision making; Multiple rank-ordered agents; Ordinal semi-democratic; Paired comparison; Preference ordering"
"Model-reduced fault detection for multi-rate sensor fusion with unknown inputs","2016","Information Fusion","10.1016/j.inffus.2016.04.002","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84964330508&doi=10.1016%2fj.inffus.2016.04.002&partnerID=40&md5=8aae1d9240273298fed5bdc585e7e242","In multi-sensor fusion, it is hard to guarantee that all sensors work at the single sampling rate, especially in the distributive and/or heterogeneous case, and fault detection (FD) in multi-rate sensor fusion may face the existence of unknown inputs (UIs) in complex environment. Meanwhile, model reduction often refers to propose a possible lower-dimensional model to replace the original model without adding significant error in practical applications. By the fact that FD in dynamic systems should only focus on the fault-related controllability and observability characteristics, it is a good idea to obtain the fault-related controllable and observable subsystem via system decomposition (i.e., model reduction) for FD. Such a kind of model reduction not only guarantee the FD performance, but also reduce the system dimensions. To this end, we propose the model-reduced fault detection (MRFD) problem for multi-rate sensor fusion subject to UIs and faults imposed on the actuator and sensors. Our aim is to design a fast and computation-effective FD scheme based on the reduced model. We use the singular decomposition for UI decoupling, and then obtain the fault-related subsystem via controllability and observability decomposition. And then the multi-rate observer (MRO) with causality constraints is designed. Different from the traditional observer used for FD, the proposed MRO outputs the fault-related partial state estimate as soon as any a sensor measurement is received, resulting in fast and computation-effective FD. Furthermore, conditions for the existence of a stable MRO, fault-to-state controllability, and fault detectability are explored. A simulation example for simplified longitudinal flight control system and method comparison with the existing multi-rate FD algorithms show the effectiveness of the proposed MRFD method. © 2016 Elsevier B.V. All rights reserved.","Fault detection; Model reduction; Multi-rate sensor fusion; Unknown input decoupling"
"Supervised learning using a symmetric bilinear form for record linkage","2015","Information Fusion","10.1016/j.inffus.2014.11.004","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84939970504&doi=10.1016%2fj.inffus.2014.11.004&partnerID=40&md5=27f4dddc423147a25744ff504fbd813d","Record Linkage is used to link records of two different files corresponding to the same individuals. These algorithms are used for database integration. In data privacy, these algorithms are used to evaluate the disclosure risk of a protected data set by linking records that belong to the same individual. The degree of success when linking the original (unprotected data) with the protected data gives an estimation of the disclosure risk. In this paper we propose a new parameterized aggregation operator and a supervised learning method for disclosure risk assessment. The parameterized operator is a symmetric bilinear form and the supervised learning method is formalized as an optimization problem. The target of the optimization problem is to find the values of the aggregation parameters that maximize the number of re-identification (or correct links). We evaluate and compare our proposal with other non-parametrized variations of record linkage, such as those using the Mahalanobis distance and the Euclidean distance (one of the most used approaches for this purpose). Additionally, we also compare it with other previously presented parameterized aggregation operators for record linkage such as the weighted mean and the Choquet integral. From these comparisons we show how the proposed aggregation operator is able to overcome or at least achieve similar results than the other parameterized operators. We also study which are the necessary optimization problem conditions to consider the described aggregation functions as metric functions. © 2014 Elsevier B.V. All rights reserved.","Bilinear form; Choquet integral; Data privacy; Disclosure risk; Record linkage"
"Jointly registering and fusing images from multiple sensors","2016","Information Fusion","10.1016/j.inffus.2015.05.007","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84931281772&doi=10.1016%2fj.inffus.2015.05.007&partnerID=40&md5=9dec1f72e805cc64b3773795630b0687","In this paper, a novel approach is proposed for jointly registering and fusing a multisensor ensemble of images. Based on the idea that both groupwise registration and fusion can be treated as estimation problems, the proposed approach simultaneously models the mapping from the fused image to the source images and the joint intensity of all images with motion parameters at first, and then combines these models into a maximum likelihood function. The relevant parameters are determined through employing an expectation maximization algorithm. To evaluate the performance of the proposed approach, some representative image registration and fusion approaches are compared on different multimodal image datasets. The criterion, which is defined as the average pixel displacement from its true registered position, is used to compare the performances of registration approaches. As for evaluating the fusion performance, three fusion quality measures which are metric Qab/f, mutual information and average gradient are employed. The experimental results show that the proposed approach has improved performance compared to conventional approaches. © 2015 Elsevier B.V.","Image fusion; Image registration; Mixture models; Multi-image; Multi-sensor"
"Preference-based anonymization of numerical datasets by multi-objective microaggregation","2015","Information Fusion","10.1016/j.inffus.2014.10.003","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84924369096&doi=10.1016%2fj.inffus.2014.10.003&partnerID=40&md5=4cfa91f8211008884075a6281f4855d4","Microaggregation is a statistical disclosure control mechanism to realize k-anonymity as a basic privacy model. The method first partitions the dataset into groups of at least k records and then aggregates the group members. Generally, larger values of k provide lower Disclosure Risk (DR) at the expense of increasing Information Loss (IL). Therefore, the data publisher has to set appropriate microaggregation parameters to produce a protected and useful anonymized data. Unfortunately, in the most of the conventional microaggregation methods, the only available parameter of the algorithm, i.e., k does not enable the data publisher to effectively control the trade-off problem between DR and IL. This paper proposes a novel microaggregation method to optimize information loss and disclosure risk, simultaneously. The trade-off problem is expressed and solved within a multi-objective optimization framework. The data publisher can choose a more preferred protected dataset from a set of non-dominated candidate solutions, or even direct the method toward a desired point. Experimental results show that for a fixed value of k, the proposed method can usually produce more protected and useful datasets in comparison with the conventional methods. © 2014 Elsevier B.V.","k-anonymity; Microaggregation; Multi-objective optimization; Privacy"
"Face recognition based on pixel-level and feature-level fusion of the top-level's wavelet sub-bands","2015","Information Fusion","10.1016/j.inffus.2014.06.001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84907883502&doi=10.1016%2fj.inffus.2014.06.001&partnerID=40&md5=5f35846db3d438501533ea5a43fab968","The traditional wavelet-based approaches directly use the low frequency sub-band of wavelet transform to extract facial features. However, the high frequency sub-bands also contain some important information corresponding to the edge and contour of face, reflecting the details of face, especially the top-level's high frequency sub-bands. In this paper, we propose a novel technique which is a joint of pixel-level and feature-level fusion at the top-level's wavelet sub-bands for face recognition. We convert the problem of finding the best pixel-level fusion coefficients of high frequency wavelet sub-bands to two optimization problems with the help of principal component analysis and linear discriminant analysis, respectively; and propose two alternating direction methods to solve the corresponding optimization problems for finding transformation matrices of dimension reduction and optimal fusion coefficients of the high frequency wavelet sub-bands. The proposed methods make full use of four top-level's wavelet sub-bands rather than the low frequency sub-band only. Experiments are carried out on the FERET, ORL and AR face databases, which indicate that our methods are effective and robust. © 2014 Elsevier B.V. All rights reserved.","Face recognition; Feature-level fusion; Pixel-level fusion; Principle component analysis; Wavelet transform"
"Data dissemination scheme for distributed storage for IoT observation systems at large scale","2015","Information Fusion","10.1016/j.inffus.2013.04.003","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84907600027&doi=10.1016%2fj.inffus.2013.04.003&partnerID=40&md5=368351ac7af0d57cca27ae0bee17a022","In the emerging field of the Internet of Things (IoT), Wireless Sensor Networks (WSNs) have a key role to play in sensing and collecting measures on the surrounding environment. In the deployment of large scale observation systems in remote areas, when there is not a permanent connection with the Internet, WSNs are calling for replication and distributed storage techniques that increase the amount of data stored within the WSN and reduce the probability of data loss. Unlike conventional network data storage, WSN-based distributed storage is constrained by the limited resources of the sensors. In this paper, we propose a low-complexity distributed data replication mechanism to increase the resilience of WSN-based distributed storage at large scale. In particular, we propose a simple, yet accurate, analytical modeling framework and an extensive simulation campaign, which complement experimental results on the SensLab testbed. The impact of several key parameters on the system performance is investigated. © 2013 Elsevier B.V. All rights reserved.","Data distribution; Data replication; RPL; SensLAB; Wireless sensor networks"
"Fusion of preferences from different perspectives in a decision-making context","2016","Information Fusion","10.1016/j.inffus.2015.07.006","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84954401474&doi=10.1016%2fj.inffus.2015.07.006&partnerID=40&md5=3634aab5e513ebacfd7a006971595a71","Solving a decision-making problem about a brand-new product might include preferences from a high number of potential customers (e.g., followers of a company on social media) and managerial constraints (or preferences) given by corporate managers with regard to different aspects (i.e., economical, technical, environmental, etc.) over multiple criteria (e.g., weight, capacity, color, or usefulness of a product). These give us some new insights on fusing preferences given by persons having different perspectives (e.g., economical, technical, environmental, etc.), including decision-makers, and aimed to be suitable for different organizational structures (e.g., multilevel structures). Herein, a proper representation is needed to merge preferences from each perspective, enabling their propagation, throughout an organizational structure until the level in which a decision is made. This representation is presented as a decision-making unit (DMU), and is used as the primary component of our decision-making model. In this paper, we propose a novel decision-making model that recursively merges the preferred criteria from different DMUs using the logic scoring of preference (LSP) method. An illustrative example demonstrating the applicability of the proposed model, in the context of a new product design, is included in the paper. © 2015 Elsevier B.V. All rights reserved.","Decision-making unit; Different perspectives; Multilevel fusion; Preference modeling; Recursive LSP"
"Decision support system for fatty liver disease using GIST descriptors extracted from ultrasound images","2016","Information Fusion","10.1016/j.inffus.2015.09.006","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84944790601&doi=10.1016%2fj.inffus.2015.09.006&partnerID=40&md5=4793fe472a2ffe0b19e6e5ba99c8ed09","Steatosis or fatty liver disease (FLD) is characterized by the abnormal retention of large vacuoles of neutral fat in the liver cells, either due to alcoholism or metabolic syndrome. Succession of FLD can lead to severe liver diseases such as hepatocellular carcinoma, cirrhosis and hepatic inflammation but it is a reversible disease if diagnosed early. Thus, computer-aided diagnostic tools play a very important role in the automated diagnosis of FLD. This paper focuses on the detection of steatosis and classification of steatotic livers from the normal using ultrasound images. The significant information from the image is extracted using GIST descriptor models. Marginal Fisher Analysis (MFA) integrated with Wilcoxon signed-rank test helps to eliminate the trivial features and provides the distinctive features for qualitative classification. Finally the clinically significant features are fused using classifiers such as decision tree (DT), support vector machine (SVM), adaBoost, k-nearest neighbor (kNN), probabilistic neural network (PNN), naïve Bayes (NB), fuzzy Sugeno (FS), linear and quadratic discriminant analysis classification of normal and abnormal liver images. Results portray that PNN classifier can diagnose FLD with an average classification accuracy of 98%, 96% sensitivity, 100% specificity and Area Under Curve (AUC) of 0.9674 correctly. © 2015 Elsevier B.V. All rights reserved.","Fatty liver disease; GIST descriptors; Liver cirrhosis; MFA; PNN; Spatial envelope energy spectrum"
"Fusing actigraphy signals for outpatient monitoring","2015","Information Fusion","10.1016/j.inffus.2014.08.003","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027957454&doi=10.1016%2fj.inffus.2014.08.003&partnerID=40&md5=7da95c2e80665500dc1f5f880af47b99","Actigraphy devices have been successfully used as effective tools in the treatment of diseases such as sleep disorders or major depression. Although several efforts have been made in recent years to develop smaller and more portable devices, the features necessary for the continuous monitoring of outpatients require a less intrusive, obstructive and stigmatizing acquisition system. A useful strategy to overcome these limitations is based on adapting the monitoring system to the patient lifestyle and behavior by providing sets of different sensors that can be worn simultaneously or alternatively. This strategy offers to the patient the option of using one device or other according to his/her particular preferences. However this strategy requires a robust multi-sensor fusion methodology capable of taking maximum profit from all of the recorded information. With this aim, this study proposes two actigraphy fusion models including centralized and distributed architectures based on artificial neural networks. These novel fusion methods were tested both on synthetic datasets and real datasets, providing a parametric characterization of the models' behavior, and yielding results based on real case applications. The results obtained using both proposed fusion models exhibit good performance in terms of robustness to signal degradation, as well as a good behavior in terms of the dependence of signal quality on the number of signals fused. The distributed and centralized fusion methods reduce the mean averaged error of the original signals to 44% and 46% respectively when using simulated datasets. The proposed methods may therefore facilitate a less intrusive and more dependable way of acquiring valuable monitoring information from outpatients. © 2014 Elsevier B.V. All rights reserved.","Actigraphy; Artificial neural networks; Major depression; Multi-sensor fusion; Outpatient monitoring"
"Information extraction from sensor networks using the Watershed transform algorithm","2015","Information Fusion","10.1016/j.inffus.2013.07.001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84907600141&doi=10.1016%2fj.inffus.2013.07.001&partnerID=40&md5=5f225ba34bdc801590fadd4eb7fd04d2","Wireless sensor networks are an effective tool to provide fine resolution monitoring of the physical environment. Sensors generate continuous streams of data, which leads to several computational challenges. As sensor nodes become increasingly active devices, with more processing and communication resources, various methods of distributed data processing and sharing become feasible. The challenge is to extract information from the gathered sensory data with a specified level of accuracy in a timely and power-efficient approach. This paper presents a new solution to distributed information extraction that makes use of the morphological Watershed algorithm. The Watershed algorithm dynamically groups sensor nodes into homogeneous network segments with respect to their topological relationships and their sensing-states. This setting allows network programmers to manipulate groups of spatially distributed data streams instead of individual nodes. This is achieved by using network segments as programming abstractions on which various query processes can be executed. Aiming at this purpose, we present a reformulation of the global Watershed algorithm. The modified Watershed algorithm is fully asynchronous, where sensor nodes can autonomously process their local data in parallel and in collaboration with neighbouring nodes. Experimental evaluation shows that the presented solution is able to considerably reduce query resolution cost without scarifying the quality of the returned results. When compared to similar purpose schemes, such as ""Logical Neighborhood"", the proposed approach reduces the total query resolution overhead by up to 57.5%, reduces the number of nodes involved in query resolution by up to 59%, and reduces the setup convergence time by up to 65.1%. © 2013 Elsevier B.V. All rights reserved.","Information extraction; Macroprogramming; Query scoping; Watershed segmentation; Wireless sensor networks"
"Kernel combination via debiased object correspondence analysis","2016","Information Fusion","10.1016/j.inffus.2015.02.002","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84938199663&doi=10.1016%2fj.inffus.2015.02.002&partnerID=40&md5=a81897e1a60fbe98e2a4baa906d8f827","This paper addresses the problem of combining multi-modal kernels in situations in which object correspondence information is unavailable between modalities, for instance, where missing feature values exist, or when using proprietary databases in multi-modal biometrics. The method thus seeks to recover inter-modality kernel information so as to enable classifiers to be built within a composite embedding space. This is achieved through a principled group-wise identification of objects within differing modal kernel matrices in order to form a composite kernel matrix that retains the full freedom of linear kernel combination existing in multiple kernel learning. The underlying principle is derived from the notion of tomographic reconstruction, which has been applied successfully in conventional pattern recognition. In setting out this method, we aim to improve upon object-correspondence insensitive methods, such as kernel matrix combination via the Cartesian product of object sets to which the method defaults in the case of no discovered pairwise object identifications. We benchmark the method against the augmented kernel method, an order-insensitive approach derived from the direct sum of constituent kernel matrices, and also against straightforward additive kernel combination where the correspondence information is given a priori. We find that the proposed method gives rise to substantial performance improvements. © 2015 Elsevier B.V. All rights reserved.","Classifier combination; Kernel methods; Support vector machines; Tomography"
"An interval type-2 fuzzy PROMETHEE method using a likelihood-based outranking comparison approach","2015","Information Fusion","10.1016/j.inffus.2014.10.002","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84925487050&doi=10.1016%2fj.inffus.2014.10.002&partnerID=40&md5=18c18fd73358d709fd44938fbff96ac8","Based on the preference ranking organization method for enrichment evaluations (PROMETHEE), the purpose of this paper is to develop a new multiple criteria decision-making method that uses the approach of likelihood-based outranking comparisons within the environment of interval type-2 fuzzy sets. Uncertain and imprecise assessment of information often occurs in multiple criteria decision analysis (MCDA). The theory of interval type-2 fuzzy sets is useful and convenient for modeling impressions and quantifying the ambiguous nature of subjective judgments. Using the approach of likelihood-based outranking comparisons, this paper presents an interval type-2 fuzzy PROMETHEE method designed to address MCDA problems based on interval type-2 trapezoidal fuzzy (IT2TrF) numbers. This paper introduces the concepts of lower and upper likelihoods for acquiring the likelihood of an IT2TrF binary relationship and defines a likelihood-based outranking index to develop certain likelihood-based preference functions that correspond to several generalized criteria. The concept of comprehensive preference measures is proposed to determine IT2TrF exiting, entering, and net flows in the valued outranking relationships. In addition, this work establishes the concepts of a comprehensive outranking index, a comprehensive outranked index, and a comprehensive dominance index to induce partial and total preorders for the purpose of acquiring partial ranking and complete ranking, respectively, of the alternative actions. The feasibility and applicability of the proposed method are illustrated with two practical applications to the problem of landfill site selection and a car evaluation problem. Finally, a comparison with other relevant methods is conducted to validate the effectiveness of the proposed method. © 2014 Elsevier B.V.","Interval type-2 fuzzy set; Interval type-2 trapezoidal fuzzy (IT2TrF) numbers; Likelihood-based preference function; Multiple criteria decision analysis (MCDA); Preference ranking organization method for enrichment evaluations (PROMETHEE)"
"A new boosting design of Support Vector Machine classifiers","2015","Information Fusion","10.1016/j.inffus.2014.10.005","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84924807118&doi=10.1016%2fj.inffus.2014.10.005&partnerID=40&md5=d6871508ff8878cf2929a6a050dd3c42","Boosting algorithms pay attention to the particular structure of the training data when learning, by means of iteratively emphasizing the importance of the training samples according to their difficulty for being correctly classified. If common kernel Support Vector Machines (SVMs) are used as basic learners to construct a Real AdaBoost ensemble, the resulting ensemble can be easily compacted into a monolithic architecture by simply combining the weights that correspond to the same kernels when they appear in different learners, avoiding to increase the operation computational effort for the above potential advantage. This way, the performance advantage that boosting provides can be obtained for monolithic SVMs, i.e., without paying in classification computational effort because many learners are needed. However, SVMs are both stable and strong, and their use for boosting requires to unstabilize and to weaken them. Yet previous attempts in this direction show a moderate success. In this paper, we propose a combination of a new and appropriately designed subsampling process and an SVM algorithm which permits sparsity control to solve the difficulties in boosting SVMs for obtaining improved performance designs. Experimental results support the effectiveness of the approach, not only in performance, but also in compactness of the resulting classifiers, as well as that combining both design ideas is needed to arrive to these advantageous designs. © 2014 Elsevier B.V.All rights reserved.","Ensemble classifiers; Linear programming; Real AdaBoost; Subsampling; Support vector machines"
"Situation awareness within the context of connected cars: A comprehensive review and recent trends","2016","Information Fusion","10.1016/j.inffus.2015.08.001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84954367515&doi=10.1016%2fj.inffus.2015.08.001&partnerID=40&md5=83c12ed2408fed7bf520bb4d6d7fdd31","Driving safety is among the most important factors in the design of next generation vehicles as an integral component of Intelligent Transportation Systems. Crash avoidance and reduction of potential subsequent fatalities require timely delivery of sensitive and pertinent safety information for the drivers. Hence, the driver can become aware of the current driving situation, and can consequently, take appropriate decisions to avoid potentially imminent hazards. In this paper, we propose a comprehensive survey on situation awareness within the context of connected vehicles and Internet of Cars (also called here as connected cars). We provide context for the Internet of Cars and highlight its major features. Furthermore, situation awareness in the Internet of Cars is explored through presenting an in-depth discussion on its different components. Various aspects of high and low level information fusions are described within this context. Besides, major methods/models in situation awareness are linked to the main aspects of each component, and an overall comparison between them is reported. Moreover, on-the-road safety frameworks incorporating situation awareness are highlighted. Finally, the challenging issues and the emerging trends that shall be faced by the research community are addressed. © 2015 Elsevier B.V. All rights reserved.","Advanced driving assisted systems; High-level information fusion; Internet of Cars; Situation awareness"
"Achievable accuracy in Gaussian plume parameter estimation using a network of binary sensors","2015","Information Fusion","10.1016/j.inffus.2014.10.007","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84925497941&doi=10.1016%2fj.inffus.2014.10.007&partnerID=40&md5=6be16ced12cf6f58ffdc7b931f8a9083","The Gaussian plume model is the core of most regulatory atmospheric dispersion models. The parameters of the model include the source characteristics (e.g. location, strength) and environmental parameters (wind speed, direction, atmospheric stability conditions). The paper presents a theoretical analysis of the best achievable accuracy in estimation of Gaussian plume parameters in the context of a continuous point-source release and using a binary sensor network for acquisition of measurements. The problem is relevant for automatic localisation of atmospheric pollutants with applications in public health and defence. The theoretical bounds of achievable accuracy provide a guideline for sensor network deployment and its performance under various environmental conditions. The bounds are compared with empirical errors obtained using a Markov chain Monte Carlo (MCMC) parameter estimation technique. © 2014 Published by Elsevier B.V. All rights reserved.","Cramér-Rao lower bound; Gaussian plume dispersion; model Binary sensor network; Source term estimation"
"Multi-focus image fusion using dictionary-based sparse representation","2015","Information Fusion","10.1016/j.inffus.2014.10.004","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84924785815&doi=10.1016%2fj.inffus.2014.10.004&partnerID=40&md5=0807a7aaf49b402ec749c8191b599bb8","Multi-focus image fusion has emerged as a major topic in image processing to generate all-focus images with increased depth-of-field from multi-focus photographs. Different approaches have been used in spatial or transform domain for this purpose. But most of them are subject to one or more of image fusion quality degradations such as blocking artifacts, ringing effects, artificial edges, halo artifacts, contrast decrease, sharpness reduction, and misalignment of decision map with object boundaries. In this paper we present a novel multi-focus image fusion method in spatial domain that utilizes a dictionary which is learned from local patches of source images. Sparse representation of relative sharpness measure over this trained dictionary are pooled together to get the corresponding pooled features. Correlation of the pooled features with sparse representations of input images produces a pixel level score for decision map of fusion. Final regularized decision map is obtained using Markov Random Field (MRF) optimization. We also gathered a new color multi-focus image dataset which has more variety than traditional multi-focus image sets. Experimental results demonstrate that our proposed method outperforms existing state-of-the-art methods, in terms of visual and quantitative evaluations. © 2014 Elsevier B.V. All rights reserved.","Dictionary learning; Guided image filtering; K-SVD; Multi-focus image fusion; Sparse representation"
"Efficient recommendation methods using category experts for a large dataset","2016","Information Fusion","10.1016/j.inffus.2015.07.005","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84943365892&doi=10.1016%2fj.inffus.2015.07.005&partnerID=40&md5=60460a01faa03ad44796db1d381fc867","Neighborhood-based methods have been proposed to satisfy both the performance and accuracy in recommendation systems. It is difficult, however, to satisfy them together because there is a tradeoff between them especially in a big data environment. In this paper, we present a novel method, called a CE method, using the notion of category experts in order to leverage the tradeoff between performance and accuracy. The CE method selects a few users as experts in each category and uses their ratings rather than ordinary neighbors'. In addition, we suggest CES and CEP methods, variants of the CE method, to achieve higher accuracy. The CES method considers the similarity between the active user and category expert in ratings prediction, and the CEP method utilizes the active user's preference (interest) on each category. Finally, we combine all the approaches to create a CESP method, considering similarity and preference simultaneously. Using real-world datasets from MovieLens and Ciao, we show that our proposal successfully leverages the tradeoff between the performance and accuracy and outperforms existing neighborhood-based recommendation methods in coverage. More specifically, the CESP method provides 5% improved accuracy compared to the item-based method while performing 9 times faster than the user-based method. © 2015 Elsevier B.V. All rights reserved.","Collaborative filtering; Expert; Performance evaluation; Recommender system"
"Composition of Constraint, Hypothesis and Error Models to improve interaction in Human-Machine Interfaces","2016","Information Fusion","10.1016/j.inffus.2015.09.001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84942474024&doi=10.1016%2fj.inffus.2015.09.001&partnerID=40&md5=652bcf859c283e46f3e78829eacd21f7","Although there are many tasks where output strings are automatically generated from a set of evidence, they are not perfect and human intervention is often required to correct the result. In this paper we present a generic Symbol Input Interaction Method for Human-Machine Interfaces that combines multi-source information: an input Hypothesis Model, an Error Model, a Constraint Model and a user interaction scheme. We use Weighted Finite-State Transducers (WFSTs) to represent the different sources of information available: the initial hypotheses, the possible errors, the constraints imposed by the task (interaction language) and the user input. The fusion of these models to find the most probable output string can be performed efficiently by using carefully selected transducer operations. The proposed system initially suggests an output based on the set of hypotheses, possible errors and Constraint Models. Then, if human intervention is needed, a multimodal approach, where the user input is combined with the aforementioned models, is applied to produce, with a minimum user effort, the desired output. This approach offers the practical advantages of a de-coupled model (e.g. input-system + parameterized rules + post-processor), keeping at the same time the error-recovery power of an integrated approach, where all the steps of the process are performed in the same formal machine (as in a typical HMM in speech recognition) to avoid that an error at a given step remains unrecoverable in the subsequent steps. After a presentation of the theoretical basis of the proposed multi-source information system, its application to two real world problems, as an example of the possibilities of this architecture, is addressed. The experimental results obtained demonstrate that a significant user effort can be saved when using the proposed procedure. A simple demonstration, to better understand and evaluate the proposed system, is available on the web https://demos.iti.upv.es/hi/. © 2015 Elsevier B.V.","Human-machine interaction; Interactive multimodal string correction; Multi-source information fusion; Weighted finite-state transducer composition"
"Human mobility synthesis using matrix and tensor factorizations","2015","Information Fusion","10.1016/j.inffus.2014.05.005","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027939597&doi=10.1016%2fj.inffus.2014.05.005&partnerID=40&md5=06b23abe9fbff5e55b8ccf3ae8fa9092","Human mobility prediction is of great advantage in route planning and schedule management. However, mobility data is a high-dimensional dataset in which multi-context prediction is difficult in a single model. Mobility data can usually be expressed as a home event, a work event, a shopping event and a traveling event. Previous works have only been able to learn and predict one type of mobility event and then integrate them. As the tensor model has a strong ability to describe high-dimensional information, we propose an algorithm to predict human mobility in tensors of location context data. Using the tensor decomposition method, we extract human mobility patterns with multiple expressions and then synthesize the future mobility event based on mobility patterns. The experiment is based on real-world location data and the results show that the tensor decomposition method has the highest accuracy in terms of prediction error among the three methods. The results also prove the feasibility of our multi-context prediction model. © 2014 Elsevier B.V. All rights reserved.","Human mobility; Mobility model; Multi-target prediction; Tensor decomposition"
"An ensemble approach of dual base learners for multi-class classification problems","2015","Information Fusion","10.1016/j.inffus.2014.09.002","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84922842596&doi=10.1016%2fj.inffus.2014.09.002&partnerID=40&md5=d4d59778a8e87fa570ee2104a19888e0","In this work, we formalise and evaluate an ensemble of classifiers that is designed for the resolution of multi-class problems. To achieve a good accuracy rate, the base learners are built with pairwise coupled binary and multi-class classifiers. Moreover, to reduce the computational cost of the ensemble and to improve its performance, these classifiers are trained using a specific attribute subset. This proposal offers the opportunity to capture the advantages provided by binary decomposition methods, by attribute partitioning methods, and by cooperative characteristics associated with a combination of redundant base learners. To analyse the quality of this architecture, its performance has been tested on different domains, and the results have been compared to other well-known classification methods. This experimental evaluation indicates that our model is, in most cases, as accurate as these methods, but it is much more efficient. © 2014 Elsevier B.V.","Artificial Neural Networks; Diversity; Ensemble of classifiers; Feature Selection; Multi-class classification"
"A group decision making model for partially ordered preference under uncertainty","2015","Information Fusion","10.1016/j.inffus.2014.11.001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84924762517&doi=10.1016%2fj.inffus.2014.11.001&partnerID=40&md5=c21bbc71b9ea4712da0f2fec57d4af43","In many decision making problems, the experts are not able to provide accurate preferences among the alternatives but some kind of partial orders with certain belief degrees, due to limited expertise related to the problem domain, lack of data, or time restriction and so on. To facilitate decision making in this type of situations, this paper proposes a belief structure to represent the partially ordered preferences with belief degrees, which can cover both qualitative and quantitative aspects of the evaluation and can also represent indifference and incomparability relations as well. An evidential reasoning based preference combination approach is then applied to combine the partially ordered preferences with belief degrees of the experts. The collective ordering of alternatives, which again could be a partial order, is generated based on a distance measure between pairs of preference relations. A group decision making model based on the preference combination and the collective ordering generation is then established for partially ordered preference under uncertainty. Numerical examples are provided to illustrate the rationality and effectiveness of the proposed approach. © 2014 Elsevier B.V.All rights reserved.","Belief structure; Distance measure; Evidential reasoning; Group decision making; Partially ordered preference"
"An approach to rank reviews by fusing and mining opinions based on review pertinence","2015","Information Fusion","10.1016/j.inffus.2014.04.002","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84908403742&doi=10.1016%2fj.inffus.2014.04.002&partnerID=40&md5=313bb35951f9de895ef1cdbb633fdd78","Fusing and mining opinions from reviews posted in webs or social networks is becoming a popular research topic in recent years in order to analyze public opinions on a specific topic or product. Existing research has been focused on extraction, classification and summarization of opinions from reviews in news websites, forums and blogs. An important issue that has not been well studied is the degree of relevance between a review and its corresponding article. Prior work simply divides reviews into two classes: spam and non-spam, neglecting that the non-spam reviews could have different degrees of relevance to the article. In this paper, we propose a notion of ""Review Pertinence"" to study the degree of this relevance. Unlike usual methods, we measure the pertinence of review by considering not only the similarity between a review and its corresponding article, but also the correlation among reviews. Experiment results based on real data sets collected from a number of popular portal sites show the obvious effectiveness of our method in ranking reviews based on their pertinence, compared with three baseline methods. Thus, our method can be applied to efficiently retrieve reviews for opinion fusion and mining and filter review spam in practice. © 2014 Elsevier B.V. All rights reserved.","Opinion fusion; Opinion mining; Retrieval model; Review pertinence; Review spam"
"Context-based Information Fusion: A survey and discussion","2015","Information Fusion","10.1016/j.inffus.2015.01.002","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84925463145&doi=10.1016%2fj.inffus.2015.01.002&partnerID=40&md5=191595a91434f4ad0b3b7ff4d0d238a1","This survey aims to provide a comprehensive status of recent and current research on context-based Information Fusion (IF) systems, tracing back the roots of the original thinking behind the development of the concept of ""context"". It shows how its fortune in the distributed computing world eventually permeated in the world of IF, discussing the current strategies and techniques, and hinting possible future trends. IF processes can represent context at different levels (structural and physical constraints of the scenario, a priori known operational rules between entities and environment, dynamic relationships modelled to interpret the system output, etc.). In addition to the survey, several novel context exploitation dynamics and architectural aspects peculiar to the fusion domain are presented and discussed. © 2015 Elsevier B.V. All rights reserved.","Architectural aspects; Context; Information Fusion; State-of-the-art; Survey"
"High-performance scheduling model for multisensor gateway of cloud sensor system-based smart-living","2015","Information Fusion","10.1016/j.inffus.2013.04.004","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84904819180&doi=10.1016%2fj.inffus.2013.04.004&partnerID=40&md5=8ffaa8cae62bd340409b2f2e38f21f5b","In cloud sensor system-based smart-living applications, large-scale distributed sensors may be deployed to collect information and report to the manipulator and the cloud. A gateway is often employed as infrastructure in this scenario, acting as the data collector, the relay and the agency of the initial multisensor fusion, and thus must be able to handle as many concurrent requests as possible from diverse sensors of different vendors. This study proposes a high-performance scheduling model with a cloud-supported caching mechanism for the gateway of the cloud sensor system-based smart-living. Scheduling and caching optimization are performed by 0-1 programming combined with the periodic task models. Correlation analyses of the simulated results determine the most effective factors to the performance, and the performance tests with the selected factors show that a gateway with 2.4 G-uniCPU/4 G-memory/300 G-harddisk can support the system with one million sensors registered in the cloud and 5000 concurrent live sensors through it, with a 25× gain throughput improvement compared to the traditional application-type scheduling. © 2013 Elsevier B.V. All rights reserved.","Cloud sensor system; Cyber physical system; Internet of things; Multisensor fusion; Periodic application"
"Cokriging for cross-attribute fusion in sensor networks","2015","Information Fusion","10.1016/j.inffus.2014.09.007","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84922941008&doi=10.1016%2fj.inffus.2014.09.007&partnerID=40&md5=d5a5321dba1e9f06847c4bff93f1a3e0","Optimisation of the number of required measurement points and their location is an important research topic in sensor networks. Finding the optimal positions increases spatial coverage and reduces deployment costs. This paper presents an approach for the case that two attributes have to be measured with a different number of available sensors. The proposed cokriging method performs cross-attribute fusion in sensor networks by being based on the analysis of multi-variable spatial correlations. To the best of our knowledge, this scientific work is the first one considering kriging and cokriging interpolations as IF methods. The single-variable ordinary kriging and bi-variable methods were applied to experimental data. The combination of humidity and temperature data in a refrigerated container is used as exemplary case, humidity measurements are considered to be the expensive attribute to measure. The average estimation error for intermediate points was estimated as a function of the number of humidity sensors. When variability is high, data fusion using the bi-variable method produced results as accurate as the single-variable one, without the necessity of deploying a large number of humidity measuring points, by complementing the estimation with temperature measurements. © 2014 Elsevier B.V.","Cokriging; Coregionalisation model; Cross-attribute fusion; Submodularity; Wireless sensor networks"
"Outlier elimination using granular box regression","2016","Information Fusion","10.1016/j.inffus.2015.04.001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84938199375&doi=10.1016%2fj.inffus.2015.04.001&partnerID=40&md5=dddcdf6c051dc05e017aa4be15e8698d","A regression method desires to fit the curve on a data set irrespective of outliers. This paper modifies the granular box regression approaches to deal with data sets with outliers. Each approach incorporates a three-stage procedure includes granular box configuration, outlier elimination, and linear regression analysis. The first stage investigates two objective functions each applies different penalty schemes on boxes or instances. The second stage investigates two methods of outlier elimination to, then, perform the linear regression in the third stage. The performance of the proposed granular box regressions are investigated in terms of: volume of boxes, insensitivity of boxes to outliers, elapsed time for box configuration, and error of regression. The proposed approach offers a better linear model, with smaller error, on the given data sets containing varieties of outlier rates. The investigation shows the superiority of applying penalty scheme on instances. © 2015 Elsevier B.V. All rights reserved.","Data abstraction; Data simplification; Granular box regression; Noisy data; Outlier elimination"
"Faceted fusion of RDF data","2015","Information Fusion","10.1016/j.inffus.2014.06.005","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84908456828&doi=10.1016%2fj.inffus.2014.06.005&partnerID=40&md5=d2eba10fa1da8f4a38f7a6146fbc1031","With the rapid growth of resource description framework (RDF) data, it shows a steady trend of data decentralization and fragmentation. This trend results in two consequences. First, data decentralization and fragmentation easily leads to a narrow understanding of specific topic for users, because of difficulty in obtaining fully-faceted RDF data on the topic. Second and more importantly, users need to exert considerable effort to in searching for the RDF data of interest. In this paper, we propose a novel approach called Faceted Fusion of RDF data (FF) to solve these challenges. This method aggregates distributed RDF data on a specific topic according to different facets, based on two topological properties of a topic-specific RDF Graph (TRG). FF first constructs TRGs from RDF datasets and then discovers a set of facets by leveraging these two topological properties. We conduct three experiments over six RDF datasets to evaluate our approach. The experimental results indicate that FF outperforms three other approaches based on data distance, structure distance and structure/attribute respectively. © 2014 Elsevier B.V. All rights reserved.","Facet discovery; Fusion; RDF data"
"Social big data: Recent achievements and new challenges","2016","Information Fusion","10.1016/j.inffus.2015.08.005","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84943350772&doi=10.1016%2fj.inffus.2015.08.005&partnerID=40&md5=a177f161a4ccda3fc166f0b0dd91e7d4","Big data has become an important issue for a large number of research areas such as data mining, machine learning, computational intelligence, information fusion, the semantic Web, and social networks. The rise of different big data frameworks such as Apache Hadoop and, more recently, Spark, for massive data processing based on the MapReduce paradigm has allowed for the efficient utilisation of data mining methods and machine learning algorithms in different domains. A number of libraries such as Mahout and SparkMLib have been designed to develop new efficient applications based on machine learning algorithms. The combination of big data technologies and traditional machine learning algorithms has generated new and interesting challenges in other areas as social media and social networks. These new challenges are focused mainly on problems such as data processing, data storage, data representation, and how data can be used for pattern mining, analysing user behaviours, and visualizing and tracking data, among others. In this paper, we present a revision of the new methodologies that is designed to allow for efficient data mining and information fusion from social media and of the new applications and frameworks that are currently appearing under the ""umbrella"" of the social networks, social media and big data paradigms. © 2015 Elsevier B.V. All rights reserved.","Big data; Data mining; Social media; Social networks; Social-based frameworks and applications"
"Human-centric wireless sensor networks to improve information availability during urban search and rescue activities","2015","Information Fusion","10.1016/j.inffus.2013.05.009","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84907599189&doi=10.1016%2fj.inffus.2013.05.009&partnerID=40&md5=ad963dd15199899924d23852b99948fa","When a natural disaster hits an urban area, the first 72 h after are the most critical. After that period the probability of finding survivors falls dramatically, therefore the search and rescue activities in that area must be conducted as quickly and effectively as possible. These activities are often improvised by first responders, stemming from the lack of communication and information support needed for making decisions in the field. Unfortunately, improvisations reduce the effectiveness and efficiency of the activities, in turn, affecting the number of people that can be rescued. To address this challenge, this article introduces the concept of a human-centric wireless sensor network, as an infrastructure that supports the capture and delivery of shared information in the field. These networks help increase the information availability, and therefore, the efficiency and effectiveness of the emergency response process. The use of these networks, which is complimentary to the currently used VHF/UHF radio systems, was evaluated using a simulated scenario and also through the feedback provided by an expert in urban search and rescue. The obtained results are highly encouraging. © 2013 Elsevier B.V. All rights reserved.","Human-based sensors; Human-centric wireless sensor networks; Information availability; Information fusion; Opportunistic networks"
"Robust track-to-track association in the presence of sensor biases and missed detections","2016","Information Fusion","10.1016/j.inffus.2015.05.002","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84934958269&doi=10.1016%2fj.inffus.2015.05.002&partnerID=40&md5=1e182189510bb337660e3819e0f82481","The paper addresses the problem of robust track-to-track association in the presence of sensor biases and missed detections. Under the condition of large range biases with sensors, it is validated that the structural difference between two sets of local tracks from different sensors can be described by a non-rigid transformation. After that, we turn the robust track-to-track association problem into the non-rigid point matching problem in the framework of TPS-RPM (Thin Plate Spline-Robust Point Matching). Further, to improve the performance of the track-to-track association, the structural feature is introduced for each local track, and the structural similarity is incorporated by regularizing the energy function of the TPS-RPM algorithm. Simulation results demonstrate the effectiveness of the proposed approaches compared with competing algorithms. © 2015 Elsevier B.V. All rights reserved.","Robust point matching (RPM); Sensor biases; Thin plate spline (TPS); Track-to-track association"
"Jeffrey's rule of conditioning with various forms for uncertainty","2015","Information Fusion","10.1016/j.inffus.2014.12.001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84939946573&doi=10.1016%2fj.inffus.2014.12.001&partnerID=40&md5=589028239bb23c2b50d821d50a444a32","We first introduce Jeffrey's rule of conditioning and explain how it allows us to determine the probability of an event related to one variable from information about a collection of conditional probabilities of that event conditioned on the state another variable. We note that in the original Jeffrey paradigm we have the uncertainty about the state of the conditioning variable expressed as a probability distribution. Here we extend this by allowing alternative formulations for the uncertainty about the conditioning variable. We first consider the case where our uncertainty is expressed in terms of a measure. This allows us to consider the case where our uncertainty is a possibility distribution. We next consider the case where our uncertainty about the conditioning variable is expressed in terms of a Dempster-Shafer belief structure. Finally we consider the case where we are ignorant about the underlying distribution and must use the decision maker's subjective attitude about the nature of uncertainty to provide the necessary information to use in the Jeffrey rule. © 2014 Elsevier B.V. All rights reserved.","Conditional probability; Jeffrey's rule; Measure; Possibility; Uncertainty"
"Model-based trajectory reconstruction with IMM smoothing and segmentation","2015","Information Fusion","10.1016/j.inffus.2014.06.004","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84907599570&doi=10.1016%2fj.inffus.2014.06.004&partnerID=40&md5=148eec9335135343c23900de469d379c","This paper presents a new approach for off-line trajectory reconstruction in air traffic control domain. The proposed algorithm, called model-based reconstruction, performs an accurate IMM smoothing process whose parameters are modified along time according to the flight modes segmented from trajectory measurements. Its competitive performance is demonstrated through comparison with previous reconstruction methods used in ATC and with classical IMM smoothing, using simulated data. © 2014 Elsevier B.V. All rights reserved.","ATC evaluation tools; IMM data smoothing; MoF segmentation; Trajectory reconstruction"
"Multimodal inverse perspective mapping","2015","Information Fusion","10.1016/j.inffus.2014.09.003","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027949320&doi=10.1016%2fj.inffus.2014.09.003&partnerID=40&md5=a5e53999d99506f7d122de0dbd54e259","Over the past years, inverse perspective mapping has been successfully applied to several problems in the field of Intelligent Transportation Systems. In brief, the method consists of mapping images to a new coordinate system where perspective effects are removed. The removal of perspective associated effects facilitates road and obstacle detection and also assists in free space estimation. There is, however, a significant limitation in the inverse perspective mapping: the presence of obstacles on the road disrupts the effectiveness of the mapping. The current paper proposes a robust solution based on the use of multimodal sensor fusion. Data from a laser range finder is fused with images from the cameras, so that the mapping is not computed in the regions where obstacles are present. As shown in the results, this considerably improves the effectiveness of the algorithm and reduces computation time when compared with the classical inverse perspective mapping. Furthermore, the proposed approach is also able to cope with several cameras with different lenses or image resolutions, as well as dynamic viewpoints. © 2014 Elsevier B.V.","Intelligent vehicles; Inverse perspective mapping; Multimodal sensor fusion"
"A method for large group decision-making based on evaluation information provided by participators from multiple groups","2016","Information Fusion","10.1016/j.inffus.2015.08.002","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84954393421&doi=10.1016%2fj.inffus.2015.08.002&partnerID=40&md5=53ea6ae2f7684ad32611f405dc58cf7d","Large group decision-making (LGDM) is a special group decision-making (GDM) problem, in which a large number of persons take part in decision process, while research concerning this issue is still relatively scarce. The objective of this paper is to develop a method to solve the LGDM problem, in which a large number of persons from multiple groups take part in the decision process and express their personal evaluations on the alternatives according to the pre-established identifier set. In the method, the percentage distribution on evaluations of each group concerning each alternative is determined. The decision weight of each group concerning each alternative is obtained by aggregating the subjective weight, which is provided by the organizer, and the objective weight, determined according to the level of consensus among participators' evaluations. According to the percentage distributions and decision weights, the dominance degrees on pairwise comparisons of alternatives are calculated, and a ranking of alternatives can be determined using the PROMETHEE II method. Finally, an example is given to illustrate the use of the proposed method. © 2015 Elsevier B.V. All rights reserved.","Large group decision-making (LGDM); Percentage distribution; Ranking; Weight"
"Pointwise multi-valued fusion","2015","Information Fusion","10.1016/j.inffus.2014.10.001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84924408241&doi=10.1016%2fj.inffus.2014.10.001&partnerID=40&md5=e64a921f6d71e063a4da5b493f663967","Assessment and improvement of data quality is a major challenge with any modern information source. An aspect of data quality that has gained a lot of interest in the past decades, is the detection and fusion of duplicate data. This paper contributes to the field of duplicate data fusion by investigating a framework of fusion functions. In particular, it is observed that multisets are a data structure for which little is known concerning fusion theory. Therefore, a class of multi-valued functions called pointwise fusion functions, is proposed and investigated. An extensive list of properties is defined in order to compare the behavior of multi-valued fusion functions. Some specific pointwise fusion functions are investigated with respect to the defined properties and they are evaluated in different fusion scenarios. Next, some quality measures are discussed and their usefulness in the different fusion scenarios is discussed. © 2014 Elsevier B.V.","Multi-valued fusion; Multiset; Set"
"Web news mining in an evolving framework","2016","Information Fusion","10.1016/j.inffus.2015.07.004","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84943364891&doi=10.1016%2fj.inffus.2015.07.004&partnerID=40&md5=cc51cc5370b31d8612f9b92578fb20ff","Online news has become one of the major channels for Internet users to get news. News websites are daily overwhelmed with plenty of news articles. Huge amounts of online news articles are generated and updated everyday, and the processing and analysis of this large corpus of data is an important challenge. This challenge needs to be tackled by using big data techniques which process large volume of data within limited run times. Also, since we are heading into a social-media data explosion, techniques such as text mining or social network analysis need to be seriously taken into consideration. In this work we focus on one of the most common daily activities: web news reading. News websites produce thousands of articles covering a wide spectrum of topics or categories which can be considered as a big data problem. In order to extract useful information, these news articles need to be processed by using big data techniques. In this context, we present an approach for classifying huge amounts of different news articles into various categories (topic areas) based on the text content of the articles. Since these categories are constantly updated with new articles, our approach is based on Evolving Fuzzy Systems (EFS). The EFS can update in real time the model that describes a category according to the changes in the content of the corresponding articles. The novelty of the proposed system relies in the treatment of the web news articles to be used by these systems and the implementation and adjustment of them for this task. Our proposal not only classifies news articles, but it also creates human interpretable models of the different categories. This approach has been successfully tested using real on-line news. © 2015 Elsevier B.V. All rights reserved.","Big data; Evolving fuzzy systems; Web news mining"
"Constructing choquet integral-based operators that generalize weighted means and OWA operators","2015","Information Fusion","10.1016/j.inffus.2014.06.003","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84908575936&doi=10.1016%2fj.inffus.2014.06.003&partnerID=40&md5=7ab73648c87de0ef6615aab6c6c8bd4e","In this paper we introduce the semi-uninorm based ordered weighted averaging (SUOWA) operators, a new class of aggregation functions that, as WOWA operators, simultaneously generalize weighted means and OWA operators. To do this we take into account that weighted means and OWA operators are particular cases of Choquet integral. So, SUOWA operators are Choquet integral-based operators where their capacities are constructed by using semi-uninorms and the values of the capacities associated to the weighted means and the OWA operators. We also show some interesting properties of these new operators and provide examples showing that SUOWA and WOWA operators are different classes of aggregation operators. © 2014 Elsevier B.V. All rights reserved.","Choquet integral; Owa operators; Semi-uninorms; Suowa operators; Weighted means"
"Precedence tree guided search for the efficient identification of multiple situations of interest - AND/OR graph matching","2016","Information Fusion","10.1016/j.inffus.2015.02.001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84938214726&doi=10.1016%2fj.inffus.2015.02.001&partnerID=40&md5=162157360b3d9048d1394cfc6c6c1727","Intelligence analysis is a domain characterized by a torrent of streaming data within which a very small portion contains useful knowledge or actionable intelligence. Intelligence analysts have to sift through the compiled data and weave through a complex web of convoluted connections in an attempt to illuminate information requirements (IR) and maintain situational awareness. Automated methodologies have eased the manual burden of this process to some extent. Data are naturally modeled in a graphical form representing the known people, places, events and the relationships between them. Graph matching algorithms in which an information requirement is formulated as a template graph or situation of interest to be found in the observed data graph have been successfully employed in intelligence analysis processes. Absent from these past contributions is the recognition that partial information requirements, such as indicators and warnings, are not mutually exclusive to a specific IR, and an understanding of the characteristics of the underlying data can lead to significant performance benefits. The knowledge of overlapping template sections forms the motivation for precedence tree guided search and AND/OR templates. Through the recognition of the overlapping sections, a single AND/OR template can be created to answer many information requirements. This paper presents a novel algorithm for the intelligent traversal of an AND/OR template, providing increased algorithmic efficiency over the execution of multiple sequential graph matching instances. This paper focuses on development of an algorithm for intelligent AND/OR template traversal with computational results illustrating the effectiveness of the developed methods. The results indicate a significant improvement in runtime (with a speedup over 5 in some cases) while maintaining a good solution quality (within 2% of multiple AND path graph matching executions) in AND/OR and precedence tree guided graph matching. ©2015 Elsevier B.V. All rights reserved.","AND/OR graph; Intelligence analysis; Precedence tree; Stochastic graph matching"
"Dynamical order construction in data fusion","2016","Information Fusion","10.1016/j.inffus.2015.05.001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84930006429&doi=10.1016%2fj.inffus.2015.05.001&partnerID=40&md5=718fb4e34bee2c2167a31c818f753a50","A crucial operation in the maintenance of data quality in relational databases is to remove tuples that mutually describe the same entity (i.e., duplicate tuples) and to replace them with a tuple that minimizes information loss. A function that combines multiple tuples into one is called a fusion function. In this paper, we investigate fusion functions for attributes of which the values can be sorted by means of an order relation that reflects a notion of generality. It is shown that providing such an order relation a priori, let alone keeping it up-to-date, is a costly operation. Therefore, the Dynamical Order Construction (DOC) algorithm is proposed that constructs an order relation in an automated fashion upon inspecting the data that need to be fused. Such order relations can be immediately deployed in a framework of selectional fusion functions, which are fusion functions that adopt the sort-and-select principle. These fusion functions are investigated closely in terms of their selection strategies. An experimental evaluation of our method shows the influence of the parameters and the benefit with respect to using a fixed and predefined taxonomy. © 2015 Elsevier B.V. All rights reserved.","Data fusion; Knowledge base construction; Order relation; Relational databases"
"A complex event processing approach to perceive the vehicular context","2015","Information Fusion","10.1016/j.inffus.2012.08.008","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84904806129&doi=10.1016%2fj.inffus.2012.08.008&partnerID=40&md5=0ff6757d0a0d0fc2943415f2b05c4377","Nowadays, most people are used to driving their own vehicles to accomplish certain routines like commuting, go shopping, and the like. Taking into account the increasing number of sensors vehicles are provided with, the present work states that it is possible to perceive the context of a vehicle by processing and fusioning the data of some of them. As a result, an on-board context-aware application that processes the usual itineraries of the Ego Vehicle as part of the vehicular context has been implemented. Particularly, the system follows a Complex Event Processing (CEP) approach, and it is able to detect the vehicular occupancy along with the meaningful points of the frequent itineraries whereby a density-based-cluster algorithm. Test results from simulations and real environments show the accuracy of the system when it comes to detect different types of itineraries. © 2012 Elsevier B.V. All rights reserved.","Complex event processing; Context awareness; Density-based clustering; Vehicular occupancy detection"
"A survey of multi-source domain adaptation","2015","Information Fusion","10.1016/j.inffus.2014.12.003","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027923926&doi=10.1016%2fj.inffus.2014.12.003&partnerID=40&md5=c3099fd7954b30ac93c9384287d75edb","In many machine learning algorithms, a major assumption is that the training and the test samples are in the same feature space and have the same distribution. However, for many real applications this assumption does not hold. In this paper, we survey the problem where the training samples and the test samples are from different distributions. This problem can be referred as domain adaptation. The training samples, always with labels, are obtained from what is called source domains, while the test samples, which usually have no labels or only a few labels, are obtained from what is called target domains. The source domains and the target domains are different but related to some extent; the learners can learn some information from the source domains for the learning of the target domains. We focus on the multi-source domain adaptation problem where there is more than one source domain available together with only one target domain. A key issue is how to select good sources and samples for the adaptation. In this survey, we review some theoretical results and well developed algorithms for the multi-source domain adaptation problem. We also discuss some open problems which can be explored in future work. © 2014 Elsevier B.V.","Domain adaptation; Machine learning; Multi-source learning; Transfer learning"
"An asynchronous sensor bias estimation algorithm utilizing targets' positions only","2016","Information Fusion","10.1016/j.inffus.2015.05.003","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84935023662&doi=10.1016%2fj.inffus.2015.05.003&partnerID=40&md5=62af9ddddfeb2e330cd7115ac4e158be","Bias estimation is a critical problem in multi-sensor tracking systems, and most existing research has focused on the bias estimation of synchronous sensors; however, in practical applications, sensor measurements are usually asynchronous. The primary contribution of this paper is that a novel algorithm using B-spline interpolation time registration to achieve asynchronous sensor bias estimation is proposed. First, measurements are transformed into synchronous data using the B-spline interpolation time registration method. The time registration results are expressed as weighted results of the measurements. Second, a pseudo measurement equation is created based on the synchronous data. Compared with the pseudo measurements of other algorithms that use weighting coefficients, which are calculated by the target's state, including the target's velocity and time of arrival (TOA), a pseudo measurement that only depends on the target's position can be derived. Thus, the problem of asynchronous sensor bias estimation, particularly with manoeuvring targets, can be solved effectively by the proposed algorithm. Finally, the effectiveness of the proposed algorithm is verified by simulations with the target performing s-shaped manoeuvres. Monte Carlo simulation results indicate that the Cramer-Rao lower bound (CRLB) is achievable; thus, the proposed algorithm is statistically efficient. © 2015 Elsevier B.V. All rights reserved.","Asynchronous sensors; Bias estimation; Data fusion; Manoeuvring targets; Spatial registration"
"Partial observable update for subjective logic and its application for trust estimation","2015","Information Fusion","10.1016/j.inffus.2015.01.005","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84939956771&doi=10.1016%2fj.inffus.2015.01.005&partnerID=40&md5=9ba22118c924916a2f9695edcfbe32a8","Subjective Logic (SL) is a type of probabilistic logic, which is suitable for reasoning about situations with uncertainty and incomplete knowledge. In recent years, SL has drawn a significant amount of attention from the multi-agent systems community as it connects beliefs and uncertainty in propositions to a rigorous statistical characterization via Dirichlet distributions. However, one serious limitation of SL is that the belief updates are done only based on completely observable evidence. This work extends SL to incorporate belief updates from partially observable evidence. Normally, the belief updates in SL presume that the current evidence for a proposition points to only one of its mutually exclusive attribute states. Instead, this work considers that the current attribute state may not be completely observable, and instead, one is only able to obtain a measurement that is statistically related to this state. In other words, the SL belief is updated based upon the likelihood that one of the attributes was observed. The paper then illustrates properties of the partial observable updates as a function of the state likelihood and illustrates the use of these likelihoods for a trust estimation application. Finally, the utility of the partial observable updates is demonstrated via various simulations including the trust estimation case. © 2015 Elsevier B.V. All rights reserved.","Dirichlet distributions; Partial observations; Subjective logic; Trust management; Uncertain information"
"Interval-valued intuitionistic fuzzy mathematical programming method for hybrid multi-criteria group decision making with interval-valued intuitionistic fuzzy truth degrees","2015","Information Fusion","10.1016/j.inffus.2015.01.006","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84939973003&doi=10.1016%2fj.inffus.2015.01.006&partnerID=40&md5=0fdb92e5cb30614ba66aa663a190a546","As an important component of group decision making, the hybrid multi-criteria group decision making (MCGDM) is very complex and interesting in real applications. The purpose of this paper is to develop a novel interval-valued intuitionistic fuzzy (IVIF) mathematical programming method for hybrid MCGDM considering alternative comparisons with hesitancy degrees. The subjective preference relations between alternatives given by each decision maker (DM) are formulated as an IVIF set (IVIFS). The IVIFSs, intuitionistic fuzzy sets (IFSs), trapezoidal fuzzy numbers (TrFNs), linguistic variables, intervals and real numbers are used to represent the multiple types of criteria values. The information of criteria weights is incomplete. The IVIFS-type consistency and inconsistency indices are defined through considering the fuzzy positive and negative ideal solutions simultaneously. To determine the criteria weights, we construct a novel bi-objective IVIF mathematical programming of minimizing the inconsistency index and meanwhile maximizing the consistency index, which is solved by the technically developed linear goal programming approach. The individual ranking order of alternatives furnished by each DM is subsequently obtained according to the comprehensive relative closeness degrees of alternatives to the fuzzy positive ideal solution. The collective ranking order of alternatives is derived through establishing a new multi-objective assignment model. A real example of critical infrastructure evaluation is provided to demonstrate the applicability and effectiveness of this method. © 2015 Elsevier B.V. All rights reserved.","Critical infrastructure evaluation; Fuzzy mathematical programming; Interval-valued intuitionistic fuzzy set; Linear Programming Technique for Multidimensional Analysis of Preference; Multi-criteria group decision making"
"Partially-supervised learning from facial trajectories for face recognition in video surveillance","2015","Information Fusion","10.1016/j.inffus.2014.05.006","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027925403&doi=10.1016%2fj.inffus.2014.05.006&partnerID=40&md5=813339c149cd1de3b9b3ffab26d787f9","Face recognition (FR) is employed in several video surveillance applications to determine if facial regions captured over a network of cameras correspond to a target individuals. To enroll target individuals, it is often costly or unfeasible to capture enough high quality reference facial samples a priori to design representative facial models. Furthermore, changes in capture conditions and physiology contribute to a growing divergence between these models and faces captured during operations. Adaptive biometrics seek to maintain a high level of performance by updating facial models over time using operational data. Adaptive multiple classifier systems (MCSs) have been successfully applied to video-to-video FR, where the face of each target individual is modeled using an ensemble of 2-class classifiers (trained using target vs. non-target samples). In this paper, a new adaptive MCS is proposed for partially-supervised learning of facial models over time based on facial trajectories. During operations, information from a face tracker and individual-specific ensembles is integrated for robust spatio-temporal recognition and for self-update of facial models. The tracker defines a facial trajectory for each individual that appears in a video, which leads to the recognition of a target individual if the positive predictions accumulated along a trajectory surpass a detection threshold for an ensemble. When the number of positive ensemble predictions surpasses a higher update threshold, then all target face samples from the trajectory are combined with non-target samples (selected from the cohort and universal models) to update the corresponding facial model. A learn-and-combine strategy is employed to avoid knowledge corruption during self-update of ensembles. In addition, a memory management strategy based on Kullback-Leibler divergence is proposed to rank and select the most relevant target and non-target reference samples to be stored in memory as the ensembles evolves. For proof-of-concept, a particular realization of the proposed system was validated with videos from Face in Action dataset. Initially, trajectories captured from enrollment videos are used for supervised learning of ensembles, and then videos from various operational sessions are presented to the system for FR and self-update with high-confidence trajectories. At a transaction level, the proposed approach outperforms baseline systems that do not adapt to new trajectories, and provides comparable performance to ideal systems that adapt to all relevant target trajectories, through supervised learning. Subject-level analysis reveals the existence of individuals for which self-updating ensembles with unlabeled facial trajectories provides a considerable benefit. Trajectory-level analysis indicates that the proposed system allows for robust spatio-temporal video-to-video FR, and may therefore enhance security and situation analysis in video surveillance. © 2014 Elsevier B.V.","Adaptive biometrics; Incremental learning; Multiple classifier systems; Video surveillance; Video-to-video face recognition"
"Multi-Hypotheses Tracking using the Dempster-Shafer Theory, application to ambiguous road context","2016","Information Fusion","10.1016/j.inffus.2015.10.001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84945535455&doi=10.1016%2fj.inffus.2015.10.001&partnerID=40&md5=e1783b06f3036aeb3c1322e3c00921a2","This paper presents a Multi-Hypotheses Tracking (MHT) approach that allows solving ambiguities that arise with previous methods of associating targets and tracks within a highly volatile vehicular environment. The previous approach based on the Dempster-Shafer Theory assumes that associations between tracks and targets are unique; this was shown to allow the formation of ghost tracks when there was too much ambiguity or conflict for the system to take a meaningful decision. The MHT algorithm described in this paper removes this uniqueness condition, allowing the system to include ambiguity and even to prevent making any decision if available data are poor. We provide a general introduction to the Dempster-Shafer Theory and present the previously used approach. Then, we explain our MHT mechanism and provide evidence of its increased performance in reducing the amount of ghost tracks and false positive processed by the tracking system. © 2015 Elsevier B.V.","Ambiguity; Association; Dempster-Shafer Theory; Tracking"
"Multisensor video fusion based on higher order singular value decomposition","2015","Information Fusion","10.1016/j.inffus.2014.09.008","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028146811&doi=10.1016%2fj.inffus.2014.09.008&partnerID=40&md5=0bf73d12e47bc7dae8e693367b623f65","With the ongoing development of sensor technologies, more and more kinds of video sensors are being employed in video surveillance systems to improve robustness and monitoring performance. In addition, there is often a strong motivation to simultaneously observe the same scene by more than one kind of sensor. How to sufficiently and effectively utilize the information captured by these different sensors is thus of considerable interest. This can be realized using video fusion, by which multiple aligned videos from different sensors are merged into a composite. In this paper, a video fusion algorithm is presented based on the 3D Surfacelet Transform (3D-ST) and the higher order singular value decomposition (HOSVD). In the proposed method, input videos are first decomposed into many subbands using the 3D-ST. Then the relevant subbands from all of the input videos are merged to obtain the corresponding subbands of the intended fused video. Finally, the fused video is constructed by performing the inverse 3D-ST on the merged subband coefficients. Typically, the spatial information in the scene backgrounds and the temporal information related to moving objects are mixed together in each subband. In the proposed fusion method, the spatial and temporal information are actually first separated from each other and then merged using the HOSVD. This is different from the currently published fusion rules (e.g., spatio-temporal energy ""maximum"" or ""matching""), which are usually just simple extensions of static image fusion rules. In these, the spatial and temporal information contained in the input videos are generally treated equally and merged by the same fusion strategy. In addition, we note that the so-called ""scene noise"" in an input video has been largely ignored by the current literature. We show that this noise can be distinguished from the spatio-temporal objects of interest in the scene and then suppressed using the HOSVD. Clearly, this would be very advantageous for a surveillance system, particularly one dealing with scenes of crowds. Experimental results demonstrate that the proposed fusion method exhibits a lower computational complexity than some existing published video fusion methods, such as the ones based on the structure tensor and the pulse-coupled neural network (PCNN). When the videos are noisy, a modified version of the proposed method is shown to perform better than specialized methods based on the Bivariate-Laplacian model and the PCNN. © 2014 Elsevier B.V.","Higher order singular value decomposition; Surfacelet Transform; Video fusion; Video tensor"
"INFFC: An iterative class noise filter based on the fusion of classifiers with noise sensitivity control","2016","Information Fusion","10.1016/j.inffus.2015.04.002","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84929995916&doi=10.1016%2fj.inffus.2015.04.002&partnerID=40&md5=481a134c0dcee9c1cfe2e6e33f00d37d","Abstract In classification, noise may deteriorate the system performance and increase the complexity of the models built. In order to mitigate its consequences, several approaches have been proposed in the literature. Among them, noise filtering, which removes noisy examples from the training data, is one of the most used techniques. This paper proposes a new noise filtering method that combines several filtering strategies in order to increase the accuracy of the classification algorithms used after the filtering process. The filtering is based on the fusion of the predictions of several classifiers used to detect the presence of noise. We translate the idea behind multiple classifier systems, where the information gathered from different models is combined, to noise filtering. In this way, we consider the combination of classifiers instead of using only one to detect noise. Additionally, the proposed method follows an iterative noise filtering scheme that allows us to avoid the usage of detected noisy examples in each new iteration of the filtering process. Finally, we introduce a noisy score to control the filtering sensitivity, in such a way that the amount of noisy examples removed in each iteration can be adapted to the necessities of the practitioner. The first two strategies (use of multiple classifiers and iterative filtering) are used to improve the filtering accuracy, whereas the last one (the noisy score) controls the level of conservation of the filter removing potentially noisy examples. The validity of the proposed method is studied in an exhaustive experimental study. We compare the new filtering method against several state-of-the-art methods to deal with datasets with class noise and study their efficacy in three classifiers with different sensitivity to noise. © 2015 Elsevier B.V.","Class noise; Classification; Fusion of classifiers; Noise filters; Noisy data"
"Focused pooling for image fusion evaluation","2015","Information Fusion","10.1016/j.inffus.2014.05.002","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84907599726&doi=10.1016%2fj.inffus.2014.05.002&partnerID=40&md5=aea8ca8f1944e3126cf667de25cc3218","This paper presents the results of an investigation into optimal spatial pooling of localised quality scores for use in objective evaluation of multisensor image fusion. We propose and evaluate a two stage focused pooling method with a localised aggregation of pixel-level performance estimates into regional fusion performance scores as the first step followed by a global pooling of regional scores into a global fusion performance score. We investigate a selection of linear and non-linear global pooling methods and show that quality driven methods which take into account regional fusion performance levels exhibit optimal performance. The proposed pooling algorithm is general and applicable to any fusion performance and quality metric based on structural preservation estimates, local differences between input and fused images. Specifically, we evaluate the proposed method in conjunction with three well-known structural preservation fusion metrics against their baseline pooling methods. We show, through correlation with an extensive subjectively annotated dataset of fused images, that regional aggregation of local performance scores over 3-6° of visual angle with selection of the worst performing region as the global score can improve performance for all the structural fusion metrics tested. © 2014 Elsevier B.V. All rights reserved.","Image fusion; Performance evaluation; Pooling"
"Two new methods for deriving the priority vector from interval multiplicative preference relations","2015","Information Fusion","10.1016/j.inffus.2014.12.002","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84939938676&doi=10.1016%2fj.inffus.2014.12.002&partnerID=40&md5=2d6a9c7550db54e60a3fdb61c1d2fa52","Interval preference relations are widely used in the analytic hierarchy process (AHP) for their ability to express the expert's uncertainty. The most crucial issue arises when deriving the interval priority vector from the interval preference relations. Based on two of the most commonly used prioritization methods (the eigenvalue method (EM) and the row geometric mean method (RGMM)), two new methods for obtaining the interval priority vector from interval multiplicative preference relations are developed, which endow the expert with different risk preferences for his/her interval judgments. In contrast to existing methods, new approaches calculate the interval priority weights of alternatives separately. Then, several concepts of acceptable consistency for interval multiplicative preference relations are defined. Using a convex combination method, the acceptable consistency of interval multiplicative preference relations can be derived from the associated and exact numerical relations. To increase the distinction of intervals, an improved interval ranking method is presented. After that, two algorithms that can cope with acceptably and unacceptably consistent cases are introduced. Meanwhile, three numerical examples are examined to show the application of the new approaches, and comparisons with several other methods are also made. © 2014 Elsevier B.V. All rights reserved.","AHP; Decision analysis; Eigenvalue method; Interval multiplicative preference relation; Row geometric mean method"
"Quadtree-based multi-focus image fusion using a weighted focus-measure","2015","Information Fusion","10.1016/j.inffus.2014.05.003","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84907599964&doi=10.1016%2fj.inffus.2014.05.003&partnerID=40&md5=027658ea17aa2ed8c6fd988786fa644c","The purpose of multi-focus image fusion is integrating the partially focused images into one single image which is focused everywhere. To achieve this purpose, we propose a new quadtree-based algorithm for multi-focus image fusion. In this work, an effective quadtree decomposition strategy is presented. According to the proposed decomposition strategy, the source images are decomposed into blocks with optimal sizes in a quadtree structure. And in this tree structure, the focused regions are detected by using a new weighted focus-measure, named as the sum of the weighted modified Laplacian. Finally, the focused regions could be well extracted from the source images and reconstructed to produce one fully focused image. Moreover, the new weighted focus-measure performs better than the commonly used focus-measures on the detection of the focused regions, since it is sensitive to the homogeneous regions. The proposed algorithm is simple yet effective, because of the quadtree decomposition strategy and the new weighted focus-measure. To do the comparison, the proposed algorithm is compared with several existing fusion algorithms, in both the qualitative and quantitative ways. The experimental results show that the proposed algorithm yields good results. © 2014 Elsevier B.V. All rights reserved.","Multi-focus image fusion; Quadtree decomposition strategy; Quadtree structure; Sum of the weighted modified Laplacian; Weighted focus-measure"
"The fusion process of interval opinions based on the dynamic bounded confidence","2016","Information Fusion","10.1016/j.inffus.2015.08.010","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84954404546&doi=10.1016%2fj.inffus.2015.08.010&partnerID=40&md5=df5bed042d51718447133280e25221ef","In this paper, we propose a novel opinion dynamics model that is based on bounded confidence and termed interval opinion dynamics with the dynamic bounded confidence. In this opinion dynamics model, the agents express their opinions in numerical intervals, and the bounded confidences vary in a specified interval as time varies (i.e., dynamic bounded confidence). Based on several theoretical analyses of the proposed opinion dynamics, we propose conditions that are sufficient to form a consensus or fragmentations among the agents. Moreover, we also design several simulation experiments to investigate the effects of the dynamic bounded confidence and interval widths on the proposed opinion dynamics and to illustrate the differences between the proposed model and the original opinion dynamics with bounded confidence. © 2015 Elsevier B.V. All rights reserved.","Consensus; Dynamic bounded confidences; Fusion process; Interval opinions; Opinion dynamics"
"In-network wireless sensor network query processors: State of the art, challenges and future directions","2015","Information Fusion","10.1016/j.inffus.2015.01.007","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84925515538&doi=10.1016%2fj.inffus.2015.01.007&partnerID=40&md5=a20ec066fa6d602ab2f2d1f0b71a3634","In wireless sensor networks (WSNs), energy is valuable because it is scarce. This causes their life time to be determined by their ability to use the available energy in an effective and frugal manner. In most of the earlier sensor network applications, the main requirement consisted mainly of data collection but transmitting all of the raw data out of the network may be prohibitively expensive (in terms of communication) or impossible at given data collection rates. In the last decade, the use of the database paradigm has emerged as a feasible solution to manage data in a WSN context. There are various sensor network query processors (SNQPs) (implementing in-network declarative query processing) that provide data reduction, aggregation, logging, and auditing facilities. These SNQPs view the wireless sensor network as a distributed database over which declarative query processor can be used to program a WSN application with much less effort. They allow users to pose declarative queries that provide an effective and efficient means to obtain data about the physical environment, as users would not need to be concerned with how sensors are to acquire the data, or how nodes transform and/or transmit the data. This paper surveys novel approaches of handling query processing by the current SNQP literature, the expressiveness of their query language, the support provided by their compiler/optimizer to generate efficient query plans and the kind of queries supported. We introduce the challenges and opportunities of research in the field of in-network sensor network query processing as well as illustrate the current status of research and future research scopes in this field. © 2015 Elsevier B.V.","Distributed processing; Distributed queries; In-network processing; Sensor network query processor (SNQP); Wireless sensor network"
"Robust multi-modal medical image fusion via anisotropic heat diffusion guided low-rank structural analysis","2015","Information Fusion","10.1016/j.inffus.2015.01.001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84939967250&doi=10.1016%2fj.inffus.2015.01.001&partnerID=40&md5=bced4f742f786814969722e79e9cc7e7","This paper proposes a novel and robust multi-modal medical image fusion method, which is built upon a novel framework comprising multi-scale image decomposition based on anisotropic heat kernel design, scale-aware salient information extraction based on low-rank analysis, and scale-specific fusion rules. Our framework respects multi-scale structure features, while being robust to complex noise perturbation. First, anisotropic heat kernel is computed by constructing an image pyramid and embedding multi-level image properties into 2D manifolds in a divide-and-conquer way, consequently, multi-scale structure-preserving image decomposition can be accommodated. Second, to extract meaningfully scale-aware salient information, we conduct low-rank analysis over the image layer groups obtained in the first step, and employ the low-rank components to form the scale space of the salient features, wherein the underlying noise can be synchronously decoupled in a natural way. Third, to better fuse the complementary salient information extracted from multi-modal images, we design an S-shaped weighting function to fuse the large-scale layers, and employ the maximum selection principle to handle the small-scale layers. Moreover, we have conducted extensive experiments on MRI and PET/SPECT images. The comprehensive and quantitative comparisons with state-of-the-art methods demonstrate the informativeness, accuracy, robustness, and versatility of our novel approach. © 2015 Elsevier B.V. All rights reserved.","Anisotropic heat kernel design; Data-specific filter; Low-rank analysis; Multi-modal image fusion; Multi-scale decomposition"
"Multi-sensor information fusion estimators for stochastic uncertain systems with correlated noises","2016","Information Fusion","10.1016/j.inffus.2015.06.001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84933502718&doi=10.1016%2fj.inffus.2015.06.001&partnerID=40&md5=9b2b6abc69511d1a3d2388ee997c69c4","The information fusion estimation problems are investigated for multi-sensor stochastic uncertain systems with correlated noises. The stochastic uncertainties caused by correlated multiplicative noises exist in the state and observation matrices. The process noise and the observation noises are one-step auto-correlated and two-step cross-correlated, respectively. While the observation noises of different sensors are one-step cross-correlated. The optimal centralized fusion filter, predictor and smoother are proposed in the linear minimum variance sense via an innovative analysis approach. To enhance the robustness and flexibility, a distributed fusion filter is put forward, which requires the calculation of filtering error cross-covariance matrices between any two local filters. To avoid the calculation of cross-covariance matrices, another distributed fusion filter is also presented by using the covariance intersection (CI) fusion algorithm, which can reduce the computational cost. A simulation example is given to show the effectiveness of the proposed algorithms. © 2015 Elsevier B.V. All rights reserved.","Correlated noise; Cross-covariance matrix; Information fusion estimator; Multiplicative noise; Stochastic uncertainty"
"Time Aware Knowledge Extraction for microblog summarization on Twitter","2016","Information Fusion","10.1016/j.inffus.2015.06.004","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84943350744&doi=10.1016%2fj.inffus.2015.06.004&partnerID=40&md5=5392602ea7897ccc6d5e8e2722bd2ee0","Microblogging services like Twitter and Facebook collect millions of user generated content every moment about trending news, occurring events, and so on. Nevertheless, it is really a nightmare to find information of interest through the huge amount of available posts that are often noisy and redundant. In the era of Big Data, social media analytics services have caught increasing attention from both research and industry. Specifically, the dynamic context of microblogging requires to manage not only meaning of information but also the evolution of knowledge over the timeline. This work defines Time Aware Knowledge Extraction (briefly TAKE) methodology that relies on temporal extension of Fuzzy Formal Concept Analysis. In particular, a microblog summarization algorithm has been defined filtering the concepts organized by TAKE in a time-dependent hierarchy. The algorithm addresses topic-based summarization on Twitter. Besides considering the timing of the concepts, another distinguishing feature of the proposed microblog summarization framework is the possibility to have more or less detailed summary, according to the user's needs, with good levels of quality and completeness as highlighted in the experimental results. © 2015 Elsevier B.V. All rights reserved.","Big Data; Fuzzy Formal Concept Analysis; Microblog summarization; Social media analytics; Time awareness"
"A new characterization of the discrete Sugeno integral","2016","Information Fusion","10.1016/j.inffus.2015.08.008","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84954390856&doi=10.1016%2fj.inffus.2015.08.008&partnerID=40&md5=19b13dbe104047fa0f1badb0125bb31d","We introduce a new property of the discrete Sugeno integrals which can be seen as their characterization, too. This property, compatibility with respect to congruences on [0, 1], stresses the importance of the Sugeno integrals in multicriteria decision support as well. © 2015 Elsevier Ltd. All rights reserved.","(Compatible) Aggregation function; Congruence; Discrete Sugeno integral; Lattice; Scale invariance"
"The fusion process with heterogeneous preference structures in group decision making: A survey","2015","Information Fusion","10.1016/j.inffus.2014.11.003","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027937998&doi=10.1016%2fj.inffus.2014.11.003&partnerID=40&md5=873410eef7d57b7b20a0256abee902be","In group decision making (GDM), decision makers who have different experiential, cultural and educational backgrounds will naturally provide their preference information by heterogeneous preference structures (e.g., utility values, preference orderings, numerical preference relations and multigranular linguistic preference relations). To date, many studies have discussed GDM problems with heterogeneous preference structures. To provide a clear perspective on the fusion process with heterogeneous preference structures in GDM, this paper presents a review of three types of fusion approaches: the indirect approach, the optimization-based approach and the direct approach. Moreover, with respect to insights gained from prior researches, several open problems are proposed for the future research. © 2014 Elsevier B.V.","Consensus; Fusion process; Group decision making; Heterogeneous preference structures"
"The power average operator for unbalanced linguistic term sets","2015","Information Fusion","10.1016/j.inffus.2014.06.002","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84907883545&doi=10.1016%2fj.inffus.2014.06.002&partnerID=40&md5=c21e1d65a0f90aa2b7874c4e95b329a2","In order to aggregate linguistic values of unbalanced linguistic term sets, this paper introduces the linguistic proportional 2-tuple power average operator, which can reflect the relationship among the aggregated values by considering the support for each value from others. Its advantage regarding other linguistic power average operators enables it to be used in such cases in which the linguistic term sets are not necessarily to be balanced, and the membership functions of the linguistic terms are utilized in the computational processes. In this operator, a linguistic proportional 2-tuple is represented by a normalized numerical representation. Some properties of the operator are discussed. A group decision making model based on the proposed operator is introduced. Finally an illustrative example is presented. © 2014 Elsevier B.V. All rights reserved.","Group decision making; Linguistic proportional 2-tuple; Normalized numerical representation; Power average operator"
"A novel algorithm for fuzzy soft set based decision making from multiobserver input parameter data set","2016","Information Fusion","10.1016/j.inffus.2015.08.007","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84954370604&doi=10.1016%2fj.inffus.2015.08.007&partnerID=40&md5=5d080c7b2fa7aa51923ed97ca7e724f1","We present two innovations that produce a novel approach to the problem of fuzzy soft set based decision making in the presence of multiobserver input parameter data sets. The first novelty consists of a new process of information fusion that furnishes a more reliable resultant fuzzy soft set from such input data set. The second one concerns the mechanism that decides among the alternatives in this resultant fuzzy soft set. It relies on scores computed from a relative Comparison matrix. The advantages of our novel procedure are a higher power of discrimination and a well-determined final solution. © 2015 Elsevier B.V. All rights reserved.","Comparison table; Decision making; Fuzzy soft set; Resultant fuzzy soft set"
"Finding a needle in the blogosphere: An information fusion approach for blog distillation search","2015","Information Fusion","10.1016/j.inffus.2014.09.001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84908565910&doi=10.1016%2fj.inffus.2014.09.001&partnerID=40&md5=ecd2bfbb5891423606ac545b2e2fdbbf","In the blogosphere, different actors express their opinions about multiple topics. Users, companies or editors socially interact by commenting, recommending and linking blogs and posts. These social media contents are increasingly growing. As a matter of fact, the size of the blogosphere is estimated to double every six months. In this context, the problem of finding a topically relevant blog to subscribe to becomes a Big Data challenge. Moreover, combining multiple types of evidence is essential for this search task. In this paper we propose a group of textual and social-based signals, and apply different Information Fusion algorithms for a blog distillation search task. Information fusion through the combination of the different types of evidence requires optimisation for appropriately weighting each source of evidence. To this end, we analyse well-established population-based search methods. Namely, global search (Particle Swarm Optimisation and Differential Evolution) and a local search method (Line Search) that has been effective in various Information Retrieval tasks. Moreover, we propose hybrid combinations between the global search and the local search method and compare all the alternatives following a standard methodology. Efficiency is an imperative here and, therefore, we focus not only on achieving high search effectiveness but also on designing efficient solutions. © 2014 Elsevier B.V. All rights reserved.","Blog distillation; Differential evolution; Information retrieval; Line search; Particle swarm optimisation"
"Adaptive routing in wireless sensor networks: QoS optimisation for enhanced application performance","2015","Information Fusion","10.1016/j.inffus.2013.02.005","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84907600067&doi=10.1016%2fj.inffus.2013.02.005&partnerID=40&md5=1602995980e2f2c67bc28c16687ce455","One of the key challenges for research in wireless sensor networks is the development of routing protocols that provide application-specific service guarantees. This paper presents a new cluster-based Route Optimisation and Load-balancing protocol, called ROL, that uses various Quality of Service (QoS) metrics to meet application requirements. ROL combines several application requirements, specifically it attempts to provide an inclusive solution to prolong network life, provide timely message delivery and improve network robustness. It uses a combination of routing metrics that can be configured according to the priorities of user-level applications to improve overall network performance. To this end, an optimisation tool for balancing the communication resources for the constraints and priorities of user applications has been developed and Nutrient-flow-based Distributed Clustering (NDC), an algorithm for load balancing is proposed. NDC works seamlessly with any clustering algorithm to equalise, as far as possible, the diameter and the membership of clusters. This paper presents simulation results to show that ROL/NDC gives a higher network lifetime than other similar schemes, such Mires++. In simulation, ROL/NDC maintains a maximum of 7% variation from the optimal cluster population, reduces the total number of set-up messages by up to 60%, reduces the end-to-end delay by up to 56%, and enhances the data delivery ratio by up to 0.98% compared to Mires++. © 2013 Elsevier B.V. All rights reserved.","Adaptive; Application performance; Distributed clustering; Load-balancing; Optimisation; Quality of service; Routing; Wireless sensor networks"
"Multi-agent information fusion system to manage data from a WSN in a residential home","2015","Information Fusion","10.1016/j.inffus.2014.03.003","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84908397294&doi=10.1016%2fj.inffus.2014.03.003&partnerID=40&md5=3b3379bd6619ac6f936b4c564d2f4e64","With the increase of intelligent systems based on Multi-Agent Systems (MAS) and the use of Wireless Sensor Networks (WSN) in context-aware scenarios, information fusion has become an essential part of this kind of systems where the information is distributed among nodes or agents. This paper presents a new MAS specially designed to manage data from WSNs, which was tested in a residential home for the elderly. The proposed MAS architecture is based on virtual organizations, and incorporates social behaviors to improve the information fusion processes. The data that the system manages and analyzes correspond to the actual data of the activities of a resident. Data is collected as the information event counts detected by the sensors in a specific time interval, typically one day. We have designed a system that improves the quality of life of dependant people, especially elderly, by fusioning data obtained by multiple sensors and information of their daily activities. The high development of systems that extract and store information make essential to improve the mechanisms to deal with the avalanche of context data. In our case, the MAS approach results appropriated because each agent can represent an autonomous entity with different capabilities and offering different services but collaborating among them. Several tests have been performed to evaluate this platform and preliminary results and the conclusions are presented in this paper. © 2014 Elsevier B.V. All rights reserved.","Ambient Intelligence; Information fusion; Multi-Agent Systems; Wireless Sensor Networks"
"Admissible orders of typical hesitant fuzzy elements and their application in ordered information fusion in multi-criteria decision making","2016","Information Fusion","10.1016/j.inffus.2015.08.009","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84954178673&doi=10.1016%2fj.inffus.2015.08.009&partnerID=40&md5=94acb97ccd3223743a4242cde9a61016","Typical hesitant fuzzy elements (HFEs) are quite useful for multi-criteria decision making (MCDM) in hesitant fuzzy setting. To reach a decision, it is necessary to derive the orders of HFEs. However, all the existing orders presented for HFEs in the literature are partial orders. We may need total orders sometimes such as in the situations when aggregating information by the ordered weighted aggregation (OWA) operators. Thus, the first purpose of this paper is to develop the total orders (called admissible orders) of HFEs for MCDM. The admissible orders improve the existing partial orders of HFEs and can be generated by a set of special functions. We demonstrate that the distinct ranking of HFEs can be derived according to different admissible orders. Another purpose is to redefine the hesitant fuzzy OWA operator based on the proposed total orders. Some interesting properties of the operator are also discussed. © 2015 Elsevier B.V. All rights reserved.","Admissible order; Hesitant fuzzy elements; Hesitant fuzzy sets; OWA operator; Partial orders"
"On the divergence of information filter for multi sensors fusion","2016","Information Fusion","10.1016/j.inffus.2015.05.005","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84931275320&doi=10.1016%2fj.inffus.2015.05.005&partnerID=40&md5=7ad6204ef1af6457e827c24aae6a613a","The paper deals with the divergence of information filter in multi sensor target tracking problem using bearing only measurements. Information filter has a number of advantages in terms of computational requirements over Kalman filter for target tracking applications. Compared to Kalman filter it also has the advantage that one can start estimation even without an initial estimate. But this filter is seen to diverge after tracking for a short period of time, even when the target is moving at a constant velocity. A technique to overcome this problem has been discussed in this paper. The information update equations of the conventional information filter are modified in terms of fuzzy function of error and change of error, and the results have been found to be encouraging. The efficacy of the technique in preventing divergence is demonstrated in the context of tracking a maneuvering target also. © 2015 Elsevier B.V. All rights reserved.","Divergence; Fuzzy function; Information filter; Information state; Multi sensor data fusion"
"A two-layer weight determination method for complex multi-attribute large-group decision-making experts in a linguistic environment","2015","Information Fusion","10.1016/j.inffus.2014.05.001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84908417131&doi=10.1016%2fj.inffus.2014.05.001&partnerID=40&md5=8b2cf68186ed654f204e8cbb6ba7c7d5","We propose a two-layer weight determination model in a linguistic environment, when all the clustering results of the experts are known, to objectively obtain expert weights in complex multi-attribute large-group decision-making (CMALGDM) problems. The linguistic information considered in this paper involves both linguistic terms and linguistic intervals. We assume that, for CMALGDM problems, the final expert weights should be determined based on the expert weight in the cluster and on the cluster weights. This is mainly because experts in the same cluster will certainly make varying contributions to the cluster's overall consensus, and different clusters will also obtain the distinctive ""cluster information quality"". Hence, a Minimized Variance Model and an Entropy Weight Model are proposed to determine the expert weights in the cluster and the cluster weights, respectively. We then synthesize these two types of weights into the final objective weights of the CMALGDM experts. The feasibility of the two-layer weight determination model method for the CMALGDM problems is illustrated using a case study of salary reform for professors at a university. © 2014 Elsevier B.V. All rights reserved.","2-Tuple linguistic (2TL) representation model; Complex multi-attribute large-group decision-making (CMALGDM); Expert weight determination; Interval-valued 2-tuple linguistic (IV2TL) representation model"
"A position and perspective analysis of hesitant fuzzy sets on information fusion in decision making. Towards high quality progress","2016","Information Fusion","10.1016/j.inffus.2015.11.004","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84954369468&doi=10.1016%2fj.inffus.2015.11.004&partnerID=40&md5=917e631ff66e320bc3064c8c86e94b09","The necessity of dealing with uncertainty in real world problems has been a long-term research challenge which has originated different methodologies and theories. Recently, the concept of Hesitant Fuzzy Sets (HFSs) has been introduced to model the uncertainty that often appears when it is necessary to establish the membership degree of an element and there are some possible values that make to hesitate about which one would be the right one. Many researchers have paid attention on this concept who have proposed diverse extensions, relationships with other types of fuzzy sets, different types of operators to compute with this type of information, applications on information fusion and decision-making, etc. Nevertheless, some of these proposals are questionable, because they are straightforward extensions of previous works or they do not use the concept of HFSs in a suitable way. Therefore, this position paper studies the necessity of HFSs and provides a discussion about current proposals including a guideline that the proposals should follow and some challenges of HFSs. © 2015 Elsevier Ltd. All rights reserved.","Hesitant fuzzy sets; Operations; Properties and decision making"
"Users joining multiple sites: Friendship and popularity variations across sites","2016","Information Fusion","10.1016/j.inffus.2015.07.002","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84943359826&doi=10.1016%2fj.inffus.2015.07.002&partnerID=40&md5=1db1ed61c8b877d5e70b04d1cfa79cac","Our social media experience is no longer limited to a single site. We use different social media sites for different purposes and our information on each site is often partial. By collecting complementary information for the same individual across sites, one can better profile users. These profiles can help improve online services such as advertising or recommendation across sites. To combine complementary information across sites, it is critical to understand how information for the same individual varies across sites. In this study, we aim to understand how two fundamental properties of users vary across social media sites. First, we study how user friendship behavior varies across sites. Our findings show how friend distributions for individuals change as they join new sites. Next, we analyze how user popularity changes across sites as individuals join different sites. We evaluate our findings and demonstrate how our findings can be employed to predict how popular users are likely to be on new sites they join. © 2015 Elsevier B.V. All rights reserved.","Cross-media study; Cross-site information fusion; Cross-site user analysis; Friendship analysis; Popularity analysis"
"A conceptual definition of a holonic processing framework to support the design of information fusion systems","2015","Information Fusion","10.1016/j.inffus.2013.08.004","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84904813794&doi=10.1016%2fj.inffus.2013.08.004&partnerID=40&md5=68ab1bbcdd7a80651e0b4b63b38bd2f5","This paper proposes a conceptual definition of an information fusion (IF) processing framework. Several concepts borrowed from complex systems theory, informational philosophy and computer sciences have been integrated to conceptualize that framework. The concepts of holon and informon developed by Koestler, Sulis, Alonso, Paggi et al. are exploited here to develop an information fusion processing framework. The proposed functional holonic structure is suitable for processing any level of information abstraction of the Joint Directors of Laboratory (JDL) data fusion model. The framework comprises the characterization of a basic element of information and the definition of an IF cell as a basic IF system unit to achieve fusion of information. The framework advocates a goal-driven approach with notions coming from business sciences to take into account quality of information for managing the fusion process. The framework is illustrated through several examples namely with an elaborated case in remote sensing. © 2013 Elsevier B.V. All rights reserved.","Archetypal dynamics; Cyber physical systems; Holons/Informons; Information fusion; Quality of information"
"Multi-focus image fusion with dense SIFT","2015","Information Fusion","10.1016/j.inffus.2014.05.004","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84908402697&doi=10.1016%2fj.inffus.2014.05.004&partnerID=40&md5=6de942e5c1c26dc25bf51fb2c61dbcd9","Multi-focus image fusion technique is an important approach to obtain a composite image with all objects in focus. The key point of multi-focus image fusion is to develop an effective activity level measurement to evaluate the clarity of source images. This paper proposes a novel image fusion method for multi-focus images with dense scale invariant feature transform (SIFT). The main novelty of this work is that it shows the great potential of image local features such as the dense SIFT used for image fusion. Particularly, the local feature descriptor can not only be employed as the activity level measurement, but also be used to match the mis-registered pixels between multiple source images to improve the quality of the fused image. In our algorithm, via the sliding window technique, the dense SIFT descriptor is first used to measure the activity level of source image patches to obtain an initial decision map, and then the decision map is refined with feature matching and local focus measure comparison. Experimental results demonstrate that the proposed method can be competitive with or even outperform the state-of-the-art fusion methods in terms of both subjective visual perception and objective evaluation metrics. © 2014 Elsevier B.V. All rights reserved.","Activity level measurement; Dense SIFT; Feature space transform; Local feature matching; Multi-focus image fusion"
"Construction of admissible linear orders for interval-valued Atanassov intuitionistic fuzzy sets with an application to decision making","2016","Information Fusion","10.1016/j.inffus.2015.03.004","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84938211421&doi=10.1016%2fj.inffus.2015.03.004&partnerID=40&md5=f7ede2ee3a38df00a7044f4384487504","In this work we introduce a method for constructing linear orders between pairs of intervals by using aggregation functions. We adapt this method to the case of interval-valued Atanassov intuitionistic fuzzy sets and we apply these sets and the considered orders to a decision making problem. © 2015 Elsevier B.V. All rights reserved.","Interval linear order; Interval-valued Atanassov intuitionistic fuzzy set; Interval-valued Atanassov intuitionistic multi-expert decision making"
"Maritime piracy situation modelling with dynamic Bayesian networks","2015","Information Fusion","10.1016/j.inffus.2014.07.001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84908458642&doi=10.1016%2fj.inffus.2014.07.001&partnerID=40&md5=67b4807f9fbe0490507a8bd8b6a1f1f9","A generative model for modelling maritime vessel behaviour is proposed. The model is a novel variant of the dynamic Bayesian network (DBN). The proposed DBN is in the form of a switching linear dynamic system (SLDS) that has been extended into a larger DBN. The application of synthetic data fabrication of maritime vessel behaviour is considered. Behaviour of various vessels in a maritime piracy situation is simulated. A means to integrate information from context based external factors that influence behaviour is provided. Simulated observations of the vessels kinematic states are generated. The generated data may be used for the purpose of developing and evaluating counter-piracy methods and algorithms. A novel methodology for evaluating and optimising behavioural models such as the proposed model is presented. The log-likelihood, cross entropy, Bayes factor and the Bhattacharyya distance measures are applied for evaluation. The results demonstrate that the generative model is able to model both spatial and temporal datasets. © 2014 Elsevier B.V. All rights reserved.","Behaviour modelling; Contextual information; Dynamic Bayesian network; Multi-agent simulation; Switching linear dynamic system"
"A framework for collaborative computing and multi-sensor data fusion in body sensor networks","2015","Information Fusion","10.1016/j.inffus.2014.03.005","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84907599702&doi=10.1016%2fj.inffus.2014.03.005&partnerID=40&md5=0389d807db2cbe285b26f2021985e202","Body Sensor Networks (BSNs) have emerged as the most effective technology enabling not only new e-Health methods and systems but also novel applications in human-centered areas such as electronic health care, fitness/welness systems, sport performance monitoring, interactive games, factory workers monitoring, and social physical interaction. Despite their enormous potential, they are currently mostly used only to monitor single individuals. Indeed, BSNs can proactively interact and collaborate to foster novel BSN applications centered on collaborative groups of individuals. In this paper, C-SPINE, a framework for Collaborative BSNs (CBSNs), is proposed. CBSNs are BSNs able to collaborate with each other to fulfill a common goal. They can support the development of novel smart wearable systems for cyberphysical pervasive computing environments. Collaboration therefore relies on interaction and synchronization among the CBSNs and on collaborative distributed computing atop the collaborating CBSNs. Specifically, collaboration is triggered upon CBSN proximity and relies on service-specific protocols allowing for managing services among the collaborating CBSNs. C-SPINE also natively supports multi-sensor data fusion among CBSNs to enable joint data analysis such as filtering, time-dependent data integration and classification. To demonstrate its effectiveness, C-SPINE is used to implement e-Shake, a collaborative CBSN system for the detection of emotions. The system is based on a multi-sensor data fusion schema to perform automatic detection of handshakes between two individuals and capture of possible heart-rate-based emotion reactions due to the individuals' meeting. © 2014 Elsevier B.V. All rights reserved.","Body sensor networks; Collaborative computing; Emotion detection; Handshake detection; Multi-sensor data fusion; SPINE"
"Using extended web technologies to develop Bluetooth multi-platform mobile applications for interact with smart things","2015","Information Fusion","10.1016/j.inffus.2013.04.008","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84904823634&doi=10.1016%2fj.inffus.2013.04.008&partnerID=40&md5=c5479ded111b9801e31a4c4a4cc1895f","Nowadays the classic web paradigms are being subjected to changes; every day millions of users around the world use their Smartphones to access web applications from anywhere. The World Wide Web it is one of the biggest repositories of information in the world, and that information is stored in internet servers and repositories, but today in the real world there are many other information sources such as electronic devices with communication capabilities: smart appliances and sensor networks. The Smartphones are equipped with communication hardware elements like the Bluetooth module, which allows the Smartphone to exchange information with nearby electronic devices. Every day more and more mobile applications are being developed for native platforms that use Bluetooth's communication module to send and receive information from different sources. Native mobile applications use the specific platform's APIs to manage the Bluetooth communication actions (send and receive information, search for devices, etc.), however, web applications do not have technical capabilities to manage the Smartphone's Bluetooth communication module and thereof cannot use that kind of information. The main objective of this research work is to design a novel framework that allows classic web applications to use information from nearby electronic devices. The proposed framework must be easy to use and able to be integrated with common web technologies. Developers can use this framework to include new information sources and data exchange procedures in an easy way. The new type of information can be merged with the web to develop or improve algorithms and web applications. © 2013 Elsevier B.V. All rights reserved.","Bluetooth; Context-aware communication; Internet of things; Mobile Web Applications; Web browser; Web information fusion"
"An intelligent context-aware communication system for one single autonomic region to realize smart living","2015","Information Fusion","10.1016/j.inffus.2013.03.002","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84904814870&doi=10.1016%2fj.inffus.2013.03.002&partnerID=40&md5=43b23094b72c0aed4ae031946dbe2929","Wireless communication plays an important role in smart living applications. People can use mobile devices to access various kinds of services via various wireless technologies such as Zigbee, RFID (Radio Frequency Identity). Conventional smart living applications tend to be designed for convenience while ignoring essential restrictions. Actually, ubiquitous communication is the privilege of authorized users in some places for specific requirements and reasons. For example, a nursing attendant may be issued a handset to communicate with a patient's family in the hospital while unauthorized communication is not allowed to prevent the handset from being misused by the nursing attendant. Principles for essential restrictions should be determined and put into practice by an administrator within a predefined region, which is defined to be single autonomic region. In this paper, an intelligent context-aware communication system is proposed to provide ubiquitous communication under location and communication party restrictions to realize smart living in one single autonomic region. We design the system by integrating heterogeneous communication technologies and one novel security protocol, double-lock protocol. We implement the designed system with an ARM-based processor on the embedded system experimental board DMA-2440XP and two pluggable modules, GSM (Global System for Mobile Communications) and GPS (Global Positioning System). In the designed communication system, only legal users can use a legitimate communication device to communicate with legal ones within the authorized area. © 2013 Elsevier B.V. All rights reserved.","ARM (Advanced RISC Machine); Embedded system; GPS; GSM; Smart living"
"Target tracking using Interactive Multiple Model for Wireless Sensor Network","2016","Information Fusion","10.1016/j.inffus.2015.05.004","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84935016494&doi=10.1016%2fj.inffus.2015.05.004&partnerID=40&md5=cf98eb90672e9fa5314c148163a39ed6","Target tracking in a Wireless Sensor Network (WSN) environment is a challenging research problem. Interactive Multiple Model (IMM) is a popular scheme for accurate target tracking. The existing target tracking scheme used in WSN employs Kalman Filter (KF) which fails to track the target accurately due to non availability of target data at regular intervals and missing of packets. Though existing KF based tracking in WSN scheme detects the target, it fails to identify the target. To overcome these problems, this paper proposes a IMM based Target Tracking in WSN named ITTWSN that uses multiple models (velocity and acceleration) to handle both maneuvering and non maneuvering targets and multiple sensors to detect and identify the targets. The performance of the proposed ITTWSN is compared with the KF scheme and it is found that the accuracy of the proposed ITTWSN is better than the existing KF based approach. © 2015 Elsevier B.V. All rights reserved.","Interacting Multiple Model (IMM); Kalman Filter (KF); Person detection; Tracking; Wireless Sensor Network (WSN)"
"Heterogeneous multiple criteria group decision making with incomplete weight information: A deviation modeling approach","2015","Information Fusion","10.1016/j.inffus.2014.10.006","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84924807340&doi=10.1016%2fj.inffus.2014.10.006&partnerID=40&md5=ca19ecc2a4efca311aba44f7b576eaf1","Multiple criteria group decision making (MCGDM) problems with multiple formats of decision information, which are called heterogeneous MCGDM problems, have broad applications in the fields of natural science, social science, economy and management, etc. It is quite common that in heterogeneous MCGDM problems both the weights of the decision makers/experts and the criteria are partially known or completely unknown, but few studies focus on this issue. The purpose of this paper is to develop a deviation modeling method to deal with the heterogeneous MCGDM problems with incomplete weight information in which the decision information is expressed as real numbers, interval numbers, linguistic variables, intuitionistic fuzzy numbers, hesitant fuzzy elements and hesitant fuzzy linguistic term sets. There are three key issues being addressed in this approach, the first one is to construct a maximizing deviation optimal model in order to determine the optimal weights of criteria for each expert. Borrowing the idea of TOPSIS, the second one is to calculate the relative closeness indices of the alternatives for each expert. The third one is to establish a minimizing deviation optimal model based on the idea that the opinion of the individual expert should be consistent with that of the group to the greatest extent, which is used to determine the weights of experts and identify the optimal alternative. The proposed approach is applied to solve the practical decision making problem concerned with the selection of Strategic Freight Forwarder of China Southern Airlines, and a comparison analysis with a similar approach is conducted to demonstrate the advantages of the proposed method. © 2014 Elsevier B.V.","Heterogeneous information; Incomplete weight information; Multiple criteria group decision making; The deviation model"
"The joint optimal filtering and fault detection for multi-rate sensor fusion under unknown inputs","2016","Information Fusion","10.1016/j.inffus.2015.10.003","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84946599640&doi=10.1016%2fj.inffus.2015.10.003&partnerID=40&md5=711a7811814254210d0e061c21beb9a7","In multi-sensor fusion, it is hard to guarantee that all sensors have an identical sampling rate, especially in the distributive and/or heterogeneous case. Meanwhile, stochastic noise, unknown inputs (UIs), and faults may coexist in complex environment. To this end, we propose the problem of joint optimal filtering and fault detection (FD) for multi-rate sensor fusion subject to UIs, stochastic noise with known covariance, and faults imposed on the actuator and sensors. Furthermore, the new scheme of optimal multi-rate observer (MRO) is presented and applied to detect faults. The observer parameters are determined optimally in pursuit of the UI decoupling and maximizing noise attenuation under the causality constraint due to multi-rate nature. Finally, the output estimation error of the MRO is used as a residual signal for FD via a hypothesis test in which the threshold is adaptively designed according to the MRO parameters. One numerical example is given to show the effectiveness of our proposed method. © 2015 Elsevier B.V.","Disturbance decoupling; Fault detection; Multi-rate sensor system; Optimal filtering; Unknown input observer"
"Topic-centric and semantic-aware retrieval system for internet of things","2015","Information Fusion","10.1016/j.inffus.2014.01.001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84908463788&doi=10.1016%2fj.inffus.2014.01.001&partnerID=40&md5=363887fd530beba454dfe38e22049b0b","The Internet of things (IoT) has been considered as one of the promising paradigms that can allow people and objects to seamlessly interact. So far, numerous applications and services have been proposed, such as retrieval service. The retrieval, however, faces a big challenge in IoT because the data belongs to different domains and user interaction with the surrounding environment is constrained. This paper proposes Acrost, a retrieval system based on topic discovery and semantic awareness in IoT environment. The initial contents with interesting information is obtained through the combination of two topic centric collectors. The metadata is extracted by aggregating regular expression-based and conditional random fields-based approaches. Moreover, the semantic-aware retrieval is achieved by parsing the query and ranking the relevance of contents. In addition, we present a case study on academic conference retrieval to validate the proposed approaches. Experimental results show that the proposed system can significantly improve the response time and efficiency of topic self-adaptive retrieval manner. © 2014, Elsevier B.V. All rights reserved.","Information retrieval; Internet of things; Knowledge network; Semantic awareness; Topic centric"
"Hierarchical distance learning by stacking nearest neighbor classifiers","2016","Information Fusion","10.1016/j.inffus.2015.09.004","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84944145496&doi=10.1016%2fj.inffus.2015.09.004&partnerID=40&md5=6c64ef5acffcd9d2933ed3e5113ea8cd","We propose a two-layer decision fusion technique, called Fuzzy Stacked Generalization (FSG) which establishes a hierarchical distance learning architecture. At the base-layer of an FSG, fuzzy k-NN classifiers receive different feature sets each of which is extracted from the same dataset to gain multiple views of the dataset. At the meta-layer, first, a fusion space is constructed by aggregating decision spaces of all the base-layer classifiers. Then, a fuzzy k-NN classifier is trained in the fusion space by minimizing the difference between the large sample and N-sample classification error. In order to measure the degree of collaboration among the base-layer classifiers and the diversity of the feature spaces, a new measure called, shareability, is introduced. Shearability is defined as the number of samples that are correctly classified by at least one of the base-layer classifiers in FSG. In the experiments, we observe that FSG performs better than the popular distance learning and ensemble learning algorithms when the shareability measure is large enough such that most of the samples are correctly classified by at least one of the base-layer classifiers. The relationship between the proposed and state-of-the-art diversity measures is experimentally analyzed. The tests performed on a variety of artificial and real-world benchmark datasets show that the classification performance of FSG increases compared to that of state-of-the art ensemble learning and distance learning methods as the number of classes increases. © 2015 Elsevier B.V. All rights reserved.","Classification; Decision fusion; Ensemble learning; Hierarchical distance learning; Nearest neighbor rule"
"Saliency-directed prioritization of visual data in wireless surveillance networks","2015","Information Fusion","10.1016/j.inffus.2014.07.002","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027932003&doi=10.1016%2fj.inffus.2014.07.002&partnerID=40&md5=2b842a10263503483cbc32916fb7175d","In wireless visual sensor networks (WVSNs), streaming all imaging data is impractical due to resource constraints. Moreover, the sheer volume of surveillance videos inhibits the ability of analysts to extract actionable intelligence. In this work, an energy-efficient image prioritization framework is presented to cope with the fragility of traditional WVSNs. The proposed framework selects semantically relevant information before it is transmitted to a sink node. This is based on salient motion detection, which works on the principle of human cognitive processes. Each camera node estimates the background by a bootstrapping procedure, thus increasing the efficiency of salient motion detection. Based on the salient motion, each sensor node is classified as being high or low priority. This classification is dynamic, such that camera nodes toggle between high-priority and low-priority status depending on the coverage of the region of interest. High-priority camera nodes are allowed to access reliable radio channels to ensure the timely and reliable transmission of data. We compare the performance of this framework with other state-of-the-art methods for both single and multi-camera monitoring. The results demonstrate the usefulness of the proposed method in terms of salient event coverage and reduced computational and transmission costs, as well as in helping analysts find semantically relevant visual information. © 2014 Elsevier B.V. All rights reserved..","Image prioritization; Monitoring applications; Salient activity detection; Wireless visual sensor networks"
"Perceptual fusion of infrared and visible images through a hybrid multi-scale decomposition with Gaussian and bilateral filters","2016","Information Fusion","10.1016/j.inffus.2015.11.003","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84971251064&doi=10.1016%2fj.inffus.2015.11.003&partnerID=40&md5=07bbfde1d18d6e30a28f9b58ed70dd25","In order to achieve perceptually better fusion of infrared (IR) and visible images than conventional pixel-level fusion algorithms based on multi-scale decomposition (MSD), we present a novel multi-scale fusion method based on a hybrid multi-scale decomposition (hybrid-MSD). The proposed hybrid-MSD transform decomposes the source images into multi-scale texture details and edge features by jointly using multi-scale Gaussian and bilateral filters. This transform enables to better capture important multi-scale IR spectral features and separate fine-scale texture details from large-scale edge features. As a result, we can use it to achieve better fusion result for human visual perception than those obtained from conventional multi-scale fusion methods, by injecting the multi-scale IR spectral features into the visible image, while preserving (or properly enhancing) important perceptual cues of the background scenery and details from the visible image. In the decomposed information fusion process, three different combination algorithms are adaptively used in accordance to different scale levels (i.e., the small-scale levels, the large-scale levels and the base level). A regularization parameter is introduced to control the relative amount of IR spectral information injected into the visible image in a soft manner, which can be adjusted further depending on user preferences. Moreover, by testing different settings of the parameter, we demonstrate that injecting a moderate amount of IR spectral information with this parameter can actually make the fused images visually better for some infrared and visible source images. Experimental results of both objective assessment and subjective evaluation by human observers also prove the superiority of the proposed method compared with conventional MSD-based fusion methods. © 2015 Elsevier B.V. All rights reserved.","Bilateral filter; Gaussian filter; Human perception; Image fusion; Multi-scale decomposition"
"Post-aggregation of classifier ensembles","2015","Information Fusion","10.1016/j.inffus.2015.01.003","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84940002820&doi=10.1016%2fj.inffus.2015.01.003&partnerID=40&md5=d387238c1e130fe848d8148ed5df01cf","We propose to apply an adequate form of an ensemble output to the last level of an additional classifier - The post-aggregation element - As a method to improve ensemble's performance. Our experimental results prove that a Gate-Generated Functional Weight Classifier post-aggregation serves to get this objective, both in situations in which data are available everywhere and when some features are missing for the post-aggregation task - A case which is relevant for distributed classification problems. Post-aggregation techniques can be especially useful for massive (integrated by many learners) ensembles - Such as most the committees, which do not allow trainable first aggregations - And for human decision fusion, because it is unclear what features are considered in this kind of processes. © 2015 Elsevier B.V. All rights reserved.","Classification; Ensemble; Maximal margin; Post-aggregation"
"Project evaluation method using non-formatted text information based on multi-granular linguistic labels","2015","Information Fusion","10.1016/j.inffus.2014.09.006","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84922943898&doi=10.1016%2fj.inffus.2014.09.006&partnerID=40&md5=dd3859163029c042919b93b48d1ac050","We propose a novel project evaluation method for non-formatted Chinese text evaluation information. First, the non-formatted Chinese text evaluation information is determined and expressed using extensible markup language and a hypertext preprocessor. Then, the evaluation problem is transformed into a multiple-criteria decision-analysis problem based on multi-granular linguistic labels, including a comprehensive evaluation score for alternatives and an evaluation criteria point score for incomplete items. Next, we propose a weighting model for the criteria based on the minimal difference between the comprehensive evaluation score and the evaluation criterion point score of decision-makers. We establish an estimation model for incomplete evaluation items with the minimal evidence distance of Dempster-Shafer theory using maximal group consistency. In addition, we calculate a weighting for the decision-makers using the similarity of the group. Finally, we present a score modification method for alternatives based on weights of the criteria and the decision-maker. We use a soft science project evaluation and selection to illustrate the application process and feasibility of the proposed method. © 2014 Elsevier B.V.","Chinese text evaluation information; Decision analysis; Multi-granular linguistic label; Multiple-criteria decision analysis; Project evaluation"
"Opinion Mining and Information Fusion: A survey","2016","Information Fusion","10.1016/j.inffus.2015.06.002","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84934960865&doi=10.1016%2fj.inffus.2015.06.002&partnerID=40&md5=e00ae814921b92e66b62915c0e781c8e","Abstract Interest in Opinion Mining has been growing steadily in the last years, mainly because of its great number of applications and the scientific challenge it poses. Accordingly, the resources and techniques to help tackle the problem are many, and most of the latest work fuses them at some stage of the process. However, this combination is usually executed without following any defined guidelines and overlooking the possibility of replicating and improving it, hence the need for a deeper understanding of the fusion process becomes apparent. Information Fusion is the field charged with researching efficient methods for transforming information from different sources into a single coherent representation, and therefore can be used to guide fusion processes in Opinion Mining. In this paper we present a survey on Information Fusion applied to Opinion Mining. We first define Opinion Mining and describe its most fundamental aspects, later explain Information Fusion and finally review several Opinion Mining studies that rely at some point on the fusion of information. © 2015 Elsevier B.V.","Information Fusion; Opinion Mining; Sentiment Analysis; Survey"
"Particle filter robot localisation through robust fusion of laser, WiFi, compass, and a network of external cameras","2016","Information Fusion","10.1016/j.inffus.2015.03.006","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84938198038&doi=10.1016%2fj.inffus.2015.03.006&partnerID=40&md5=b84fef6a1a53cb710c985e8f0dfb40e7","In this paper, we propose a multi-sensor fusion algorithm based on particle filters for mobile robot localisation in crowded environments. Our system is able to fuse the information provided by sensors placed on-board, and sensors external to the robot (off-board). We also propose a methodology for fast system deployment, map construction, and sensor calibration with a limited number of training samples. We validated our proposal experimentally with a laser range-finder, a WiFi card, a magnetic compass, and an external multi-camera network. We have carried out experiments that validate our deployment and calibration methodology. Moreover, we performed localisation experiments in controlled situations and real robot operation in social events. We obtained the best results from the fusion of all the sensors available: the precision and stability was sufficient for mobile robot localisation. No single sensor is reliable in every situation, but nevertheless our algorithm works with any subset of sensors: if a sensor is not available, the performance just degrades gracefully. © 2015 Elsevier B.V. All rights reserved.","Multi-camera network; Particle filter; Robot localisation; Sensor fusion; WiFi localisation"
"Fuzzy multiattribute group decision making based on intuitionistic fuzzy sets and evidential reasoning methodology","2016","Information Fusion","10.1016/j.inffus.2015.03.002","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84938216546&doi=10.1016%2fj.inffus.2015.03.002&partnerID=40&md5=2744063670e8be5c61ccda0206a97699","In this paper, we propose a new fuzzy multiattribute group decision making method based on intuitionistic fuzzy sets and the evidential reasoning methodology. First, the proposed method uses the evidential reasoning methodology to aggregate each decision maker's decision matrix and the weights of the attributes to get the aggregated decision matrix of each decision maker. Then, it uses the obtained aggregated decision matrices of the experts, the weights of the experts and the evidential reasoning methodology to get the aggregated intuitionistic fuzzy value of each alternative. Finally, it calculates the transformed value of the obtained intuitionistic fuzzy value of each alternative. The smaller the transformed value, the better the preference order of the alternative. The proposed method can overcome the drawbacks of the existing methods for fuzzy multiattribute group decision making in intuitionistic fuzzy environments. © 2015 Elsevier B.V. All rights reserved.","Evidential reasoning methodology; Fuzzy multiattribute group decision making; Intuitionistic fuzzy sets; Similarity measures"
"How ""oPTIMUS"" is a city in terms of energy optimization? e-SCEAF: A web based decision support tool for local authorities","2016","Information Fusion","10.1016/j.inffus.2015.10.002","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84954362207&doi=10.1016%2fj.inffus.2015.10.002&partnerID=40&md5=e19d6983722847a2d112a304d8ac01f4","Nowadays cities tend to become ""Smarter"", usually disregarding the issues of energy efficiency and sustainability. Therefore, optimizing energy use in a city remains a challenge and respective decision support systems are important to guide local authorities toward that direction. This paper provides a holistic approach presenting a Smart City Energy Assessment Framework (SCEAF) along with a specific web based decision support tool, the so-called e-SCEAF, which can provide local authorities with fruitful results for assessing the energy behavior and performance of their city. The tool merges heterogeneous information, such as clearly quantifiable energy related indicators, the related city policy context performance and the integration of smart infrastructure. This multi-source information fusion is based on the 2-tuple linguistic representation model of Herrera and Martínez. This particular model has been widely used in decision problems and was mainly selected due to the fact that it provides linguistic results that are accurate and easy to understand by the cities' local authorities. The performance, usefulness and effectiveness of the SCEAF framework and the e-SCEAF tool are tested on a real life application in three different cities, Savona (Italy), Sant Cugat del Vallès (Spain) and Zaanstad (The Netherlands). In this respect, the role of fusion methods and algorithms for merging multiple information will be evaluated in a ""real life environment"". © 2015 Elsevier B.V. All rights reserved.","2-Tuple linguistic model; Decision support system; Energy assessment framework; Information fusion; Smart cities"
"Steerable local frequency based multispectral multifocus image fusion","2015","Information Fusion","10.1016/j.inffus.2014.07.003","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027921388&doi=10.1016%2fj.inffus.2014.07.003&partnerID=40&md5=798caa83676fe4615fe2d454ff055806","Design of a focus measure and a fusion algorithm which will perform well across different spectra remains an extremely challenging task. In this work, the problem of multispectral multifocus image fusion is addressed using the phase information of the source image pixels at different orientations. We make the local frequency, the spatial derivative of the local phase of the pixels, steerable to obtain a good novel focus measure. Oriented analytic image based on the theory of steerable filters is constructed for that purpose. A multifocus fusion algorithm is proposed next using this focus measure. Comprehensive experimentations clearly demonstrate that our focus measure as well as the multifocus fusion algorithm yield promising results across the visual (VIS), the near-infrared (NIR) and the thermal (TH) spectra. © 2014 Elsevier B.V. All rights reserved.","Multifocus image fusion; Multispectral focus measure; Oriented analytic image; Steerable local frequency"
"Modeling multi-criteria objective functions using fuzzy measures","2016","Information Fusion","10.1016/j.inffus.2015.07.007","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84954368039&doi=10.1016%2fj.inffus.2015.07.007&partnerID=40&md5=5e806460c0c9f8f6c7a31860253c4168","We introduce the idea of a measure. We describe several important finite integrals useful for obtaining an average value of a collection of argument values weighted by a measure. We particularly look at the case of binary measures and show that all integrals in this case evaluate to the same value. We describe the use of measures in multi-criteria decision making as a way of expressing a decision maker's objective function in terms of collection of relevant criteria. We look at the role of an integral as a way to evaluate an alternative's overall satisfaction to their objective function in terms of its satisfaction to the individual criteria. We look at a number of special types of measure based decision objective functions. © 2015 Elsevier B.V. All rights reserved.","Decision making; Fuzzy measures; Integrals; Multi-criteria"
"Towards crowd density-aware video surveillance applications","2015","Information Fusion","10.1016/j.inffus.2014.09.005","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84922896830&doi=10.1016%2fj.inffus.2014.09.005&partnerID=40&md5=793d5f43e34253c0b74b5c4d7ae52004","Crowd density analysis is a crucial component in visual surveillance mainly for security monitoring. This paper proposes a novel approach for crowd density measure, in which local information at pixel level substitutes a global crowd level or a number of people per-frame. The proposed approach consists of generating automatic crowd density maps using local features as an observation of a probabilistic density function. It also involves a feature tracking step which excludes feature points belonging to the background. This process is favorable for the later density estimation as the influence of features irrelevant to the underlying crowd density is removed. Since the proposed crowd density conveys rich information about the local distributions of persons in the scene, we employ it as a side information to complement other tasks related to video surveillance in crowded scenes. First, since conventional detection and tracking methods are hard to be scalable to crowds, we use the proposed crowd density to enhance detection and tracking in videos of high density crowds. Second, we employ the local density together with regular motion patterns as crowd attributes for high level applications such as crowd change detection and event recognition. Third, we investigate the concept of crowd context-aware privacy protection by adjusting the obfuscation level according to the crowd density. In the experimental results, our proposed approach for crowd density estimation is evaluated on videos from different datasets, and the results demonstrate the effectiveness of feature tracks for crowd measurements. Moreover, the employment of crowd density in other applications demonstrate good performances for detection, tracking, behavior analysis, and privacy preservation. © 2014 Elsevier B.V.","Behavior analysis; Crowd density; Detection; Privacy protection; Tracking"
"Regret theory-based group decision-making with multidimensional preference and incomplete weight information","2015","Information Fusion","10.1016/j.inffus.2015.12.001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84953295831&doi=10.1016%2fj.inffus.2015.12.001&partnerID=40&md5=f2ed2f408bca22db85e54c628d303ad0","In this paper, we study fuzzy multi-attribute group decision-making (FMAGDM) problems with multidimensional preference information in the form of pairwise alternatives and incomplete weight information. We develop a new group decision-making (GDM) method considering regret aversion of the decision-makers (DMs). Firstly, we define a fuzzy regret/rejoice function and a computational formula for the perceived utility of alternative decisions. We propose a perceived utility value-based group consistency index (which reflects the total consistency) and a group inconsistency index (which represents the total inconsistency) for pairwise rankings of alternatives based on regret theory and an a priori multidimensional preference order given by the DMs. Then, under the circumstances of an unknown fuzzy ideal solution, we set up a mathematical programming model to determine the optimal attribute weights and a defuzzified fuzzy ideal solution with the idea of the Linear Programming Technique for Multidimensional Analysis of Preference (LINMAP). We compute the DMs' optimal comprehensive perceived utility values and obtain the ranking order of alternatives. Finally, we illustrate the application of the developed procedures with an air-fighter selection problem. The rationality and validity of the proposed method is demonstrated by comparing with two other GDM methods, including the fuzzy LINMAP (FLINMAP) method and the prospect theory-based GDM method. © 2015 Elsevier B.V. All rights reserved.","Consistency degree; Fuzzy multi-attribute group decision-making; Incomplete weight information; Multidimensional preference information; Regret theory"
"DOCODE 3.0 (DOcument COpy DEtector): A system for plagiarism detection by applying an information fusion process from multiple documental data sources","2016","Information Fusion","10.1016/j.inffus.2015.05.006","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84934888651&doi=10.1016%2fj.inffus.2015.05.006&partnerID=40&md5=bea262a6a0a94cb53719b9bf4586ee1a","Plagiarism refers to the act of presenting external words, thoughts, or ideas as one's own, without providing references to the sources from which they were taken. The exponential growth of different digital document sources available on the Web has facilitated the spread of this practice, making the accurate detection of it a crucial task for educational institutions. In this article, we present DOCODE 3.0, a Web system for educational institutions that performs automatic analysis of large quantities of digital documents in relation to their degree of originality. Since plagiarism is a complex problem, frequently tackled at different levels, our system applies algorithms in order to perform an information fusion process from multi data source to all these levels. These algorithms have been successfully tested in the scientific community in solving tasks like the identification of plagiarized passages and the retrieval of source candidates from the Web, among other multi data sources as digital libraries, and have proven to be very effective. We integrate these algorithms into a multi-tier, robust and scalable JEE architecture, allowing many different types of clients with different requirements to consume our services. For users, DOCODE produces a number of visualizations and reports from the different outputs to let teachers and professors gain insights on the originality of the documents they review, allowing them to discover, understand and handle possible plagiarism cases and making it easier and much faster to analyze a vast number of documents. Our experience here is so far focused on the Chilean situation and the Spanish language, offering solutions to Chilean educational institutions in any of their preferred Virtual Learning Environments. However, DOCODE can easily be adapted to increase language coverage. © 2015 Elsevier B.V. All rights reserved.","Multi documental data sources; Plagiarism detection; Text patterns information fusion"
"A general framework for image fusion based on multi-scale transform and sparse representation","2015","Information Fusion","10.1016/j.inffus.2014.09.004","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027936737&doi=10.1016%2fj.inffus.2014.09.004&partnerID=40&md5=405e3477e108de1f002c2fcd88eb1fa6","In image fusion literature, multi-scale transform (MST) and sparse representation (SR) are two most widely used signal/image representation theories. This paper presents a general image fusion framework by combining MST and SR to simultaneously overcome the inherent defects of both the MST- and SR-based fusion methods. In our fusion framework, the MST is firstly performed on each of the pre-registered source images to obtain their low-pass and high-pass coefficients. Then, the low-pass bands are merged with a SR-based fusion approach while the high-pass bands are fused using the absolute values of coefficients as activity level measurement. The fused image is finally obtained by performing the inverse MST on the merged coefficients. The advantages of the proposed fusion framework over individual MST- or SR-based method are first exhibited in detail from a theoretical point of view, and then experimentally verified with multi-focus, visible-infrared and medical image fusion. In particular, six popular multi-scale transforms, which are Laplacian pyramid (LP), ratio of low-pass pyramid (RP), discrete wavelet transform (DWT), dual-tree complex wavelet transform (DTCWT), curvelet transform (CVT) and nonsubsampled contourlet transform (NSCT), with different decomposition levels ranging from one to four are tested in our experiments. By comparing the fused results subjectively and objectively, we give the best-performed fusion method under the proposed framework for each category of image fusion. The effect of the sliding window's step length is also investigated. Furthermore, experimental results demonstrate that the proposed fusion framework can obtain state-of-the-art performance, especially for the fusion of multimodal images. © 2014 Elsevier B.V.","Image fusion; Multi-scale transform; Sparse representation"
"Ocular biometrics: A survey of modalities and fusion approaches","2015","Information Fusion","10.1016/j.inffus.2015.03.005","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84929472818&doi=10.1016%2fj.inffus.2015.03.005&partnerID=40&md5=f26ead1ff6b53b96488b9da084bc827a","Biometrics, an integral component of Identity Science, is widely used in several large-scale-county-wide projects to provide a meaningful way of recognizing individuals. Among existing modalities, ocular biometric traits such as iris, periocular, retina, and eye movement have received significant attention in the recent past. Iris recognition is used in Unique Identification Authority of India's Aadhaar Program and the United Arab Emirate's border security programs, whereas the periocular recognition is used to augment the performance of face or iris when only ocular region is present in the image. This paper reviews the research progression in these modalities. The paper discusses existing algorithms and the limitations of each of the biometric traits and information fusion approaches which combine ocular modalities with other modalities. We also propose a path forward to advance the research on ocular recognition by (i) improving the sensing technology, (ii) heterogeneous recognition for addressing interoperability, (iii) utilizing advanced machine learning algorithms for better representation and classification, (iv) developing algorithms for ocular recognition at a distance, (v) using multimodal ocular biometrics for recognition, and (vi) encouraging benchmarking standards and open-source software development. © 2015 Elsevier B.V. All rights reserved.","Information fusion; Iris; Ocular biometrics; Periocular; Retina"
"A memoryless binary query tree based Successive Scheme for passive RFID tag collision resolution","2015","Information Fusion","10.1016/j.inffus.2013.08.006","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84907398365&doi=10.1016%2fj.inffus.2013.08.006&partnerID=40&md5=b5d00dd28986372aee1b963e3d688152","The deployments of RFID system are seriously affected by collision caused by multiple tags responding simultaneously. To facilitate the resolution of collisions caused by densely distributed memoryless passive tags in successive cycles, based on the binary query tree protocol, this paper proposes a new Successive Scheme. In this scheme, the binary query tree constructed by the protocol will be reused. In the subsequent cycle, only the successful or idle binary query strings in the tree are adopted directly as the initial binary query strings, and these collision query strings in the tree are skipped. Due to the dynamic entrance and departure of tags, new nodes will be added to and abundant nodes will be removed from the tree. The performance of this Successive Scheme will be analyzed theoretically and examined with numeric simulations. Results indicate that in almost all cases, the Successive Scheme outperforms the commonly used binary query tree protocols in terms of system efficiency, message complexity, time, and time system efficiency. Especially when the tags stay stable, the system efficiency of the scheme is improved to 69.2%. Besides, simulation results also reveal that the scheme can deal efficiently with the case that the binary tag identifiers are in biased distribution. © 2013 Elsevier B.V. All rights reserved.","Binary query tree; Performance evaluation; RFID; Tag collision resolution"
"Joint patch clustering-based dictionary learning for multimodal image fusion","2016","Information Fusion","10.1016/j.inffus.2015.03.003","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84938200080&doi=10.1016%2fj.inffus.2015.03.003&partnerID=40&md5=55f473301318783d79e708f0ac8c5ca1","Constructing a good dictionary is the key to a successful image fusion technique in sparsity-based models. An efficient dictionary learning method based on a joint patch clustering is proposed for multimodal image fusion. To construct an over-complete dictionary to ensure sufficient number of useful atoms for representing a fused image, which conveys image information from different sensor modalities, all patches from different source images are clustered together with their structural similarities. For constructing a compact but informative dictionary, only a few principal components that effectively describe each of joint patch clusters are selected and combined to form the over-complete dictionary. Finally, sparse coefficients are estimated by a simultaneous orthogonal matching pursuit algorithm to represent multimodal images with the common dictionary learned by the proposed method. The experimental results with various pairs of source images validate effectiveness of the proposed method for image fusion task. © 2015 Elsevier B.V. All rights reserved.","Clustering; Dictionary learning; K-SVD; Multimodal image fusion; Sparse representation"
"Collaborative detection of repetitive behavior by multiple uncalibrated cameras","2015","Information Fusion","10.1016/j.inffus.2014.01.010","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84904808757&doi=10.1016%2fj.inffus.2014.01.010&partnerID=40&md5=63c91a156cc38ecb4c8b755e6329046e","In smart environments, the embedded sensing systems should intelligently adapt to the behavior of the users. Many interesting types of behavior are characterized by repetition of actions such as certain activities or movements. A generic methodology to detect and classify repetitions that may occur at different scales is introduced in this paper. The proposed method is called Action History Matrices (AHM). The properties of AHM for detecting repetitive movement behavior are demonstrated in analyzing four customer behavior classes in a shop environment observed by multiple uncalibrated cameras. Two different datasets, video recordings in the shop environment and motion path simulations, are created and used in the experiments. The AHM-based system achieves an accuracy of 97% with most suitable scale and naive Bayesian classifier on the single-view simulated movement data. In addition, the performance of two fusion levels and three fusion methods are compared with AHM method on the multi-view recordings. In our results, fusion at the decision-level offers consistently better accuracy than feature-level, and the coverage-based view-selection fusion method (51%) marginally outperforms the majority method. The upper limit with the recorded data for accuracy by view-selection is found to be 75%. © 2014 Elsevier B.V. All rights reserved.","Fusion; Multi-view; Repetitive behavior; Transition modeling"
"Interval Algebra - An effective means of scheduling surveillance radar networks","2015","Information Fusion","10.1016/j.inffus.2014.08.002","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027945602&doi=10.1016%2fj.inffus.2014.08.002&partnerID=40&md5=43f412fb99c30e3e27ec67fad3952e27","Interval Algebra provides an effective means to schedule surveillance radar networks, as it is a temporal ordering constraint language. Thus it provides a solution to a part of resource management, which is included in the revised Data Fusion Information Group model of information fusion. In this paper, the use of Interval Algebra to schedule mechanically steered radars to make multistatic measurements for selected targets of importance is shown. Interval Algebra provides a framework for incorporating a richer set of requirements, without requiring modifications to the underlying algorithms. The performance of Interval Algebra was compared to that of the Greedy Randomised Adaptive Search Procedure and the applicability of Interval Algebra to nimble scheduling was investigated using Monte-Carlo simulations of a binary radar system. The comparison was accomplished in terms of actual performance as well as in terms of computation time required. The performance of the algorithms was quantified by keeping track of the number of targets that could be measured simultaneously. It was found that nimble scheduling is important where the targets are moving fast enough to rapidly change the recognised surveillance picture during a scan. Two novel approaches for implementing Interval Algebra for scheduling surveillance radars are presented. It was found that adding targets on the fly and improving performance by incrementally growing the network is more efficient than pre-creating the full network. The second approach stemmed from constraint ordering. It was found that for simple constraint sets, the Interval Algebra relationship matrix reduces to a single vector of interval sets. The simulations revealed that an Interval Algebra algorithm that utilises both approaches can perform as well as the Greedy Randomised Adaptive Search Procedure with similar processing time requirements. Finally, it was found that nimble scheduling is not required for surveillance radar networks where ballistic and supersonic targets can be ignored. Nevertheless, Interval Algebra can easily be used to perform nimble scheduling with little modification and may be useful in scheduling the scans of multifunction radars. © 2014 Elsevier B.V. All rights reserved.","Interval Algebra; Multistatic radar; Process refinement; Resource management; Scheduling"
"Color-appearance-model based fusion of gray and pseudo-color images for medical applications","2014","Information Fusion","10.1016/j.inffus.2012.07.002","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84897969551&doi=10.1016%2fj.inffus.2012.07.002&partnerID=40&md5=455a811c9c473ce6eecc39e113bdf31c","Fusion of gray and pseudo-color images presents more information of biological tissues in a single image and facilitates the interpretation of multimodalities in medical practice. However, fused results are hampered by the problems of blurred details, faded color and artifact contours. This paper reports a method to solve the problems by precisely predicting the attributes of color perception using the color appearance model of International Commission on Illumination published in 2002 (CIECAM02). First, a rainbow palette is generated from the color attributes. It is uniform in lightness, and thus the valuable information of pseudo-color image can be totally sealed in its chromatic properties. Then the fusion process is carried out with the adjustment of gray image in lightness. Here, the predicted hue and saturation of pseudo-color image is merged with the predicted lightness of gray one. Therefore, information of two original images exists separately in achromatic and chromatic properties of the resulting image. Based on different color spaces (CSs) and color appearance models (CAMs), the color aggregations available for displaying fused images are presented and compared. The aggregation based on the CIECAM02 exhibited more uniform variation in lightness and hue. Fused results of simulated lesion and breast phantom manifested the compromise between the scope of gray and the perception of color. Furthermore, in the quantitative experiment on 49 sets of simulated ultrasound and strain images, the visual information fidelity (VIF) was applied to assess the similarity between the result and its sources. It revealed the superiority of the proposed method over the traditional ones including CSs-based methods, transparency technique, alternating display technique, frequency encoding methods, and maximum-selection-rule based rules. The results of two clinical cases demonstrated its practicality in medical applications. Besides, its feasibility in fusing two high-resolution structural images was preliminarily approved based on the simulated MRI data. © 2012 Elsevier B.V. All rights reserved.","Biomedical image fusion; CIECAM02; Color appearance model (CAM); Magnetic resonance imaging (MRI); Rainbow palette; Ultrasound"
"An information fusion based method for liver classification using texture analysis of ultrasound images","2014","Information Fusion","10.1016/j.inffus.2013.05.007","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84898010508&doi=10.1016%2fj.inffus.2013.05.007&partnerID=40&md5=7428450ad5148a378e898ae50d098420","This paper presents a method for classification of liver ultrasound images based on texture analysis. The proposed method uses a set of seven texture features having high discriminative power which can be used by radiologists to classify the liver. Feature extraction is carried out using the following texture models: Spatial Gray Level Co-occurrence Matrix, Gray Level Difference Statistics, First order Statistics, Fourier Power Spectrum, Statistical Feature Matrix, Law's Texture Energy Measures and Fractal Features. Based upon the results of Linear Discriminative Analysis (LDA) followed by box-plot analysis and Pearson's correlation coefficient, 7 best features from a set of 35 features are selected. These selected features are then fused using a linear classifier. The novelty of the proposed method is that, it combines the best features from different texture domains along with their weights and 'weighted z-score' values. Subsequently, these values are used to compute a discriminative index for liver classification. The results show that this method has overall classification accuracy of 95% and low computational complexity. © 2013 Elsevier B.V. All rights reserved.","Discriminative index; Information fusion; Medical ultrasound imaging; Texture analysis; Tissue characterization"
"Medical image fusion using multi-level local extrema","2014","Information Fusion","10.1016/j.inffus.2013.01.001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84897997749&doi=10.1016%2fj.inffus.2013.01.001&partnerID=40&md5=8abab00ddbaac845544750efe25616d0","The fusion of data for medical imaging has become a central issue in such biomedical applications as image-guided surgery and radiotherapy. The multi-level local extrema (MLE) representation has been shown to have many advantages over conventional image representation methods. In this paper, we propose a new fusion algorithm for multi-modal medical images based on MLE. Our method enables the decomposition of input images into coarse and detailed layers in the MLE schema, and utilizes local energy and contrast fusion rules for coefficient selection in the different layers. This preserves more detail in the source images and further improves the quality of the fused image. The final fused image is obtained from the superposition of selected coefficients in the coarse and detailed layers. We illustrate the performance of the proposed method using three groups of medical images from different sources as our experimental subjects. We also compare our method with other techniques using cumulative mutual information, the objective image fusion performance measure, spatial frequency, and a blind quality index. Experimental results show that our method achieves a superior performance in both subjective and objective assessment criteria. © 2013 Elsevier B.V. All rights reserved.","Medical image fusion; Multi-level local extrema; Quality assessment"
"Fuzzy m-ary adjacency relations in social network analysis: Optimization and consensus evaluation","2014","Information Fusion","10.1016/j.inffus.2011.11.001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84888294238&doi=10.1016%2fj.inffus.2011.11.001&partnerID=40&md5=9cd8955d76fe9874c01773d04236c00c","The main contribution of this paper consists in extending the 'soft' consensus paradigm of fuzzy group decision making developed under the framework of numerical fuzzy preferences. We address the problem of consensus evaluation by endogenously computing the importance of the decision makers in terms of their influence strength in the network. To this aim, we start from centrality measure and combine it with the fuzzy m-ary adjacency relation approach. In this way, we introduce a flexible consensus measure that takes into account the influence strength of the decision makers according to their eigenvector centrality. Moreover, we propose an optimization problem which determines the maximum number of the most important decision makers that share a fixed desirable consensus level. © 2011 Elsevier B.V. All rights reserved.","Consensus; Eigenvector centrality; Fuzzy adjacency relations; Group decision making; Social network analysis"
"Multi-modal medical image fusion using the inter-scale and intra-scale dependencies between image shift-invariant shearlet coefficients","2014","Information Fusion","10.1016/j.inffus.2012.03.002","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84897979082&doi=10.1016%2fj.inffus.2012.03.002&partnerID=40&md5=7e3a73f784b772c9448eadf941ed502b","For the quality of the fused outcome is determined by the amount of the information captured from the source images, thus, a multi-modal medical image fusion method is developed in the shift-invariant shearlet transform (SIST) domain. The two-state Hidden Markov Tree (HMT) model is extended into the SIST domain to describe the dependent relationships of the SIST coefficients of the cross-scale and inter-subbands. Base on the model, we explain why the conventional Average-Maximum fusion scheme is not the best rule for medical image fusion, and therefore a new scheme is developed, where the probability density function and standard deviation of the SIST coefficients are employed to calculate the fused coefficients. Finally, the fused image is obtained by directly applying the inverse SIST. Integrating the SIST and the HMT model, more spatial feature information of the singularities and more functional information contents can be preserved and transferred into the fused results. Visual and statistical analyses demonstrate that the fusion quality can be significantly improved over that of five typical methods in terms of entropy and mutual information, edge information, standard deviation, peak signal to noise and structural similarity. Besides, color distortion can be suppressed to a great extent, providing a better visual sense. © 2013 Elsevier B.V. All rights reserved.","Hidden Markov Tree model; Image fusion; Medical image; Shearlet transform; Shift-invariance"
"Modeling the impact of observation conditions on localization systems","2014","Information Fusion","10.1016/j.inffus.2012.09.002","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84885952249&doi=10.1016%2fj.inffus.2012.09.002&partnerID=40&md5=6cbe3a63d3e7d0d197753ca08b51cffa","In various applications, sensor fusion has demonstrated success as means to enhance a system performance in perceiving its environment. By combing observations of different sensors, the system is able to achieve improved sensing accuracy, and potentially, expanded sensing capabilities. However, the observation conditions in the surrounding of any multi-sensor system have a considerable impact on the performance of the system. This impact can be hard to mitigate if the observation conditions are stochastic in nature. Therefore, for any sensor fusion strategy to achieve reliable and robust performance it must possess a capability to assess the quality of the observation conditions in its surrounding, and ultimately, the quality of its decisions, as a function of these conditions. One typical application where the impact of the observation conditions can cause sever deterioration of the sensing performance is vehicle localization. It is typical in this application that location measurements obtained from multiple sensors (e.g., GPS, Vision, Inertial, etc.) are combined together to compute accurate vehicle location. However, such improved accuracy can only be attained under nominal observation conditions. Therefore, real-time awareness of the observation conditions around the vehicle position is pivotal for the multi-sensor system to achieve effective fusion performance. In this paper, a Markovian model is proposed to capture the impact of observation conditions on a sensor's localization performance and to consequently determine a reliability index with respect to the localization accuracy claimed by the sensor. The proposed model is implemented on two localization techniques: single-sensor localization and multi-sensor localization. A number of experiments are conducted to determine the different levels of localization accuracy that can be achieved by each technique under a wide range of observation conditions. The proposed reliability model is tested in a variety of real-life and simulated observation conditions scenarios. It is evident from the experimental results that the proposed model is able to estimate the reliability of location estimates produced by either one of the localization techniques. The paper discusses how such reliability model can benefit multi-sensor systems. © 2012 Elsevier B.V. All rights reserved.","Global Positioning System (GPS); Localization accuracy assessment; Reliability assessment; Sensor fusion; Uncertainty modeling; Vehicle localization"
"Fault detection in multi-sensor networks based on multivariate time-series models and orthogonal transformations","2014","Information Fusion","10.1016/j.inffus.2014.03.006","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84901627230&doi=10.1016%2fj.inffus.2014.03.006&partnerID=40&md5=e2e8aa6d572bde6be41141e78a985c31","We introduce the usage of multivariate orthogonal space transformations and vectorized time-series models in combination with data-driven system identification models to achieve an enhanced performance of residual-based fault detection in condition monitoring systems equipped with multi-sensor networks. Neither time-consuming annotated samples nor fault patterns/models need to be available, as our approach is solely based on on-line recorded data streams. The system identification step acts as a fusion operation by searching for relations and dependencies between sensor channels measuring the state of system variables. We therefore apply three different vectorized time-series variants: (i) non-linear finite impulse response models (NFIR) relying only on the lagged input variables, (ii) non-linear output error models (NOE), also including the lags of the own predictions and (iii) non-linear Box-Jenkins models (NBJ) which include the lags of the predictions errors as well. The use of multivariate orthogonal space transformations allows to produce more compact and accurate models due to an integrated dimensionality (noise) reduction step. Fault detection is conducted based on finding anomalies (untypical occurrences) in the temporal residual signal in incremental manner. Our experimental results achieved on four real-world condition monitoring scenarios employing multi-sensor network systems demonstrate that the Receiver Operating Characteristic (ROC) curves are improved over those ones achieved with native static models (w/o lags, w/o transformations) by about 20-30%. © 2014 Elsevier B.V. All rights reserved.","Multivariate orthogonal space transformations; On-line incremental residual analysis; Residual-based fault detection; System identification; Vectorized time-series models (types of)"
"Ensembles of decision trees based on imprecise probabilities and uncertainty measures","2013","Information Fusion","10.1016/j.inffus.2012.03.003","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84887815878&doi=10.1016%2fj.inffus.2012.03.003&partnerID=40&md5=19417e4a7fa9d3f898b090dc4601eb0c","In this paper, we present an experimental comparison among different strategies for combining decision trees built by means of imprecise probabilities and uncertainty measures. It has been proven that the combination or fusion of the information obtained from several classifiers can improve the final process of the classification. We use previously developed schemes, known as Bagging and Boosting, along with a new one based on the variation of the root node via the information rank of each feature of the class variable. To this end, we applied two different approaches to deal with missing data and continuous variables. We use a set of tests on the performance of the methods analyzed here, to show that, with the appropriate approach, the Boosting scheme constitutes an excellent way to combine this type of decision tree. It should be noted that it provides good results, even compared with a standard Random Forest classifier, a successful procedure very commonly used in the literature. © 2012 Elsevier B.V. All rights reserved.","Credal sets; Decision trees; Ensemble methods; Imprecise probabilities; Supervised classification; Uncertainty measures"
"Estimation of a semi-physical GLBE model using dual EnKF learning algorithm coupled with a sensor network design strategy: Application to air field monitoring","2013","Information Fusion","10.1016/j.inffus.2013.03.001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84876109575&doi=10.1016%2fj.inffus.2013.03.001&partnerID=40&md5=0e04c6876adba89e6849934adb2d9b79","In this paper, we present the fusion of two complementary approaches for modeling and monitoring the spatio-temporal behavior of a fluid flow system. We also propose a mobile sensor deployment strategy to produce the most accurate estimate of the true system state. For this purpose, deterministic and statistical information was used. We adopted a filtering method based on a semi-physical model which derives from a fluid flow numerical model known as lattice Boltzmann model (LBM). The a priori physical knowledge was introduced by the Navier-Stokes equations which were discretized by the lattice Boltzmann approach. Moreover, its multiple-relaxation-time (MRT) variant not only improved the stability, but also enabled the introduction of additional degrees of freedom to be estimated like the synaptic weights of a neural network. The statistical knowledge was then introduced into the model by performing a sequential learning of these parameters and an estimation of the speed field of the fluid flow starting from measurements. The low spatial density of measurements, the large amount of data inherent to environmental issues and the nonlinearity of the generalized lattice Boltzmann equations (GLBEs) enjoined us to use the ensemble Kalman filter (EnKF) for the recursive estimation procedure. A dual state-parameter estimation which results in a significantly reduced computation time was used by combining two filters consecutively activated in the same iteration. Finally, we proposed to complete the lack of spatial information of the sparse-observation network by adding a mobile sensor, which was routed to the location where the cell-by-cell output estimation error was the highest. Experimental results in the context of the standard lid-driven cavity problem revealed the presence of few zones of interest, where fixed sensors can be deployed to increase performances in terms of convergence speed and estimation quality. Finally, the study showed the feasibility of introducing some additional parameters which act as degrees of freedom, to perform large-eddy simulation of turbulent flows without numerical instabilities.","Air field monitoring; Grey-box modeling; Model fusion; Sensor network design"
"Spatio-spectral fusion of satellite images based on dictionary-pair learning","2014","Information Fusion","10.1016/j.inffus.2013.08.005","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84892364431&doi=10.1016%2fj.inffus.2013.08.005&partnerID=40&md5=d98757c971daea1695992a53e8d32268","This paper proposes a novel spatial and spectral fusion method for satellite multispectral and hyperspectral (or high-spectral) images based on dictionary-pair learning. By combining the spectral information from sensors with low spatial resolution but high spectral resolution (LSHS) and the spatial information from sensors with high spatial resolution but low spectral resolution (HSLS), this method aims to generate fused data with both high spatial and spectral resolution. Based on the sparse non-negative matrix factorization technique, this method first extracts spectral bases of LSHS and HSLS images by making full use of the rich spectral information in LSHS data. The spectral bases of these two categories data then formulate a dictionary-pair due to their correspondence in representing each pixel spectra of LSHS data and HSLS data, respectively. Subsequently, the LSHS image is spatial unmixed by representing the HSLS image with respect to the corresponding learned dictionary to derive its representation coefficients. Combining the spectral bases of LSHS data and the representation coefficients of HSLS data, fused data are finally derived which are characterized by the spectral resolution of LSHS data and the spatial resolution of HSLS data. The experiments are carried out by comparing the proposed method with two representative methods on both simulation data and actual satellite images, including the fusion of Landsat/ETM+ and Aqua/MODIS data and the fusion of EO-1/Hyperion and SPOT5/HRG multispectral images. By visually comparing the fusion results and quantitatively evaluating them in term of several measurement indices, it can be concluded that the proposed method is effective in preserving both the spectral information and spatial details and performs better than the comparison approaches. © 2013 Elsevier B.V. All rights reserved.","Dictionary-pair learning; High spatial resolution; High spectral resolution; Sparse non-negative matrix factorization; Spatio-spectral fusion"
"Group decision making with multi-attribute interval data","2013","Information Fusion","10.1016/j.inffus.2013.01.003","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84887820666&doi=10.1016%2fj.inffus.2013.01.003&partnerID=40&md5=6b90b67f1fa839a99fe11de477796904","The aim of this paper is to present a group decision making methodology, in which the decision information, including the attribute values, attribute weights and weights of decision makers, is expressed in interval data. An extended TOPSIS technique is twice used in the proposed method, which is first used to determine the weights of decision makers, and second used to rank the preference order of alternatives. There is no aggregation of decision information in decision process, except that the ideal decisions as auxiliary decision tools are used in decision process. We give a comparison with another method for group decision making to show the technical advance of reported method. Additionally, we also give a real life application for supplier selection and a discussion to test the effectiveness and practical implications of the proposed method. © 2013 Elsevier B.V. All rights reserved.","Extended topsis technique; Interval number; Multi-attribute group decision making; Supplier selection; Weight of decision maker"
"Multi-scale weighted gradient-based fusion for multi-focus images","2014","Information Fusion","10.1016/j.inffus.2013.11.005","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84901609240&doi=10.1016%2fj.inffus.2013.11.005&partnerID=40&md5=a01f4f1c992196944fc1db5cf00ac53f","Anisotropic blur and mis-registration frequently happen in multi-focus images due to object or camera motion. These factors severely degrade the fusion quality of multi-focus images. In this paper, we present a novel multi-scale weighted gradient-based fusion method to solve this problem. This method is based on a multi-scale structure-based focus measure that reflects the sharpness of edge and corner structures at multiple scales. This focus measure is derived based on an image structure saliency and introduced to determine the gradient weights in the proposed gradient-based fusion method for multi-focus images with a novel multi-scale approach. In particular, we focus on a two-scale scheme, i.e., a large scale and a small scale, to effectively solve the fusion problems raised by anisotropic blur and mis-registration. The large-scale structure-based focus measure is used first to attenuate the impacts of anisotropic blur and mis-registration on the focused region detection, and then the gradient weights near the boundaries of the focused regions are carefully determined by applying the small-scale focus measure. Experimental results clearly demonstrate that the proposed method outperforms the conventional fusion methods in the presence of anisotropic blur and mis-registration. © 2014 Elsevier B.V. All rights reserved.","Anisotropic blur; Focus measure; Gradient-based fusion; Mis-registration; Multi-focus images"
"A multi-temporal multi-sensor circular fusion filter","2014","Information Fusion","10.1016/j.inffus.2013.05.012","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84892368536&doi=10.1016%2fj.inffus.2013.05.012&partnerID=40&md5=ee3f90046bc72c21e60af41e572b3cbc","In many multi-sensor applications, noisy angular data are modeled as random variables which are commonly defined on the linear domain while the ""classical fusion and filtering"" are used to process their realizations. Weighted sum and Kalman filter are indeed the common approaches used to fuse and filter the data in most cases. These approaches are limited by the periodic nature of the angular data. In this article, the error of angular measurements is assumed to follow a von Mises distribution. Under this assumption, a multi-sensor fusion operator is proposed. Under the same assumption, a a magnetometer and a gyroscope. © 2013 Elsevier B.V. All rights reserved.","Bayesian estimation; Circular statistic; Fusion"
"Fuzzy clustering based ET image fusion","2013","Information Fusion","10.1016/j.inffus.2012.09.004","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84887826525&doi=10.1016%2fj.inffus.2012.09.004&partnerID=40&md5=b2497b3844315039f1303fc31cb2bf02","Electrical tomography (ET) is a technique to visually reconstruct inhomogeneous medium distributions by injecting currents or voltages at the boundary of the medium and measuring the resulted changes in the investigated fields. The ET techniques have been widely used in industrial practices owing to the low cost, rapid response time, non-existent radiation exposure, and non-intrusive characteristics comparing to other tomographic modalities. However, the spatial resolution of ET images using single modality or single-driven patterns (adjacent pattern vs. opposite pattern for imaging reconstruction) is low, which may limit its applications. In this research, the application of fuzzy clustering based fusion techniques for ET imaging is studied. Both multi-modality imaging and multi-driven patterns are of interest. Specifically, two modality images are fused: Electrical Capacitance Tomography (ECT), which performs well for imaging material of large permittivity difference, and Electrical Resistance Tomography (ERT), which is suited for imaging materials having large conductivity differences. The research also explores the fusion of adjacent and opposite patterns for either ECT or ERT modalities. Experiments show that the proposed method can construct high quality ET images by discovering the strong complementary natures of the modalities and/or driven patterns. © 2012 Elsevier B.V. All rights reserved.","Driven pattern; Electrical tomography; Image fusion; Modality"
"A hybrid model through the fusion of type-2 fuzzy logic systems and extreme learning machines for modelling permeability prediction","2014","Information Fusion","10.1016/j.inffus.2012.06.001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84887049157&doi=10.1016%2fj.inffus.2012.06.001&partnerID=40&md5=a9e76c35864cabcc80ade64b53450897","Extreme learning machines (ELM), as a learning tool, have gained popularity due to its unique characteristics and performance. However, the generalisation capability of ELM often depends on the nature of the dataset, particularly on whether uncertainty is present in the dataset or not. In order to reduce the effects of uncertainties in ELM prediction and improve its generalisation ability, this paper proposes a hybrid system through a combination of type-2 fuzzy logic systems (type-2 FLS) and ELM; thereafter the hybrid system was applied to model permeability of carbonate reservoir. Type-2 FLS has been chosen to be a precursor to ELM in order to better handle uncertainties existing in datasets beyond the capability of type-1 fuzzy logic systems. The type-2 FLS is used to first handle uncertainties in reservoir data so that its final output is then passed to the ELM for training and then final prediction is done using the unseen testing dataset. Comparative studies have been carried out to compare the performance of the proposed T2-ELM hybrid system with each of the constituent type-2 FLS and ELM, and also artificial neural network (ANN) and support Vector machines (SVM) using five different industrial reservoir data. Empirical results show that the proposed T2-ELM hybrid system outperformed each of type-2 FLS and ELM, as the two constituent models, in all cases, with the improvement made to the ELM performance far higher against that of type-2 FLS that had a closer performance to the hybrid since it is already noted for being able to model uncertainties. The proposed hybrid also outperformed ANN and SVM models considered. © 2012 Elsevier B.V. All rights reserved.","Extreme learning machines (ELM); Feedforward neural networks; Hybrid intelligent systems; Permeability; Type-2 fuzzy logic systems; Well logs"
"Reply to the comment on ""some hybrid weighted averaging operators and their application to decision making""","2014","Information Fusion","10.1016/j.inffus.2012.03.005","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84887083005&doi=10.1016%2fj.inffus.2012.03.005&partnerID=40&md5=7a81e327f0244e7159aeb79df509b708","In reply to Weize Wang, the difference between the HWAA operator and the IP-OWA operator is interpreted. Based on the order preserving of arguments, the monotonicity of the HWQA operator and C-HWQA operator is defined and proved in detail, respectively. © 2012 Elsevier B.V. All rights reserved.","Aggregation operator; Monotonicity; Order preserving"
"A Bayesian approach to visualization-oriented hyperspectral image fusion","2013","Information Fusion","10.1016/j.inffus.2013.02.007","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84876375258&doi=10.1016%2fj.inffus.2013.02.007&partnerID=40&md5=78e044fca21113688f7237f414d12843","In this paper, we propose a Bayesian approach towards fusion of hyperspectral images for the purpose of efficient visualization. Fusion has been posed as an estimation problem where the observed hyperspectral bands have been related to the fused image through a first order model of image formation. The parameters of the model indicate the quality of the pixel captured locally. As visualization is our primary aim of fusion, we expect higher contribution of the ""visually important"" pixels towards the final fused image. We propose a two-step framework for fusion of hyperspectral image, where the first step identifies the quality of each pixel of the data based on some of the local quality measures of the hyperspectral data. Subsequently, we formulate the problem of the estimation of the fused image in a MAP framework. We incorporate the total variation (TV) norm-based prior which preserves the sharp discontinuities in the fused image. The fused images, thus, appear sharp and natural where the edges and boundaries have been retained. We have provided visual as well as quantitative results to substantiate the effectiveness of the proposed technique. © 2013 Elsevier B.V. All rights reserved.","Hyperspectral image fusion; MAP framework; Total variation"
"Medical image fusion: A survey of the state of the art","2014","Information Fusion","10.1016/j.inffus.2013.12.002","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84897986730&doi=10.1016%2fj.inffus.2013.12.002&partnerID=40&md5=20250b9d262ea59d1780e4de271d67ad","Medical image fusion is the process of registering and combining multiple images from single or multiple imaging modalities to improve the imaging quality and reduce randomness and redundancy in order to increase the clinical applicability of medical images for diagnosis and assessment of medical problems. Multi-modal medical image fusion algorithms and devices have shown notable achievements in improving clinical accuracy of decisions based on medical images. This review article provides a factual listing of methods and summarizes the broad scientific challenges faced in the field of medical image fusion. We characterize the medical image fusion research based on (1) the widely used image fusion methods, (2) imaging modalities, and (3) imaging of organs that are under study. This review concludes that even though there exists several open ended technological and scientific challenges, the fusion of medical images has proved to be useful for advancing the clinical reliability of using medical imaging for medical diagnostics and analysis, and is a scientific discipline that has the potential to significantly grow in the coming years. © 2013 Elsevier B.V. All rights reserved.","Diagnostics; Image fusion; Medical image analysis; Medical imaging"
"Retinal image quality assessment using generic image quality indicators","2014","Information Fusion","10.1016/j.inffus.2012.08.001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84897986454&doi=10.1016%2fj.inffus.2012.08.001&partnerID=40&md5=05b651bb152482cd66dc297d8890dc1d","A retinal image gradability assessment algorithm based on the fusion of generic image quality indicators is introduced. Four features quantifying image colour, focus, contrast and illumination are computed using novel image processing techniques. These quality indicators are also combined and classified to evaluate the image suitability for diagnostic purposes. The algorithm performance is thoroughly appraised through comparison of the automatic classification results of 2032 retinal images from proprietary, DRIVE, Messidor, ROC and STARE datasets with human made classification, revealing a sensitivity of 99.76% and a specificity of 99.49%. The algorithm computational complexity and sensitivity to image noise and resolution were also experimentally quantified demonstrating very good performance and confirming the usability of the solution in an ambulatory application environment. © 2012 Elsevier B.V. All rights reserved.","Colour measure; Contrast measure; Focus measure; Illumination measure; Retinal image quality"
"Context-based multi-level information fusion for harbor surveillance","2015","Information Fusion","10.1016/j.inffus.2014.01.011","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84904793304&doi=10.1016%2fj.inffus.2014.01.011&partnerID=40&md5=f14b7496db4ee2392d217d5c9591756a","Harbor surveillance is a critical and challenging part of maritime security procedures. Building a surveillance picture to support decision makers in detection of potential threats requires the integration of data and information coming from heterogeneous sources. Context plays a key role in achieving this task by providing expectations, constraints and additional information for inference about the items of interest. This paper proposes a fusion system for context-based situation and threat assessment with application to harbor surveillance. The architecture of the system is organized in two levels. The lowest level uses an ontological model to formally represent input data and to classify harbor objects and basic situations by deductive reasoning according to the harbor regulations. The higher level applies Belief-based Argumentation to evaluate the threat posed by suspicious vessels. The functioning of the system is illustrated with several examples that reproduce common harbor scenarios. © 2014 Elsevier B.V. All rights reserved.","Belief argumentation system; Context; Higher-level fusion; Maritime surveillance; Ontologies"
"Space-variant blur deconvolution and denoising in the dual exposure problem","2013","Information Fusion","10.1016/j.inffus.2012.08.003","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84887818192&doi=10.1016%2fj.inffus.2012.08.003&partnerID=40&md5=57a8b39a770ef5071d05e746eb8bf98b","In this paper we propose a space-variant blur estimation and effective denoising/deconvolution method for combining a long exposure blurry image with a short exposure noisy one. The blur in the long exposure shot is mainly caused by camera shake or object motion, and the noise in the underexposed image is introduced by the gain factor applied to the sensor when the ISO is set to an high value. Due to the space variant degradation, the image pair is divided into overlapping patches for processing. The main idea in the deconvolution algorithm is to incorporate a combination of prior image models into a spatially-varying deblurring/denoising framework which is applied to each patch. The method employs a kernel and parameter estimation method to choose between denoising or deblurring each patch. Experiments on both synthetic and real images are provided to validate the proposed approach. © 2012 Elsevier B.V.","Blind deconvolution; Image denoising; Image fusion; Low light imaging; Motion blur"
"An approach to implement data fusion techniques in wireless sensor networks using genetic machine learning algorithms","2014","Information Fusion","10.1016/j.inffus.2013.05.003","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84885953963&doi=10.1016%2fj.inffus.2013.05.003&partnerID=40&md5=0ce979aab09e34dad09d104d739845da","Wireless Sensor Networks (WSNs) can be used to monitor hazardous and inaccessible areas. In these situations, the power supply (e.g. battery) of each node cannot be easily replaced. One solution to deal with the limited capacity of current power supplies is to deploy a large number of sensor nodes, since the lifetime and dependability of the network will increase through cooperation among nodes. Applications on WSN may also have other concerns, such as meeting temporal deadlines on message transmissions and maximizing the quality of information. Data fusion is a well-known technique that can be useful for the enhancement of data quality and for the maximization of WSN lifetime. In this paper, we propose an approach that allows the implementation of parallel data fusion techniques in IEEE 802.15.4 networks. One of the main advantages of the proposed approach is that it enables a trade-off between different user-defined metrics through the use of a genetic machine learning algorithm. Simulations and field experiments performed in different communication scenarios highlight significant improvements when compared with, for instance, the Gur Game approach or the implementation of conventional periodic communication techniques over IEEE 802.15.4 networks. © 2013 Elsevier Ltd. All rights reserved.","Autonomic computing; Classifier systems; Partial data fusion"
"Multi-metric learning for multi-sensor fusion based classification","2013","Information Fusion","10.1016/j.inffus.2012.05.002","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84887818232&doi=10.1016%2fj.inffus.2012.05.002&partnerID=40&md5=764b57e0e30f8281787c1caba81390c4","In this paper, we propose a multiple-metric learning algorithm to learn jointly a set of optimal homogenous/ heterogeneous metrics in order to fuse the data collected from multiple sensors for joint classification. The learned metrics have the potential to perform better than the conventional Euclidean metric for classification. Moreover, in the case of heterogenous sensors, the learned multiple metrics can be quite different, which are adapted to each type of sensor. By learning the multiple metrics jointly within a single unified optimization framework, we can learn better metrics to fuse the multi-sensor data for a joint classification. Furthermore, we also exploit multi-metric learning in a kernel induced feature space to capture the non-linearity in the original feature space via kernel mapping. © 2012 Elsevier B.V. All rights reserved.","Joint classification; Metric learning; Multi-sensor fusion"
"Mixture of feature specified experts","2014","Information Fusion","10.1016/j.inffus.2014.02.006","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84901624374&doi=10.1016%2fj.inffus.2014.02.006&partnerID=40&md5=526f88b160d00ee0fc940a71d7caafa2","Mixture of Experts is one of the most popular ensemble methods in pattern recognition systems. Although, diversity between the experts is one of the necessary conditions for the success of combining methods, ensemble systems based on Mixture of Experts suffer from the lack of enough diversity among the experts caused by unfavorable initial parameters. In the conventional Mixture of Experts, each expert receives the whole feature space. To increase diversity among the experts, solve the structural issues of Mixture of Experts such as zero coefficient problem, and improve efficiency in the system, we intend to propose a model, entitled Mixture of Feature Specified Experts, in which each expert gets a different subset of the original feature set. To this end, we first select a set of feature subsets which lead to a set of diverse and efficient classifiers. Then the initial parameters are infused to the system with training classifiers on the selected feature subsets. Finally, we train the expert and the gating networks using the learning rule of classical Mixture of Experts to organize collaboration between the members of system and aiding the gating network to find the best partitioning of the problem space. To evaluate our proposed method, we have used six datasets from the UCI repository. In addition the generalization capability of our proposed method is considered on real-world database of EEG based Brain-Computer Interface. The performance of our method is evaluated with various appraisal criteria and significant improvement in recognition rate of our proposed method is indicated in all practical tests. © 2014 Elsevier Ltd. All rights reserved.","BCI; Combining classifiers; Diversity; EEG; Mixture of experts"
"Revised HLMS: A useful algorithm for fuzzy measure identification","2013","Information Fusion","10.1016/j.inffus.2013.01.002","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84887817268&doi=10.1016%2fj.inffus.2013.01.002&partnerID=40&md5=66293615b1946117b7b2783f73b1b0c5","An important limitation of fuzzy integrals for information fusion is the exponential growth of coefficients for an increasing number of information sources. To overcome this problem a variety of fuzzy measure identification algorithms has been proposed. HLMS is a simple gradient-based algorithm for fuzzy measure identification which suffers from some convergence problems. In this paper, two proposals for HLMS convergence improvement are presented, a modified formula for coefficients update and new policy for monotonicity check. A comprehensive experimental work shows that these proposals indeed contribute to HLMS convergence, accuracy and robustness. ©2013 Elsevier B.V. All rights reserved.","Choquet integral; Convergence; Gradient descent; Multicriteria"
"A novel distance estimation approach for 3D localization in wireless sensor network using multi dimensional scaling","2014","Information Fusion","10.1016/j.inffus.2013.06.003","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84885958896&doi=10.1016%2fj.inffus.2013.06.003&partnerID=40&md5=7a6964d77f5231b58a3d7235f53774ee","Node localization is very important in Wireless Sensor Network (WSN) and distance estimation between pairs of nodes is the prerequisite for localization and thus the applicability of the reported events. The paper proposes a novel distance estimation algorithm to estimate distances of each node to every other node in the network. The main contribution of the paper is the definition of a dissimilarity matrix representing the distance of each node to every other node in the network. MDS based localization algorithm is used to determine coordinates of the node in a local coordinate system and Helmert Transformation is used to convert the local coordinates of the node into a global coordinate system. The effect of various parameters affecting the performance of proposed algorithm is also presented in the paper. Finally, the efficiency of the proposed algorithm is established through the simulation results. © 2013 Elsevier B.V. All rights reserved.","3D space; Distance matrix; Localization; MDS; WSN"
"On query processing in wireless sensor networks using classes of quality of queries","2014","Information Fusion","10.1016/j.inffus.2012.01.010","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84885957962&doi=10.1016%2fj.inffus.2012.01.010&partnerID=40&md5=ed271b623d52529922a730d5750ca034","This paper introduces the concept of quality of queries (QoQs) towards a more adaptive query processing in wireless sensor networks (WSNs). This approach aims at the intelligent consumption of the limited resources (energy and memory) available in these networks while still delivering a reasonable level of data quality as expected by client applications. In a nutshell, the concept of QoQ stipulates that the results of different queries injected into the same WSN can be tailored according to different criteria, in particular the levels of query result accuracy and energy consumption. For this purpose, four classes of QoQ (CoQoQ) are specified having in mind distinct requirements in terms of these criteria. To allow the implementation of these classes in a real WSN setting, a new novelty-detection based algorithm, referred to as AdaQuali (which stands for ""ADAptive QUALIty control for query processing in WSN""), is also proposed in a manner as to control the sensor node activities through the dynamic adjustment of their rates of data collection and transmission. In order to validate the novel approach, simulations with a prototype implemented in Sinalgo have been conducted over real temperature data. The results achieved evidence the suitability of the proposal and point to gains of up to 66.76%, for different CoQoQ, in terms of reduction in energy consumption. © 2013 Elsevier Ltd. All rights reserved.","Energy consumption; In-network query processing; Novelty detection; Quality of queries; Wireless sensor networks"
"A switch-mode information fusion filter based on ISRUKF for autonomous navigation of spacecraft","2014","Information Fusion","10.1016/j.inffus.2013.04.012","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84892373336&doi=10.1016%2fj.inffus.2013.04.012&partnerID=40&md5=37f40d0743c3634cb699f9619d09c485","Aiming at the problem of loss of accuracy using extended Kalman filter (EKF) in case of orbit maneuver, this paper proposes a novel information fusion filtering algorithm-iterated square root unscented Kalman filter (ISRUKF), and then designs a switch-mode information fusion filter based on ISRUKF and extended Kalman filter (EKF). This method combines navigation sensors' geocentric vector and geocentric distance with starlight angular distance, which efficiently improves the reliability of autonomous navigation. On this basis, the method deduced measurement function of information fusion. With a semi-physical simulation to verify the proposed method, the simulation results for stably running and orbital maneuvering spacecraft show that the switch-mode information fusion filter can reduce the complexity of the algorithm and ensure the accuracy of the estimation. Thus, the proposed switch-mode filter is very suitable for spacecraft autonomous navigation system and other strong nonlinear state estimation fields. © 2013 Elsevier B.V. All rights reserved.","Autonomous navigation; Iterated square root unscented Kalman filter; Switch-mode information fusion filter"
"A partial binary tree DEA-DA cyclic classification model for decision makers in complex multi-attribute large-group interval-valued intuitionistic fuzzy decision-making problems","2014","Information Fusion","10.1016/j.inffus.2013.06.004","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84892373055&doi=10.1016%2fj.inffus.2013.06.004&partnerID=40&md5=4e89b4e83d3078f3de64f1193558cf55","This paper proposes the idea of combining ""interest groups"" with the practical decision information to classify the decision makers (DMs) in complex multi-attribute large-group decision-making (CMALGDM) problems in interval-valued intuitionistic fuzzy (IVIF) environment. It constructs a partial binary tree DEA-DA cyclic classification model to achieve the multiple groups' classification of DMs. Not only does this method provide references for the classification of DMs when the decision information is known, but it also lays foundations for DMs' effective weight determination and the aggregation of decision information. First, this paper normalizes all of the cost attributes into benefit attributes to avoid the wrong decision result. Second, it employs the C-OWA operator to transform IVIF number (IVIFN) samples into single-valued samples. With respect to this transformation, this paper provides the corresponding BUM functions of DMs according to their risk attitudes; therefore, the preference information of DMs can be more objectively aggregated. Third, this paper adopts the partial binary tree DEA-DA cyclic classification model to present an accurate classification of DMs. Thus, for each interest group, group members with different interest preferences can be distinguished and distributed to the appropriate groups. Finally, to show the feasibility and validity of the model, we give an illustrative example. © 2013 Elsevier B.V. All rights reserved.","Classification of decision makers (DMs); Complex multi-attribute large-group decision-making (CMALGDM); Interest groups; Partial binary tree DEA-DA cyclic classification model"
"Generalized Atanassov's intuitionistic fuzzy power geometric operators and their application to multiple attribute group decision making","2013","Information Fusion","10.1016/j.inffus.2013.02.001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84887827202&doi=10.1016%2fj.inffus.2013.02.001&partnerID=40&md5=90d6a861a42efbbf981fbd7848c47221","In this paper, we extend the power geometric (PG) operator and the power ordered weighted geometric (POWG) operator [Z.S. Xu, R.R. Yager, Power-geometric operators and their use in group decision making, IEEE Transactions on Fuzzy Systems 18 (2010) 94-105] to Atanassov's intuitionistic fuzzy environments, i.e., we develop a series of generalized Atanassov's intuitionistic fuzzy power geometric operators to aggregate input arguments that are Atanassov's intuitionistic fuzzy numbers (IFNs). Then, we study some desired properties of these aggregation operators and investigate the relationships among these operators. Furthermore, we apply these aggregation operators to develop some methods for multiple attribute group decision making with Atanassov's intuitionistic fuzzy information. Finally, two practical examples are provided to illustrate the proposed methods. © 2013 Elsevier B.V. All rights reserved.","Atanassov's intuitionistic fuzzy numbers; Atanassov's intuitionistic fuzzy sets; Generalized Atanassov's intuitionistic fuzzy power geometric operators; Multiple attribute group decision making; Power aggregation operators"
"EGGDD: An explicit dependency model for multi-modal medical image fusion in shift-invariant shearlet transform domain","2014","Information Fusion","10.1016/j.inffus.2013.04.005","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84898071727&doi=10.1016%2fj.inffus.2013.04.005&partnerID=40&md5=4348087d782b0031392a6e77377c31cc","Most of the traditional medical image fusion methods that use the multi-scale decomposition schemes suffer from the bad image representations and the loss of the dependency in different highpass subbands. To deal with these problems, a novel dependency model, named Explicit Generalized Gaussian Density Dependency (EGGDD) model, is developed by the shift-invariant shearlet transform (SIST). Substantially different from describing the dependency by two hidden states in the Hidden Markov Tree (HMT) model, we provide the scheme to explicitly describe the marginal statistics of each highpass subband using the Generalized Gaussian Density (GGD), as well as the dependency between different subbands by the Kullback-Leibler distance (KLD). After embedding the obtained dependency into each highpass subband, an efficient fusion scheme, inspired by the divisive normalization response in the V1 visual cortex model, is developed to combine the highpass-subband coefficients. The experiments demonstrate that the developed method can produce better fusion results than those of some existing methods by the comparison of visual sense and quantitative measurements in terms of mutual information, entropy, spatial frequency, standard deviation, QAB/F and QW.© 2013 Elsevier B.V. All rights reserved.","Divisive normalization response; Generalized Gaussian Density; KLD; Medical image fusion; Shift-invariant shearlet transform"
"Consensus under a fuzzy context: Taxonomy, analysis framework AFRYCA and experimental case of study","2014","Information Fusion","10.1016/j.inffus.2014.03.002","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84901619037&doi=10.1016%2fj.inffus.2014.03.002&partnerID=40&md5=7211749642c8a89b96a1e7a13c917dd8","Consensus reaching processes play an increasingly important role in the resolution of group decision making problems: a solution acceptable to all the experts participating in a problem is necessary in many real-life contexts. A large number of consensus approaches have been proposed to support groups in such processes, each one with its own characteristics, such as the methods utilized for the fusion of information regarding the preferences of experts. Given this variety of existing approaches in the literature to support consensus reaching processes, this paper considers two main objectives. Firstly, we propose a taxonomy that provides an overview and categorization of some existing consensus models for group decision making problems defined in a fuzzy context, taking into account the main features of each model. Secondly, the paper presents AFRYCA, a simulation-based analysis framework for the resolution of group decision making problems by means of different consensus models. The framework is aimed at facilitating a study of the performance of each consensus model, as well as determining the most suitable model/s for the resolution of a specific problem. An experimental study is carried out to show the usefulness of the framework. © 2014 Elsevier Ltd. All rights reserved.","Consensus measure; Consensus model; Consensus reaching process; Consensus support system; Group decision making"
"Towards context aware data fusion: Modeling and integration of situationally qualified human observations to manage uncertainty in a hard + soft fusion process","2015","Information Fusion","10.1016/j.inffus.2013.04.011","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84904798986&doi=10.1016%2fj.inffus.2013.04.011&partnerID=40&md5=f4409c4655492aff77190ef33bc36752","This paper presents a framework for characterizing errors associated with different categories of human observation combined with a method for integrating these into a hard + soft data fusion system. Error characteristics of human observers (often referred to as soft data sensors) have typically been artificially generated and lack contextual considerations that in a real-world application can drastically change the accuracy and precision of these characteristics. The proposed framework and method relies on error values that change based upon known and unknown states of qualifying variables empirically shown to affect observation accuracy under different contexts. This approach allows fusion systems to perform uncertainty alignment on data coming from human observers. The preprocessed data yields a more complete and reliable situation assessment when it is processed by data association and stochastic graph matching algorithms. This paper also provides an approach and results of initial validation testing of the proposed methodology. The testing approach leverages error characterization models for several exemplar categories of observation in combination with simulated synthetic data. Results have shown significant performance improvements with respect to both data association and situation assessment fusion processes with an average F-measure improvement of 0.16 and 0.20 for data association and situation assessment respectively. These F-measure improvements are representative of fewer incorrect and missed associations and fewer graph matching results, which then must be considered by human analysts. These benefits are expected to translate into a reduction of the overall cognitive workload facing human analysts in situations where they are tasked with developing and maintaining situational awareness. © 2013 Elsevier B.V. All rights reserved.","Data fusion; Human observation; Human observers; Soft data sensors; Uncertainty alignment"
"An integrated information fusion approach based on the theory of evidence and group decision-making","2013","Information Fusion","10.1016/j.inffus.2012.08.002","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84887827053&doi=10.1016%2fj.inffus.2012.08.002&partnerID=40&md5=088f16dfa5afe68f2d0c64c9cd362b22","Dempster-Shafer theory of evidence has been employed as a major method for reasoning with multiple evidence. The Dempster's rule of combination is however incapable of managing highly conflicting evidence coming from different information sources at the normalization step. Extending current rules, we incorporate the ideas of group decision-making into the theory of evidence and propose an integrated approach to automatically identify and discount unreliable evidence. An adaptive robust combination rule that incorporates the information contained in the consistent focal elements is then constructed to combine such evidence. This rule adjusts the weights of the conjunctive and disjunctive rules according to a function of the consistency of focal elements. The theoretical arguments are supported by numerical experiments. Compared to existing combination rules, the proposed approach can obtain a reasonable and reliable decision, as well as the level of uncertainty about it. ©2012 Elsevier B.V. All rights reserved.","Adaptive robust combination rule; Discount on evidence; Group decision making; Information fusion; Theory of evidence"
"Information fusion in wireless sensor networks with source correlation","2014","Information Fusion","10.1016/j.inffus.2012.09.001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84885953833&doi=10.1016%2fj.inffus.2012.09.001&partnerID=40&md5=ab8e92537f9682aecadb6e84d32d140c","In this paper, we consider a central estimating officer (CEO) scenario, where sensors observe a noisy version of a binary sequence generated by a single source (the ""phenomenon"") and the access point (AP)'s goal is to estimate, by properly fusing the received data, this sequence. Due to this system model, the data sent by the sensors are correlated and, therefore, it is possible to exploit a proper a priori information in the localized fusion operation performed at the AP. In the presence of channel coding at the sensors and block faded communication links, we first derive the optimum maximum a priori probability (MAP) joint decoding and fusion rule, showing its computational unfeasibility. We then derive two suboptimal decoding/fusion strategies. In the first case, the fusion rule exploits the source correlation and receives, at its input, the soft-output values generated by a joint channel decoder (JCD). Two possible iterative JCD algorithms are proposed: one with ""circular"" iterations between the component decoders (associated with the sources) and one with ""parallel"" iterations between the component decoders. For each algorithm, two information combining strategies are considered. In the second case, a separate channel decoding (SCD) scheme is considered and the correlation is exploited only during the fusion operation. Our results show that the scheme with SCD followed by fusion basically leads to the same probability of decision error of the scheme with JCD and fusion with, however, a much lower computational complexity, thus making it suitable to resource-constrained scenarios. © 2013 Elsevier Ltd. All rights reserved.","Central estimating officer (CEO) problem; Information fusion; Joint channel decoding (JCD); Source correlation; Wireless sensor networks"
"Conservativeness of estimates given by probability density functions: Formulation and aspects","2014","Information Fusion","10.1016/j.inffus.2014.01.004","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84901592758&doi=10.1016%2fj.inffus.2014.01.004&partnerID=40&md5=1e094fee0194a5797e1f27c4d7f4787c","In state estimation, the output of a filter can consist of a vector estimate with an associated quality matrix or it can be given by a probability density function. Although the first option prevails in tracking, in many problems, it is necessary to cope with multiple hypotheses, i.e. with multiple vector-matrix pairs. The pairs are called conservative, if the quality matrices do not undervalue a measure of uncertainty of the vector estimates. However, no conservativeness definition for multiple pairs or for densities has been coined yet. The paper proposes such a definition for densities, provides a sufficient condition, explores some aspects and gives several special cases and numerical examples. © 2014 Elsevier B.V. All rights reserved.","Conservative probability density; Information measures; Nonlinear estimation; Performance evaluation"
"Intuitionistic fuzzy PRI-AND and PRI-OR aggregation operators","2013","Information Fusion","10.1016/j.inffus.2012.10.006","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84887827957&doi=10.1016%2fj.inffus.2012.10.006&partnerID=40&md5=0b7ee370b2d5283ceabeb3546c0ce73d","In this paper, we investigate the multi-attribute decision making (MADM) problem under Atanassov's intuitionistic fuzzy environment in which the attributes are in different priority levels. We develop the intuitionistic fuzzy prioritized ""and"" operator and intuitionistic fuzzy prioritized ""or"" operator, which are motivated by the idea of Yager's prioritized ""and"" operator and prioritized ""or"" operator. These intuitionistic fuzzy prioritized aggregation operators can be applied to aggregate intuitionistic fuzzy information when the attributes are in different priority levels. A practical example is used to illustrate the applicability and effectiveness of the proposed intuitionistic fuzzy prioritized ""or"" operator. © 2012 Elsevier B.V. All rights reserved.","Atanassov's intuitionistic fuzzy sets; Intuitionistic fuzzy prioritized ""and"" operator; Intuitionistic fuzzy prioritized ""or"" operator; Multi-attribute decision making"
"Quantum inspired method of feature fusion based on von Neumann entropy","2014","Information Fusion","10.1016/j.inffus.2013.10.003","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84888181047&doi=10.1016%2fj.inffus.2013.10.003&partnerID=40&md5=3fb8287fb0a78b8d2adefaa1bcd45332","One mission of feature fusion is to obtain a complete yet concise presentation of all existing feature data by detecting and fusing the duplicate feature data. In contrast to the already developed feature fusion methods which have shown their limitations, this paper applies the theories of quantum information to feature fusion. Further, a novel and effective step-wise quantum inspired feature fusion method, which detects the duplicate feature data based on maximum von Neumann mutual information and fuses the duplicate feature data using the operations on quantum state, is developed. This same idea is also used for feature dimensionality reduction, and the corresponding models are investigated. For comparison, another quantum inspired feature fusion method based on average quantum phase is presented here. The experimental results show that the quantum inspired feature fusion method based on von Neumann entropy gives better results on completeness and conciseness than the method based on average quantum phase. © 2013 Elsevier B.V. All rights reserved.","Data fusion; Duplicate detection; Feature fusion; Quantum information; Von Neumann entropy"
"A label field fusion model with a variation of information estimator for image segmentation","2014","Information Fusion","10.1016/j.inffus.2013.10.012","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84901593176&doi=10.1016%2fj.inffus.2013.10.012&partnerID=40&md5=bb60f4d1853c82806ee49e8f9d41cce9","This paper proposes a new and reliable segmentation approach based on a fusion framework for combining multiple region-based segmentation maps (with any number of regions) to provide a final improved (i.e., accurate and consistent) segmentation result. The core of this new combination model is based on a consensus (cost) function derived from the recent information Theory based variation of information criterion, proposed by Meila, and allowing to quantify the amount of information that is lost or gained in changing from one clustering to another. In this case, the resulting consensus energy-based segmentation fusion model can be efficiently optimized by exploiting an iterative steepest local energy descent strategy combined with a connectivity constraint. This new framework of segmentation combination, relying on the fusion of inaccurate, quickly and roughly calculated, spatial clustering results, emerges as an appealing alternative to the use of complex segmentation models existing nowadays. Experiments on the Berkeley Segmentation Dataset show that the proposed fusion framework compares favorably to previous techniques in terms of reliability scores. © 2013 Elsevier B.V. All rights reserved.","Cluster ensemble algorithm; Combination of multiple segmentations; Label field fusion; Segmentation ensemble; Variation of information"
"Interactive color image segmentation via iterative evidential labeling","2014","Information Fusion","10.1016/j.inffus.2014.03.007","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84901634940&doi=10.1016%2fj.inffus.2014.03.007&partnerID=40&md5=9d31d9070470b49a1dd5affb4aff822f","We develop an interactive color image segmentation method in this paper. This method makes use of the conception of Markov random fields (MRFs) and D-S evidence theory to obtain segmentation results by considering both likelihood information and priori information under Bayesian framework. The method first uses expectation maximization (EM) algorithm to estimate the parameter of the user input regions, and the Bayesian information criterion (BIC) is used for model selection. Then the beliefs of each pixel are assigned by a predefined scheme. The result is obtained by iteratively fusion of the pixel likelihood information and the pixel contextual information until convergence. The method is initially designed for two-label segmentation, however it can be easily generalized to multi-label segmentation. Experimental results show that the proposed method is comparable to other prevalent interactive image segmentation algorithms in most cases of two-label segmentation task, both qualitatively and quantitatively. © 2014 Elsevier B.V. All rights reserved.","Bayesian information criterion (BIC); Dempster-Shafer's (DS) theory of evidence; Information fusion; Interactive image segmentation; Markov random fields (MRFs)"
"Tree ensemble construction using a GRASP-based heuristic and annealed randomness","2014","Information Fusion","10.1016/j.inffus.2014.01.009","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84901585967&doi=10.1016%2fj.inffus.2014.01.009&partnerID=40&md5=e05719dc96c6c2c710710ec01784ce4e","Two new methods for tree ensemble construction are presented: G-Forest and GAR-Forest. In a similar way to Random Forest, the tree construction process entails a degree of randomness. The same strategy used in the GRASP metaheuristic for generating random and adaptive solutions is used at each node of the trees. The source of diversity of the ensemble is the randomness of the solution generation method of GRASP. A further key feature of the tree construction method for GAR-Forest is a decreasing level of randomness during the process of constructing the tree: maximum randomness at the root and minimum randomness at the leaves. The method is therefore named ""GAR"", GRASP with annealed randomness. The results conclusively demonstrate that G-Forest and GAR-Forest outperform Bagging, AdaBoost, MultiBoost, Random Forest and Random Subspaces. The results are even more convincing in the presence of noise, demonstrating the robustness of the method. The relationship between base classifier accuracy and their diversity is analysed by application of kappa-error diagrams and a variant of these called kappa-error relative movement diagrams. © 2014 Elsevier B.V. All rights reserved.","Boosting; Classifier ensembles; Decision trees; GRASP metahuristic; Random Forest"
"Providing SIEM systems with self-adaptation","2015","Information Fusion","10.1016/j.inffus.2013.04.009","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84904798451&doi=10.1016%2fj.inffus.2013.04.009&partnerID=40&md5=4b8492c48dd4fcb70eb5ee1fe2ad26c6","Security information and event management (SIEM) is considered to be a promising paradigm to reconcile traditional intrusion detection processes along with most recent advances on artificial intelligence techniques in providing automatic and self-adaptive systems. However, classic management-related flaws still persist, e.g. the fusion of large amounts of security events reported from many heterogeneous systems, whilst novel intriguing challenges arise specially when dealing with the adaptation to newly encountered and multi-step attacks. In this article, we provide SIEM correlation with self-adaptation capabilities to optimize and significantly reduce the intervention of operators. In particular, our enhanced correlation engine automatically learns and produces correlation rules based on the context for different types of multi-step attacks using genetic programming. The context is considered as the knowledge and reasoning, not only acquired by a human expert but also inferred by our system, which assist in the identification and fusion of events. In this regard, a number of artificial neural networks are trained to classify events according to the corresponding context established for the attack. Experimentation is conducted on a real deployment within OSSIM to validate our proposal. © 2013 Elsevier B.V. All rights reserved.","Adaptive system; Artificial neural networks; Event correlation; Genetic programming; SIEM"
"A survey of multiple classifier systems as hybrid systems","2014","Information Fusion","10.1016/j.inffus.2013.04.006","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84887090067&doi=10.1016%2fj.inffus.2013.04.006&partnerID=40&md5=e8b0dd8f6b66adbedfac98868e803ad7","A current focus of intense research in pattern classification is the combination of several classifier systems, which can be built following either the same or different models and/or datasets building approaches. These systems perform information fusion of classification decisions at different levels overcoming limitations of traditional approaches based on single classifiers. This paper presents an up-to-date survey on multiple classifier system (MCS) from the point of view of Hybrid Intelligent Systems. The article discusses major issues, such as diversity and decision fusion methods, providing a vision of the spectrum of applications that are currently being developed. © 2013 Elsevier B.V. All rights reserved.","Classifier ensemble; Classifier fusion; Combined classifier; Hybrid classifier; Multiple classifier system"
"Fusing uncertain knowledge and evidence for maritime situational awareness via Markov Logic Networks","2015","Information Fusion","10.1016/j.inffus.2013.03.004","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84904793445&doi=10.1016%2fj.inffus.2013.03.004&partnerID=40&md5=f9be3ff2dfe06fa8ec0de7496d5d5a5f","The concepts of event and anomaly are important building blocks for developing a situational picture of the observed environment. We here relate these concepts to the JDL fusion model and demonstrate the power of Markov Logic Networks (MLNs) for encoding uncertain knowledge and compute inferences according to observed evidence. MLNs combine the expressive power of first-order logic and the probabilistic uncertainty management of Markov networks. Within this framework, different types of knowledge (e.g. a priori, contextual) with associated uncertainty can be fused together for situation assessment by expressing unobservable complex events as a logical combination of simpler evidences. We also develop a mechanism to evaluate the level of completion of complex events and show how, along with event probability, it could provide additional useful information to the operator. Examples are demonstrated on two maritime scenarios of rules for event and anomaly detection. © 2013 NATO Science and Technology Organization, Centre for Maritime Research and Experimentation. Published by Elsevier B.V. All rights reserved.","Context-based fusion; Markov Logic Networks; Situational awareness; Uncertainty management"
"Nearest neighbor imputation using spatial-temporal correlations in wireless sensor networks","2014","Information Fusion","10.1016/j.inffus.2012.08.007","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84885954235&doi=10.1016%2fj.inffus.2012.08.007&partnerID=40&md5=15d1ee8fb353e7693c7dfacf7bd86c3f","Missing data is common in Wireless Sensor Networks (WSNs), especially with multi-hop communications. There are many reasons for this phenomenon, such as unstable wireless communications, synchronization issues, and unreliable sensors. Unfortunately, missing data creates a number of problems for WSNs. First, since most sensor nodes in the network are battery-powered, it is too expensive to have the nodes re-transmit missing data across the network. Data re-transmission may also cause time delays when detecting abnormal changes in an environment. Furthermore, localized reasoning techniques on sensor nodes (such as machine learning algorithms to classify states of the environment) are generally not robust enough to handle missing data. Since sensor data collected by a WSN is generally correlated in time and space, we illustrate how replacing missing sensor values with spatially and temporally correlated sensor values can significantly improve the network's performance. However, our studies show that it is important to determine which nodes are spatially and temporally correlated with each other. Simple techniques based on Euclidean distance are not sufficient for complex environmental deployments. Thus, we have developed a novel Nearest Neighbor (NN) imputation method that estimates missing data in WSNs by learning spatial and temporal correlations between sensor nodes. To improve the search time, we utilize a kd-tree data structure, which is a non-parametric, data-driven binary search tree. Instead of using traditional mean and variance of each dimension for kd-tree construction, and Euclidean distance for kd-tree search, we use weighted variances and weighted Euclidean distances based on measured percentages of missing data. We have evaluated this approach through experiments on sensor data from a volcano dataset collected by a network of Crossbow motes, as well as experiments using sensor data from a highway traffic monitoring application. Our experimental results show that our proposed K-NN imputation method has a competitive accuracy with state-of-the-art Expectation-Maximization (EM) techniques, while using much simpler computational techniques, thus making it suitable for use in resource-constrained WSNs. © 2013 Elsevier Ltd. All rights reserved.","kd-Tree; Missing data imputation; Nearest neighbor imputation; Wireless sensor networks"
"Skew-sensitive boolean combination for adaptive ensembles - An application to face recognition in video surveillance","2014","Information Fusion","10.1016/j.inffus.2013.11.001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84901624112&doi=10.1016%2fj.inffus.2013.11.001&partnerID=40&md5=5d8fe799a9c76f8392db809faa6c8d55","Several ensemble-based techniques have been proposed to design pattern recognition systems when data has imbalanced class distributions, although class proportions may change over time according to the operational environment. For instance, in video surveillance applications, face recognition (FR) is employed to detect the presence of target individuals of interest in potentially complex and changing environments. Systems for FR in video surveillance are typically designed a priori with a limited amount of reference target data and prior knowledge of underlying class distributions. However, the relatively proportion of target and non-target faces captured during operations varies over time. Estimating the actual proportion of data from the input data stream could allow to dynamically adapt ensembles to reflect operational conditions. In this paper, the selection and fusion of ensembles produced through Boolean Combination (BC) of classifiers is periodically adapted based on the class proportions estimated from input streams. BC techniques have been shown to efficiently integrate the responses of multiple diversified classifiers in the ROC space, yet the impact on performance of imbalanced data distributions is difficult to observe from ROC curves. Given a diversified pool of classifiers and a desired false positive rate (fpr), the new Skew-Sensitive Boolean Combination (SSBC) technique exploits the Precision-Recall Operating Characteristic (PROC) space, leading to a higher level of performance. A set of BCs of base classifiers is initially produced with imbalanced reference data in the PROC space, where each BC curve corresponds to different level of imbalance (a growing number of non-target samples versus a fixed number of target ones). Then, during operations, the closest adjacent levels of class imbalance are periodically estimated using the Hellinger distance between the data distribution of inputs and that of imbalance levels, and used to approximate the most accurate BC of classifiers from operational points of these curves. Simulation results on Faces In Action video surveillance data indicate that ensemble-based FR systems using the SSBC technique outperform the same systems using traditional BC techniques with Random Under-Sampling and One-Sided Selection. It allows to dynamically select BCs that provide a higher level of precision (and F1 value) for target individuals, and a significantly smaller difference between desired and actual fpr. Performance of this adaptive approach is also comparable to the costly full recalculation of BCs (as required by a BC technique to accommodate a specific level of imbalance), but for a computational complexity that is considerably lower. Finally, SSBC is shown to achieve a high level of discrimination between target and non-target individuals when face tracking is exploited to accumulate ensemble predictions for facial captures that correspond to a same person in the video scene. © 2013 Elsevier B.V. All rights reserved.","Boolean combination; Class imbalance; Classifier ensembles; Face recognition; Information fusion"
"A review of soft consensus models in a fuzzy environment","2014","Information Fusion","10.1016/j.inffus.2013.04.002","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84888304605&doi=10.1016%2fj.inffus.2013.04.002&partnerID=40&md5=a1610880771585bf865d61eceeb7b77a","In the consensus reaching processes developed in group decision making problems we need to measure the closeness among experts' opinions in order to obtain a consensus degree. As it is known, to achieve a full and unanimous consensus is often not reachable in practice. An alternative approach is to use softer consensus measures, which reflect better all possible partial agreements, guiding the consensus process until high agreement is achieved among individuals. Consensus models based on soft consensus measures have been widely used because these measures represent better the human perception of the essence of consensus. This paper presents an overview of consensus models based on soft consensus measures, showing the pioneering and prominent papers, the main existing approaches and the new trends and challenges. © 2013 Elsevier B.V. All rights reserved.","Consensus; Fuzzy logic; Group decision making; Soft consensus measures"
"Joint target tracking and classification via RFS-based multiple model filtering","2014","Information Fusion","10.1016/j.inffus.2013.05.010","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84892365171&doi=10.1016%2fj.inffus.2013.05.010&partnerID=40&md5=bacbc7988e49f9c3d5bfbc4b0e36ca9a","Firstly, a multiple model extension of the random finite set (RFS)-based single-target Bayesian filtering (STBF), referred as MM-STBF, is presented to accommodate the possible target maneuvering behavior in a straightforward manner. This paper is concerned with joint target tracking and classification (JTC) which are closely coupled. In particular, we take into account extraneous target-originated measurements which were not modeled in the existing JTC algorithms. Therefore, the main contribution is that the paper derives a new JTC algorithm based on the MM-STBF, i.e., MM-STBF-JTC. The MM-STBF-JTC is an optimal Bayesian solution, which can simultaneously accommodate unknown data association, miss-detection, clutter and several measurements originated from a target. The MM-STBF-JTC can reduce to a traditional JTC algorithm under some assumptions. The simulation results are provided to demonstrate the tracking and classification performance of the MM-STBF-JTC algorithm. © 2013 Elsevier B.V. All rights reserved.","IMMPDAF; Joint target tracking and classification; Multiple model filtering; Random finite set"
"A ranking procedure based on a natural monotonicity constraint","2014","Information Fusion","10.1016/j.inffus.2012.01.003","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84888293743&doi=10.1016%2fj.inffus.2012.01.003&partnerID=40&md5=e4696c7611d2fae6247d0719927174cd","We formulate a new ranking procedure in the traditional context where each voter has expressed a linear order relation or ranking over the candidates. The final ranking of the candidates is taken to be the one which best adheres to a natural monotonicity constraint. For a ranking a b c, monotonicity implies that the strength with which a c is supported should not be less than the strength with which either one of a b or b c is supported. We investigate some properties of this ranking procedure and encounter some surprising preliminary results. © 2012 Elsevier B.V. All rights reserved.","Monotonicity; Ranking; Social ordering; Social preference"
"Semi-hidden target recognition in gated viewer images fused with thermal IR images","2014","Information Fusion","10.1016/j.inffus.2013.08.001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84892372668&doi=10.1016%2fj.inffus.2013.08.001&partnerID=40&md5=389e358dc029633b538a53c2ab427d37","Defense and security surveillance scenarios typically involve the detection and classification of targets in complex and dynamic backgrounds. Imaging systems deployed for this purpose should therefore provide imagery that enables optimal simultaneous recognition of both targets and their context. Here we investigate the recognition of semi-hidden targets, which are targets that are embedded in complex scenes, and which may either be occluded by or merged with other details in the scene. Imagery of semi-hidden targets obtained with conventional visual (TV) and Infra-Red (IR) cameras is typically not optimal for recognition and classification purposes. Previous studies on image fusion did not consider semi-hidden targets. This study investigates the potential benefits of (1) adding a laser range gated viewer (GV) to an IR camera and of (2) fusing GV and IR imagery for the recognition of semi-hidden targets. A combination of an Image Quality Metric (IQM) and an accurate saliency metric is used to select a fusion method that is optimal for semi-hidden target recognition. The results of both metrics are validated through a human observer experiment. For application in very complex scenes (in which target recognition remains difficult after fusion) we designed a background dimming algorithm that either uniformly dims the entire background or applies less dimming in the local target background or in regions with important contextual information, without affecting the target representation itself. The optimal combination of fusion method and amount of dimming is determined through a second observer experiment. In a third observer experiment, we tested if target motion influences the preferred amount of dimming. We find that fusing GV with IR imagery improves human recognition of semi-hidden targets. A simple pixel-based approach with a PCA-based weighted fusion scheme appears to be the optimal fusion method. Contextual dimming improves target recognition in complex backgrounds. In addition, moving objects appear to affect observer's dimming preference, but further research is needed to quantify this effect. © 2013 Elsevier B.V. All rights reserved.","Image fusion; Infra-red; Laser range gated viewer; Saliency; Target recognition"
"A localized algorithm for Structural Health Monitoring using wireless sensor networks","2014","Information Fusion","10.1016/j.inffus.2012.02.002","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84885960871&doi=10.1016%2fj.inffus.2012.02.002&partnerID=40&md5=ded1be983615e9f69f9237b1fe583fad","Structural Health Monitoring (SHM) has been proving to be a suitable application domain for wireless sensor networks, whose techniques attempt to autonomously evaluate the integrity of structures, occasionally aiming at detecting and localizing damage. In this paper, we propose a localized algorithm supported by multilevel information fusion techniques to enable detection, localization and extent determination of damage sites using the resource constrained environment of a wireless sensor network. Each node partakes in different network tasks and has a localized view of the whole situation, so collaboration mechanisms and multilevel information fusion techniques are key components of this proposal to efficiently achieve its goal. Experimental results with the MICAz mote platform showed that the algorithm performs well in terms of network resources utilization. © 2013 Elsevier Ltd. All rights reserved.","Damage localization; Information fusion; Localized algorithm; Resource constrained networks; Structural Health Monitoring; Wireless sensor networks"
"RWO-Sampling: A random walk over-sampling approach to imbalanced data classification","2014","Information Fusion","10.1016/j.inffus.2013.12.003","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84901596053&doi=10.1016%2fj.inffus.2013.12.003&partnerID=40&md5=17f5f58bc388596930fb7514e8048728","This study investigates how to alleviate the class imbalance problems for constructing unbiased classifiers when instances in one class are more than that in another. Since keeping the data distribution unchanged and expanding class boundaries after synthetic samples have been added influence the classification performance greatly, we take into account the above two factors, and propose a Random Walk Over-Sampling approach (RWO-Sampling) to balancing different class samples by creating synthetic samples through randomly walking from the real data. When some conditions are satisfied, it can be proved that, both the expected average and the standard deviation of the generated samples equal to that of the original minority class data. RWO-Sampling also expands the minority class boundary after synthetic samples have been generated. In this work, we perform a broad experimental evaluation, and experimental results show that, RWO-Sampling statistically does much better than alternative methods on imbalanced data sets when implementing common baseline algorithms. © 2014 Elsevier B.V. All rights reserved.","Data fusion; Imbalanced data classification; Over-sampling; Probability distribution; Random walk"
"Image fusion using intuitionistic fuzzy sets","2014","Information Fusion","10.1016/j.inffus.2013.10.011","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84901595802&doi=10.1016%2fj.inffus.2013.10.011&partnerID=40&md5=981d5122267c660846f1bb05c737bd6a","Image fusion is the process of combining one or more images which are obtained from different environment into a single image which is more useful for further image processing tasks. Image registration and image fusion are of great importance in defence and civilian sectors, particularly for recognizing a ground/air force vehicle and medical imaging. In this paper a new way is drawn to fuse two or more images by using maximum, minimum operations in intuitionistic fuzzy sets (IFSs). IFSs are more suitable for image processing since every digital image have lot of uncertainties. In processing phase, images are reformed into intuitionistic fuzzy images (IFIs). Entropy is employed to obtain the optimum value of the parameter in membership and non-membership function. Then the resulting IFIs are disintegrated into image blocks and the corresponding blocks of the images are reunioned by finding the count of blackness and whiteness of the blocks. This paper evaluates the performance of simple averaging (AVG), principal component analysis (PCA), discrete wavelet transform (DWT), stationary wavelet transform (SWT), dual tree complex wavelet transform (DTCWT), multi-resolution singular value decomposition (MSVD), nonsubsampled contourlet transform (NSCT) and IFS (proposed method) in terms of various performance measure. The experimental and comparison results show that luminance and contrast is of great importance for image processing and prove that the proposed method is better than all other methods. © 2013 Elsevier B.V. All rights reserved.","Entropy; Image fusion; Intuitionistic fuzzy image; Intuitionistic fuzzy set"
"Estimation fusion algorithms in the presence of partially known cross-correlation of local estimation errors","2014","Information Fusion","10.1016/j.inffus.2013.09.003","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84892366816&doi=10.1016%2fj.inffus.2013.09.003&partnerID=40&md5=bc872eb4d1e21adc1415dddec158ef6d","This paper addresses estimation fusion when the cross-correlation of local estimation errors is partially known. The statistical dependence of local estimation errors is first discussed, and then the concept of correlation coefficient is introduced to model the cross-correlation approximately. Two algorithms are proposed. One is based on min-max technique, which minimizes the maximal Mahalanobis distance between two fused estimates. The other one uses the prior distribution of the correlation coefficient and obtains a closed form of estimation fusion with the help of a series of matrix manipulations. Compared with some available algorithms in literature, simulation results demonstrate the effectiveness of the proposed approaches. © 2013 Elsevier B.V. All rights reserved.","Correlation coefficient; Cross-correlation; Estimation fusion; Mahalanobis distance; Min-max"
"Brain morphometry of MR images for automated classification of first-episode schizophrenia","2014","Information Fusion","10.1016/j.inffus.2013.02.002","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84898016888&doi=10.1016%2fj.inffus.2013.02.002&partnerID=40&md5=536f668a3eab4e0ec7d0f4b1ceb3b1f5","Schizophrenia is a disabling psychiatric disorder that usually begins to affect individuals during their adolescence or early adulthood and most patients continue to suffer social, economic, and psychological difficulties from the very onset of the disorder. The neurobiology of the disorder comprises of changes in the brain that can be detected using MR imaging. Focus on the morphological changes in patients with first episode schizophrenia limits the confounding effect of factors such as long-term medication or progression. Therefore, the detected abnormalities are more likely to indicate the primary pathology and the existence of such changes provides the opportunity of applying them for subject recognition based on brain imaging. This paper presents a combination of methods pertaining to automated whole-brain morphometry of MR images and the methods of supervised learning. The designed recognition procedure is successfully used here for classification of 104 subjects into groups of patients and healthy volunteers with the use of k-NN and SVM classifiers. The same algorithm is further used for distinguishing between patients who responded well to treatment and those who did not show adequate symptomatic relief. © 2013 Elsevier B.V. All rights reserved.","Brain morphometry; Computational neuroanatomy; Group analysis; Image registration; Pattern recognition; Schizophrenia"
"GeoSpray: A geographic routing protocol for vehicular delay-tolerant networks","2014","Information Fusion","10.1016/j.inffus.2011.11.003","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84885959091&doi=10.1016%2fj.inffus.2011.11.003&partnerID=40&md5=9d91eb6179ddd108164957052b55cc95","Vehicular networks are characterized by a highly dynamic network topology, and disruptive and intermittent connectivity. In such network environments, a complete path from source to destination does not exist on the most part of the time. Vehicular delay-tolerant network (VDTN) architecture was introduced to deal with these connectivity constraints. VDTN assumes asynchronous, bundle-oriented communication, and a store-carry-and-forward routing paradigm. A routing protocol for VDTNs should make the best use of the tight resources available in network nodes to create a multi-hop path that exists over time. This paper proposes a VDTN routing protocol, called GeoSpray, which takes routing decisions based on geographical location data, and combines a hybrid approach between multiple-copy and single-copy schemes. First, it starts with a multiple-copy scheme, spreading a limited number of bundle copies, in order to exploit alternative paths. Then, it switches to a forwarding scheme, which takes advantage of additional contact opportunities. In order to improve resources utilization, it clears delivered bundles across the network nodes. It is shown that GeoSpray improves significantly the delivery probability and reduces the delivery delay, compared to traditional location and non location-based single-copy and multiple-copy routing protocols. © 2013 Elsevier Ltd. All rights reserved.","Design; Geographic routing; Multiple-copy routing; Performance assessment; Routing protocols; Single-copy routing; Vehicular delay-tolerant networks"
"Using multi-sensor data fusion for vibration fault diagnosis of rolling element bearings by accelerometer and load cell","2014","Information Fusion","10.1016/j.inffus.2013.10.002","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84887493381&doi=10.1016%2fj.inffus.2013.10.002&partnerID=40&md5=61109f6eba7d6ee9ba471b5fc71132e6","This paper presents a new method for bearing fault diagnosis using the fusion of two primary sensors: an accelerometer and a load cell. A novel condition-based monitoring (CBM) system consisting of six modules: sensing, signal processing, feature extraction, classification, high-level fusion and decision making module has been proposed. To obtain acceleration and load signals, a work bench has been used. In the next stage, signal indices for each signal in both time and frequency domains have been calculated. After calculation of signal indices, principal component analysis is employed for redundancy reduction. Two principal features have been extracted from load and acceleration indices. In the fourth module, K-Nearest Neighbor (KNN) classifier has been used in order to identify the condition of the ball bearing based on vibration signal and load signal. In the fifth module, a high-level sensor fusion is used to derive information that would not be available from single sensor. Based on situation assessment carried out during the training process of classifier, a relationship between bearing condition and sensor performance has been found. Finally, a logical program has been used to decide about the condition of the ball bearing. The test results demonstrate that the load cell is powerful to detect the healthy ball bearings from the defected ones, and the accelerometer is useful to detect the location of fault. Experimental results show the effectiveness of this method. © 2013 Elsevier B.V. All rights reserved.","Accelerometer; Bearing diagnosis; Load cell; Multiple sensor fusion; Pattern recognition"
"Using consensus and distances between generalized multi-attribute linguistic assessments for group decision-making","2014","Information Fusion","10.1016/j.inffus.2011.09.001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84888296696&doi=10.1016%2fj.inffus.2011.09.001&partnerID=40&md5=e7b842ffb291178fcb38da948a1d9142","This paper proposes a mathematical framework and methodology for group decision-making under multi-granular and multi-attribute linguistic assessments. It is based on distances between linguistic assessments and a degree of consensus. Distances in the space of qualitative assessments are defined from the geodesic distance in graph theory and the Minkowski distance. The degree of consensus is defined through the concept of entropy of a qualitatively-described system. Optimal assessments in terms of both proximity to all the expert opinions in the group and the degree of consensus are used to compare opinions and define a methodology to rank multi-attribute alternatives. © 2011 Elsevier B.V. All rights reserved.","Consensus; Group decision; Information theory; Multi attribute group decision making; Qualitative reasoning"
"Fusion of Gaussian mixture models for possible mismatches of sensor model","2014","Information Fusion","10.1016/j.inffus.2014.02.002","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84901643489&doi=10.1016%2fj.inffus.2014.02.002&partnerID=40&md5=ea57aa8d2f5d22c0f9f6b19c42beaf44","This paper addresses estimation fusion in the presence of possible mismatches of sensor model. The main concerns of the paper lie in two aspects. One is to improve the filter performance of the single sensor when there are possible mismatches about the sensor model. The other one is to adopt a good fusion scheme to combine local estimates. For these purposes, the measurement process of the local sensor is modeled by multiple models firstly, and the IMM (interacting multiple model) estimator is implemented to produce estimates for individual models. Next, we describe the local estimate by a Gaussian mixture rather than a single Gaussian density in the baseline IMM filter. Such a GMM (Gaussian mixture model) representation of the system state allows us to keep the detailed information about the local tracker, which contributes to the further fusion if treated properly. Finally, the fusion of two Gaussian mixtures is done in the probabilistic framework, and a close-form solution is derived without complex numerical operations. Simulation results demonstrate the effectiveness of the proposed approach. © 2014 Elsevier Ltd. All rights reserved.","Estimation fusion; Gaussian mixture model (GMM); Interacting multiple model (IMM)"
"Cryptanalysis of a remote user authentication scheme for mobile client-server environment based on ECC","2013","Information Fusion","10.1016/j.inffus.2012.12.002","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84887815438&doi=10.1016%2fj.inffus.2012.12.002&partnerID=40&md5=687b40face823172f26fb0149ffc05ff","Understanding security failures of cryptographic protocols is the key to both patching existing protocols and designing future schemes. The design of secure remote user authentication schemes based on elliptic curve crypto-graphy (ECC) for mobile applications is still quite a challenging problem, though many schemes have been published lately. In this paper, we analyze an efficient ID-based scheme for mobile client-server environment without the MapToPoint function introduced by He et al. in 2012. This proposal attempts to overcome many of the well known security and efficiency shortcomings of previous schemes, and it also carries a claimed proof of security in the random oracle model. However, notwithstanding its formal security arguments, we show that He et al.'s protocol even cannot attain the basic goal of mutual authentication by demonstrating its vulnerabilities to reflection attack and parallel session attack. Besides these two security vulnerabilities, their scheme also suffers from some practical pitfalls such as user anonymity violation and clock synchronization problem. In addition, we carry out an investigation into their security proof and propose some changes to the scheme so that it can achieve at least its basic security goal, in the hope that similar mistakes are no longer made in the future. © 2013 Elsevier B.V. All rights reserved.","Authentication protocol; Cryptanalysis; Elliptic curve cryptography; Mobile device; Random oracle model"
"A Multi-Modal Incompleteness Ontology model (MMIO) to enhance information fusion for image retrieval","2014","Information Fusion","10.1016/j.inffus.2014.02.003","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84901621299&doi=10.1016%2fj.inffus.2014.02.003&partnerID=40&md5=839fd937b1396a86a9ec9da3e3eae360","A significant effort by researchers has advanced the ability of computers to understand, index and annotate images. This entails automatic domain specific knowledge-base (KB) construction and metadata extraction from visual information and any associated textual information. However, it is challenging to fuse visual and textual information and build a complete domain-specific KB for image annotation due to several factors such as: the ambiguity of natural language to describe image features; the semantic gap when using image features to represent visual content and the incompleteness of the metadata in the KB. Typically the KB is based upon a domain specific Ontology. However, it is not an easy task to extract the data needed from annotations and images, and then to automatically process these and transform them into an integrated Ontology model, because of the ambiguity of terms and because of image processing algorithm errors. As such, it is difficult to construct a complete KB covering a specific domain of knowledge. This paper presents a Multi-Modal Incompleteness Ontology-based (MMIO) system for image retrieval based upon fusing two derived indices. The first index exploits low-level features extracted from images. A novel technique is proposed to represent the semantics of visual content, by restructuring visual word vectors into an Ontology model by computing the distance between the visual word features and concept features, the so called concept range. The second index relies on a textual description which is processed to extract and recognise the concepts, properties, or instances that are defined in an Ontology. The two indexes are fused into a single indexing model, which is used to enhance the image retrieval efficiency. Nonetheless, this rich index may not be sufficient to find the desired images. Therefore, a Latent Semantic Indexing (LSI) algorithm is exploited to search for similar words to those used in a query. As a result, it is possible to retrieve images with a query using (similar) words that do not appear in the caption. The efficiency of the KB is validated experimentally with respect to three criteria, correctness, multimodality, and robustness. The results show that the multi-modal metadata in the proposed KB could be utilised efficiently. An additional experiment demonstrates that LSI can handle an incomplete KB effectively. Using LSI, the system can still retrieve relevant images when information in the Ontology is missing, leading to an enhanced retrieval performance. © 2014 Elsevier Ltd. All rights reserved.","Incomplete Ontology; Knowledge base; Multi-Modal Ontology; Visual and textual information fusion"
"On the use of a multi-criteria approach for reliability estimation in belief function theory","2014","Information Fusion","10.1016/j.inffus.2013.04.010","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84892367101&doi=10.1016%2fj.inffus.2013.04.010&partnerID=40&md5=0a3ffa92425ba3cd8c9582e06a053588","Decision analysis models often require the assessments of uncertain events elicited from informed experts to support the decision-making process. Expert opinions are often polled but their fusion is frequently beset by a number of difficulties pertaining to conflict and imperfection. Decision makers need, therefore, to reconcile inconsistencies by fusing the information provided by multiple sources of expertise. To reduce conflict and manage imperfection, expert information, represented by belief functions, need to be discounted proportionally to the degree they contribute to the conflict and its imperfection. The present study proposes a novel approach for determining the discounting operator of the information provided by a set of experts based on multiple criteria using the PROMETHEE II method. Expert judgments are then discounted and combined. Simple numerical examples and Monte Carlo simulations, including tests and comparative analysis with current approaches in the literature, are presented to illustrate the potential of the proposed approach. © 2013 Elsevier B.V. All rights reserved.","Belief function theory; Expert judgments; Information fusion; Multi-criteria decision aid; Reliability degree"
"License plate detection based on multistage information fusion","2014","Information Fusion","10.1016/j.inffus.2013.05.008","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84892372030&doi=10.1016%2fj.inffus.2013.05.008&partnerID=40&md5=158892ccba0741c31d3f32de46629f63","Adaboost detector has been successfully used in object detection. In this paper, we propose a new License Plate (LP) detection technique based on multistage information fusion, which is adopted to reduce high false alarm rate in the conventional Adaboost detector. The proposed multistage information fusion system is composed of an enhanced Adaboost detector, a color checking module and an SVM detector, where the latter two stages further check whether the image patch that gets through the Adaboost detector is an LP. Test results of the dataset that consists of 950 real-world images show that the fusion reduces the false alarm rate. The proposed Fusion detector outperforms the conventional Adaboost detector throughout the ROC (Receiver Operating Characteristic) curve. The AUC (Area Under the Curve) of the best Fusion detector reaches 0.9081; however, the AUC of the best Adaboost detector is only 0.8441, which shows that the modification on feature extraction and the multistage information fusion significantly improve the LP detection performance. © 2013 Elsevier B.V. All rights reserved.","Adaboost; HSI; License plate detection; Multistage information fusion; SVM"
"A tour of BeAware - A situation awareness framework for control centers","2014","Information Fusion","10.1016/j.inffus.2014.01.008","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84901596980&doi=10.1016%2fj.inffus.2014.01.008&partnerID=40&md5=846e2feee6ffed0813bb867c0dde925b","Large control centers, as needed in road traffic, typically manage highly dynamic environments. They process vast amounts of information from heterogeneous data sources about a large number of real-world objects, which are anchored in time and space. In such systems, human operators are vulnerable to information overload and, thus, may fail to be aware of the overall meaning of available information and its implications. With BeAware, we propose a software framework that supports the development of situation awareness applications for control centers. The contribution of this paper is twofold: First, we integrate existing ontologies with spatio-temporal reasoning concepts, focusing on extensibility. We introduce meta-modeling concepts that allow us to assess and project situations and actions using semantic web technology. Second, we compare the runtime performance of the situation comprehension capabilities of a generic, ontology-driven implementation and a domain-specific relational-database-backed implementation, and discuss the strengths and shortcomings of each approach. © 2014 Elsevier B.V. All rights reserved.","Framework; Ontologies; Road traffic control; Situation awareness; Spatio-temporal reasoning"
"Measuring consensus in a preference-approval context","2014","Information Fusion","10.1016/j.inffus.2012.02.004","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84888299718&doi=10.1016%2fj.inffus.2012.02.004&partnerID=40&md5=5aa7eb1111cb91c0462168da82299ecc","We consider measuring the degree of homogeneity for preference-approval profiles which include the approval information for the alternatives as well as the rankings of them. A distance-based approach is followed to measure the disagreement for any given two preference-approvals. Under the condition that a proper metric is used, we propose a measure of consensus which is robust to some extensions of the ordinal framework. This paper also shows that there exists a limit for increasing the homogeneity level in a group of individuals by simply replicating their preference-approvals. © 2012 Elsevier B.V. All rights reserved.","Approval voting; Consensus; Hamming metric; Kemeny metric; Preference-approval"
"An energy efficiency semi-static routing algorithm for WSNs based on HAC clustering method","2015","Information Fusion","10.1016/j.inffus.2013.05.001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84904791165&doi=10.1016%2fj.inffus.2013.05.001&partnerID=40&md5=ab5759a5cac294c77c17760a8e5cd462","In Wireless Sensor Networks (WSNs), energy efficiency is one of the most important factors influencing the networks' performance. Through a well designed routing algorithm, WSNs' energy efficiency can be improved evidently. Among various routing algorithms, hierarchical routing algorithms have advantages in improving nets' robustness and flexibility, and it is more appropriate for large scale of networks. In this paper, some typical hierarchical routing algorithms are introduced, and their advantages and defects are analyzed. Based on these analyses, a new hierarchical routing algorithm with high energy efficiency named EESSC is proposed which is based on the improved HAC clustering approach. In EESSC, the sensor nodes' residual energy would be taken into account in clustering operation, and a special packet head is defined to help update nodes' energy information when transmitting message among the nodes. When the clusters have been formed, the nodes in cluster would be arrayed in a list and cluster head would be rotated automatically by the order of list. And a re-cluster mechanism is designed to dynamic adjust the result of clustering to make sensor nodes organization more reasonable. At last, EESSC is compared to other typical hierarchical routing algorithms in a series of experiments, and the experiments' result which proves that EESSC has obviously improved the WSNs' energy efficiency has been analyzed. Crown Copyright © 2013 Published by Elsevier B.V. All rights reserved.","Energy efficiency; Hierarchical routing algorithm; Semi-static clustering; WSNs"
"Features modeling with an α-stable distribution: Application to pattern recognition based on continuous belief functions","2013","Information Fusion","10.1016/j.inffus.2013.02.004","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84887825121&doi=10.1016%2fj.inffus.2013.02.004&partnerID=40&md5=b7b6d97f19c07c42ebe6037b180b6d42","The aim of this paper is to show the interest in fitting features with an α-stable distribution to classify imperfect data. The supervised pattern recognition is thus based on the theory of continuous belief functions, which is a way to consider imprecision and uncertainty of data. The distributions of features are supposed to be unimodal and estimated by a single Gaussian and α-stable model. Experimental results are first obtained from synthetic data by combining two features of one dimension and by considering a vector of two features. Mass functions are calculated from plausibility functions by using the generalized Bayes theorem. The same study is applied to the automatic classification of three types of sea floor (rock, silt and sand) with features acquired by a mono-beam echo-sounder. We evaluate the quality of the α-stable model and the Gaussian model by analyzing qualitative results, using a Kolmogorov-Smirnov test (K-S test), and quantitative results with classification rates. The performances of the belief classifier are compared with a Bayesian approach. © 2013 Elsevier B.V. All rights reserved.","Bayesian approach; Continuous belief functions; Gaussian and α-stable model; Kolmogorov-Smirnov test; Supervised pattern recognition; Unimodal features"
"Fusing navigation and vision information with the Transferable Belief Model: Application to an intelligent speed limit assistant","2014","Information Fusion","10.1016/j.inffus.2013.05.013","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84892365315&doi=10.1016%2fj.inffus.2013.05.013&partnerID=40&md5=ab42122b280ace706fb3d31d36923a64","The present paper focuses on the fusion, based on imprecise and uncertain information, between a Geographic Information System (GIS) and a Speed Limit Sign Recognition System (SLSRS), performed on camera images. This study is dedicated to the development of a Speed Limit Assistant (SLA) in the context of vehicle driving aid. The proposed SLA is developed within the Evidence Theory framework. The information from the sources is interpreted as belief functions using a non-antagonistic basic belief assignment (bba) in the Transferable Belief Model (TBM) semantics. This bba ensures that the conflict which could appear after the global fusion is exclusively due to source discordances. The present paper proposes a way to manage these discordances by formalizing a conflict-related constraint decision rule. As far as the application is concerned, a two-level (decentralized) fusion architecture is developed. The sensor relevancy is estimated in a first step, followed by the GIS intra-sensor fusion with a maximum of Credibility decision which determines the context-compliant speed candidate considering the road information given by the digital map. This allows the detection of possible errors of the GIS. The multi-sensor fusion then combines the GIS and SLSRS information considering that the sensors are independent and specialized in one speed, each. For the decision, two strategies are adopted. The first one considers the conflict as a threshold for the final speed selection, and so allows the SLA to stay undecided in case of highly conflicting situations. The second strategy employs the 5th version of the Proportional Conflict Redistribution operator. The SLA has been tested in simulation and in real-time experiments by qualitative and quantitative performance evaluations. © 2013 Elsevier B.V. All rights reserved.","Conflict-based decision; Decentralized fusion; Sensor relevancy estimation; Transferable Belief Model"
"Image fusion with morphological component analysis","2014","Information Fusion","10.1016/j.inffus.2013.06.001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84892366523&doi=10.1016%2fj.inffus.2013.06.001&partnerID=40&md5=9b4f52f0aa062da6b00de59f6b226814","Image fusion can produce a single image that describes the scene better than the individual source image. One of the keys to image fusion algorithm is how to effectively and completely represent the source images. Morphological component analysis (MCA) believes that an image contains structures with different spatial morphologies and can be accordingly modeled as a superposition of cartoon and texture components, and that the sparse representations of these components can be obtained by some specific decomposition algorithms which exploit the structured dictionary. Compared with the traditional multiscale decomposition, which has been successfully applied to pixel-level image fusion, MCA employs the morphological diversity of an image and provides more complete representation for an image. Taking advantage of this property, we propose a multi-component fusion method for multi-source images in this paper. In our method, source images are separated into cartoon and texture components, and essential fusion takes place on the representation coefficients of these two components. Our fusion scheme is verified on three kinds of images and compared with six single-component fusion methods. According to the visual perceptions and objective evaluations on the fused results, our method can produce better fused images in our experiments, compared with other single-component fusion methods. © 2013 Elsevier B.V. All rights reserved.","Image fusion; Morphological component analysis; Multi-component fusion; Multiscale transform; Sparse representation"
"A new multiple decisions fusion rule for targets detection in multiple sensors distributed detection systems with data fusion","2014","Information Fusion","10.1016/j.inffus.2013.09.002","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84892365675&doi=10.1016%2fj.inffus.2013.09.002&partnerID=40&md5=31b5b5e0509fd86c75126293003ef68e","Currently, multiple sensors distributed detection systems with data fusion are used extensively in both civilian and military applications. The optimality of most detection fusion rules implemented in these systems relies on the knowledge of probability distributions for all distributed sensors. The overall detection performance of the central processor is often worse than expected due to instabilities of the sensors probability density functions. This paper proposes a new multiple decisions fusion rule for targets detection in distributed multiple sensor systems with data fusion. Unlike the published studies, in which the overall decision is based on single binary decision from each individual sensor and requires the knowledge of the sensors probability distributions, the proposed fusion method derives the overall decision based on multiple decisions from each individual sensor assuming that the probability distributions are not known. Therefore, the proposed fusion rule is insensitive to instabilities of the sensors probability distributions. The proposed multiple decisions fusion rule is derived and its overall performance is evaluated. Comparisons with the performance of single sensor, optimum hard detection, optimum centralized detection, and a multiple thresholds decision fusion, are also provided. The results show that the proposed multiple decisions fusion rule has higher performance than the optimum hard detection and the multiple thresholds detection systems. Thus it reduces the loss in performance between the optimum centralized detection and the optimum hard detection systems. Extension of the proposed method to the case of target detection when some probability density functions are known and applications to binary communication systems are also addressed. © 2013 Elsevier B.V. All rights reserved.","Binary detection systems; Data fusion; Decision fusion; Distributed detection systems; Target detection"
"Introducing spatial neighbourhood in Evidential C-Means for segmentation of multi-source images: Application to prostate multi-parametric MRI","2014","Information Fusion","10.1016/j.inffus.2012.04.002","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84897997380&doi=10.1016%2fj.inffus.2012.04.002&partnerID=40&md5=ff413d2fdc31fbc565adbfac12052445","In this paper we introduce an evidential multi-source segmentation scheme for the extraction of prostate zonal anatomy using multi-parametric MRI. The Evidential C-Means (ECM) classifier was adapted to a segmentation scheme by introducing spatial neighbourhood-based relaxation step in its optimisation process. In order to do so, basic belief assignments on voxels membership were relaxed using distance-weighted combination of belief from spatial neighbours. For the application on prostate tissues, geometric a priori was modelled and used as an additional data source. Our method was first experimented on simulated images to prove the improvement brought to the ECM. A validation study of the segmentation method was then conducted on 31 patients MRI data. In order to take into account inter-observer variability, each MRI was manually segmented by three independent expert radiologists, and an estimated truth was computed using STAPLE algorithm. This validation proved that segmentation obtained with our method is accurate and comparable to expert segmentation. We also show that our segmentation scheme enables to detect and highlight outliers, which could be interpreted by physicians as irregular tissues. The use of belief functions also provides additional information on borders between structures. We do believe these are sources of evidence that could help physicians/algorithms in characterising tissues and structures. The method that is introduced in this paper is a step forward to the use of belief functions theory in the context of multi-source image segmentation. Nevertheless, a full comparison to both baseline (e.g. Gaussian Mixture Models) and recent (e.g. Graph Cut) segmentation methods is needed to assess its performance. © 2012 Elsevier B.V. All rights reserved.","Belief functions; Dempster-Shafer theory; Evidential C-Means; Multi-parametric MRI; Peripheral zone; Prostate; Segmentation; Transition zone; Zonal anatomy"
"Fusion of multimodal medical images using Daubechies complex wavelet transform - A multiresolution approach","2014","Information Fusion","10.1016/j.inffus.2012.09.005","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84897983786&doi=10.1016%2fj.inffus.2012.09.005&partnerID=40&md5=c79f8520c3c7af60616c4ef8b92eb56f","Multimodal medical image fusion is an important task for the retrieval of complementary information from medical images. Shift sensitivity, lack of phase information and poor directionality of real valued wavelet transforms motivated us to use complex wavelet transform for fusion. We have used Daubechies complex wavelet transform (DCxWT) for image fusion which is approximately shift invariant and provides phase information. In the present work, we have proposed a new multimodal medical image fusion using DCxWT at multiple levels which is based on multiresolution principle. The proposed method fuses the complex wavelet coefficients of source images using maximum selection rule. Experiments have been performed over three different sets of multimodal medical images. The proposed fusion method is visually and quantitatively compared with wavelet domain (Dual tree complex wavelet transform (DTCWT), Lifting wavelet transform (LWT), Multiwavelet transform (MWT), Stationary wavelet transform (SWT)) and spatial domain (Principal component analysis (PCA), linear and sharp) image fusion methods. The proposed method is further compared with Contourlet transform (CT) and Nonsubsampled contourlet transform (NSCT) based image fusion methods. For comparison of the proposed method, we have used five fusion metrics, namely entropy, edge strength, standard deviation, fusion factor and fusion symmetry. Comparison results prove that performance of the proposed fusion method is better than any of the above existing fusion methods. Robustness of the proposed method is tested against Gaussian, salt & pepper and speckle noise and the plots of fusion metrics for different noise cases established the superiority of the proposed fusion method. © 2013 Elsevier B.V. All rights reserved.","Daubechies complex wavelet transform; Fusion metrics; Medical imaging; Multimodal medical image fusion; Phase information; Wavelet transform"
"A granulation of linguistic information in AHP decision-making problems","2014","Information Fusion","10.1016/j.inffus.2011.09.003","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84888305716&doi=10.1016%2fj.inffus.2011.09.003&partnerID=40&md5=1177836a4b20463e635963885f101e68","To be fully utilized, linguistic information present in decision-making, has to be made operational through information granulation. This study is concerned with information granulation present in the problems of Analytic Hierarchy Process (AHP), which is available in the characterization of a pairwise assessment of alternatives studied in the decision-making problem. The granulation of entries of reciprocal matrices forming the cornerstone of the AHP is formulated as a optimization problem in which an inconsistency index is minimized by a suitable mapping of the linguistic terms on the predetermined scale. Particle Swarm Optimization is used as an optimization framework. Both individual and group decision-making models of AHP are discussed. © 2011 Elsevier B.V. All rights reserved.","AHP method; Decision-making; Granular computing; Information granules; Linguistic evaluation; Membership function estimation; Particle swarm optimization (PSO)"
"A Lattice-Computing ensemble for reasoning based on formal fusion of disparate data types, and an industrial dispensing application","2014","Information Fusion","10.1016/j.inffus.2011.04.003","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84887108522&doi=10.1016%2fj.inffus.2011.04.003&partnerID=40&md5=d9813bdfd95137c003902b5573644bc9","By ""fusion"" this work means integration of disparate types of data including (intervals of) real numbers as well as possibility/probability distributions defined over the totally-ordered lattice (R, ≤) of real numbers. Such data may stem from different sources including (multiple/multimodal) electronic sensors and/or human judgement. The aforementioned types of data are presented here as different interpretations of a single data representation, namely Intervals' Number (IN). It is shown that the set F of INs is a partially-ordered lattice (F, â̄) originating, hierarchically, from (R, ≤). Two sound, parametric inclusion measure functions σ:FN × FN → [0, 1] result in the Cartesian product lattice (FN, â̄) towards decision-making based on reasoning. In conclusion, the space (FN, â̄) emerges as a formal framework for the development of hybrid intelligent fusion systems/schemes. A fuzzy lattice reasoning (FLR) ensemble scheme, namely FLR pairwise ensemble, or FLRpe for short, is introduced here for sound decision-making based on descriptive knowledge (rules). Advantages include the sensible employment of a sparse rule base, employment of granular input data (to cope with imprecision/uncertainty/vagueness), and employment of all-order data statistics. The advantages as well as the performance of our proposed techniques are demonstrated, comparatively, by computer simulation experiments regarding an industrial dispensing application. © 2011 Elsevier B.V. All rights reserved.","Disparate data fusion; Ensemble of experts; Fuzzy lattice reasoning (FLR); Granular data; Inclusion measure; Intervals' Number (IN); Lattice theory; Lattice-Computing; Sparse rules"
"A generalized framework for mean aggregation: Toward the modeling of cognitive aspects","2014","Information Fusion","10.1016/j.inffus.2011.10.001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84889084097&doi=10.1016%2fj.inffus.2011.10.001&partnerID=40&md5=f6d4d01f77dd9b8675eb84c386ee7305","We provide an overview of mean/averaging operators. We introduce the basic OWA operator and look at some cases of the generalized OWA operator. We next look at the issue of importance weighted mean aggregation. We provide a generalized formulation using a fuzzy measure to convey information about the importances of the different arguments in the aggregation. We look at some different measures and the associated importance formulation they manifest. We further generalize our formulation by allowing for the inclusion of an attitudinal aggregation function. This allows us to implement many different types of aggregation including Max, Min and Median. Finally we provide a simple parameterized formulation for generalized class of mean operators. © 2011 Elsevier B.V. All rights reserved.","Aggregation; Aggregation attitude; Information fusion; Median; OWA operators"
"An approach using Dempster-Shafer theory to fuse spatial data and satellite image derived crown metrics for estimation of forest stand leading species","2013","Information Fusion","10.1016/j.inffus.2012.05.004","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84887826952&doi=10.1016%2fj.inffus.2012.05.004&partnerID=40&md5=1d9d449650662a6140947cfcdbc702cf","Leading species at the forest stand level is a required forest inventory attribute. Information regarding leading species enables the calculation of volume and biomass in support of forest monitoring and reporting activities. In this study, approaches for leading species estimation based upon very high spatial resolution (pixel sided <1 m) have been developed and implemented, with opportunities for improving attribute accuracy using data fusion methods. Over a study region located in the Yukon Territory, Canada, we apply the Dempster-Shafer Theory (DST) to integrate multiple resolutions of satellite imagery (including spatial and spectral), topographic information, and fire disturbance history records for the estimation of leading species. Among the data source combinations tested in the study, the QuickBird panchromatic combined with selected optical channels from Landsat-5 Thematic Mapper (TM) imagery provided the highest overall accuracy (70.4%) for identifying leading species and improved the accuracy by 3.1% over a baseline from a classification-tree based method applied on all data sources. Additional insights to the application of DST to fuse satellite imagery with ancillary data sources to map leading stand species in a boreal environment are also elaborated upon, including the range and distribution of training data and DST mass function establishment. © 2012 Elsevier B.V. All rights reserved.","Evidential reasoning; Forest; Landscape; Mapping; Satellite imagery; Tree crown object metrics"
"Biased sink mobility with adaptive stop times for low latency data collection in sensor networks","2014","Information Fusion","10.1016/j.inffus.2012.04.003","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84885949027&doi=10.1016%2fj.inffus.2012.04.003&partnerID=40&md5=4f4d2910a1c3306e83c1c497b96da7ab","Collecting sensory data using a mobile data sink has been shown to drastically reduce energy consumption at the cost of increasing delivery delay. Towards improved energy-latency trade-offs, we propose a biased, adaptive sink mobility scheme, that adjusts to local network conditions, such as the surrounding density, remaining energy and the number of past visits in each network region. The sink moves probabilistically, favoring less visited areas in order to cover the network area faster, while adaptively stopping more time in network regions that tend to produce more data. We implement and evaluate our mobility scheme via simulation in diverse network settings. Compared to known blind random, non-adaptive schemes, our method achieves significantly reduced latency, especially in networks with non-uniform sensor distribution, without compromising the energy efficiency and delivery success. © 2013 Elsevier Ltd. All rights reserved.","Adaptivity; Random walk; Sensor networks"
"Architecture for management and fusion of context information","2015","Information Fusion","10.1016/j.inffus.2013.10.007","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84904797056&doi=10.1016%2fj.inffus.2013.10.007&partnerID=40&md5=fc6bd590f8bd741cb9d1f735344ac208","Information in a context-aware system has diverse natures. Raw data coming from sensors are aggregated and filtered to create more abstract information, which can be processed by context-aware application components to decide what actions should be performed. This process involves several activities: finding the available sources of information and their types, gathering the data from these sources, facilitating the fusion (aggregation and interpretation) of the different pieces of data, and updating the representation of the context to be used by applications. The reverse path also appears in context-aware systems, from changes in the context representation to trigger actions in certain actuators. FAERIE (Framework for AmI: Extensible Resources for Intelligent Environments) is a framework that facilitates management and fusion of context information at different levels. It is implemented as a distributed blackboard model. Each node of the system has a private blackboard to manage pieces of information that can be accessed by observer components, either locally or remotely (from other nodes) in a transparent way. The use of the framework is illustrated with a case study of an application for guiding people to meetings in a university building. © 2013 Elsevier B.V. All rights reserved.","Context aggregation; Context propagation; Context-aware framework; Context-awareness; Distributed blackboard model"
"Convex ensemble learning with sparsity and diversity","2014","Information Fusion","10.1016/j.inffus.2013.11.003","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84901636774&doi=10.1016%2fj.inffus.2013.11.003&partnerID=40&md5=f485d87b91dae4010546b1fda1a803ec","Classifier ensemble has been broadly studied in two prevalent directions, i.e., to diversely generate classifier components, and to sparsely combine multiple classifiers. While most current approaches are emphasized on either sparsity or diversity only, we investigate classifier ensemble focused on both in this paper. We formulate the classifier ensemble problem with the sparsity and diversity learning in a general mathematical framework, which proves beneficial for grouping classifiers. In particular, derived from the error-ambiguity decomposition, we design a convex ensemble diversity measure. Consequently, accuracy loss, sparseness regularization, and diversity measure can be balanced and combined in a convex quadratic programming problem. We prove that the final convex optimization leads to a closed-form solution, making it very appealing for real ensemble learning problems. We compare our proposed novel method with other conventional ensemble methods such as Bagging, least squares combination, sparsity learning, and AdaBoost, extensively on a variety of UCI benchmark data sets and the Pascal Large Scale Learning Challenge 2008 webspam data. Experimental results confirm that our approach has very promising performance. © 2013 Elsevier B.V. All rights reserved.","Classifier ensemble; Convex quadratic programming; Diversity; Sparsity"
"Detecting trends on the Web: A multidisciplinary approach","2014","Information Fusion","10.1016/j.inffus.2014.01.006","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84901608418&doi=10.1016%2fj.inffus.2014.01.006&partnerID=40&md5=33021270e8c099bdde8cf4e156fa0282","This paper introduces a framework for trend modeling and detection on the Web through the usage of Opinion Mining and Topic Modeling tools based on the fusion of freely available information. This framework consists of a four step model that runs periodically: crawl a set of predefined sources of documents; search for potential sources and extract topics from the retrieved documents; retrieve opinionated documents from social networks for each detected topic and extract sentiment information from them. The proposed framework was applied to a set of 20 sources of documents over a period of 8 months. After the analysis period and that the proposed experiments were run, an F-Measure of 0.56 was obtained for the detection of significant events, implying that the proposed framework is a feasible model of how trends could be represented through the analysis of documents freely available on the Web. © 2014 Elsevier B.V. All rights reserved.","Topic modeling; Trend detection; Web opinion mining"
"Combining cluster analysis with classifier ensembles to predict financial distress","2014","Information Fusion","10.1016/j.inffus.2011.12.001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84887039251&doi=10.1016%2fj.inffus.2011.12.001&partnerID=40&md5=dba355a9cf08c9d81d9a1dce9fcb370e","The ability to accurately predict business failure is a very important issue in financial decision-making. Incorrect decision-making in financial institutions is very likely to cause financial crises and distress. Bankruptcy prediction and credit scoring are two important problems facing financial decision support. As many related studies develop financial distress models by some machine learning techniques, more advanced machine learning techniques, such as classifier ensembles and hybrid classifiers, have not been fully assessed. The aim of this paper is to develop a novel hybrid financial distress model based on combining the clustering technique and classifier ensembles. In addition, single baseline classifiers, hybrid classifiers, and classifier ensembles are developed for comparisons. In particular, two clustering techniques, Self-Organizing Maps (SOMs) and k-means and three classification techniques, logistic regression, multilayer-perceptron (MLP) neural network, and decision trees, are used to develop these four different types of bankruptcy prediction models. As a result, 21 different models are compared in terms of average prediction accuracy and Type I & II errors. By using five related datasets, combining Self-Organizing Maps (SOMs) with MLP classifier ensembles performs the best, which provides higher predication accuracy and lower Type I & II errors. © 2011 Elsevier B.V. All rights reserved.","Bankruptcy prediction; Classifier ensembles; Credit scoring; Financial distress; Hybrid classifiers; Machine learning"
"Patterns for context-based knowledge fusion in decision support systems","2015","Information Fusion","10.1016/j.inffus.2013.10.010","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84904793137&doi=10.1016%2fj.inffus.2013.10.010&partnerID=40&md5=d1279136470d661917d2d2188c10fafb","The here presented research focuses on the context-based knowledge fusion patterns. Patterns are discovered based on an analysis and investigation of knowledge fusion processes in a context aware decision support system at the operational stage of the system functioning. At this stage the context-based knowledge fusion processes are manifested around the context. The patterns are generalized in regard to the following three aspects: (1) the effects that the knowledge fusion processes produce in the system; (2) the preservation of internal structures for the context and multiple sources the information/knowledge is fused from; and (3) the preservation of multiple sources and the context autonomies. At that, seven knowledge fusion patterns have been discovered: simple fusion, extension, instantiated fusion, configured fusion, adaptation, flat fusion, and historical fusion. © 2013 Elsevier B.V. All rights reserved.","Context aware decision support; Knowledge fusion patterns; Ontology-based context"
"Integrated biometrics template protection technique based on fingerprint and palmprint feature-level fusion","2014","Information Fusion","10.1016/j.inffus.2013.09.001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84892369281&doi=10.1016%2fj.inffus.2013.09.001&partnerID=40&md5=e8bbbb2ab9e7a8985982cff827ea695a","Multi-biometric systems are known to be universal and more accurate in biometric recognition. However, the storage of multiple biometric templates as separate entities pose major threats to user privacy and system security. Therefore, we propose to fuse multiple biometric modalities at the feature level in order to obtain an integrated template and to secure the fused templates using a hybrid template protection method. The proposed method is made out of a feature transformation technique known as Random Tiling and an equal-probable 2N discretization scheme. The former enables the revocability of the template and the latter converts the feature elements into binary representations according to the area under the genuine interval curve, in order to offer better privacy protection to the template. Our experimental results show that the proposed multi-biometric template protection scheme demonstrates better verification results as compared to their unibiometric counterparts while preserving template security. © 2013 Elsevier B.V. All rights reserved.","Discretization; Feature level fusion; Random tiling; Template protection"
"Consensus in multi-expert decision making problems using penalty functions defined over a Cartesian product of lattices","2014","Information Fusion","10.1016/j.inffus.2011.10.002","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84888286997&doi=10.1016%2fj.inffus.2011.10.002&partnerID=40&md5=8da4d8f86e072596d652e7d6d1ed6563","In this paper we introduce an algorithm to aggregate the preference relations provided by experts in multi-expert decision making problems. Instead of using a single aggregation function for the whole process, we start from a set of aggregation functions and select, by means of consensus done through penalty functions, the most suitable aggregation function in order to aggregate the individual preferences for each of the elements. An advantage of the method that we propose is that it allows us to recover the classical methods, just by using a single aggregation function. We also present a generalization of the concepts of restricted dissimilarity function and distance between sets for the case where we are working with a Cartesian product of lattices and use such concepts to build penalty functions. Finally, we propose an algorithm that allows us to choose the best combination of aggregation functions for a multi-expert decision making problem. © 2011 Elsevier B.V. All rights reserved.","Fuzzy distance; Multipurpose decision making; Penalty functions; Restricted dissimilarity function; Selection process"
"A fuzzy graph matching approach in intelligence analysis and maintenance of continuous situational awareness","2014","Information Fusion","10.1016/j.inffus.2013.05.006","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84892364695&doi=10.1016%2fj.inffus.2013.05.006&partnerID=40&md5=5aa781a605d4afec169896dad9f62806","In intelligence analysis a situation of interest is commonly obscured by the more voluminous amount of unimportant data. This data can be broadly divided into two categories, hard or physical sensor data and soft or human observed data. Soft intelligence data is collected by humans through human interaction, or human intelligence (HUMINT). The value and difficulty in manual processing of these observations due to the volume of available data and cognitive limitations of intelligence analysts necessitate an information fusion approach toward their understanding. The data representation utilized in this work is an attributed graphical format. The uncertainties, size and complexity of the connections within this graph make accurate assessments difficult for the intelligence analyst. While this graphical form is easier to consider for an intelligence analyst than disconnected multi-source human and sensor reports, manual traversal for the purpose of obtaining situation awareness and accurately answering priority information requests (PIRs) is still infeasible. To overcome this difficulty an automated stochastic graph matching approach is developed. This approach consists of three main processes: uncertainty alignment, graph matching result initialization and graph matching result maintenance. Uncertainty alignment associates with raw incoming observations a bias adjusted uncertainty representation representing the true value containing spread of the observation. The graph matching initialization step provides template graph to data graph matches for a newly initialized situation of interest (template graph). Finally, the graph matching result maintenance algorithm continuously updates graph matching results as incoming observations augment the cumulative data graph. Throughout these processes the uncertainties present in the original observations and the template to data graph matches are preserved, ultimately providing an indication of the uncertainties present in the current situation assessment. In addition to providing the technical details of this approach, this paper also provides an extensive numerical testing section which indicates a significant performance improvement of the proposed algorithm over a leading commercial solver. © 2013 Elsevier B.V. All rights reserved.","Fuzzy systems; Graph matching; Incremental graph matching; Situational awareness; Stochastic graphical methods"
"User-adapted travel planning system for personalized schedule recommendation","2015","Information Fusion","10.1016/j.inffus.2013.05.011","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84904805114&doi=10.1016%2fj.inffus.2013.05.011&partnerID=40&md5=0ea6d0cd15adbb6b6d7c42b45ae09e2d","Recently, the Internet has made a lot of services and products appear online provided by many tourism sectors. By this way, many information such as timetables, routes, accommodations, and restaurants are easily available to help travelers plan their travels. However, how to plan the most appropriate travel schedule under simultaneously considering several factors such as tourist attractions visiting, local hotels selecting, and travel budget calculation is a challenge. This gives rise to our interest in exploring the recommendation systems with relation to schedule recommendation. Additionally, the personalized concept is not implemented completely in most of travel recommendation systems. One notable problem is that they simply recommended the most popular travel routes or projects, and cannot plan the travel schedule. Moreover, the existing travel planning systems have limits in their capabilities to adapt to the changes based on users' requirements and planning results. To tackle these problems, we develop a personalized travel planning system that simultaneously considers all categories of user requirements and provides users with a travel schedule planning service that approximates automation. A novel travel schedule planning algorithm is embedded to plan travel schedules based on users' need. Through the user-adapted interface and adjustable results design, users can replace any unsatisfied travel unit to specific one. The feedback mechanism provides a better accuracy rate for next travel schedule to new users. An experiment was conducted to examine the satisfaction and use intention of the system. The results showed that participants who used the system with schedule planning have statistical significant on user satisfaction and use intention. We also analyzed the validity of applying the proposed algorithm to a user preference travel schedule through a number of practical system tests. In addition, comparing with other travel recommendation systems, our system had better performance on the schedule adjustment, personalization, and feedback giving. © 2013 Elsevier B.V. All rights reserved.","e-Tourism; Personalization; Recommendation system; Travel planning"
"Consistency and consensus measures for linguistic preference relations based on distribution assessments","2014","Information Fusion","10.1016/j.inffus.2012.01.006","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84888300532&doi=10.1016%2fj.inffus.2012.01.006&partnerID=40&md5=500ffd28bfa6b587c46646af177dce14","In this paper, we propose the concept of distribution assessments in a linguistic term set, and study the operational laws of linguistic distribution assessments. The weighted averaging operator and the ordered weighted averaging operator for linguistic distribution assessments are presented. We also develop the concept of distribution linguistic preference relations, whose elements are linguistic distribution assessments. Further, we study the consistency and consensus measures for group decision making based on distribution linguistic preference relations. Two desirable properties of the proposed measures are shown. A consensus model also has been developed to help decision makers improve the consensus level among distribution linguistic preference relations. Finally, illustrative numerical examples are given. The results in this paper provide a theoretic basis for the application of linguistic distribution assessments in group decision making. © 2012 Elsevier B.V. All rights reserved.","Consensus; Consistency; Distribution assessments; Group decision making; Linguistic preference relations"
"Data fusion for high spatial resolution LAI estimation","2014","Information Fusion","10.1016/j.inffus.2012.04.001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84887081326&doi=10.1016%2fj.inffus.2012.04.001&partnerID=40&md5=e0376e93f6cd0e1b6f5d661006d78ae2","Leaf Area Index (LAI) is a critical variable for forest management. It is difficult to obtain accurate LAI estimations of high spatial resolution over large areas. Local estimations can be obtained from in situ field measurements. Extrapolation of local measurements is prone to error. Remote sensing LAI estimation products, such as the one provided by MODIS are of very low resolution and subject to criticism in recent validation works. Forest management requires increasingly high resolution estimations of LAI. We propose a data fusion process for high spatial resolution estimation of the LAI over a large area, combining several heterogeneous information sources: field sampled data, elevation data and remote sensing data. The process makes use of spatial interpolation techniques. We follow a hybrid validation approach that combines the conventional prediction error measures with a spatial validation based on image segmentation. We obtain encouraging results of this information fusion process on data from a forest area in the north of Portugal. © 2012 Elsevier B.V. All rights reserved.","Hybrid validation; Kriging; Leaf Area Index (LAI); Remote sensing; Vegetation indices"
"Ordering based decision making - A survey","2013","Information Fusion","10.1016/j.inffus.2012.10.005","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84887820603&doi=10.1016%2fj.inffus.2012.10.005&partnerID=40&md5=06d88c1f5107690425455d949cfb2149","Decision making is the crucial step in many real applications such as organization management, financial planning, products evaluation and recommendation. Rational decision making is to select an alternative from a set of different ones which has the best utility (i.e., maximally satisfies given criteria, objectives, or preferences). In many cases, decision making is to order alternatives and select one or a few among the top of the ranking. Orderings provide a natural and effective way for representing indeterminate situations which are pervasive in commonsense reasoning. Ordering based decision making is then to find the suitable method for evaluating candidates or ranking alternatives based on provided ordinal information and criteria, and this in many cases is to rank alternatives based on qualitative ordering information. In this paper, we discuss the importance and research aspects of ordering based decision making, and review the existing ordering based decision making theories and methods providing future research directions. © 2012 Elsevier B.V. All rights reserved.","Aggregation; Decision making; Lattice; Logic; Ordering relation; Preference"
"Spatial query processing in wireless sensor networks - A survey","2014","Information Fusion","10.1016/j.inffus.2012.08.006","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84885948044&doi=10.1016%2fj.inffus.2012.08.006&partnerID=40&md5=6886746cd09f3e96bba1880cef76f7fc","Wireless sensor networks (WSN) are particularly useful for obtaining data concerning events limited to a well-defined geographic region, such as a disaster site or a malfunctioning subsection of a factory plant. Such applications typically use spatial queries, which are SQL-like queries where location constraints are imposed on the collected data. Further, spatial queries allow changing the set of nodes (the region of interest) at runtime. This work surveys spatial queries in WSN. Due to the particular energy and resource constraints of WSN, spatial queries are performed by mechanisms having several stages, each of them implemented using localized distributed algorithms. This article categorizes the existing strategies for each stage, in order to ease the understanding of the state of the art. Finally, we analyze the most recent works on spatial query processing, identifying which classes of algorithms are used on each stage. © 2012 Elsevier B.V. All rights reserved.","KNN; Spatial query; Window query; Wireless sensor network"
"Dynamic clustering of multi-modal sensor networks in urban scenarios","2014","Information Fusion","10.1016/j.inffus.2012.09.003","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84885948283&doi=10.1016%2fj.inffus.2012.09.003&partnerID=40&md5=6b2f6af99f4884c27b7246aa6f232305","The paper addresses the issue of self-adaptation of a multi-modal sensor network with mobile sensors to better observe and track events of interest in a changing urban scenario by presenting a software module (middleware) called Event-driven Network Controller (ENC) that resides at every sensor node in the network and is independent of the sensor type. ENC translates the requirements of the application layer into messages that are diffused locally with the purpose of clustering multi-modal sensor nodes in the vicinity of an event and dynamically changing the local network topology, all to enhance the quality of the multi-modal data fusion. ENC is implemented in NS-2 to show its applicability for tracking a mobile target in an urban scenario using a network of pressure, video, and magnetic sensors. © 2013 Elsevier Ltd. All rights reserved.","Multi-modal data fusion; Network controller; Urban scenario"
"Fusion of multispectral and panchromatic images via sparse representation and local autoregressive model","2014","Information Fusion","10.1016/j.inffus.2013.11.004","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84901639992&doi=10.1016%2fj.inffus.2013.11.004&partnerID=40&md5=351eeb75ee63682c8264bbb2eea7f017","In this paper, a novel model-based pan-sharpening method via sparse representation and local autoregressive (AR) model is proposed. To recover the high-resolution multispectral (HRMS) image from the observed images, we impose sparsity prior on the unknown HRMS image in the restoration model. The quality of the recovered HRMS image depends on the employed sparse domain. Hence, a new sparse representation model for the HRMS image is constructed, in which we suppose that the low-frequency and high-frequency components of the HRMS image can be sparsely represented by a spectral dictionary and a spatial-detail dictionary respectively. The spectral dictionary and spatial-detail dictionary are learned from the source images: low-spatial-resolution multispectral (LRMS) image and high-spatial-resolution panchromatic (HRP) image adaptively. Additionally, local autoregressive (AR) model is employed to improve the spatial structure of the HRMS image patch. Firstly, a set of AR model parameters are learned from the PAN image patches. Then, the local spatial structure of a given HRMS image patch is regularized by an AR model with the learned parameters. By solving the l1 -norm optimization problem, the HRMS image can be well reconstructed. Experiments are carried out on very high-resolution QuickBird and GeoEye-1 images. In the simulated and real experiments, our proposed method demonstrates its good performance in terms of visual analysis and quantitative evaluation. © 2014 Elsevier B.V. All rights reserved.","Fusion; Local autoregressive model (AR); Multispectral (MS); Panchromatic (PAN); Sparse representation"
"Pansharpening of multispectral images using the nonseparable framelet lifting transform with high vanishing moments","2014","Information Fusion","10.1016/j.inffus.2014.02.005","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84901631991&doi=10.1016%2fj.inffus.2014.02.005&partnerID=40&md5=664b5878c54906ef5daeee9cfc4f528b","This paper proposes a novel nonseparable lifting scheme for wavelet frames with high vanishing moments. A specific nonseparable framelet lifting transform (NFLT), combined with a modified covariance intersection (CI) algorithm, has been applied to pansharpening of multispectral images. Experiments are carried out on the multispectral and panchromatic images acquired by the SPOT, QuickBird and Landsat spaceborne sensors. Benefiting from the high order of vanishing moments, the proposed NFLT can distinguish the low- and high-frequency efficiently and can compact most of the energy into the low-pass subband. Thus the spectral distortion can be minimized. Experimental results show that the NFLT-CI method reduces the spectral distortion while improves the spatial resolution simultaneously, and outperforms the other state-of-the-art methods derived from various transforms and injection models. © 2014 Elsevier Ltd. All rights reserved.","Covariance intersection; Lifting scheme; Nonseparable wavelet frame; Pansharpening; Vanishing moment"
"Automatic evaluation of air mission routes with respect to combat survival","2014","Information Fusion","10.1016/j.inffus.2013.12.001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84901591357&doi=10.1016%2fj.inffus.2013.12.001&partnerID=40&md5=370ed5e1cc68a60a1ca7f55953725e06","Aircraft flying in hostile environments are exposed to ground-based air defense systems. It is not always possible to both accomplish the mission and fly outside the range of the enemy's weapon systems, especially if the positions of the enemy's systems are not perfectly known. Automatic evaluation of mission routes from a combat survival perspective could therefore aid the pilots to plan their missions. When updated information regarding the positions and capabilities of the enemy's systems is received during flight, the route could be re-evaluated and the mission could be re-planed or aborted if it is assessed to be too dangerous. The survivability model presented here describes the relation between the aircraft and the enemy's defense systems. It calculates the probabilities that the aircraft is in certain modes along the route, e.g., undetected, tracked or hit. Contrary to previous work, the model is able to capture that the enemy's systems can communicate and that the enemy must track the aircraft before firing a weapon. The survivability model is used to calculate an expected cost for the mission route. The expected cost has the attractive properties of summarizing the route into a single value and is able to take the pilot's risk attitude for the mission into account. The evaluation of the route is influenced by uncertainty regarding the locations of the enemy's sensors and weapons. Monte Carlo simulations are used to capture this uncertainty by calculating the mean and standard deviation for the expected cost. These two parameters give the pilots an assessment of the danger associated with the route as well as the reliability of this assessment. The paper concludes that evaluating routes with the survivability model and the expected cost could aid the pilots to plan and execute their missions. © 2014 Elsevier B.V. All rights reserved.","Air mission route; Fighter aircraft; Markov model; Survivability; Threat assessment"
"A consensus framework for multiple attribute group decision analysis in an evidential reasoning context","2014","Information Fusion","10.1016/j.inffus.2011.12.002","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84888307294&doi=10.1016%2fj.inffus.2011.12.002&partnerID=40&md5=0d390e166c51174dbfe2f4cddb7d9363","In group decision analysis, consensus has usually been reached by one of two strategies, modifying assessments of experts and adjusting weights of experts. Due to lack of attention paid to the unauthentic change and neglect of experts' assessments, respectively, this paper develops a consensus framework to combine them. The consensus framework is implemented in an evidential reasoning context. It can deal effectively with the situation of missing assessments on specific attributes (the attributes are called missing attributes), which may be caused by lack or limitation of knowledge, experience, and available data about the problem domain. The recommendations generated based on the idea of reaching the maximal consensus on missing attributes and group discussion help experts to give effective assessments on missing attributes. Furthermore, the consensus framework contains a feedback mechanism to provide guidance for experts in order to accelerate convergence to consensus. Identification rules at three levels, including the attribute, alternative and global levels, and a suggestion rule are involved in the feedback mechanism. The former indicates that specific experts are recommended to renew their identified assessments damaging consensus, and the latter generates appropriate recommendations for the experts to renew their assessments. If consensus is still not reached after two consecutive rounds of recommendation generating and assessment renewing, then optimization algorithms still constructed at three levels are used to adjust subjective weights of experts so as to facilitate convergence to consensus. An engineering project management software selection problem is solved by the consensus framework to demonstrate its detailed implementation process, validity, and applicability. © 2011 Elsevier B.V. All rights reserved.","Consensus framework; Evidential reasoning approach; Feedback mechanism; Missing assessment; Multiple attribute group decision analysis; Optimization algorithm"
"Composite distance based approach to von Mises mixture reduction","2014","Information Fusion","10.1016/j.inffus.2014.01.003","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84901624830&doi=10.1016%2fj.inffus.2014.01.003&partnerID=40&md5=7ab22130ac20dec495dfb87b921e4a73","This paper presents a systematic approach for component number reduction in mixtures of exponential families, putting a special emphasis on the von Mises mixtures. We propose to formulate the problem as an optimization problem utilizing a new class of computationally tractable composite distance measures as cost functions, namely the composite Rényi α-divergences, which include the composite Kullback-Leibler distance as a special case. Furthermore, we prove that the composite divergence bounds from above the corresponding intractable Rényi α-divergence between a pair of mixtures. As a solution to the optimization problem we synthesize that two existing suboptimal solution strategies, the generalized k-means and a pairwise merging approach, are actually minimization methods for the composite distance measures. Moreover, in the present paper the existing joining algorithm is also extended for comparison purposes. The algorithms are implemented and their reduction results are compared and discussed on two examples of von Mises mixtures: a synthetic mixture and a real-world mixture used in people trajectory shape analysis. © 2014 Elsevier B.V. All rights reserved.","Composite distance measure; Mixture component number reduction; People trajectory shape analysis; Rényi α-divergence; Von Mises mixture"
"Object tracking and credal classification with kinematic data in a multi-target context","2014","Information Fusion","10.1016/j.inffus.2014.01.007","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84901643571&doi=10.1016%2fj.inffus.2014.01.007&partnerID=40&md5=bf89d57aaa2e93dfffceb7d23edcfb87","This article proposes a method to classify multiple maneuvering targets at the same time. This task is a much harder problem than classifying a single target, as sensors do not know how to assign captured observations to known targets. This article extends previous results scattered in the literature and unifies them in a single global framework with belief functions. Through two examples, it is shown that the full algorithm using belief functions improves results obtained with standard Bayesian classifiers and that it can be applied to a large variety of applications. © 2014 Elsevier B.V. All rights reserved.","Credal classification; Data assignment; Multi-target tracking; Target management"
"Some hybrid weighted averaging operators and their application to decision making","2014","Information Fusion","10.1016/j.inffus.2011.06.001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84887088593&doi=10.1016%2fj.inffus.2011.06.001&partnerID=40&md5=fdce44046238ffa6b396c58fb1616239","Two new hybrid weighted averaging operators for aggregating crisp and fuzzy information are proposed, some of which desirable properties are studied. These operators helps us to overcome the drawback in the existed reference. With respect to the proposed operators, three special types of preferred centroid of triangular fuzzy number are defined. On the base of these preferred centroid, we develop two algorithms to deal with decision making problems. Two numerical examples are provided to illustrate the practicality and validity of the proposed methods. © 2011 Elsevier B.V. All rights reserved.","Decision making; Fuzzy number; Hybrid weighted averaging operator; OWA operator"
"A belief function distance metric for orderable sets","2013","Information Fusion","10.1016/j.inffus.2013.03.003","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84876354757&doi=10.1016%2fj.inffus.2013.03.003&partnerID=40&md5=6c824b5a8e73a2f0c70e0e16ae0f976c","This paper describes a new metric for characterizing conflict between belief assignments. The new metric, specifically designed to quantify conflict on orderable sets, uses a Hausdorff-based measure to account for the distance between focal elements. This results in a distance metric that can accurately measure conflict between belief assignments without saturating simply because two assignments do not have common focal elements. The proposed metric is particularly attractive in sensor fusion applications in which belief is distributed on a continuous measurement space. Several example cases demonstrate the proposed metric's performance, and comparisons with other common measures of conflict show the significant benefit of using the proposed metric in cases where a sensor's error and noise characteristics are not known precisely a priori. © 2013 Elsevier B.V. All rights reserved.","Dempster-Shafer theory; Distance metric; Orderable sets; Sensor fault detection"
"Feature structure fusion and its application","2014","Information Fusion","10.1016/j.inffus.2014.01.002","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84901640581&doi=10.1016%2fj.inffus.2014.01.002&partnerID=40&md5=f4025720338f3a264a4615bebb619825","The structure of data is important to the recognition of data. It is a fundamental question how measures and complements the structure of multi-features, because the fusion structure of multi-features is more complete than that of the single feature. To settle the question, we propose three methods for feature structure fusion in feature vectors or feature vector spaces. Firstly, the applicability of the different metric is analyzed. Secondly, optimization questions of various features are constructed based on manifold learning methods. Finally, multiple target optimization questions are transformed to a single target optimization question, and the principle of feature structure fusion is uncovered. In the classification of shape analysis and human action recognition, it is proven that structure fusion methods are effective. © 2014 Published by Elsevier B.V. All rights reserved.","Feature classification; Feature structure fusion; Structure metric"
"A new image fusion performance metric based on visual information fidelity","2013","Information Fusion","10.1016/j.inffus.2011.08.002","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84880331058&doi=10.1016%2fj.inffus.2011.08.002&partnerID=40&md5=27f0b1fa21351f29e770a5175e4a4d91","Because subjective evaluation is not adequate for assessing work in an automatic system, using an objective image fusion performance metric is a common approach to evaluate the quality of different fusion schemes. In this paper, a multi-resolution image fusion metric using visual information fidelity (VIF) is presented to assess fusion performance objectively. This method has four stages: (1) Source and fused images are filtered and divided into blocks. (2) Visual information is evaluated with and without distortion information in each block. (3) The visual information fidelity for fusion (VIFF) of each sub-band is calculated. (4) The overall quality measure is determined by weighting the VIFF of each sub-band. In our experiment, the proposed fusion assessment method is compared with several existing fusion metrics using the subjective test dataset provided by Petrovic. We found that VIFF performs better in terms of both human perception matching and computational complexity. © 2011 Elsevier B.V. All rights reserved.","Image fusion assessment Fused image quality Visual information fidelity Visual information fidelity for fusion"
"Information fusion in data privacy: A survey","2012","Information Fusion","10.1016/j.inffus.2012.01.001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84861597722&doi=10.1016%2fj.inffus.2012.01.001&partnerID=40&md5=f876677ce4eeb8fe700ce5bd9c5abc2a","In this paper, we review the role of information fusion in data privacy. To that end, we introduce data privacy, and describe how information and data fusion are used in some fields of data privacy. Our study is focused on the use of aggregation for privacy protections, and record linkage techniques. © 2011 Elsevier B.V. All rights reserved.","Data privacy; Information fusion; Microaggregation; Record linkage"
"A novel dynamic model for multiple pedestrians tracking in extremely crowded scenarios","2013","Information Fusion","10.1016/j.inffus.2012.08.004","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84885418944&doi=10.1016%2fj.inffus.2012.08.004&partnerID=40&md5=d969e865ef9aa60394916867010d3341","Tracking hundreds of persons in the large and high density scenarios is a particularly challenging task due to the frequent occlusions and merged measurements. In such circumstances, a stronger dynamic model for prediction usually plays a more important role in the overall tracking process. In this paper, we propose an elaborate dynamic model for multiple pedestrians tracking in the extremely crowded environments. The novelty of this tracking model is that: The global semantic scene structure, local instantaneous crowd flow and the social interactions among persons are taken into account together and combined into an unified approach, which can make the prediction for persons' motion more powerful and accurate. We apply the proposed model by using an online ""tracking-learning"" framework, which can not only perform the robust tracking in the extremely crowded scenarios, but also ensures that the entire process is fully automatic and online. The testing is conducted on the JR subway station of Tokyo, and the experimental results show that the system with our tracking model can robustly track more than 180 targets at the same time while the occlusions and merge/split frequently occur. © 2012 Elsevier B.V.","Multi-target tracking motion model laser-based surveillance"
"An ID-based client authentication with key agreement protocol for mobile client-server environment on ECC with provable security","2012","Information Fusion","10.1016/j.inffus.2011.01.001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-80051571433&doi=10.1016%2fj.inffus.2011.01.001&partnerID=40&md5=944e1781d644b5eca03799f85cc9088d","Recently, lots of remote user authentication schemes are implemented on elliptic curve cryptosystem (ECC) to reduce the computation loads for mobile devices. However, most of those remote user authentication schemes on ECC suffer from different attacks and can not provide provable security. Therefore, we propose an ID-based remote mutual authentication with key agreement scheme on ECC in this paper. The proposed scheme not only provides mutual authentication but also supports a session key agreement between the user and the server. The scheme also provides the known session key security, the perfect forward secrecy, the no key-compromise impersonation, the no unknown key-share and the no key control. Compared with the related works, the proposed scheme is more efficient and practical for mobile devices. We also give a security proof under the random oracle.","Elliptic curve cryptosystem; ID-based; Key agreement; Modular multiplication; Mutual authentication; Perfect forward secrecy"
"SAR image multiclass segmentation using a multiscale and multidirection triplet Markov fields model in nonsubsampled contourlet transform domain","2013","Information Fusion","10.1016/j.inffus.2012.12.001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84887807143&doi=10.1016%2fj.inffus.2012.12.001&partnerID=40&md5=d4744222e8d4faa515e848a4801878c2","Triplet Markov fields (TMFs) model recently proposed is to deal with nonstationary image segmentation and has achieved promising results. In this paper, we propose a multiscale and multidirection TMF model for nonstationary synthetic aperture radar (SAR) image multiclass segmentation in nonsubsampled contourlet transform (NSCT) domain, named as NSCT-TMF model. NSCT-TMF model is capable of capturing the contextual information of image content in the spatial and scale spaces effectively by the construction of multiscale energy functions. And the derived multiscale and multidirection likelihoods of NSCT-TMF model can capture the dependencies of NSCT coefficients across scale and directions. In this way, the proposed model is able to achieve multiscale information fusion in terms of image configuration and features in underlying labeling process. Experimental results demonstrate that due to the effective propagation of the contextual information, NSCT-TMF model turns out to be more robust against speckle noise and improves the performance of nonstationary SAR image segmentation. © 2012 Elsevier B.V. All rights reserved.","Multiscale information fusion; NSCT-HMT; NSCT-TMF energy function; NSCT-TMF model; SAR image multiclass segmentation"
"Statistical models and learning algorithms for ordinal regression problems","2013","Information Fusion","10.1016/j.inffus.2012.05.006","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84880332987&doi=10.1016%2fj.inffus.2012.05.006&partnerID=40&md5=2d900718d7bd874e09a3ef683618dfd8","In this study, we propose a learning algorithm for ordinal regression problems. In most existing learning algorithms, the threshold or location model is assumed to be the statistical model. For estimation of conditional probability of labels for a given covariate vector, we extended the location model to apply ordinal regressions. We present this learning algorithm using the squared-loss function with the location-scale models for estimating conditional probability. We prove that the estimated conditional probability satisfies the monotonicity of the distribution function. Furthermore, we have conducted numerical experiments to compare these proposed methods with existing approaches. We found that, in its ability to predict labels, our method may not have an advantage over existing approaches. However, for estimating conditional probabilities, it does outperform the learning algorithm using location models. © 2011 Elsevier B.V. All rights reserved.","Ordinal regression Location models Location-scale models Conditional probability"
"Pixel-level image fusion with simultaneous orthogonal matching pursuit","2012","Information Fusion","10.1016/j.inffus.2010.04.001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-80053987231&doi=10.1016%2fj.inffus.2010.04.001&partnerID=40&md5=68544e5651c860ccb89cdc97be6c0bb9","Pixel-level image fusion integrates the information from multiple images of one scene to get an informative image which is more suitable for human visual perception or further image-processing. Sparse representation is a new signal representation theory which explores the sparseness of natural signals. Comparing to the traditional multiscale transform coefficients, the sparse representation coefficients can more accurately represent the image information. Thus, this paper proposes a novel image fusion scheme using the signal sparse representation theory. Because image fusion depends on local information of source images, we conduct the sparse representation on overlapping patches instead of the whole image, where a small size of dictionary is needed. In addition, the simultaneous orthogonal matching pursuit technique is introduced to guarantee that different source images are sparsely decomposed into the same subset of dictionary bases, which is the key to image fusion. The proposed method is tested on several categories of images and compared with some popular image fusion methods. The experimental results show that the proposed method can provide superior fused image in terms of several quantitative fusion evaluation indexes. © 2011 Elsevier B.V. All rights reserved.","Image fusion; Multi-sensor fusion; Multiscale transform; Simultaneous orthogonal matching pursuit; Sparse representation"
"Multisensor data fusion: A review of the state-of-the-art","2013","Information Fusion","10.1016/j.inffus.2011.08.001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84867336190&doi=10.1016%2fj.inffus.2011.08.001&partnerID=40&md5=607bb29552a0451e4b7bd30391ef3311","There has been an ever-increasing interest in multi-disciplinary research on multisensor data fusion technology, driven by its versatility and diverse areas of application. Therefore, there seems to be a real need for an analytical review of recent developments in the data fusion domain. This paper proposes a comprehensive review of the data fusion state of the art, exploring its conceptualizations, benefits, and challenging aspects, as well as existing methodologies. In addition, several future directions of research in the data fusion community are highlighted and described. © 2011 Elsevier B.V. All rights reserved.","Fusion methodologies; Multisensor data fusion; Taxonomy"
"Improving Logitboost with prior knowledge","2013","Information Fusion","10.1016/j.inffus.2011.11.004","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84880332427&doi=10.1016%2fj.inffus.2011.11.004&partnerID=40&md5=1f9543c14634685b7d81cb48ee8edad5","The purpose of this study is to incorporate prior knowledge into a boosting algorithm. Existing approaches require additional samples that represent the prior knowledge. Moreover, in order to adjust the balance between the information in training samples and the prior knowledge in the data domain, one needs to repeat the boosting algorithm with a different regularization parameter. These properties lead to costly computation. In this paper, we propose a boosting algorithm with prior knowledge that avoids computational issues. In our method, the mixture distribution of the estimator and prior knowledge is considered. We describe numerical experiments showing the effectiveness of our approach. © 2012 Elsevier B.V. All rights reserved.","Boosting Prior knowledge Mixture distribution Multi-class"
"Optimizing biosurveillance systems that use threshold-based event detection methods","2012","Information Fusion","10.1016/j.inffus.2009.12.002","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84855887388&doi=10.1016%2fj.inffus.2009.12.002&partnerID=40&md5=8d9ecb805e730013900c57ec8f16fbf6","We describe a methodology for optimizing a threshold detection-based biosurveillance system. The goal is to maximize the system-wide probability of detecting an ""event of interest"" against a noisy background, subject to a constraint on the expected number of false signals. We use nonlinear programming to appropriately set detection thresholds taking into account the probability of an event of interest occurring somewhere in the coverage area. Using this approach, public health officials can ""tune"" their biosurveillance systems to optimally detect various threats, thereby allowing practitioners to focus their public health surveillance activities. Given some distributional assumptions, we derive a one-dimensional optimization methodology that allows for the efficient optimization of very large systems. We demonstrate that optimizing a syndromic surveillance system can improve its performance by 20-40%. © 2009 Elsevier B.V. All rights reserved.","Biosurveillance; Bioterrorism; Optimization; Public health; Shewhart chart; Syndromic surveillance"
"A comparative study of classifier combination applied to nlp tasks","2013","Information Fusion","10.1016/j.inffus.2012.05.001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84885431390&doi=10.1016%2fj.inffus.2012.05.001&partnerID=40&md5=85ff925f0a305edc963533e346456c60","The paper is devoted to a comparative study of classifier combination methods, which have been successfully applied to multiple tasks including Natural Language Processing (NLP) tasks. There is variety of classifier combination techniques and the major difficulty is to choose one that is the best fit for a particular task. In our study we explored the performance of a number of combination methods such as voting, Bayesian merging, behavior knowledge space, bagging, stacking, feature sub-spacing and cascading, for the part-of-speech tagging task using nine corpora in five languages. The results show that some methods that, currently, are not very popular could demonstrate much better performance. In addition, we learned how the corpus size and quality influence the combination methods performance. We also provide the results of applying the classifier combination methods to the other NLP tasks, such as name entity recognition and chunking. We believe that our study is the most exhaustive comparison made with combination methods applied to NLP tasks so far. © 2012 Elsevier B.V.","Classifier combination; Natural language processing; Part-of-speech tagging; Text analysis"
"Multi-focus image fusion using a morphology-based focus measure in a quad-tree structure","2013","Information Fusion","10.1016/j.inffus.2012.01.007","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84880325401&doi=10.1016%2fj.inffus.2012.01.007&partnerID=40&md5=f83a90044cdc0bc63bd444f540cd42ce","Finite depth-of-field poses a problem in light optical imaging systems since the objects present outside the range of depth-of-field appear blurry in the recorded image. Effective depth-of-field of a sensor can be enhanced considerably without compromising the quality of the image by combining multi-focus images of a scene. This paper presents a block-based algorithm for multi-focus image fusion. In general, finding a suitable block-size is a problem in block-based methods. A large block is more likely to contain portions from both focused and defocused regions. This may lead to selection of considerable amount of defocused regions. On the other hand, small blocks do not vary much in relative contrast and hence difficult to choose from. Moreover, small blocks are more affected by mis-registration problems. In this work, we present a block-based algorithm which do not use a fixed block-size and rather makes use of a quad-tree structure to obtain an optimal subdivision of blocks. Though the algorithm starts with blocks, it ultimately identifies sharply focused regions in input images. The algorithm is simple, computationally efficient and gives good results. A new focus-measure called energy of morphologic gradients is introduced and is used in the algorithm. It is comparable with other focus measures viz.energy of gradients, variance, Tenengrad, energy of Laplacian and sum modified Laplacian. The algorithm is robust since it works with any of the above focus measures. It is also robust against pixel mis-registration. Performance of the algorithm has been evaluated by using two different quantitative measures. © 2012 Elsevier B.V. All rights reserved.","Depth-of-field Multi-focus image fusion Block-based fusion Focus measure Energy of morphologic gradients Quad-tree structure"
"A low-cost variational-bayes technique for merging mixtures of probabilistic principal component analyzers","2013","Information Fusion","10.1016/j.inffus.2012.08.005","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84885431196&doi=10.1016%2fj.inffus.2012.08.005&partnerID=40&md5=49433697018f687d94b802a0b3671e0f","Mixtures of probabilistic principal component analyzers (MPPCA) have shown effective for modeling high-dimensional data sets living on non-linear manifolds. Briefly stated, they conduct mixture model estimation and dimensionality reduction through a single process. This paper makes two contributions: first, we disclose a Bayesian technique for estimating such mixture models. Then, assuming several MPPCA models are available, we address the problem of aggregating them into a single MPPCA model, which should be as parsimonious as possible. We disclose in detail how this can be achieved in a cost-effective way, without sampling nor access to data, but solely requiring mixture parameters. The proposed approach is based on a novel variational-Bayes scheme operating over model parameters. Numerous experimental results and discussion are provided. © 2012 Elsevier B.V.","Aggregation; Mixture models; Probabilistic pca; Variational-bayes"
"The multiscale directional bilateral filter and its application to multisensor image fusion","2012","Information Fusion","10.1016/j.inffus.2011.01.002","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84858080785&doi=10.1016%2fj.inffus.2011.01.002&partnerID=40&md5=55bec149c6602690aee63687fa2b6f9b","In this paper, a novel multiscale geometrical analysis called the multiscale directional bilateral filter (MDBF) which introduces the nonsubsampled directional filter bank into the multiscale bilateral filter is proposed. Through combining the characteristic of preserving edge of the bilateral filter with the ability of capturing directional information of the directional filter bank, the MDBF can better represent the intrinsic geometrical structure of images. The MDBF, which is a multiscale, multidirectional and shift-invariant image decomposition scheme, is used to fuse multisensor images in this paper. The source images are first decomposed into the directional detail subbands and the approximation subbands via the MDBF. Then, the directional detail subbands and the approximation subbands are fused according to the given fusion rule, respectively. Finally, the inverse MDBF is applied to the fused subbands to obtain the fused image. Experimental results over visible and infrared images and medical images demonstrate the superiority of our method compared with conventional methods in terms of visual inspection and objective measures. © 2010 Elsevier B.V. All rights reserved.","Bilateral filter; Directional filter bank; Multiscale transform; Multisensor image fusion"
"Formal foundations for situation awareness based on dependent type theory","2013","Information Fusion","10.1016/j.inffus.2012.02.006","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84867328195&doi=10.1016%2fj.inffus.2012.02.006&partnerID=40&md5=eb18e9d51e7f47f4b0ee26f46f933b85","Cognitive situation awareness has recently caught the attention of the information fusion community. Some approaches have developed formalizations that are both ontology-based and underpinned with Situation Theory. While the semantics of Situation Theory is very attractive from the cognitive point of view, the languages that are used to express knowledge and to reason with suffer from a number of limitations concerning both expressiveness and reasoning capabilities. In this paper we propose a more general formal foundation denoted S-DTT (Situation-based Dependent Type Theory) that is expressed with the language of the Extended Calculus of Constructions (ECC), a widely used theory in mathematical formalization and in software validation. Situation awareness relies on small blocks of knowledge called situation fragment types whose composition leads to a very expressive and unifying theory. The semantic part is provided by an ontology that is rooted in the S-DTT theory and, on which higher-order reasoning can be performed. The basis of the theory is summarized and its expressing power is illustrated with numerous examples. A scenario in the healthcare context for patient safety issues is detailed and a comparison with well-known approaches is discussed. © 2011 Elsevier B.V. All rights reserved.","Aggregation; Dependent types; Ontologies; Situation awareness; Subsumption; Type inhabitation"
"Continuous-discrete confidence interval observer - Application to vehicle positioning","2013","Information Fusion","10.1016/j.inffus.2013.02.006","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84887782567&doi=10.1016%2fj.inffus.2013.02.006&partnerID=40&md5=151d8b9067a177ee0e9f1d005539b0b9","In vehicle positioning applications, the confidence level in the position and velocity estimates can be even more significant than accuracy. In this study, a probabilistic interval method is proposed, which combines, through union and intersection operations, the information from a possibly uncertain predictor (the vehicle model) and measurement sensors. The proposed method is compared to Kalman filtering and to guaranteed interval estimation in the context of railway vehicles where security is the key objective. © 2013 Elsevier B.V. All rights reserved.","Intervals; Positioning systems; Railways; State observer; Vehicles"
"Asymmetric homomorphisms for secure aggregation in heterogeneous scenarios","2012","Information Fusion","10.1016/j.inffus.2011.03.002","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84861586183&doi=10.1016%2fj.inffus.2011.03.002&partnerID=40&md5=b959b582eff786dc4193c3516a3d6efc","In multicast communication, a single source transmits the same content to a large amount of receivers. This kind of communication is usually represented following a tree model where the root of the tree is the multicast source and the leaves are the receivers. Scalability problems arise when the root needs to collect data (sensor information, metering data, etc.) from the leaves. This results in a many-to-one (leaf-to-root) communication. The matter is further complicated if there are security requirements on the leaf-to-root traffic. In this paper we present a method for secure and scalable many-to-one lossy transmission based on asymmetric homomorphisms which enables the root of the tree to compute any mathematical function (e.g. minimum, maximum, average, ...) on the data sent by the leaves. Our proposal preserves the confidentiality of those data. Authentication is guaranteed in the sense that only authorized nodes can participate in the protocol. Integrity against compromised leaves is also achieved. In the case of a compromised intermediate node which colludes with a compromised leave, they can only cause a limited deviation in the final aggregate value. © 2011 Elsevier B.V. All rights reserved.","Asymmetric homomorphisms; Data aggregation; Many-to-one communication; Scalability; Security"
"Eyeglasses removal of thermal image based on visible information","2013","Information Fusion","10.1016/j.inffus.2011.09.002","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84880332571&doi=10.1016%2fj.inffus.2011.09.002&partnerID=40&md5=c109c0c232c5978c2c8d69cb349c568b","Recently, a number of studies have demonstrated that thermal infrared (IR) imagery offers a promising alternative to visible imagery in face recognition problems due to its invariance to visible illumination changes. However, thermal IR has other limitations such as being opaque to glass. As a result, thermal IR imagery is very sensitive to facial occlusion caused by eyeglasses. Fusion of the visible and thermal IR images is an effective way to solve this problem. In this paper, using the face reconstruction information of the visible images, we propose two thermal image reconstruction algorithms, called the visible information aided eyeglasses removing algorithm (VIAER) and the refined visible information aided eyeglasses removing algorithm (refined VIAER). Experiments on publicly available data set show the excellent performance of our algorithms. © 2012 Elsevier B.V. All rights reserved.","Face image reconstruction Thermal infrared imagery Visible imagery"
"Objective priors from maximum entropy in data classification","2013","Information Fusion","10.1016/j.inffus.2012.01.012","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84880331044&doi=10.1016%2fj.inffus.2012.01.012&partnerID=40&md5=f8b16abe54edd3665a87a3e3402398c8","Lack of knowledge of the prior distribution in classification problems that operate on small data sets may make the application of Bayes' rule questionable. Uniform or arbitrary priors may provide classification answers that, even in simple examples, may end up contradicting our common sense about the problem. Entropic priors (EPs), via application of the maximum entropy (ME) principle, seem to provide good objective answers in practical cases leading to more conservative Bayesian inferences. EP are derived and applied to classification tasks when only the likelihood functions are available. In this paper, when inference is based only on one sample, we review the use of the EP also in comparison to priors that are obtained from maximization of the mutual information between observations and classes. This last criterion coincides with the maximization of the KL divergence between posteriors and priors that for large sample sets leads to the well-known reference (or Bernardo's) priors. Our comparison on single samples considers both approaches in prospective and clarifies differences and potentials. A combinatorial justification for EP, inspired by Wallis' combinatorial argument for entropy definition, is also included. The application of the EP to sequences (multiple samples) that may be affected by excessive domination of the class with the maximum entropy is also considered with a solution that guarantees posterior consistency. An explicit iterative algorithm is proposed for EP determination solely from knowledge of the likelihood functions. Simulations that compare EP with uniform priors on short sequences are also included. © 2012 Elsevier B.V. All rights reserved.","Decision theory Prior determination Data classification Maximum entropy"
"Use of secondary data to estimate instantaneous model parameters of diabetic heart disease: Lemonade Method","2012","Information Fusion","10.1016/j.inffus.2010.08.003","https://www.scopus.com/inward/record.uri?eid=2-s2.0-80054002184&doi=10.1016%2fj.inffus.2010.08.003&partnerID=40&md5=1202a6813a0b88ca9714c236469f8b1c","With the increasing burden of chronic diseases on the health care system, Markov-type models are becoming popular to predict the long-term outcomes of early intervention and to guide disease management. However, statisticians have not been actively involved in the development of these models. Typically, the models are developed by using secondary data analysis to find a single ""best"" study to estimate each transition in the model. However, due to the nature of secondary data analysis, there frequently are discrepancies between the theoretical model and the design of the studies being used. This paper illustrates a likelihood approach to correctly model the design of clinical studies under the conditions where (1) the theoretical model may include an instantaneous state of distinct interest to the researchers and (2) the study design may be such that study data cannot be used to estimate a single parameter in the theoretical model of interest. For example, a study may ignore intermediary stages of disease. Using our approach, not only can we accommodate the two conditions above, but more than one study may be used to estimate model parameters. In the spirit of ""If life gives you lemon, make lemonade"", we call this method ""Lemonade Method"". Simulation studies are carried out to evaluate the finite sample property of this method. In addition, the method is demonstrated through application to a model of heart disease in diabetes. © 2009 Elsevier B.V. All rights reserved.","Chronic disease; Designed absorption; Diabetes; Disease modeling; Meta-analysis; Multi-state model"
"Multiple hypothesis tracking for data association in vehicular networks","2013","Information Fusion","10.1016/j.inffus.2013.04.001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84887695576&doi=10.1016%2fj.inffus.2013.04.001&partnerID=40&md5=9d8d4b5279f6612c999d615c1fcf6d19","The introduction of Vehicle to Vehicle (V2V) and Vehicle to Infrastructure (V2I) communications in Intelligent Transportation Systems of the future brings new opportunities and new challenges into the automotive scene. Vehicular communications broaden the information spectrum that is available to each vehicle, allowing the enhancement of existing applications and the introduction of new ones. Undoubtedly, the impact of this new technology in transportation safety, efficiency and infotainment is expected to be very important. A significant part of research in vehicular networks (VANETs) is dedicated to networking issues like routing and safety. However, perception systems which until now were based on onboard sensors only, need to incorporate the wirelessly received information in order to extend the situation awareness of the vehicle and the driver. This paper presents an algorithm for associating targets tracked from an onboard radar sensor with the position and motion data received from the VANET. The core of the algorithm is a track oriented multiple hypothesis tracker that is modified for incorporating information included in VANET messages. The algorithm is tested in real scenarios using two experimental vehicles and then compared with two other algorithmic approaches. One is using a simpler single hypothesis algorithm for association of VANET messages and the second is using only the onboard sensors for environment perception. As a result, the advantages of the Multiple Hypothesis Algorithm regarding association performance and the added value of wireless information in the perception system are highlighted. © 2013 Elsevier B.V. All rights reserved.","Data association; Sensor data fusion; Track oriented multiple hypothesis tracking; Vehicular networks"
"Simulated annealing based classifier ensemble techniques: Application to part of speech tagging","2013","Information Fusion","10.1016/j.inffus.2012.06.002","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84885427104&doi=10.1016%2fj.inffus.2012.06.002&partnerID=40&md5=5d19e3447c3bac1f9743df16eacdb488","Part-of-Speech (PoS) tagging is an important pipelined module for almost all Natural Language Processing (NLP) application areas. In this paper we formulate PoS tagging within the frameworks of single and multiobjective optimization techniques. At the very first step we propose a classifier ensemble technique for PoS tagging using the concept of single objective optimization (SOO) that exploits the search capability of simulated annealing (SA). Thereafter we devise a method based on multiobjective optimization (MOO) to solve the same problem, and for this a recently developed multiobjective simulated annealing based technique, AMOSA, is used. The characteristic features of AMOSA are its concepts of the amount of domination and archive in simulated annealing, and situation specific acceptance probabilities. We use Conditional Random Field (CRF) and Support Vector Machine (SVM) as the underlying classification methods that make use of a diverse set of features, mostly based on local contexts and orthographic constructs. We evaluate our proposed approaches for two Indian languages, namely Bengali and Hindi. Evaluation results of the single objective version shows the overall accuracy of 88.92% for Bengali and 87.67% for Hindi. TheMOObased ensemble yields the overall accuracies of 90.45% and 89.88% for Bengali and Hindi, respectively. © 2012 Elsevier B.V.","Bengali; Classifier ensemble; Conditional random field (crf); Hindi; Multiobjective optimization (moo); Part of speech (pos) tagging; Simulated annealing (sa); Support vector machine (svm)"
"An evidential approach for detection of abnormal behaviour in the presence of unreliable sensors","2012","Information Fusion","10.1016/j.inffus.2011.01.004","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84855890846&doi=10.1016%2fj.inffus.2011.01.004&partnerID=40&md5=5c16de547cc83d806ec90fbfcef227d8","We address the problem of abnormal behaviour recognition of the inhabitant of a smart home in the presence of unreliable sensors. The corner stone of this work is a two-level architecture sensor fusion based on the Transferable Belief Model (TBM). The novelty of our work lies in the way we detect both unreliable sensors and abnormal behaviour within our architecture by using a temporal analysis of conflict resulting from the fusion of sensors. Detection of abnormal behaviour is based on a prediction/observation process and the influence of the faulty sources is discarded by discounting coefficients. Our architecture is tested in a real-life setting using three heterogeneous sensors enabling the detection of impossible transitions between three possible postures: Sitting, Standing and Lying. The impact of having a faulty sensor management is also tested in the real-life experiment for posture detection. © 2009 Elsevier B.V. All rights reserved.","Abnormal behaviour; Conflict analysis; Data fusion; Sensor reliability; Sensors diagnostics; Transferable Belief Model"
"Image matting for fusion of multi-focus images in dynamic scenes","2013","Information Fusion","10.1016/j.inffus.2011.07.001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84878308650&doi=10.1016%2fj.inffus.2011.07.001&partnerID=40&md5=f20bfaee5d15f8c9405f2976a405d7c6","In this paper, we address the problem of fusing multi-focus images in dynamic scenes. The proposed approach consists of three main steps: first, the focus information of each source image obtained by morphological filtering is used to get the rough segmentation result which is one of the inputs of image matting. Then, image matting technique is applied to obtain the accurate focused region of each source image. Finally, the focused regions are combined together to construct the fused image. Through image matting, the proposed fusion algorithm combines the focus information and the correlations between nearby pixels together, and therefore tends to obtain more accurate fusion result. Experimental results demonstrate the superiority of the proposed method over traditional multi-focus image fusion methods, especially for those images in dynamic scenes. © 2011 Elsevier B.V. All rights reserved.","Multi-focus image fusion Image matting Dynamic scenes Morphological filtering Focus information"
"An evaluation of several fusion algorithms for anti-tank landmine detection and discrimination","2012","Information Fusion","10.1016/j.inffus.2009.10.001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84855891896&doi=10.1016%2fj.inffus.2009.10.001&partnerID=40&md5=b8d9fd5e4e84fb2cab6d2acf2978c60b","Many algorithms have been proposed for detecting anti-tank landmines and discriminating between mines and clutter objects using data generated by a ground penetrating radar (GPR) sensor. Our extensive testing of some of these algorithms has indicated that their performances are strongly dependent upon a variety of factors that are correlated with geographical and environmental conditions. It is typically the case that one algorithm may perform well in one setting and not so well in another. Thus, fusion methods that take advantage of the stronger algorithms for a given setting without suffering from the effects of weaker algorithms in the same setting are needed to improve the robustness of the detection system. In this paper, we discuss, test, and compare seven different fusion methods: Bayesian, distance-based, Dempster-Shafer, Borda count, decision template, Choquet integral, and context-dependent fusion. We present the results of a cross validation experiment that uses a diverse data set together with results of eight detection and discrimination algorithms. These algorithms are the top ranked algorithms after extensive testing. The data set was acquired from multiple collections from four outdoor sites at different locations using the NIITEK GPR system. This collection covers over 41,807 m 2 of ground and includes 1593 anti-tank mine encounters. © 2009 Elsevier B.V. All rights reserved.","Bayesian fusion; Borda count; Context-dependent fusion; Decision template; Dempster-Shafer; Fuzzy integral; Landmine detection"
"Information fusion in practice: A distributed cognition perspective on the active role of users","2012","Information Fusion","10.1016/j.inffus.2011.01.005","https://www.scopus.com/inward/record.uri?eid=2-s2.0-80053950119&doi=10.1016%2fj.inffus.2011.01.005&partnerID=40&md5=8d2f0a5c9f1efcd4ce28a7c0ce2e41fc","Traditionally, the focus of most information fusion research has been on computational aspects, as illustrated by, for example, different versions of the JDL data fusion model. Consequently, the human user has mainly been conceived as a relatively passive recipient of fused information. However, the importance of understanding the active role of human information processing in information fusion is gaining increasing recognition, as also reflected in discussions of a ""level 5"" in the JDL model. This paper presents a case study of the interaction between human and machine information processing in a maritime surveillance control room. A detailed analysis of cognitive processes and information flows involved in identifying and tracking moving vessels illustrates how machines and human operators collaboratively perform fusion in a highly distributed fashion. The theoretical framework of distributed cognition provides an alternative or complementary way of analysing information fusion systems/processes that more clearly reveals the actual complexities of the interaction between human and machine information processing in practice. © 2011 Elsevier B.V. All rights reserved.","Distributed cognition; Human factors; Human-computer interaction; Maritime surveillance; User refinement; User-fusion"
"Privacy protection of textual attributes through a semantic-based masking method","2012","Information Fusion","10.1016/j.inffus.2011.03.004","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84861589008&doi=10.1016%2fj.inffus.2011.03.004&partnerID=40&md5=4abc4037894cc79f1e0c6be833997469","Using microdata provided by statistical agencies has many benefits from the data mining point of view. However, such data often involve sensitive information that can be directly or indirectly related to individuals. An appropriate anonymisation process is needed to minimise the risk of disclosure. Several masking methods have been developed to deal with continuous-scale numerical data or bounded textual values but approaches to tackling the anonymisation of textual values are scarce and shallow. Because of the importance of textual data in the Information Society, in this paper we present a new masking method for anonymising unbounded textual values based on the fusion of records with similar values to form groups of indistinguishable individuals. Since, from the data exploitation point of view, the utility of textual information is closely related to the preservation of its meaning, our method relies on the structured knowledge representation given by ontologies. This domain knowledge is used to guide the masking process towards the merging that best preserves the semantics of the original data. Because textual data typically consist of large and heterogeneous value sets, our method provides a computationally efficient algorithm by relying on several heuristics rather than exhaustive searches. The method is evaluated with real data in a concrete data mining application that involves solving a clustering problem. We also compare the method with more classical approaches that focus on optimising the value distribution of the dataset. Results show that a semantically grounded anonymisation best preserves the utility of data in both the theoretical and the practical setting, and reduces the probability of record linkage. At the same time, it achieves good scalability with regard to the size of input data. © 2011 Elsevier B.V. All rights reserved.","Anonymity; Fusion of textual data; Ontologies; Privacy protection; Semantic similarity"
"Exchange rates determination based on genetic algorithms using mendel's principles: Investigation and estimation under uncertainty","2013","Information Fusion","10.1016/j.inffus.2011.12.003","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84880447443&doi=10.1016%2fj.inffus.2011.12.003&partnerID=40&md5=7dfd1f21557d3af79e8a995283de8289","A genetic algorithm using Mendel's principle (Mendel-GA), in which the random assignment of alleles from parents to offsprings is implied by the Mendel genetic operator, is proposed for the exchange rates determination problem. Besides the traditional genetic operators of selection, crossover, and mutation, Mendel's principles are included, in the form of an operator in the genetic algorithm's evolution process. In the quantitative analysis of exchange rates determination, the Mendel-GA examines the exchange rate fluctuations at the short-run horizon. Specifically, the aim is to revisit the determination of high-frequency exchange rates and examine the differences between the method of genetic algorithms and that of the traditional estimation methods. A simulation with a given initial conditions has been devised in MATLAB, and it is shown that the Mendel-GA can work valuably as a tool for the exchange rates estimation modelling with high-frequency data. © 2012 Elsevier B.V.","Estimation; Exchange rates; Genetic algorithm; High-frequency; Mendel's principle; Regression; Uncertainty"
"Distributed information fusion models for regional public health surveillance","2012","Information Fusion","10.1016/j.inffus.2010.12.002","https://www.scopus.com/inward/record.uri?eid=2-s2.0-80053984303&doi=10.1016%2fj.inffus.2010.12.002&partnerID=40&md5=3d218651ec7b56f5e904d3df43d46992","Biosurveillance systems designed and deployed in the United States and abroad to allow public health authorities to monitor the health of their communities have significant design limitations despite their wide usage. One limitation is the lack of algorithmic solutions to combine local data sources for regional situation awareness. The objective of the current study is to develop and demonstrate the value of automated information fusion methods applied to the distributed neighboring public health sites. A prototype system consisting of distributed Bayesian models was designed to enable informed regional and local cognitive decision support response. The Intelligent Decision Support Network (IDSN) is composed of Bayesian Information Fusion Models (BIFMs) that target a particular syndrome or disease type. Using local data from county health departments in Northern Virginia for the time period between August 2005 and May 2007, we estimated the probability of a gastrointestinal (GI) outbreak in two ways: First, based on data from the local hospitals only; and second, based on the relative probability of outbreak by combining local hospital data and probabilities of GI events from the neighboring counties' BIFMs. Preliminary findings showed that the network of distributed models detected events that would be undetected without multi-jurisdictional data. © 2009 Elsevier B.V. All rights reserved.","Automation; Bayesian networks; Biosurveillance; Data processing algorithms; Decision support systems"
"Random feature weights for decision tree ensemble construction","2012","Information Fusion","10.1016/j.inffus.2010.11.004","https://www.scopus.com/inward/record.uri?eid=2-s2.0-80053990343&doi=10.1016%2fj.inffus.2010.11.004&partnerID=40&md5=5ae0af3fb57707d9e4fb17603a809321","This paper proposes a method for constructing ensembles of decision trees, random feature weights (RFW). The method is similar to Random Forest, they are methods that introduce randomness in the construction method of the decision trees. In Random Forest only a random subset of attributes are considered for each node, but RFW considers all of them. The source of randomness is a weight associated with each attribute. All the nodes in a tree use the same set of random weights but different from the set of weights in other trees. So, the importance given to the attributes will be different in each tree and that will differentiate their construction. The method is compared to Bagging, Random Forest, Random-Subspaces, AdaBoost and MultiBoost, obtaining favourable results for the proposed method, especially when using noisy data sets. RFW can be combined with these methods. Generally, the combination of RFW with other method produces better results than the combined methods. Kappa-error diagrams and Kappa-error movement diagrams are used to analyse the relationship between the accuracies of the base classifiers and their diversity. © 2011 Elsevier B.V. All rights reserved.","Bagging; Boosting; Classifier ensembles; Decision trees; Random Forests; Random-Subspaces"
"Improving data fusion in personal positioning systems for outdoor environments","2013","Information Fusion","10.1016/j.inffus.2012.01.009","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84867330435&doi=10.1016%2fj.inffus.2012.01.009&partnerID=40&md5=42d1ab4c802c294a4970d08b402cb89f","A fault detection and correction methodology for personal positioning systems for outdoor environments is presented. We demonstrate its successful use in a system consisting of a global positioning system receiver and an inertial measurement unit. Localization is based on the dead reckoning algorithm. In order to obtain more reliable information from data fusion, which is carried out with Kalman filtering, the proposed methodology involves: (1) evaluation of the information provided by the sensors and (2) adaptability of the filtering. By carefully analyzing these factors we accomplish fault detection in different sources of information and in filtering. This allows us to apply corrections whenever the system requires it. Hence, our methodology consists of two stages. In the first stage, the evaluation is conducted. We apply the principles of causal diagnosis using possibility theory by defining states for normal behavior and for fault states. When a fault occurs, corrective measures are applied according to empirical knowledge. In the second stage, the consistency test of the filtering is performed. If this is inconsistent, principles of adaptive Kalman filtering are applied, which means the process and measurement noise matrices are tuned. Our results indicate a reasonable improvement of the trajectory obtained. At the same time, we can achieve consistent filtering, to obtain a more robust system and reliable information. © 2011 Elsevier B.V. All rights reserved.","Adaptive Kalman filtering; Causal diagnosis; Chi-square test; Dead reckoning; Fault detection; Pedestrian positioning"
"Fusion of possibly biased location estimates using Gaussian mixture models","2012","Information Fusion","10.1016/j.inffus.2011.02.002","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84858073298&doi=10.1016%2fj.inffus.2011.02.002&partnerID=40&md5=b031c55c445b52f557760648cdf5e6f1","A probabilistic framework for fusing location estimates, which may be biased and inconsistent, is presented. The proposed method, involving Gaussian mixture models (GMMs), utilizes prior information regarding the sensor bias, firstly, to reduce errors in the fused location estimate, and secondly, to produce a fused covariance matrix that better reflects the expected location error. Simulations are used to evaluate performance, relative to other techniques, such as the covariance union (CU) method. A passive geolocation application involving an airborne electronic support (ES) system is considered. © 2010 Elsevier B.V. All rights reserved.","Bias; Data fusion; Electronic support; Gaussian mixture model; Multisensor systems; Passive geolocation"
"Quantifying the correctness, computational complexity, and security of privacy-preserving string comparators for record linkage","2012","Information Fusion","10.1016/j.inffus.2011.04.004","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84861588233&doi=10.1016%2fj.inffus.2011.04.004&partnerID=40&md5=e8cae93f3d12ccad352b9ee807f7598b","Record linkage is the task of identifying records from disparate data sources that refer to the same entity. It is an integral component of data processing in distributed settings, where the integration of information from multiple sources can prevent duplication and enrich overall data quality, thus enabling more detailed and correct analysis. Privacy-preserving record linkage (PPRL) is a variant of the task in which data owners wish to perform linkage without revealing identifiers associated with the records. This task is desirable in various domains, including healthcare, where it may not be possible to reveal patient identity due to confidentiality requirements, and in business, where it could be disadvantageous to divulge customers' identities. To perform PPRL, it is necessary to apply string comparators that function in the privacy-preserving space. A number of privacy-preserving string comparators (PPSCs) have been proposed, but little research has compared them in the context of a real record linkage application. This paper performs a principled and comprehensive evaluation of six PPSCs in terms of three key properties: (1) correctness of record linkage predictions, (2) computational complexity, and (3) security. We utilize a real publicly-available dataset, derived from the North Carolina voter registration database, to evaluate the tradeoffs between the aforementioned properties. Among our results, we find that PPSCs that partition, encode, and compare strings yield highly accurate record linkage results. However, as a tradeoff, we observe that such PPSCs are less secure than those that map and compare strings in a reduced dimensional space. © 2011 Elsevier B.V. All rights reserved.","Approximate matching; Privacy; Record linkage; String comparison"
"A multilevel information fusion approach for visual quality inspection","2012","Information Fusion","10.1016/j.inffus.2011.02.005","https://www.scopus.com/inward/record.uri?eid=2-s2.0-80053954923&doi=10.1016%2fj.inffus.2011.02.005&partnerID=40&md5=22c8f884db193de40f43ef37c9e4bce8","For visual quality inspection systems to be applicable in industrial settings, it is mandatory that they are highly flexible, robust and accurate. In order to improve these characteristics a multilevel information fusion approach is presented. A first fusion step at the feature-level enables the system to learn from an undefined number of potential defects which might be segmented from the images. This allows for the quality control operators to label the data at the image-level and the sub-image-level, and use this information during the learning process. Additionally, the operators are allowed to provide a confidence measure for their labelling. The additional information obtained from the increased flexibility of the operator inputs allows to build more accurate classifiers. A second fusion step at the decision-level combines the classifications of different classifiers, making the system more accurate and more robust with respect to the classification method chosen. The experimental results, using various artificial and real-world visual quality inspection data sets, show that each of these fusion approaches can significantly improve the classification accuracy. If both information fusion approaches are combined the accuracy increases even further, significantly outperforming each of the fusion approaches on their own. © 2011 Elsevier B.V. All rights reserved.","Classifier fusion; Decision fusion; Feature fusion; Multilevel information fusion; Visual quality inspection"
"High-Level fusion for intelligence applications using Recombinant Cognition Synthesis","2012","Information Fusion","10.1016/j.inffus.2010.08.002","https://www.scopus.com/inward/record.uri?eid=2-s2.0-80053977927&doi=10.1016%2fj.inffus.2010.08.002&partnerID=40&md5=93f71b564ba3efaef3ce4c626d855330","Intelligence applications exploit heterogeneous data using High-Level fusion systems to gain information superiority. Whereas Low-Level fusion systems have well established frameworks, High-Level fusion has not yet achieved the same level of maturity. Most High-Level systems implement specialized algorithms that yield useful results, albeit for a very narrow input space, and are characterized by stove-pipe architectures and a fragmented workflow. Recombinant Cognition Synthesis bridges the implementation gap of existing fusion models by defining a comprehensive framework of semantic, temporal, and geospatial enablers comprising the primitives, functions, and models, which through a recombinant workflow, maximize the data exploitation value-chain. This paper presents a methodology and the underlying architectural components necessary to implement a unified High-Level fusion intelligence application, followed by a case study that demonstrates the resulting improvements in knowledge discovery and predictive accuracy. © 2011 Elsevier B.V. All rights reserved.","Data fusion; Knowledge discovery; Predictive analytics; Situation Awareness; Threat Assessment"
"Fusion of multispectral and panchromatic images based on support value transform and adaptive principal component analysis","2012","Information Fusion","10.1016/j.inffus.2010.09.003","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84858075329&doi=10.1016%2fj.inffus.2010.09.003&partnerID=40&md5=d077c8a6588551b16c794c9ad16299da","In this paper we combined the projection-substitution with ARSIS (French acronym for ""Amélioration de la Résolution Spatiale par Injection de Structures"", i.e., Improving Spatial Resolution by Structure Injection) concept assumption for fusion of panchromatic (PAN) and multispectral (MS) images. Firstly support value filter (SVF) is used to establish a new multiscale model (MSM), support vector transform (SVT), and adaptive principal component analysis (APCA) is then employed to select the principal components of MS images by means of a statistical measure of the correlation between MS and PAN images; secondly, a local approach is used to check whether a structure should appear in the new principal component and PAN high frequency structures are transformed by high resolution interband structure model (HRIBSM) before inserting in the MS modalities. Because SVT is an undecimated, dyadic and aliasing transform with shift-invariant property, the fused image can avoid ringing effects suffered from sampling. Additionally, the ARSIS concept can make full use of the remote sensing physics to reduce the spatial and spectrum distortion in the structure injection. Texture extraction is also employed to avoid the spectral distortion caused by the mistaken injection of low-pass components into the MS images. Experimental results including visual and numerical evaluation also proves the superiority of the proposed method to its counterparts. © 2010 Elsevier B.V. All rights reserved.","Adaptive PCA; ARSIS; Fusion; Support value transform; Texture extraction"
"Finding FUN in FUsioN - LIII","2013","Information Fusion","10.1016/j.inffus.2013.04.007","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84887230892&doi=10.1016%2fj.inffus.2013.04.007&partnerID=40&md5=f679b7d0eb8426d4afa2b5fc720e8c6d","[No abstract available]",""
"Information fusion techniques for change detection from multi-temporal remote sensing images","2013","Information Fusion","10.1016/j.inffus.2012.05.003","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84867335433&doi=10.1016%2fj.inffus.2012.05.003&partnerID=40&md5=f27d08d29d07fdf5478ed0b0d7e16ac9","In order to investigate the impacts of different information fusion techniques on change detection, a sequential fusion strategy combining pan-sharpening with decision level fusion is introduced into change detection from multi-temporal remotely sensed images. Generally, change map from multi-temporal remote sensing images using any single method or single kind of data source may contain a number of omission/commission errors, degrading the detection accuracy to a great extent. To take advantage of the merits of multi-resolution image and multiple information fusion schemes, the proposed procedure consists of two steps: (1) change detection from pan-sharpened images, and (2) final change detection map generation by decision level fusion. Impacts of different fusion techniques on change detection results are evaluated by unsupervised similarity metric and supervised accuracy indices. Multi-temporal QuickBird and ALOS images are used for experiments. The experimental results demonstrate the positive impacts of different fusion strategies on change detection. Especially, pan-sharpening techniques improve spatial resolution and image quality, which effectively reduces the omission errors in change detection; and decision level fusion integrates the change maps from spatially enhanced fusion datasets and can well reduce the commission errors. Therefore, the overall accuracy of change detection can be increased step by step by the proposed sequential fusion framework. © 2011 Elsevier B.V. All rights reserved.","Change detection (CD); Decision level fusion; Multi-resolution images; Pan-sharpening; Remote sensing"
"Prioritized intuitionistic fuzzy aggregation operators","2013","Information Fusion","10.1016/j.inffus.2012.01.011","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84867331951&doi=10.1016%2fj.inffus.2012.01.011&partnerID=40&md5=b844c958c7f0e63f60bf3e005e350105","In some multi-attribute decision making problems, distorted conclusions will be generated due to the lack of considering various relationships among the attributes of decision making. In this paper, we investigate the prioritization relationship of attributes in multi-attribute decision making with intuitionistic fuzzy information (i.e., partial or all decision information, like attribute values and weights, etc., is represented by intuitionistic fuzzy values (IFVs)). Firstly, we develop a new method for comparing two IFVs, based on which the basic intuitionistic fuzzy operations satisfy monotonicities. In addition, we devise a method to derive the weights with intuitionistic fuzzy forms, which can indicate the importance degrees of the corresponding attributes. Then we develop a prioritized intuitionistic fuzzy aggregation operator, which is motivated by the idea of the prioritized aggregation operators [R.R. Yager, Prioritized aggregation operators, International Journal of Approximate Reasoning 48 (2008) 263-274]. Furthermore, we propose an intuitionistic fuzzy basic unit monotonic (IF-BUM) function to transform the derived intuitionistic fuzzy weights into the normalized weights belonging to the unit interval. Finally, we develop a prioritized intuitionistic fuzzy ordered weighted averaging operator on the basis of the IF-BUM function and the transformed weights. © 2011 Elsevier B.V. All rights reserved.","Intuitionistic fuzzy values; Multi-attribute decision making; Prioritization relationships; Prioritized aggregation operator"
"A novel approach to quantitative evaluation of hyperspectral image fusion techniques","2013","Information Fusion","10.1016/j.inffus.2011.03.008","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84867328371&doi=10.1016%2fj.inffus.2011.03.008&partnerID=40&md5=6d392fc480f25751343947309e15903a","In recent years, several image fusion techniques have been proposed to cater to various objectives. An appropriate visualization of the data is one of the key objectives of image fusion, particularly in case of hyperspectral images where the number of bands are far more than those can be displayed on standard tristimulus display. While a few techniques that address the issue of visualization of hyperspectral data can be seen in the literature, the evaluation of performances of these different techniques is still an open problem. In this paper, we first introduce a notion called fusion consistency and we suggest that the fusion techniques should satisfy the consistency criterion under appropriate measures that evaluate the fusion performance. We also propose several modifications for a number of existing measures that can quantify the progression of fusion operation efficiently for the fusion of a large number of image bands. We use these observations to validate suitability of any given technique for fusion of hyperspectral images. © 2011 Elsevier B.V. All rights reserved.","Fusion consistency; Hyperspectral image fusion; Image quality assessment; Performance evaluation"
"Distributed weighted robust Kalman filter fusion for uncertain systems with autocorrelated and cross-correlated noises","2013","Information Fusion","10.1016/j.inffus.2011.09.004","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84867331341&doi=10.1016%2fj.inffus.2011.09.004&partnerID=40&md5=627d499c369edbaba98ccbaf62ea26b2","In this paper, the problem of distributed weighted robust Kalman filter fusion is studied for a class of uncertain systems with autocorrelated and cross-correlated noises. The system under consideration is subject to stochastic uncertainties or multiplicative noises. The process noise is assumed to be one-step autocorrelated. For each subsystem, the measurement noise is one-step autocorrelated, and the process noise and the measurement noise are two-step cross-correlated. An optimal robust Kalman-type recursive filter is first designed for each subsystem. Then, based on the newly obtained optimal robust Kalman-type recursive filter, a distributed weighted robust Kalman filter fusion algorithm is derived for uncertain systems with multiple sensors. The distributed fusion algorithm involves a recursive computation of the filtering error cross-covariance matrix between any two subsystems. Compared with the centralized Kalman filter, the distributed weighted robust Kalman filter developed in this paper has stronger fault-tolerance ability. Simulation results are provided to demonstrate the effectiveness of the proposed approaches. © 2011 Elsevier B.V. All rights reserved.","Autocorrelation; Cross-correlation; Minimum variance; Multiplicative noises; Robust Kalman filter; Weighted fusion"
"The accuracy comparison of multisensor covariance intersection fuser and three weighting fusers","2013","Information Fusion","10.1016/j.inffus.2012.05.005","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84880327860&doi=10.1016%2fj.inffus.2012.05.005&partnerID=40&md5=ac580b135d063e96c495ce96567c5808","For multisensor systems with exactly known local filtering error variances and cross-covariances, a covariance intersection (CI) fusion steady-state Kalman filter without cross-covariances is presented. It is rigorously proved that it has consistency, and its accuracy is higher than that of each local Kalman filter and is lower than that of the optimal Kalman fuser with matrix weights. Under the unbiased linear minimum variance (ULMV) criterion, it is proved that the accuracy of the fuser with matrix weights is higher than that of the fuser with scalar weights, and the accuracy of the fuser with diagonal matrix weights is in between both of them, and the accuracies of all three weighting fusers and the CI fuser are lower than that of centralized Kalman fuser, and are higher than that of each local Kalman filter. The geometric interpretations of the above accuracy relations are given based on the covariance ellipsoids. A Monte-Carlo simulation example for tracking system verifies correctiveness of the proposed theoretical accuracy relations, and shows that the actual accuracy of the CI Kalman fuser is close to that of the optimal Kalman fuser, so that it has higher accuracy and good performance. When the actual local filtering error variances and cross-covariances are unknown, if the local filtering estimates are consistent, then the corresponding robust CI fuser is also consistent, and its robust accuracy is higher than that of each local filter. © 2011 Elsevier B.V. All rights reserved.","Multisensor data fusion Covariance intersection fusion Weighting fusion Kalman filter Consistency Covariance ellipsoid"
"Super-resolution image reconstruction techniques: Trade-offs between the data-fidelity and regularization terms","2012","Information Fusion","10.1016/j.inffus.2010.11.005","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84858081130&doi=10.1016%2fj.inffus.2010.11.005&partnerID=40&md5=acb9ede2ad0e364f4d5f8bcae0480a9f","Stochastic regularized methods are quite advantageous in super-resolution (SR) image reconstruction problems. In the particular techniques, the SR problem is formulated by means of two terms, the data-fidelity term and the regularization term. The present work examines the effect of each one of these terms on the SR reconstruction result with respect to the presence or absence of noise in the low-resolution (LR) frames. Experimentation is carried out with the widely employed L 2, L 1, Huber and Lorentzian estimators for the data-fidelity term. The Tikhonov and Bilateral (B) Total Variation (TV) techniques are employed for the regularization term. The extracted conclusions can, in practice, help to select an effective SR method for a given sequence of LR frames. Thus, in case that the potential methods present common data-fidelity or regularization term, and frames are noiseless, the method which employs the most robust regularization or data-fidelity term should be used. Otherwise, experimental conclusions regarding performance ranking vary with the presence of noise in frames, the noise model as well as the difference in robustness of efficiency between the rival terms. Estimators employed for the data-fidelity term or regularizations stand for the rival terms. © 2010 Elsevier B.V. All rights reserved.","Data-fidelity; Method selection; Noisy frames; Regularization; Super-resolution"
"Kd-trees and the real disclosure risks of large statistical databases","2012","Information Fusion","10.1016/j.inffus.2011.03.001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84861636225&doi=10.1016%2fj.inffus.2011.03.001&partnerID=40&md5=d615030c338ded58417058f96de7db03","Estimating the disclosure risk of a Statistical Disclosure Control (SDC) protection method by means of (distance-based) record linkage techniques is a very popular approach to analyze the privacy level offered by such a method. When databases are very large, some particular record linkage techniques such as blocking or partitioning are usually applied to make this process reasonably efficient. However, in this case the record linkage process is not exact, which means that the disclosure risk of a SDC protection method may be underestimated. In this paper we propose the use of kd-trees techniques to apply exact yet very efficient record linkage when (protected) datasets are very large. We describe some experiments showing that this approach achieves better results, in terms of both accuracy and running time, than more classical approaches such as record linkage based on a sliding window. We also discuss and experiment on the use of these techniques not to link a whole protected record with its original one, but just to guess the value of some confidential attribute(s) of the record(s). This fact leads to concepts such as k-neighbor l-diversity or k-neighbor p-sensitivity, a generalization (to any SDC protection method) of l-diversity or p-sensitivity, which have been defined for SDC protection methods ensuring k-anonymity, such as microaggregation. © 2011 Elsevier B.V. All rights reserved.","Attribute disclosure; Kd-trees; Real disclosure risk; Record linkage; Statistical Disclosure Control"
"Poisson image fusion based on markov random field fusion model","2013","Information Fusion","10.1016/j.inffus.2012.07.003","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84885429303&doi=10.1016%2fj.inffus.2012.07.003&partnerID=40&md5=4f6cc3f3e058a448db73c1d1ffcc5aef","In this paper, we present a gradient domain image fusion framework based on the Markov Random Field (MRF) fusion model. In this framework, the salient structures of the input images are fused in the gradient domain, then the final fused image is reconstructed by solving a Poisson equation which forces the gradients of the fused image to be close to the fused gradients. To fuse the structures in the gradient domain, an effective MRF-based fusion model is designed based on both the per-pixel fusion rule defined by the local saliency and also the smoothness constraints over the fusion weights, which is optimized by graph cut algorithm. This MRF-based fusion model enables the accurate estimation of region-based fusion weights for the salient objects or structures. We apply this method to the applications of multi-sensor image fusion, including infrared and visible image fusion, multi-focus image fusion and medical image fusion. Extensive experiments and comparisons show that the proposed fusion model is able to better fuse the multi-sensor images and produces high-quality fusion results compared with the other stateof- the-art methods. © 2012 Elsevier B.V.","Fusion rule; Gradient domain; Image fusion; Markov random field model"
"Simultaneous image fusion and super-resolution using sparse representation","2013","Information Fusion","10.1016/j.inffus.2012.01.008","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84885423284&doi=10.1016%2fj.inffus.2012.01.008&partnerID=40&md5=2211e7b37fb762519fe0bbc5e060957d","Given multiple source images of the same scene, image fusion integrates the inherent complementary information into one single image, and thus provides a more complete and accurate description. However, when the source images are of low-resolution, the resultant fused image can still be of low-quality, hindering further image analysis. To improve the resolution, a separate image super-resolution step can be performed. In this paper, we propose a novel framework for simultaneous image fusion and super-resolution. It is based on the use of sparse representations, and consists of three steps. First, the low-resolution source images are interpolated and decomposed into high- And low-frequency components. Sparse coefficients from these components are then computed and fused by using image fusion rules. Finally, the fused sparse coefficients are used to reconstruct a high-resolution fused image. Experiments on various types of source images (including magnetic resonance images, X-ray computed tomography images, visible images, infrared images, and remote sensing images) demonstrate the superiority of the proposed method both quantitatively and qualitatively. © 2012 Elsevier B.V.","Image fusion; Image super-resolution; Sparse representation"
"Bayesian CAR models for syndromic surveillance on multiple data streams: Theory and practice","2012","Information Fusion","10.1016/j.inffus.2009.10.005","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84855894109&doi=10.1016%2fj.inffus.2009.10.005&partnerID=40&md5=01e6a5208a979841e359dcba1f1138f3","Syndromic surveillance has, so far, considered only simple models for Bayesian inference. This paper details the methodology for a serious, scalable solution to the problem of combining symptom data from a network of US hospitals for early detection of disease outbreaks. The approach requires high-end Bayesian modeling and significant computation, but the strategy described in this paper appears to be feasible and offers attractive advantages over the methods that are currently used in this area. The method is illustrated by application to ten quarters worth of data on opioid drug abuse surveillance from 636 reporting centers, and then compared to two other syndromic surveillance methods using simulation to create known signal in the drug abuse database. © 2009 Elsevier B.V. All rights reserved.","Bayes; CAR models; Gibbs distribution; Markov random field; Syndromic surveillance"
"Information geometry of target tracking sensor networks","2013","Information Fusion","10.1016/j.inffus.2012.02.005","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84885420251&doi=10.1016%2fj.inffus.2012.02.005&partnerID=40&md5=0608ba9a8d4a243ef8eb87777d0439c9","In this paper, the connections between information geometry and performance of sensor networks for target tracking are explored to pursue a better understanding of placement, planning and scheduling issues. Firstly, the integrated Fisher information distance (IFID) between the states of two targets is analyzed by solving the geodesic equations and is adopted as a measure of target resolvability by the sensor. The differences between the IFID and the well known Kullback-Leibler divergence (KLD) are highlighted. We also explain how the energy functional, which is the ""integrated, differential"" KLD, relates to the other distance measures. Secondly, the structures of statistical manifolds are elucidated by computing the canonical Levi-Civita affine connection as well as Riemannian and scalar curvatures. We show the relationship between the Ricci curvature tensor field and the amount of information that can be obtained by the network sensors. Finally, an analytical presentation of statistical manifolds as an immersion in the Euclidean space for distributions of exponential type is given. The significance and potential to address system definition and planning issues using information geometry, such as the sensing capability to distinguish closely spaced targets, calculation of the amount of information collected by sensors and the problem of optimal scheduling of network sensor and resources, etc., are demonstrated. The proposed analysis techniques are presented via three basic sensor network scenarios: A simple range-bearing radar, two bearings-only passive sonars, and three ranges-only detectors, respectively. © 2012 Elsevier B.V.","Energy functional; Information geometry; Integrated fisher information distance; Kullback-leibler divergence; Ricci curvature; Sensor networks; Target tracking"
"Improving record linkage with supervised learning for disclosure risk assessment","2012","Information Fusion","10.1016/j.inffus.2011.05.001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84861580897&doi=10.1016%2fj.inffus.2011.05.001&partnerID=40&md5=ef31eb353142cca11b2c2d05082e1336","In data privacy, record linkage can be used as an estimator of the disclosure risk of protected data. To model the worst case scenario one normally attempts to link records from the original data to the protected data. In this paper we introduce a parametrization of record linkage in terms of a weighted mean and its weights, and provide a supervised learning method to determine the optimum weights for the linkage process. That is, the parameters yielding a maximal record linkage between the protected and original data. We compare our method to standard record linkage with data from several protection methods widely used in statistical disclosure control, and study the results taking into account the performance in the linkage process, and its computational effort. © 2011 Elsevier B.V. All rights reserved.","Data privacy; Record linkage"
"Entropy/cross entropy-based group decision making under intuitionistic fuzzy environment","2012","Information Fusion","10.1016/j.inffus.2010.12.001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-80054001280&doi=10.1016%2fj.inffus.2010.12.001&partnerID=40&md5=433fc18779ed2ee57f8a25741812ba3c","We study the group decision making problem under intuitionistic fuzzy environment. Based on entropy and cross entropy, we give two methods to determine the optimal weights of attributes, and develop two pairs of entropy and cross entropy measures for intuitionistic fuzzy values. Then, we discuss the properties of these measures and the relations between them and the existing ones. Furthermore, we introduce three new aggregation operators, which treat the membership and non-membership information fairly, to aggregate intuitionistic fuzzy information. Finally, several practical examples are presented to illustrate the developed methods. © 2011 Elsevier B.V. All rights reserved.","Aggregation operator; Cross entropy; Entropy; Group decision making; Intuitionistic fuzzy values; Weight vector"
"Privacy-preserving identity-based broadcast encryption","2012","Information Fusion","10.1016/j.inffus.2011.03.003","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84861593834&doi=10.1016%2fj.inffus.2011.03.003&partnerID=40&md5=956cae9116ac4ce2b61b0d6c67b7b8e8","Broadcast encryption enables a broadcaster to encrypt messages and transmit them to some subset S of authorized users. In identity-based broadcast encryption schemes, a broadcasting sender typically encrypts a message by combining public identities of receivers in S and system parameters. However, previous identity-based broadcast encryption schemes have not been concerned about preserving the privacy of receivers. Consequently, all of the identities of broadcast receivers in S are exposed to the public in the previous schemes, which may be subject to attacks on user privacy in lots of pragmatic applications. We propose a novel privacy-preserving identity-based broadcast encryption scheme against an active attacker. The proposed scheme protects the privacy of receivers of broadcasted messages by hiding the identities of receivers in S. Additionally, it achieves less storage and computation costs required to encrypt and decrypt the broadcast message, compared to the previous identity-based broadcast encryption schemes that do not provide user privacy. © 2011 Elsevier B.V. All rights reserved.","Broadcast encryption; Hidden receiver; Identity-based encryption; Privacy"
"Fusing distributional and experiential information for measuring semantic relatedness","2013","Information Fusion","10.1016/j.inffus.2012.02.001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84876901478&doi=10.1016%2fj.inffus.2012.02.001&partnerID=40&md5=49ff79d0219b7033342038625bc306ac","Models of semantic relatedness have usually focused on language-based distributional information without taking into account ""experiential data"" concerning the embodied sensorial source of the represented concepts. In this paper, we present an integrative cognitive model of semantic relatedness. The model - semantic family resemblance - uses a variation of the co-product as a mathematical structure that guides the fusion of distributional and experiential information. Our algorithm provides superior results in a set expansion task and a significant correlation with two benchmarks of human rated word-pair similarity datasets. © 2012 Elsevier B.V.","Cognition; Family resemblance; Interdisciplinary research; Semantic relatedness; Semantic representation; Semiotics"
"A measure of competence based on random classification for dynamic ensemble selection","2012","Information Fusion","10.1016/j.inffus.2011.03.007","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84858073995&doi=10.1016%2fj.inffus.2011.03.007&partnerID=40&md5=3af0eb6f1241361b91e2e6d4787df1bc","In this paper, a measure of competence based on random classification (MCR) for classifier ensembles is presented. The measure selects dynamically (i.e. for each test example) a subset of classifiers from the ensemble that perform better than a random classifier. Therefore, weak (incompetent) classifiers that would adversely affect the performance of a classification system are eliminated. When all classifiers in the ensemble are evaluated as incompetent, the classification accuracy of the system can be increased by using the random classifier instead. Theoretical justification for using the measure with the majority voting rule is given. Two MCR based systems were developed and their performance was compared against six multiple classifier systems using data sets taken from the UCI Machine Learning Repository and Ludmila Kuncheva Collection. The systems developed had typically the highest classification accuracies regardless of the ensemble type used (homogeneous or heterogeneous). © 2010 Elsevier B.V. All rights reserved.","Competence measure; Dynamic ensemble selection; Multiple classifier system; Random classification"
"Integrating generic sensor fusion algorithms with sound state representations through encapsulation of manifolds","2013","Information Fusion","10.1016/j.inffus.2011.08.003","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84867331149&doi=10.1016%2fj.inffus.2011.08.003&partnerID=40&md5=1520b8e9062d6a01dba0b45489dff6b7","Common estimation algorithms, such as least squares estimation or the Kalman filter, operate on a state in a state space S that is represented as a real-valued vector. However, for many quantities, most notably orientations in 3D, S is not a vector space, but a so-called manifold, i.e. it behaves like a vector space locally but has a more complex global topological structure. For integrating these quantities, several ad hoc approaches have been proposed. Here, we present a principled solution to this problem where the structure of the manifold S is encapsulated by two operators, state displacement: S× Rn→S and its inverse:S×S→ Rn. These operators provide a local vector-space view δ x δ around a given state x. Generic estimation algorithms can then work on the manifold S mainly by replacing +/- with / where appropriate. We analyze these operators axiomatically, and demonstrate their use in least-squares estimation and the Unscented Kalman Filter. Moreover, we exploit the idea of encapsulation from a software engineering perspective in the Manifold Toolkit, where the / operators mediate between a ""flat-vector"" view for the generic algorithm and a ""named-members"" view for the problem specific functions. © 2011 Elsevier B.V. All rights reserved.","3D orientation; Boxplus-method; Estimation; Least squares; Manifold; Manifold toolkit; Unscented Kalman Filter"
