{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Classify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# df = pd.read_excel('../data/Elsevier-CS/Texts_3000.xlsx')\n",
    "df = pd.read_excel('../data/Elsevier-LIS/Texts.xlsx')\n",
    "ats = df['Abstract'].tolist()\n",
    "hts = df['Highlights'].tolist()\n",
    "links = df['Pii'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of sentence  highlight:10991  abstract:25215\n"
     ]
    }
   ],
   "source": [
    "ht_sens, at_sens = [], []\n",
    "ht_links, at_links = [], []\n",
    "\n",
    "for i, at in enumerate(ats):\n",
    "    at_sens.extend(at.split('.'))\n",
    "    at_links.extend([links[i]]*len(at.split('.')))\n",
    "    ht_sens.extend(hts[i].split(';'))\n",
    "    ht_links.extend([links[i]]*len(hts[i].split(';')))\n",
    "\n",
    "print(\"The number of sentence  highlight:{}  abstract:{}\".format(len(ht_sens), len(at_sens)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from configparser import ConfigParser, ExtendedInterpolation\n",
    "from typing import Dict, Any\n",
    "\n",
    "def load_config(config_file: str) ->dict:\n",
    "    config = ConfigParser(interpolation=ExtendedInterpolation())\n",
    "    config.optionxform = lambda option: option\n",
    "    config.read(config_file)\n",
    "\n",
    "    config_dct: Dict[str, Dict] = dict()\n",
    "    for section in config.sections():\n",
    "        tmp_dct: Dict[str, Any] = dict()\n",
    "\n",
    "        for key, value in config.items(section):\n",
    "            if value == '':\n",
    "                tmp_dct[key] = None\n",
    "                continue\n",
    "            try:\n",
    "                tmp_dct[key] = eval(value)\n",
    "            except NameError:\n",
    "                print(\"Note the configuration file format\")\n",
    "        \n",
    "        config_dct[section] = tmp_dct\n",
    "\n",
    "    return config_dct\n",
    "\n",
    "config = load_config('prompt.ini')\n",
    "\n",
    "prefix = config['prompt']['template_1'] + config['prompt']['label_desc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key = 'sk-lvLL8tKYmNPZPJaJ00Ce9b9165A9482f9b43625c3a9cC67a',\n",
    "    base_url = 'https://api.gpt.ge/v1'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from langchain_core.prompts import FewShotPromptTemplate, PromptTemplate\n",
    "\n",
    "jis_example = pd.read_excel('SentenceLabel/label_example.xlsx')\n",
    "texts = jis_example['Text'].tolist()\n",
    "labels = jis_example['Label'].tolist()\n",
    "\n",
    "examples = []\n",
    "\n",
    "for i, text in enumerate(texts):\n",
    "    example = {}\n",
    "    example['input'] = text\n",
    "    example['output'] = labels[i]\n",
    "    examples.append(example)\n",
    "\n",
    "example_formatter_template = \"\"\"\n",
    "input:{input}\n",
    "output:{output}\n",
    "\"\"\"\n",
    "\n",
    "example_prompt = PromptTemplate(\n",
    "    input_variables= ['input','output'],\n",
    "    template = example_formatter_template\n",
    ")\n",
    "\n",
    "suffix = '\\ninput:'\n",
    "\n",
    "few_shot_prompt = FewShotPromptTemplate(\n",
    "    examples = examples,\n",
    "    example_prompt = example_prompt,\n",
    "    prefix=prefix,\n",
    "    suffix=suffix,\n",
    "    input_variables = ['input'],\n",
    "    example_separator = '\\n',\n",
    ")\n",
    "\n",
    "example_strings = [few_shot_prompt.example_prompt.format(**example) for example in examples]\n",
    "pieces = [prefix, *example_strings, suffix]\n",
    "template = ''.join([piece for piece in pieces if piece])\n",
    "# print(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'gpt-3.5-turbo-0125'\n",
    "system_message = template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13291"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pred_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:10<00:00,  1.53s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      \n",
    "\n",
    "start_pos = 11917+len(pred_labels)\n",
    "for text in tqdm(at_sens[start_pos:]):\n",
    "    completion = client.chat.completions.create(\n",
    "        model = model_name,\n",
    "        messages=[\n",
    "            {'role': 'system', 'content': system_message},\n",
    "            {'role': 'user', 'content': text+'\\noutput:'}\n",
    "        ]\n",
    "    )\n",
    "    label = completion.choices[0].message.content\n",
    "    pred_labels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df['text'] = at_sens[11917:11917+len(pred_labels)]\n",
    "df['label'] = pred_labels\n",
    "df.to_excel('SentenceLabel/LIS_A_Pred_Other.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10991\n",
      "10849\n"
     ]
    }
   ],
   "source": [
    "# 标签过滤\n",
    "import pandas as pd\n",
    "df = pd.read_excel('SentenceLabel/LIS_A_Pred.xlsx')\n",
    "labels = df['label'].tolist()\n",
    "texts = df['text'].tolist()\n",
    "\n",
    "standard_labels = ['class_1: Research and introduction',\n",
    "                   'class_2: Purpose and background',\n",
    "                   'class_3: Process and method',\n",
    "                   'class_4: Result or Conclusion',\n",
    "                   'class_5: Contribution and promotion']\n",
    "\n",
    "new_labels = []\n",
    "new_links = []\n",
    "new_texts = []\n",
    "for i, label in enumerate(labels):\n",
    "    cnt = 0\n",
    "    new_label = ''\n",
    "    if type(label) == str:\n",
    "        for standard_label in standard_labels:\n",
    "            filter_standard_label = standard_label.lower().replace('_','').replace(' ','').replace('and','')\n",
    "            filter_label = label.lower().strip().replace('_','').replace(' ','').replace('and','')\n",
    "            if filter_standard_label in filter_label:\n",
    "                new_label = standard_label\n",
    "                cnt += 1\n",
    "\n",
    "    if cnt == 1:\n",
    "        new_labels.append(new_label)\n",
    "        new_links.append(ht_links[i])\n",
    "        new_texts.append(texts[i])\n",
    "    # else:\n",
    "    #     new_labels.append(label)\n",
    "\n",
    "print(len(df))\n",
    "print(len(new_links))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df['label'] = new_labels\n",
    "df['link'] = new_links\n",
    "df['text'] = new_texts\n",
    "df = df.dropna().reset_index(drop=True)\n",
    "df.to_excel('SentenceLabel/LIS_A_Pred_Standard.xlsx', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
