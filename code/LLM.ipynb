{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "df = pd.read_excel('../data/Elsevier-LIS/Texts.xlsx')\n",
    "links = df['Pii'].tolist()\n",
    "abs = df['Abstract'].tolist()\n",
    "hts = df['Highlights'].tolist()\n",
    "\n",
    "link_to_keywords = {}\n",
    "with open('../data/Elsevier-LIS/Keywords.json', 'r') as f:\n",
    "    link_to_keywords = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = []\n",
    "\n",
    "for i, link in enumerate(links):\n",
    "    try:\n",
    "        keywords.append(link_to_keywords[link])\n",
    "    except:\n",
    "        keywords.append([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ahts, hats = [], []\n",
    "\n",
    "for i, link in enumerate(links):\n",
    "    ahts.append(abs[i] + ' ' + hts[i])\n",
    "    hats.append(hts[i] + ' ' + abs[i])\n",
    "\n",
    "keywords = list(link_to_keywords.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### GPT-3.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# api-key: sk-LUmyq6sPQ5g0Wm362329654c68Aa493aAe738018C4190661\n",
    "# api-base: 'https://api.aimd5.com/v1'\n",
    "# api-key: sk-CwIP4r9DuGSeoEpB4d1a9e762655470e8096F3Db0fB789E2\n",
    "# api-base: 'https://scornful-kit-abcd1256.koyeb.app'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "\n",
    "client = OpenAI(\n",
    "   api_key = 'sk-f2Ojy8n1PhauagN53971475f4e10456288Ad91544d5c3a15',\n",
    "   base_url = 'https://burn.hair/v1' \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords_pred = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1442/1442 [47:56<00:00,  1.99s/it]  \n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "start_pos = len(keywords_pred)\n",
    "for i, text in enumerate(tqdm(hts[start_pos:])):\n",
    "    completion = client.chat.completions.create(\n",
    "        model = 'gpt-3.5-turbo-1106',\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": \"You are an expert in the academic field of computer science\"},\n",
    "            {\"role\": \"user\", \"content\": \"Based on the text below, give the keyword set of the paper in which it is located, sort the results from high to low importance, and separate the results with commas. Note that only the results are given without any additional explanations.\"+text}\n",
    "        ]            \n",
    "    )\n",
    "    \n",
    "    keyword_pred = completion.choices[0].message.content\n",
    "    keywords_pred.append(keyword_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.DataFrame()\n",
    "new_df['Keywords'] = keywords_pred\n",
    "new_df.to_excel('LLM_Pred/Elsevier-CS-GPT-H.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Claude3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# api-key: sk-LUmyq6sPQ5g0Wm362329654c68Aa493aAe738018C4190661\n",
    "# api-base: https://api.v3.cm\n",
    "from openai import OpenAI\n",
    "import openai\n",
    "import os\n",
    "\n",
    "openai.api_key = 'sk-bvnuW6ca0HXnslYBF4De808c61Dd4241847bA21603051231'\n",
    "openai.base_url = 'https://api.v3.cm/v1/'\n",
    "openai.default_headers = {\n",
    "    \"x-foo\":\"true\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords_pred = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2996"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(keywords_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 680/680 [33:45<00:00,  2.98s/it]  \n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "pos = len(keywords_pred)\n",
    "for i, text in enumerate(tqdm(abs[pos:])):\n",
    "    completion = openai.chat.completions.create(\n",
    "        model = 'claude-3-sonnet-20240229',\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": \"You are an expert in the academic field of computer science\"},\n",
    "            {\"role\": \"user\", \"content\": \"Based on the text below, give the keyword set of the paper in which it is located, sort the results from high to low importance, and separate the results with commas. Note that only the results are given without any additional explanations.\"+text}\n",
    "        ]            \n",
    "    )\n",
    "\n",
    "    keyword_pred = completion.choices[0].message.content\n",
    "    keywords_pred.append(keyword_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.DataFrame()\n",
    "new_df['Keywords'] = keywords_pred\n",
    "new_df.to_excel('LLM_Pred/Elsevier-CS-Claude-A.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "new_df = pd.read_excel('LLM_Pred/Elsevier-LIS-GPT-AH.xlsx')\n",
    "raw_pred_keywords = new_df['Keywords'].tolist()\n",
    "pred_keywords = []\n",
    "regex = r'\\d. '\n",
    "for elem in raw_pred_keywords:\n",
    "    keyword = []\n",
    "    if ':' in elem:\n",
    "        pos = elem.rindex(':')\n",
    "        elem = elem[pos+1:]\n",
    "        if ',' in elem:\n",
    "            keyword = elem.split(',')\n",
    "        elif '\\n' in elem:\n",
    "            keyword = elem.split('\\n')\n",
    "    if ':' not in elem:\n",
    "        if ',' in elem:\n",
    "            keyword = elem.split(',')\n",
    "        elif '\\n' in elem:\n",
    "            keyword = elem.split('\\n')\n",
    "\n",
    "    new_keyword = []\n",
    "    for i, word in enumerate(keyword):\n",
    "        word = word.strip()\n",
    "        if len(word.split(' ')) >=5:\n",
    "            continue\n",
    "        if '- ' in word:\n",
    "            pos = word.index(' ')\n",
    "            word = word[pos+1:]\n",
    "        elif re.search(regex, word):\n",
    "            pos = re.search(regex, word).span()[1]\n",
    "            word = word[pos:]\n",
    "\n",
    "        if word != '':\n",
    "            if word[-1] == '.':\n",
    "                new_keyword.append(word[:-1])\n",
    "            else:\n",
    "                new_keyword.append(word)\n",
    "\n",
    "    keyword = [word.strip() for word in new_keyword]\n",
    "    pred_keywords.append(keyword)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "porter = nltk.PorterStemmer()\n",
    "\n",
    "def stemmer(raw_sequences):\n",
    "    stemmed_sequences = []\n",
    "\n",
    "    for i, words in enumerate(raw_sequences):\n",
    "        new_words = []\n",
    "        for word in words:\n",
    "            if type(word) == list:\n",
    "                # for h_candidates and a_candidates\n",
    "                word = word[0]\n",
    "            items = word.split()\n",
    "            new_word = ' '.join(porter.stem(item) for item in items)\n",
    "            new_words.append(new_word.strip())\n",
    "        stemmed_sequences.append(new_words)\n",
    "    \n",
    "    return stemmed_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "class Logger(object):\n",
    "\n",
    "    def __init__(self, filename, level='info'):\n",
    "        level = logging.INFO if level == 'info' else logging.DEBUG\n",
    "        self.logger = logging.getLogger(filename)\n",
    "        self.logger.propagate = False\n",
    "        self.logger.setLevel(level)  #\n",
    "\n",
    "        th = logging.FileHandler(filename, 'a')\n",
    "\n",
    "        self.logger.addHandler(th)\n",
    "\n",
    "log = Logger('LLM_Pred/Elsevier-LIS.log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calPRF(num_c, num_e, num_s):\n",
    "    F1 = 0.0\n",
    "    P = float(num_c) / float(num_e) if num_e!=0 else 0.0\n",
    "    R = float(num_c) / float(num_s) if num_s!=0 else 0.0\n",
    "    if (P + R == 0.0):\n",
    "        F1 = 0\n",
    "    else:\n",
    "        F1 = 2 * P * R / (P + R)\n",
    "    return P, R, F1\n",
    "\n",
    "def getPRF(references, predictions, log):\n",
    "    num_c_5, num_c_10, num_c_15 = 0, 0, 0\n",
    "    num_e_5, num_e_10, num_e_15 = 0, 0, 0\n",
    "    num_s = 0\n",
    "    for i  in range(len(references)):\n",
    "        reference = references[i]\n",
    "        prediction = predictions[i]\n",
    "        j = 0\n",
    "        for candidate in prediction[:15]:\n",
    "            if candidate in reference:\n",
    "                if j<5:\n",
    "                    num_c_5 += 1\n",
    "                    num_c_10 += 1\n",
    "                    num_c_15 += 1\n",
    "                elif (j<10 and j>=5):\n",
    "                    num_c_10 += 1\n",
    "                    num_c_15 += 1\n",
    "                elif (j<15 and j>=10):\n",
    "                    num_c_15 += 1\n",
    "            j += 1\n",
    "        \n",
    "        if len(prediction[0:5]) == 5:\n",
    "            num_e_5 += 5\n",
    "        else:\n",
    "            num_e_5 += len(prediction[0:5])\n",
    "        \n",
    "        if len(prediction[0:10]) == 10:\n",
    "            num_e_10 += 10\n",
    "        else:\n",
    "            num_e_10 += len(prediction[0:10])\n",
    "        \n",
    "        if len(prediction[0:15]) == 15:\n",
    "            num_e_15 += 15\n",
    "        else:\n",
    "            num_e_15 += len(prediction[0:15])\n",
    "\n",
    "        num_s += len(reference)\n",
    "    \n",
    "    P, R, F1 = calPRF(num_c_5, num_e_5, num_s)\n",
    "    log.logger.info(\"P@5:{} R@5:{} F1@5:{}\".format(P,R,F1))\n",
    "    P, R, F1 = calPRF(num_c_10, num_e_10, num_s)\n",
    "    log.logger.info(\"P@10:{} R@10:{} F1@10:{}\".format(P,R,F1))\n",
    "    P, R, F1 = calPRF(num_c_15, num_e_15, num_s)\n",
    "    log.logger.info(\"P@15:{} R@15:{} F1@15:{}\".format(P,R,F1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_standards_stem = stemmer(keywords)\n",
    "pred_candidates_stem = stemmer(pred_keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "log.logger.info('GPT-AH')\n",
    "getPRF(gold_standards_stem, pred_candidates_stem, log)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
